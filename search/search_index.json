{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Polkadot Wiki","text":"<p>The Polkadot Wiki is a high-level technical documentation about the Polkadot Ecosystem. Use the cards below to explore and learn more about Polkadot.</p> <p>Explore</p> <p>       Explore Wallets, Applications and Programmes within the Polkadot Ecosystem.     </p> <p>Learn</p> <p>       Learn about Polkadot and how it provides Shared Security and Secure Interoperability to its Parachains.     </p> <p>Build</p> <p>       Most up-to-date Information on the Status of Development Tools in the Polkadot Ecosystem.     </p> <p>Maintain</p> <p>       Information and Guides on how to Deploy a Node and Run the Network.     </p>"},{"location":"build/","title":"Builder's Guides","text":"<p>Welcome to the builder's section of the Polkadot Wiki.</p> <p>Here, you will discover many development tools and resources in the Polkadot ecosystem. We are always adding new tools and frameworks as we learn about them, so if you are working on something that should be included, please reach out to us on Element.</p>"},{"location":"build/#development-guide","title":"Development Guide","text":"<ul> <li>Starter's Guide - High-level overview on choosing a parachain or smart contract   for your project and how to get started.</li> <li>Parachain Development - Tools for building parachains.</li> <li>Smart Contracts - Tools to deploy contracts to a parachain.</li> </ul>"},{"location":"build/#tools-resources","title":"Tools &amp; Resources","text":"<ul> <li>Tools - Maintained list of tools.</li> <li>Subkey - Command line utility   for generating and inspecting key pairs.</li> <li>JS tools - TypeScript tools for offline signing of   transactions, RPC calls, and more.</li> <li>Examples - Example projects sourced from the community -- see what others   are building.</li> </ul>"},{"location":"build/#grants","title":"Grants","text":"<ul> <li>Grants - Information regarding grants and funding sources available in the   Polkadot ecosystem.</li> </ul>"},{"location":"build/#pcps","title":"PCPs","text":"<p>Polkadot Contracts Proposals (PCPs) are standards for smart contracts in the Polkadot ecosystem.</p> <ul> <li>PCP GitHub Repository - Read, create, or discuss standards and   proposals.</li> </ul>"},{"location":"build/#hackathon","title":"Hackathon","text":"<ul> <li>Resources For Running a Hackathon</li> </ul>"},{"location":"build/build-client-side/","title":"Building Client-side Apps","text":"<p>As with any blockchain, building decentralized applications (dApps) is a significant part of how a developer can build on Polkadot.</p> <p>As an application developer, you can compose your front-end apps in a few different ways. Because the relay chain and its parachains are all built using the Polkadot SDK. You can often use the same SDK to communicate with the relay chain, a parachain, or any other Substrate-based chain.</p> <p>Substrate-based chains use an SS58 encoding for their address formats.</p> <p>Please see the SS58 registry to see which chain corresponds to a given prefix, and which prefixes are available.</p>"},{"location":"build/build-client-side/#sdks-libraries","title":"SDKS &amp; Libraries","text":"<p>If one aims to develop a dApp (Decentralized App), the Polkadot ecosystem contains various SDKs to tap into the relay chain and parachains. There are several languages already supported - see the tooling page for a detailed overview of different SDKs and libraries that are available.</p>"},{"location":"build/build-client-side/#frameworks-toolkits","title":"Frameworks &amp; Toolkits","text":"<p>For front-end applications, several options exist for interfacing with Substrate-based chains (parachains, relay chains, etc.) and smart contracts. These will often interact with the RPC of a Substrate node:</p> Polkadot.jsPolkadot API (PAPI)Reactive DOTSubxtReact Hooks for ink!ink!athon BoilerplatePolkadot Cloud <p>Promise and RxJS APIs around Polkadot, Kusama, and other Substrate-based chains via RPC calls. It is dynamically generated based on what the Substrate runtime provides regarding metadata. Full documentation &amp; examples available\u00a0here.</p> <p>Polkadot-API will serve as a replacement for Polkadot JS. Full documentation &amp; examples available\u00a0here.</p> <p>A reactive library for building Substrate front-ends. Full documentation &amp; examples available\u00a0here.</p> <p>Query and submit extrinsics (transactions) to a Substrate node via RPC using Rust. Also referred to as Rust Parity. Full documentation &amp; examples available\u00a0here.</p> <p>React hooks library for ink! smart contracts that abstract the functionality of polkadot.js. Full documentation &amp; examples available\u00a0here.</p> <p>ink!athon is a starter kit for full-stack dApp development with ink! smart contracts and a React-based frontend in one place. With convenient helper scripts and a pre-configured project setup, you can quickly scaffold any dApp. Live example &amp; full documentation available\u00a0here.</p> <p>Polkadot Cloud hosts a library of assets, ranging from data sources, graphical elements, to fully functional components, for app developers to plug and play into their codebases. \u00a0Learn more here.</p>"},{"location":"build/build-client-side/#oracle-options","title":"Oracle Options","text":"<p>In the blockchain context, an oracle is a way to bring real-world data onto the blockchain so that it can be used by a decentralized application.</p> <p>Oracles serve many purposes for application builder, as they allow for outside data (price feeds, the ability to make HTTP requests, etc) to enter the decentralized world.</p> <p>Oracle solutions range from centralized and trusted to decentralized and game-theory based. On the centralized end of the spectrum, an oracle could be a single account that has the authority to dictate the real-world data on-chain. On the decentralized end, a complex game of \"chicken\" can be played among various staked actors who risk getting slashed if they don't submit the same data as everyone else.</p> ChainlinkAcurast <p>Solutions such as Chainlink fit somewhere in the middle, where the amount of trust you put into the reporting oracles can be adjusted based on your preferences. A Chainlink Feed Pallet is available to allow smart contracts across smart contract-enabled parachains to access price reference data and is available as a Substrate oracle pallet.</p> <p>Solutions such as Acurast enables developers to delegate oracle requests to their network of phones, which provide off-chain data and computation to the Acurast Pallet. Acurast supports both Substrate (WASM) and EVM environments.</p> <p>When using an oracle in your application you should be aware of the benefits and risks that are baked into its specific model.</p>"},{"location":"build/build-client-side/#decentralized-storage-options","title":"Decentralized Storage Options","text":"<p>Storage is an integral part of modern computer systems, and the same is true for distributed and decentralized systems like a blockchain. When interacting with the Polkadot ecosystem, it will be helpful if you familiarize yourself with the current Web3 approach towards decentralized storage.</p>"},{"location":"build/build-client-side/#dcs-decentralized-cloud-storage","title":"DCS (Decentralized Cloud Storage)","text":"<p>The key attribute that characterizes centralized cloud storage is the location of data. In decentralized cloud storage, the key attribute becomes the data itself instead of the data's location. This can be viewed as the shift from the centralized location-centric storage approach to the decentralized content-centric approach.</p> IPFS (Interplanetary File System)Crust StorageFilebase <p>IPFS is a peer-to-peer distributed file system that seeks to connect all computing devices with the same system of files, by utilizing features such as content-addressing, content-signing, and enhanced security methods through encryption. IPFS aims to address the current hurdles of the HTTP-based Internet.</p> <p>Crust Network provides a Web3.0 decentralized storage network for the Metaverse. It is designed to realize core values of decentralization, privacy, and assurance. Crust supports multiple storage-layer protocols such as IPFS, and exposes instant accessible on-chain storage functions to users. Crust\u02bcs technical stack is also capable of supporting data manipulating and computing.</p> <p>Crust provides a native cross-chain communication pallet based on XCMP, called xStorage.</p> <p>The protocol also supports most smart contract platforms, including Ethereum, with its cross-chain dStorage solution.</p> <p>To learn more about Crust, check out the Crust Network Wiki. Try integrating with Crust by following their Crust Storage 101 guide.</p> <p>Filebase is the first S3-compatible object storage platform that allows you to store data in a secure, redundant, and performant manner across multiple decentralized storage networks.</p> <p>Filebase offers a geo-redundant IPFS pinning service that allows you to pin files to IPFS across multiple diverse geographic locations. All files uploaded to IPFS through Filebase are automatically pinned to the Filebase infrastructure with 3x replication across the globe. This ensures that your data is globally available and redundant at all times.</p> <p>Filebase acts as an easy on-ramp to IPFS and decentralized storage by offering a user-friendly web console dashboard, making drag-and-dropping files onto Web3 simple and easy. Filebase also provides an S3-compatible API for widespread integrations and configurations in current workflows.</p> <p>To learn more about Filebase, check out the Filebase Documentation, and specifically the documentation on deploying Polkadot dApp on decentralized storage. You can get started with Filebase by signing up here.</p>"},{"location":"build/build-dapp/","title":"Building dApps","text":"<p>As with any blockchain, building decentralized applications (dApps) is a huge part of how a developer can build on Polkadot.</p> <p>As an application developer, you can compose your front-end apps in a few different ways. Because Polkadot and its parachains are all built using Substraste; you can often use the same SDK to communicate with Polkadot, a parachain, or any other Substrate-based chain.</p> <p>Substrate-based chains use an SS58 encoding for their address formats.</p> <p>Please see the SS58 registry to see which chain corresponds to a given prefix, and which prefixes are available.</p>"},{"location":"build/build-dapp/#sdks-libraries","title":"SDKS &amp; Libraries","text":"<p>If one aims to develop a dApp (Decentralized App), the Polkadot ecosystem contains various SDKs to tap into the relay chain and parachains. There are several languages already supported - see the tooling page for a detailed overview of different SDKs and libraries that are available.</p>"},{"location":"build/build-dapp/#frameworks-toolkits","title":"Frameworks &amp; Toolkits","text":"<p>For front-end applications, several options exist for interfacing with Substrate-based chains (parachains, relay chains, etc.) and smart contracts. These often will interact with the RPC of a Substrate node:</p> Polkadot.jsPolkadot-APIReactive DOTSubxtReact Hooks for ink!ink!athon BoilerplatePolkadot Cloud <p>Promise and RxJS APIs around Polkadot and Substrate-based chains via RPC calls. It is dynamically generated based on what the Substrate runtime provides regarding metadata. Full documentation &amp; examples available here.</p> <p>Polkadot-API will serve as a replacement for Polkadot JS. Full documentation &amp; examples available here.</p> <p>A reactive library for building Substrate front-ends. Full documentation &amp; examples available here.</p> <p>Query and submit extrinsics (transactions) to a Substrate node via RPC using Rust. Also referred to as Rust Parity. Full documentation &amp; examples available here.</p> <p>React hooks library for ink! smart contracts that abstract the functionality of Polkadot-JS. Full documentation &amp; examples available here.</p> <p>ink!athon is a starter kit for full-stack dApp development with ink! smart contracts and a React-based frontend in one place. With convenient helper scripts and a pre-configured project setup, you can quickly scaffold any dApp. Live example &amp; full documentation available here.</p> <p>Polkadot Cloud hosts a library of assets, ranging from data sources, graphical elements, to fully functional components, for app developers to plug and play into their codebases. Learn more here</p>"},{"location":"build/build-data/","title":"Explorer, Data, & Indexing Tools","text":"<p>The tools that accentuate and aggregate the data within blockchains are integral for a multi-chain future. Parachains will need robust and secure ways to index and aggregate data, such as a data aggregation layer.</p>"},{"location":"build/build-data/#custom-indexer","title":"Custom Indexer","text":""},{"location":"build/build-data/#sqd","title":"SQD","text":"<p>SQD is an open-source framework for building tailored GraphQL APIs to query Substrate chain state and history.</p> <p>SQD replaces direct gRPC node access with performant Squid archive gateways, allowing quick synchronization of the API with the historical on-chain data.</p> <p>SQD-powered APIs support filtering, pagination, union types, interfaces, and full-text search out-of-the-box, and can be further extended with custom GraphQL resolvers.</p>"},{"location":"build/build-data/#subquery","title":"SubQuery","text":"<p>SubQuery is a fast, flexible, and reliable open-source data indexer that provides you with custom APIs for your Substrate/Polkadot project. We build the best, fully-featured indexer, so you don\u2019t have to, with:</p> <ul> <li>automatic support for any Substrate network</li> <li>support for all Polkadot smart contract frameworks (FrontierEVM, Acala EVM+, and Wasm)</li> <li>automated historical state tracking to enable faster partial re-indexing</li> <li>a lightweight and portable design that doesn't require centralized archives</li> <li>full support for GraphQL filtering, pagination, interfaces, subscriptions, and aggregations</li> <li>a future decentralized network acts as chain-agnostic data aggregation, indexing, and querying   layer between blockchains and applications that will not require centralized services.</li> </ul> <p>To start building, head to the SubQuery documentation where you'll find quick start guides and walkthrough developer tutorials.</p>"},{"location":"build/build-data/#traceye","title":"Traceye","text":"<p>Traceye is a data indexing solution for Web3. Diverse range L1/L2 blockchains, rollups, appchains, and Dapps can leverage Traceye to build and deploy their custom data indexers optimized for fast indexing, 50% reduced data lag, 99.99% uptime, automated sync, and 24/7 monitoring. Traceye also offers value-added features like webhooks, BI analytics tools, custom entities, community subgraphs, and more to suit developers\u2019 needs.</p>"},{"location":"build/build-data/#analytics-platform","title":"Analytics platform","text":""},{"location":"build/build-data/#covalent","title":"Covalent","text":"<p>Covalent offers a unified API to understand the data on a blockchain, and is currently live on the Moonbeam network, bringing visibility to billions of blockchain data points to Polkadot via their unified API. The approach to deploying on Moonbeam simplifies the development of Polkadot-based blockchain applications as compared to implementing a full parachain or an on-demand parachain.</p> <p>Covalent captures the entire history of blockchains and offers a way to zoom into data points recorded in smart contracts that are often not accessible.</p>"},{"location":"build/build-data/#data-warehouse","title":"Data warehouse","text":""},{"location":"build/build-data/#bigquery-by-google-cloud","title":"BigQuery by Google Cloud","text":"<p>BigQuery makes Polkadot blockchain data available for Google Cloud users. Check this announcement for details on how to access the data.</p>"},{"location":"build/build-data/#block-explorers","title":"Block Explorers","text":"<p>As you can imagine, blockchain explorers also offer data analytics through an interface where users can examine common data points.</p> <p>Some block explorers in the Polkadot ecosystem are listed on the tools page.</p>"},{"location":"build/build-guide/","title":"Polkadot Developer Portal","text":"<p>Polkadot is a blockchain network protocol that provides shared security among all connected parachains and allowing all connected tasks to interoperate by using XCM.</p> <p>With the Polkadot SDK and Agile Coretime, the time it takes to develop and launch a new chain has dropped significantly. Depending on your goals, it may only take weeks or even days.</p> <p>This starters guide will walk you through the steps you can take today to get started building your vision with Polkadot. It will also point to resources you can use to start building immediately.</p> <p>!!!note For Developers!     Please note that the following documentation is more geared towards developers. If you are looking     for more general knowledge related to Polkadot, be sure to check out the     Learn section.</p> <p>This build guide covers three different areas, taking a top-down approach from protocol development to user-facing applications:</p> <ol> <li>Runtime Development - Developing parachains/blockchains</li> <li>Smart Contract Development - How Polkadot handles smart contracts</li> <li>dApp Development - The tools available for dApp development on Polkadot</li> </ol> <p>Keep reading to find out more, or explore each respective area</p> <p>Keep in mind that these areas are merely suggestive, and there are many ways to utilize Polkadot, Substrate, and their various developmental components. For more inspiration, look at the open source projects featured here in the wiki!</p>"},{"location":"build/build-guide/#development-ecosystem-overview","title":"Development Ecosystem Overview","text":"<pre><code>%%{\n init: {\n 'theme': 'base',\n 'themeVariables': {\n 'fontFamily': 'Unbounded',\n 'primaryColor': '#E6007A',\n 'fontSize': '16px',\n 'primaryTextColor': '#fff',\n 'primaryBorderColor': '#7C0000',\n 'lineColor': '#140523',\n 'secondaryColor': '#552BBF',\n 'tertiaryColor': '#fff'\n }\n }\n}%%\nflowchart TB\n subgraph PL [\"Protocol Land (Parachains, Smart Contracts)\"]\n\n subgraph SCD [\"Smart Contract Development\"]\n direction LR\n SC[\"Use Smart Contract Parachain\"]\n SC --&gt; ink!\n SC --&gt; Solidity\n end\n\n subgraph PSL [\"Blockchain Development\"]\n direction LR\n PS[\"Polkadot SDK\"] --&gt; R[WASM Runtime - Substrate &amp; FRAME]\n R --&gt;Parachain[\"Parachain/Task\"]--&gt;SSC[\"Shared Security - Cumulus\"]\n R --&gt;SoloChain[Solo Chain]--&gt;NSS[\"No Shared Security\"]\n end\n end\n\n PL--&gt;| Develop apps| CS\n\n subgraph CS [\"Client/User Land (dApps/uApps)\"]\n LC[\"Light Clients (Smoldot)\"]\n UA[uApp]\n ReDot[Reactive DOT]\n UA --&gt; PAPI[Polkadot-API]\n UA --&gt; ReDot\n ReDot --&gt; PAPI[Polkadot API]\n UA --&gt; PJS[Polkadot JS]\n UA --&gt; SubXT\n PAPI --&gt; LC\n PJS --&gt; LC\n SubXT --&gt; LC\n end</code></pre> <p>Before diving into the various paths one can take in developing on Polkadot, it's essential to realize and know key terms that make up the following sections. Even before considering what kind of application you want to build, it's prudent to understand what Polkadot is, and what each developmental component can do for you within the Polkadot ecosystem.</p> <p>Before diving into any one of these tracks, it is encouraged to read about Polkadot and its networks in order to gain context about the application you could make.</p> <p>Take a look at the various development network options here.</p>"},{"location":"build/build-guide/#building-parachains","title":"Building Parachains","text":"<p>Polkadot is canonically referred to as the relay chain. It is also considered a layer zero protocol, as it enables the interoperability and shared security of multiple parachains, which are layer one protocols. Parachains currently connect to a relay chain using the Parachains Protocol. More elaborate (or simpler) tasks could be constructed in the future.</p> <p></p> <p>Info</p> <p>Throughout this document, you may encounter the term runtime or STF (State Transition Function). Both refer to the same concept, as they define how a particular system, i.e., a blockchain, should deal with state changes externally and internally. Both of these terms are used extensively in Polkadot and Substrate.</p> <p>Parachains built through the Polkadot SDK, open possibilities to construct complex runtime, or STF (state transition function) the logic that would be too expensive to execute with smart contracts. However, unlike smart contracts, parachains lack a mandatory gas metering system entirely and could potentially be vulnerable to bugs that cause infinite loops (something that is prevented by design in smart contracts). This vulnerability is mitigated by the weight system that is implemented in Substrate -- although it places more of a burden on the developer of the parachain to perform properly benchmarks.</p> <p>What is an on-demand parachain?</p> <p>On-demand parachains use a \"pay-as-you-go\" model enabled by Agile Coretime to interact with the relay chain. On-demand parachains will only produce a block when needed, unlike full parachains, which have access to bulk coretime to produce a block at every block of the relay chain. When building an on-demand parachain, you will use the same tools (like PDKs) and get all the benefits of building a parachain without the cost drawback of purchasing bulk coretime.</p>"},{"location":"build/build-guide/#polkadot-sdk-overview","title":"Polkadot SDK Overview","text":"<p>Polkadot is built using the Polkadot SDK, which, the Polkadot node/host implementation, within contains the source code for:</p> <ul> <li>Substrate - a set of core libraries used for constructing blockchains - mostly un-opinionated</li> <li>FRAME - the framework used to build Substrate runtimes - more opinionated</li> <li>Cumulus - parachain/task specific functions which allow for solo chains to become compatible   with Polkadot</li> </ul> <p>Substrate is a highly configurable and dynamic framework for building blockchains. At a lower level, Substrate provides a set of tools and libraries ranging from block production, finality gadgets to peer-to-peer networking. Both Polkadot and Kusama, as well as most parachains, are built using Substrate.</p> <p>In essence, Substrate can break down a blockchain's development process by providing crucial building blocks of functionality, removing the need for re-engineering complex mechanisms that usually involved when developing a blockchain.</p> <p>Substrate can be used as a basis for a parachain to connect to a relay chain like Polkadot or Kusama, or even as a basis to form a conventional layer one solo chain.</p> <p>Currently, the most streamlined way of utilizing Substrate is through FRAME, which conveniently allows for a runtime/STF to be generated from a set of modules (called pallets). Runtimes in Substrate are built using WebAssembly (Wasm), and represent the state transition function for a network. FRAME provides a framework for pallets, to construct a runtime/STF and define how your task is supposed to behave. Ranging from identity to smart contracts, pallets can be quite extensive in providing on-chain functionality.</p> <p>Even though FRAME is heavily used, it is not the only way to create a valid runtime/STF using Substrate. Substrate can be used to create new paradigms and abstractions. One such example is the Open Runtime Module Library (ORML), which is another way of creating and using runtime modules.</p> <p>Note</p> <p>Although most parachains utilize FRAME and Substrate to build runtime/STFs for connecting to the relay chain, it is not contingent. Building a parachain using other tools is possible if they follow the Parachains Protocol.</p> <p>As a general rule of thumb, Substrate provides the means for this to become possible through comparably minimal effort.</p>"},{"location":"build/build-guide/#building-parachains-with-cumulus","title":"Building Parachains with Cumulus","text":"<p>Cumulus is a set of tools that allows you to convert a blockchain developed using Substrate and FRAME into a Polkadot-compatible Parachain. More specifically, it provides libraries for all of the necessary parts of the Polkadot protocol necessary for Parachains to work, for example:</p> <ul> <li>Creating new parachain blocks via Collators</li> <li>Listening to the relay chain for updates</li> <li>Synchronizing upgrades between the parachain and relay chain</li> </ul> <p>For most developers, the best place to start is to get familiar with Substrate independently, followed by FRAME, with Cumulus as the final step to understanding the entire parachain building process. This way, one can view how various paradigms are applied and decide on integrating or utilizing Substrate for their particular use case.</p> <p>Please see our guides on getting started with coretime for how to get started on building and deploying a parachain.</p>"},{"location":"build/build-guide/#parachains-benefits","title":"Parachains Benefits","text":"<p>Parachains contain their own runtime/STF logic and benefit from the shared security and the cross-consensus messaging provided by the relay chain. Parachains permit high flexibility and customization but require more effort to create and maintain over time. A production-grade parachain is typically more involved to create due to the complexity involved in blockchain networks' technical and economic aspects.</p> <p>Parachains grant the creators more space to build the monetary system and other chain aspects from the ground up. They will allow for a more concise and efficient execution of complex logic than a smart contract platform could offer. Parachains also provide more flexibility in the form of governance and can perform complete upgrades in a less controversial way than the current process of hard forks.</p> <p>Some examples of features you can have on a parachain:</p> <ul> <li>Custom fee structure (for example, pay a flat transaction fee or pay per byte).</li> <li>Shared security and finalization via the relay chain (Polkadot or Kusama).</li> <li>Custom monetary policy for the native token and local economy.</li> <li>Treasury to be funded through transitions in your state function.</li> <li>A governance mechanism that could manage a DAO that is responsible for allocating your on-chain   treasury.</li> </ul>"},{"location":"build/build-guide/#building-a-pallet","title":"Building a Pallet","text":"<p>While parachains are highly customizable, they are often complex to develop. If you wish to get familiar with FRAME and Substrate, a good place to start is by building a pallet in a development environment. A pallet is a fully customizable module that allows you to implement layer one logic with relatively minimal development time on a fundamental level while still allowing the possibility of building advanced functionality into your custom chain.</p>"},{"location":"build/build-guide/#developing-smart-contracts","title":"Developing Smart Contracts","text":"<p>Smart contracts are another option that enables an often simpler developer experience. Below is a quick comparison of how building a smart contract compares to building a parachain:</p> Parachains Smart Contracts Speed of Development - + Ease of Deployment - + Complexity of logic + - Maintenance overhead - + Level of customization + - Strict resource control - + Native chain features + - Scalability + - <p>!!!info What's the difference between a smart contract and a pallet?     If you recall, a parachain comprises a runtime/STF usually built on Substrate. These runtime/STFs     often utilize FRAME, which is subsequently made of pallets. Pallets are part of a Substrate     runtime/STF, whereas smart contracts are a product of a pallet (see:     pallet_contracts).     Pallets require more engineering and thought, as they can directly affect the chain's state.</p> <pre><code>For a more comprehensive (and maintained) comparison, be sure to check out the\n[comparison from the Polkadot SDK documentation](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/runtime_vs_smart_contract/index.html).\n</code></pre>"},{"location":"build/build-guide/#ink-and-evm-based-smart-contracts","title":"ink! and EVM-based Smart Contracts","text":"<p>At a high level, a smart contract is simply some code that exists at an address on a chain and is callable by external actors. Whether it's EVM-based or written using ink!, smart contracts are sandboxed, executable programs that live on-chain.</p> <p>Note</p> <p>The Polkadot relay chain does not support smart contracts. However, several parachains do. See the smart contracts guide for the exact chains in which you can deploy contracts on Polkadot.</p> <p>A Polkadot-native choice for smart contracts is ink!. Other parachains that offer EVM-based contracts written in Solidity alongside ink! are also available.</p> <p>Because smart contracts exist on a single chain at a time, they can have smooth interoperability with other smart contracts on the same chain. However, they will always be constrained and limited by the inherent characteristics of their host chain.</p> <p>As a developer, you will need to consider the storage and complexity of your smart contract to ensure that gas usage stays within reasonable bounds. Consider using the listed options on the decentralized storage page to keep the data and submit only the content address on the chain.</p> <p>Info</p> <p>Please see the smart contracts guide for how to get started on building a smart contract.</p>"},{"location":"build/build-guide/#developing-a-dapp","title":"Developing a dApp","text":"<p>If one aims to develop a dApp (Decentralized App), the Polkadot ecosystem contains various SDKs to tap into the relay chain and parachains.</p> <p>For front-end applications, several options exist for interfacing with Substrate-based chains (parachains, relay chains, etc.) and smart contracts. These often will interact with the RPC of a Substrate node.</p> <p>Please visit the documentation for developing dApps and other general client-side development resources.</p> <p>For a complete list of tools, please take a look here: Tools, APIs, and Languages</p>"},{"location":"build/build-guide/#resources","title":"Resources","text":"<ul> <li>Agile Coretime Fellowship RFC</li> <li>Polkadot Bridges</li> <li>The Path of a Parachain Block</li> <li>The Path of a Parachain Block (Parachain Protocol page)</li> <li>How to become a parachain on Polkadot (Video)</li> <li>Trusted Execution Environments and the Polkadot Ecosystem</li> </ul>"},{"location":"build/build-guides-coretime-start/","title":"Getting Started - Intro to the Polkadot SDK","text":"<p>Warning</p> <p>This section is under construction.</p>"},{"location":"build/build-guides-coretime-start/#using-the-polkadot-sdk","title":"Using the Polkadot SDK","text":"<p>The Polkadot SDK is comprised of three important repositories:</p> <ul> <li>Polkadot -   This included both client implementation and runtime until the runtime was moved to the Polkadot   Fellows organization.</li> <li>Substrate -   The underlying core primitives and libraries for building blockchains (any blockchain, not just   one for Polkadot). Much of Polkadot is built with Substrate.</li> <li>Cumulus -   A set of libraries and tools pertaining specifically to connecting blockchains to Polkadot, known   as parachains.</li> </ul> <p>For an in-depth dive into the monorepo, it is highly recommended that you look into the Polkadot SDK Docs, which explains everything.</p> <p>What is a task?</p> <p>You might see the term \"task\" referenced often in place of \"parachain\". In most cases, it refers to a process utilizing the relay chain's compute. This could be a parachain or any other computational process, provided that it adheres to the Polkadot protocol interface.</p> <p>The full definition can be found here.</p> <ol> <li>Reserving a <code>ParaId</code>, where you will upload your runtime and    genesis state.</li> <li>Compiling the runtime (written in Rust) to a WebAssembly blob,    thereby defining how your state transitions from one state to the next. This runtime is created    using the Polkadot SDK.</li> <li>Ensure your chain spec is viable and ready to be deployed as a live, working parachain.</li> <li>Generating your genesis state and wasm.</li> <li>Obtaining a core, most likely through a    Coretime marketplace.</li> <li>Assigning that core to your <code>ParaId</code>.</li> <li>Ensuring you have at least one honest, synced collator for your task</li> </ol>"},{"location":"build/build-guides-coretime-start/#deploying-on-a-core","title":"Deploying on a Core","text":"<p>Once you have your runtime and pallets developed, you will be able to deploy it on a core, which is how one utilizes the shared security of the Polkadot network. One does so by:</p> <pre><code>%%{\n init: {\n 'theme': 'base',\n 'themeVariables': {\n 'fontFamily': 'Unbounded',\n 'primaryColor': '#E6007A',\n 'fontSize': '16px',\n 'primaryTextColor': '#fff',\n 'primaryBorderColor': '#7C0000',\n 'lineColor': '#140523',\n 'secondaryColor': '#552BBF',\n 'tertiaryColor': '#fff'\n }\n }\n}%%\nflowchart TD\n    subgraph GA[\"Generate Artifacts\"]\n        direction LR\n        A[\"Creating a runtime\"]--&gt;B[\"Compiling to Wasm\"]--&gt;C[\"Generate Genesis State\"]\n    end\n\n    subgraph PC[\"Procure ParaId &amp; Core\"]\n        direction LR\n        PARAID[\"Reserve ParaId\"]\n        PARAID--&gt;D[\"Buy Bulk Coretime\"]\n        PARAID--&gt;E[\"Issue On-Demand Coretime Extrinsic\"]\n    end\n\n\n    subgraph DEP[\"Deploying\"]\n        direction LR\n        F[\"Register artifacts to ParaId\"]--&gt;assign[\"Assign Core\"]--&gt;G[\"Sync collator\"]--&gt;H[\"Begin generating blocks!\"]\n    end\n\nGA--&gt;PC\nPC--&gt;DEP</code></pre>"},{"location":"build/build-guides-coretime-start/#install-dependencies","title":"Install dependencies","text":"<p>Make sure you have everything you need for your target system here.</p> <p>Be sure you also install the <code>polkadot-parachain</code> and <code>chain-spec-builder</code> binaries, as they needed to start and run your chain!</p>"},{"location":"build/build-guides-coretime-start/#deployment-example-adder-collator","title":"Deployment Example - Adder Collator","text":"<p>Try out the above by deploying the adder collator, a straightforward \"counter\" parachain implementation.</p>"},{"location":"build/build-guides-coretime-start/#openzeppelin-templates-guides","title":"OpenZeppelin Templates &amp; Guides","text":"<p>OpenZeppelin offers a generic parachain template, which has support for:</p> <ul> <li>Proxy Pallet</li> <li>Multisig Pallet</li> <li>Governance support - a treasury, referenda (OpenGov!), and assets configuration</li> <li>Collation/Parachain Support</li> <li>XCM (Cross Consensus Messaging) Configuration and Support</li> </ul> <p>For more information, check their Substrate parachain runtime guide.</p>"},{"location":"build/build-guides-coretime-start/#polkadot-sdk-parachain-template","title":"Polkadot SDK Parachain Template","text":"<p>If you wish to the Polkadot SDK's Parachain template, please follow the Template to Core guide.</p>"},{"location":"build/build-guides-coretime-troubleshoot/","title":"Coretime Troubleshooting FAQ","text":"<p>This page aims to cover and aggregate various resources that relate to troubleshooting common problems when using the Polkadot SDK or deploying on a core.</p>"},{"location":"build/build-guides-coretime-troubleshoot/#faq-troubleshooting","title":"FAQ / Troubleshooting","text":""},{"location":"build/build-guides-coretime-troubleshoot/#why-do-i-have-to-sync-paseo-locally-cant-i-just-use-a-remote-trusted-node-and-connect-to-that","title":"Why do I have to sync Paseo locally? Can't I just use a remote, trusted node and connect to that?","text":"<p>You can remotely connect to Paseo network via the <code>--relay-chain-rpc-urls</code> flag, which can be passed to your node. Unfortunately, the caveat is you can't use this node for collation at this time - meaning if you intend on being a collator/validator for your blockchain and intend to create blocks, you need to sync the chain locally.</p>"},{"location":"build/build-guides-coretime-troubleshoot/#my-collator-is-not-producing-blocks","title":"My collator is not producing blocks","text":"<p>Check these sanity checklists:</p> <ul> <li>https://substrate.stackexchange.com/questions/178/how-can-i-get-my-parachain-to-produce-blocks-sanity-checklist</li> <li>https://substrate.stackexchange.com/questions/1394/our-parachain-doesnt-produce-blocks-checklist</li> </ul>"},{"location":"build/build-guides-coretime-troubleshoot/#i-want-to-run-more-than-one-collator-how-do-i-do-that","title":"I want to run more than one collator, how do I do that?","text":"<p>Ideally, you would want to run these on separate machines/servers, but you could as long as you ensure you can provide different RPC/WebSocket and P2P ports for each collator. You also may need to sync a separate instance of Paseo for each collator on the same machine. You also will need to choose the block production mechanism like Aura.</p>"},{"location":"build/build-guides-coretime-troubleshoot/#why-do-we-only-have-one-collator-in-the-parachain-guides-on-the-wiki-isnt-it-better-to-have-more","title":"Why do we only have one collator in the parachain guides on the Wiki? Isn't it better to have more?","text":"<p>Mostly for simplicity. If we have more than one collator, we would have to also spin it up, which would be a hassle on a single machine (it is possible though). Of course, if you had an actual network with multiple collators, it is assumed you'd have separate VPS/servers for each.</p>"},{"location":"build/build-guides-coretime-troubleshoot/#why-are-we-registering-parathreads-and-not-parachains","title":"Why are we registering parathreads and not parachains?","text":"<p>When registering a parachain on a relay chain, they are assigned a <code>ParaID</code>, and they are referred to as Parathreads till they start producing blocks. Parathreads are a bit of an outdated term now. They refer to what are now known as on-demand parachains. Although they be references in various places through PolkadotJS, docs, or other UIs, really we only have two types of parachain: on-demand parachains, and parachains which use bulk coretime.</p>"},{"location":"build/build-guides-install-deps/","title":"Install Polkadot SDK Dependencies","text":""},{"location":"build/build-guides-install-deps/#macos","title":"macOS","text":"<p>You can install Rust and set up a Substrate development environment on Apple macOS computers with either Intel or an Apple M1 processors.</p>"},{"location":"build/build-guides-install-deps/#before-you-begin","title":"Before you begin","text":"<p>Before you install Rust and set up your development environment on macOS, verify that your computer meets the following basic requirements:</p> <ul> <li>Operating system version is 10.7 Lion, or later.</li> <li>Processor speed of at least 2Ghz, 3Ghz recommended.</li> <li>Memory of at least 8 GB RAM, 16 GB recommended.</li> <li>Storage of at 10 GB available space.</li> <li>Broadband Internet connection.</li> </ul>"},{"location":"build/build-guides-install-deps/#support-for-apple-silicon","title":"Support for Apple Silicon","text":"<p>Protobuf must be installed before the build process can begin. To install it, run the following command:</p> <p><code>brew install protobuf</code></p>"},{"location":"build/build-guides-install-deps/#install-homebrew","title":"Install Homebrew","text":"<p>In most cases, you should use Homebrew to install and manage packages on macOS computers. If you don't already have Homebrew installed on your local computer, you should download and install it before continuing.</p> <p>To install Homebrew:</p> <ol> <li> <p>Open the Terminal application.</p> </li> <li> <p>Download and install Homebrew by running the following command:</p> </li> </ol> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n</code></pre> <ol> <li>Verify Homebrew has been successfully installed by running the following command:</li> </ol> <pre><code>brew --version\n</code></pre> <p>The command displays output similar to the following:</p> <pre><code>Homebrew 3.3.1\nHomebrew/homebrew-core (git revision c6c488fbc0f; last commit 2021-10-30)\nHomebrew/homebrew-cask (git revision 66bab33b26; last commit 2021-10-30)\n</code></pre>"},{"location":"build/build-guides-install-deps/#installation","title":"Installation","text":"<p>Because the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as <code>openssl</code>.</p> <p>To install <code>openssl</code> and the Rust toolchain on macOS:</p> <ol> <li> <p>Open the Terminal application.</p> </li> <li> <p>Ensure you have an updated version of Homebrew by running the following command:</p> </li> </ol> <pre><code>brew update\n</code></pre> <ol> <li>Install the <code>openssl</code> package by running the following command:</li> </ol> <pre><code>brew install openssl\n</code></pre> <ol> <li>Download the <code>rustup</code> installation program and use it to install Rust by running the following    command:</li> </ol> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre> <ol> <li> <p>Follow the prompts displayed to proceed with a default installation.</p> </li> <li> <p>Update your current shell to include Cargo by running the following command:</p> </li> </ol> <pre><code>source ~/.cargo/env\n</code></pre> <ol> <li>Configure the Rust toolchain to default to the latest stable version by running the following    commands:</li> </ol> <pre><code>rustup default stable\nrustup update\nrustup target add wasm32-unknown-unknown\n</code></pre> <ol> <li>Add the <code>nightly</code> release and the <code>nightly</code> WebAssembly (wasm) targets to your development    environment by running the following commands:</li> </ol> <pre><code>rustup update nightly\nrustup target add wasm32-unknown-unknown --toolchain nightly\n</code></pre> <ol> <li> <p>Verify your installation here.</p> </li> <li> <p>Install <code>cmake</code> using the following command:</p> </li> </ol> <pre><code>brew install cmake\n</code></pre>"},{"location":"build/build-guides-install-deps/#linux","title":"Linux","text":"<p>Rust supports most Linux distributions. Depending on the specific distribution and version of the operating system you use, you might need to add some software dependencies to your environment. In general, your development environment should include a linker or C-compatible compiler such as <code>clang</code> and an appropriate integrated development environment (IDE).</p>"},{"location":"build/build-guides-install-deps/#before-you-begin_1","title":"Before you begin","text":"<p>Check the documentation for your operating system for information about the packages that are installed and how to download and install any additional packages you might need. For example, if you use Ubuntu, you can use the Ubuntu Advanced Packaging Tool (<code>apt</code>) to install the <code>build-essential</code> package:</p> <pre><code>sudo apt install build-essential\n</code></pre> <p>At a minimum, you need the following packages before you install Rust:</p> <pre><code>clang curl git make\n</code></pre> <p>Because the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as <code>libssl-dev</code> or <code>openssl-devel</code>.</p>"},{"location":"build/build-guides-install-deps/#install-required-packages-and-rust","title":"Install required packages and Rust","text":"<p>To install the Rust toolchain on Linux:</p> <ol> <li> <p>Log on to your computer and open a terminal shell.</p> </li> <li> <p>Check the packages you have installed on the local computer by running an appropriate package    management command for your Linux distribution.</p> </li> <li> <p>Add any package dependencies you are missing to your local development environment by running an    appropriate package management command for your Linux distribution.</p> </li> </ol> <p>For example, on Ubuntu Desktop or Ubuntu Server, you might run a command similar to the    following:</p> <pre><code>sudo apt install --assume-yes git clang curl libssl-dev protobuf-compiler\n</code></pre> <p>Click the tab titles to see examples for other Linux operating systems:</p> DebianArchFedoraopenSUSE <pre><code>sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n</code></pre> <pre><code>pacman -Syu --needed --noconfirm curl git clang make protobuf\n</code></pre> <pre><code>sudo dnf update\nsudo dnf install clang curl git openssl-devel make protobuf-compiler\n</code></pre> <pre><code>sudo zypper install clang curl git openssl-devel llvm-devel libudev-devel make protobuf\n</code></pre> <p>Remember that different distributions might use different package managers and bundle packages in different ways. For example, depending on your installation selections, Ubuntu Desktop and Ubuntu Server might have different packages and different requirements. However, the packages listed in the command-line examples are applicable for many common Linux distributions, including Debian, Linux Mint, MX Linux, and Elementary OS.</p> <ol> <li>Download the <code>rustup</code> installation program and use it to install Rust by running the following    command:</li> </ol> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre> <ol> <li> <p>Follow the prompts displayed to proceed with a default installation.</p> </li> <li> <p>Update your current shell to include Cargo by running the following command:</p> </li> </ol> <pre><code>source $HOME/.cargo/env\n</code></pre> <ol> <li>Verify your installation by running the following command:</li> </ol> <pre><code>rustc --version\n</code></pre> <ol> <li>Configure the Rust toolchain to default to the latest stable version by running the following    commands:</li> </ol> <pre><code>rustup default stable\nrustup update\n</code></pre> <ol> <li>Add the <code>nightly</code> release and the <code>nightly</code> WebAssembly (wasm) targets to your development    environment by running the following commands:</li> </ol> <pre><code>rustup update nightly\nrustup target add wasm32-unknown-unknown --toolchain nightly\n</code></pre> <ol> <li>Verify your installation here.</li> </ol>"},{"location":"build/build-guides-install-deps/#windows-wsl","title":"Windows (WSL)","text":"<p>In general, UNIX-based operating systems\u2014like macOS or Linux\u2014provide a better development environment for building Substrate-based blockchains.</p> <p>However, if your local computer uses Microsoft Windows instead of a UNIX-based operating system, you can configure it with additional software to make it a suitable development environment for building Substrate-based blockchains. To prepare a development environment on a computer running Microsoft Windows, you can use Windows Subsystem for Linux (WSL) to emulate a UNIX operating environment.</p>"},{"location":"build/build-guides-install-deps/#before-you-begin_2","title":"Before you begin","text":"<p>Before installing on Microsoft Windows, verify the following basic requirements:</p> <ul> <li>You have a computer running a supported version of the Microsoft Windows operating system.</li> <li>You must be running Microsoft Windows 10, version 2004 or later, or Microsoft Windows 11 to   install Windows Subsystem for Linux on a computer with the Windows desktop operating system.</li> <li>You must be running Microsoft Windows Server 2019, or later, to install Windows Subsystem for   Linux on a computer with the Windows server operating system.</li> <li>You have good internet connection and access to a shell terminal on your local computer.</li> </ul>"},{"location":"build/build-guides-install-deps/#set-up-windows-subsystem-for-linux","title":"Set up Windows Subsystem for Linux","text":"<p>Windows Subsystem for Linux (WSL) enables you to emulate a Linux environment on a computer that uses the Windows operating system. The primary advantage of this approach for Substrate development is that you can use all of the code and command-line examples as described in the Substrate documentation. For example, you can run common commands\u2014such as <code>ls</code> and <code>ps</code>\u2014unmodified. By using Windows Subsystem for Linux, you can avoid configuring a virtual machine image or a dual-boot operating system.</p> <p>To prepare a development environment using Windows Subsystem for Linux:</p> <ol> <li>Check your Windows version and build number to see if Windows Subsystem for Linux is enabled by    default.</li> </ol> <p>If you have Microsoft Windows 10, version 2004 (Build 19041 and higher), or Microsoft Windows 11,    Windows Subsystem for Linux is available by default and you can continue to the next step.</p> <p>If you have an older version of Microsoft Windows installed, see    WSL manual installation steps for older versions.    If you are installing on an older version of Microsoft Windows, you can download and install WLS    2 if your computer has Windows 10, version 1903 or higher.</p> <ol> <li> <p>Select Windows PowerShell or Command Prompt from the Start menu, right-click, then Run as    administrator.</p> </li> <li> <p>In the PowerShell or Command Prompt terminal, run the following command:</p> </li> </ol> <pre><code>wsl --install\n</code></pre> <p>This command enables the required WSL 2 components that are part of the Windows operating system,    downloads the latest Linux kernel, and installs the Ubuntu Linux distribution by default.</p> <p>If you want to review the other Linux distributions available, run the following command:</p> <pre><code>wsl --list --online\n</code></pre> <ol> <li> <p>After the distribution is downloaded, close the terminal.</p> </li> <li> <p>Click the Start menu, select Shut down or sign out, then click Restart to restart the    computer.</p> </li> </ol> <p>Restarting the computer is required to start the installation of the Linux distribution. It can    take a few minutes for the installation to complete after you restart.</p> <p>For more information about setting up WSL as a development environment, see    Set up a WSL development environment.</p>"},{"location":"build/build-guides-install-deps/#install-required-packages-and-rust_1","title":"Install required packages and Rust","text":"<p>To install the Rust toolchain on WSL:</p> <ol> <li> <p>Click the Start menu, then select Ubuntu.</p> </li> <li> <p>Type a UNIX user name to create user account.</p> </li> <li> <p>Type a password for your UNIX user, then retype the password to confirm it.</p> </li> <li> <p>Download the latest updates for the Ubuntu distribution using the Ubuntu Advanced Packaging Tool    (<code>apt</code>) by running the following command:</p> </li> </ol> <pre><code>sudo apt update\n</code></pre> <ol> <li>Add the required packages for the Ubuntu distribution by running the following command:</li> </ol> <pre><code>sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n</code></pre> <ol> <li>Download the <code>rustup</code> installation program and use it to install Rust for the Ubuntu distribution    by running the following command:</li> </ol> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre> <ol> <li> <p>Follow the prompts displayed to proceed with a default installation.</p> </li> <li> <p>Update your current shell to include Cargo by running the following command:</p> </li> </ol> <pre><code>source ~/.cargo/env\n</code></pre> <ol> <li>Verify your installation by running the following command:</li> </ol> <pre><code>rustc --version\n</code></pre> <ol> <li> <p>Configure the Rust toolchain to use the latest stable version as the default toolchain by     running the following commands:</p> <pre><code>rustup default stable\nrustup update\n</code></pre> </li> <li> <p>Add the <code>nightly</code> version of the toolchain and the <code>nightly</code> WebAssembly (<code>wasm</code>) target to your     development environment by running the following commands:</p> <pre><code>rustup update nightly\nrustup target add wasm32-unknown-unknown --toolchain nightly\n</code></pre> </li> <li> <p>Verify your installation here.</p> </li> </ol>"},{"location":"build/build-guides-install-deps/#verifying-installation","title":"Verifying Installation","text":"<p>Verify the configuration of your development environment by running the following command:</p> <pre><code>rustup show\nrustup +nightly show\n</code></pre> <p>The command displays output similar to the following:</p> <pre><code># rustup show\n\nactive toolchain\n----------------\n\nstable-x86_64-unknown-linux-gnu (default)\nrustc 1.61.0 (fe5b13d68 2022-05-18)\n\n# rustup +nightly show\n\nactive toolchain\n----------------\n\nnightly-x86_64-unknown-linux-gnu (overridden by +toolchain on the command line)\nrustc 1.63.0-nightly (e7144\n</code></pre>"},{"location":"build/build-guides-install-deps/#install-polkadot-parachain-and-chain-spec-builder","title":"Install <code>polkadot-parachain</code> and <code>chain-spec-builder</code>","text":"<p>The <code>polkadot-parachain</code> can be used a universal collator instance for running most of the parachains (an \"omninode beta\"). It can be installed as follows:</p> <pre><code>cargo install --git https://github.com/paritytech/polkadot-sdk --tag polkadot-v1.15.1 --force polkadot-parachain-bin\n</code></pre> <p><code>chain-spec-builder</code> is how you will generate chain specifications for your network. It requires a <code>wasm</code> runtime bundle to generate the chain specification from.</p> <p>It can be installed as follows:</p> <p>Note that chain-spec-builder only works with select Polkadot SDK versions (<code>&lt;v1.13.0</code>)</p> <pre><code>cargo install staging-chain-spec-builder\n</code></pre>"},{"location":"build/build-guides-template-basic/","title":"Template to Core - Setup & Initial Deployment of a Parachain","text":"<p>Not a production ready guide.</p> <p>This guide is considered a moving document and currently uses the Paseo testnet. This guide is also applicable to the parachains on the Kusama relay chain, as coretime is also enabled there.</p> <p>This instructions on this guide are applicable for the Polkadot SDK repository with tag <code>polkadot-v1.15.1</code></p> <p>This guide aims to get you up and running with the basics of:</p> <ul> <li>Compiling and configuring your first template</li> <li>Obtaining Coretime (bulk or on-demand)</li> <li>Deploying your template on your procured core</li> </ul>"},{"location":"build/build-guides-template-basic/#getting-roc-and-reserving-a-paraid","title":"Getting ROC and Reserving a ParaId","text":"<p>Before starting to work with coretime, you'll need some ROC tokens to pay fees, reserve a ParaId, and more.</p> <p>Head over to Polkadot-JS to reserve a ParaId. We'll need a ParaId to upload our parachain's code:</p> <ol> <li>Get the Polkadot-JS Web Extension.</li> <li>Create a wallet, and get some ROC via the faucet. with your new    address.</li> <li>Go to the Polkadot-JS Web App, and make sure you select    Paseo as your network via the tabs on the side    or visit this link to get to Paseo directly</li> <li>Head to    Network &gt; Parachains &gt; Parathreads (the tab)</li> <li>Follow these instructions to reserve a ParaId.</li> </ol> <p>Visit the Accounts tab to view all registered accounts and associated balances within the Polkadot-JS Extension. Once finished, you should see your new ParaId at the bottom of the list within Network &gt; Parachains &gt; Parathreads with the option to \"Deregister\" to the right:</p> <p></p>"},{"location":"build/build-guides-template-basic/#compiling-parachain-runtime-and-generating-wasm-blob","title":"Compiling Parachain Runtime and Generating Wasm Blob","text":"<p>We can now move on to working with the template. Essential prerequisites are:</p> <ol> <li>Have a command line, git, and other common development tools to edit code/files.</li> <li>Rust, its associated tooling, the nightly toolchain, and the <code>wasm32-unknown-unknown</code>    compilation target.</li> </ol> <p>Install dependencies</p> <p>Visit the dependencies' installation page before starting.</p> <p>This guide uses release <code>polkadot-v1.15.1</code>, for associated tooling (such as <code>polkadot-parachain</code> and <code>chain-spec-builder</code>).</p> <p>We will be using the Polkadot SDK's parachain template, which is mirrored in the templates folder within Polkadot SDK repository.</p> <p>Clone the repository:</p> <pre><code>git clone git@github.com:paritytech/polkadot-sdk-parachain-template.git\n</code></pre> <p>Now, navigate to <code>polkadot-sdk-parachain-template/</code>:</p> <pre><code>cd polkadot-sdk-parachain-template\n</code></pre> <p>Open this in your code editor of choice. This template contains the necessary dependencies we need to utilize a core.</p>"},{"location":"build/build-guides-template-basic/#compiling-the-parachain-template-node","title":"Compiling the Parachain Template Node","text":"<p>This tutorial won't go into the specifics of the template, nor will it go into the specifics of FRAME and Substrate. All you need to know is the following:</p> <ul> <li><code>runtime/</code> - Contains the runtime and business logic. This is how all of your pallets (runtime   modules) are configured. The runtime, once it's compiled as a WebAssembly blob, is uploaded   on-chain.</li> <li><code>node/</code> - The node implementation, which takes care of networking and RPC setup.</li> </ul> <p>Pallets are essentially just Rust crates, which are imported as dependencies, as seen in <code>runtime/Cargo.toml</code>. Read more about pallets here.</p> <p>When we compile our template, we can extract the runtime code as a WebAssembly <code>.wasm</code> blob, which is one of the key artifacts for registering our parachain on the relay chain.</p> <p>Build the node using the following command:</p> <pre><code>cargo build --release\n</code></pre> <p>For the sake of this example, we won't go into adding or modifying any pallets. However, this is definitely a next step after you get used to deploying your parachain.</p>"},{"location":"build/build-guides-template-basic/#customizing-our-chain-specifications-patch-file","title":"Customizing our chain specification's patch file","text":"<p>The chain specification is a JSON file that describes Polkadot SDK-based networks. It usually contains the genesis runtime (in hex) under <code>genesis.runtimeGenesis.code</code> and also contains genesis values/state for the pallets included in your runtime.</p> <p>You can bootstrap your network with some initial values, such as initial collators, balances for certain accounts, and more. This is done using a patch file, which the <code>chain-spec-builder</code> tool uses to create the full chain specification of your network. You should do the following to create your <code>patch.json</code>:</p> <p>Feel free to use the patch provided here, which you can look to tweak to your liking.</p> <ol> <li>Create the file: <code>touch patch.json</code></li> <li>Paste the below patch JSON.</li> </ol> <p>The patch JSON states that:</p> <ul> <li>The <code>Alice</code> and <code>Bob</code> accounts get a substantial balance.</li> <li><code>Alice</code> is the collator and block producer of this network. This makes it easy for us to run our   collator with <code>--alice</code> later on.</li> <li><code>Alice</code> is the sudo key of our network.</li> </ul> <p>Make sure you replace <code>YOUR_PARA_ID_HERE</code> with your reserved ParaId!</p> <p>This should be the same as the ID you reserved.</p> <pre><code>{\n  \"balances\": {\n    \"balances\": [\n      [\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\", 1152921504606846976],\n      [\"5FHneW46xGXgs5mUiveU4sbTyGBzmstUspZC92UhjJM694ty\", 1152921504606846976]\n    ]\n  },\n  \"collatorSelection\": {\n    \"candidacyBond\": 16000000000,\n    \"invulnerables\": [\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\"]\n  },\n  \"parachainInfo\": {\n    \"parachainId\": YOUR_PARA_ID_HERE\n  },\n  \"polkadotXcm\": {\n    \"safeXcmVersion\": 4\n  },\n\n  \"session\": {\n    \"keys\": [\n      [\n        \"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\",\n        \"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\",\n        {\n          \"aura\": \"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\"\n        }\n      ]\n    ]\n  },\n  \"sudo\": {\n    \"key\": \"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\"\n  }\n}\n</code></pre>"},{"location":"build/build-guides-template-basic/#generating-the-chain-specification","title":"Generating the chain specification","text":"<p>Ensure you have the <code>chain-spec-builder</code> installed before following along!</p> <p>By now, you should have <code>patch.json</code> created and populated, and your <code>./target</code> folder should look something akin to:</p> <pre><code>./target/release/wbuild/parachain-template-runtime\n\u251c\u2500\u2500 Cargo.lock\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 parachain_template_runtime.compact.compressed.wasm\n\u251c\u2500\u2500 parachain_template_runtime.compact.wasm\n\u251c\u2500\u2500 parachain_template_runtime.wasm\n\u251c\u2500\u2500 src\n\u2514\u2500\u2500 target\n</code></pre> <p>We'll be using <code>parachain_template_runtime.wasm</code> in conjunction with <code>chain-spec-builder</code> to build our chain specification:</p> <pre><code>chain-spec-builder create \\\n-v \\\n-r ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.wasm \\\npatch patch.json\n</code></pre> <p>You should now see <code>chain_spec.json</code> generated, with the message <code>Genesis config verification: OK</code>. The <code>-v</code> does a superficial verification of the JSON to ensure all fields are properly populated.</p> <p>Next, you'll need to modify a few things in your chain spec, namely by adding the following fields to make it parachain-ready. Once again, make sure you set <code>para_id</code> to the one you reserved earlier:</p> <pre><code>\"protocolId\": \"my-live-protocol\",\n\"properties\": {\n   \"ss58Format\": 42,\n   \"tokenDecimals\": 12,\n   \"tokenSymbol\": \"UNIT\"\n},\n\"para_id\": PARA_ID_HERE,\n\"relay_chain\": \"paseo\",\n</code></pre> <p>Once you finish modifying the file, it should look like this:</p> <pre><code>{\n  \"name\": \"Custom\",\n  \"id\": \"custom\",\n  \"chainType\": \"Live\",\n  \"bootNodes\": [],\n  \"telemetryEndpoints\": null,\n  \"protocolId\": \"my-live-protocol\",\n  \"properties\": {\n    \"ss58Format\": 42,\n    \"tokenDecimals\": 12,\n    \"tokenSymbol\": \"UNIT\"\n  },\n  \"para_id\": YOUR_PARA_ID_HERE,\n  \"relay_chain\": \"paseo\",\n  \"codeSubstitutes\": {},\n  \"genesis\": { ... }\n}\n</code></pre> <p>Feel free to customize various aspects of your spec, such as the <code>UNIT</code> ticker, <code>name</code>, <code>id</code>, or other fields.</p> <p>Now you should open your <code>chain_spec.json</code>, and use this checklist to ensure all the necessary fields are in place:</p> <ol> <li>Make sure that <code>relay_chain</code> is set to the target relay chain (<code>paseo</code>, in our case)</li> <li>Make sure that <code>para_id</code> (right below <code>relay_chain</code>) is set to your reserved ParaId</li> <li>Make sure that our <code>chain_type</code> is set to <code>Live</code></li> <li>Optionally, change the name, id, and token symbol of your chain.</li> </ol> <p>If you fail to do one of these, your chain may fail to produce blocks.</p> <p>For more information on chain specifications, check out the reference document from the Polkadot SDK.</p>"},{"location":"build/build-guides-template-basic/#generating-the-runtime-and-genesis","title":"Generating the Runtime and Genesis","text":"<p>With our chain specification successfully generated, we can move to generating the genesis state and runtime.</p> <p>Generate the genesis following the instructions below:</p> <pre><code>polkadot-parachain export-genesis-head --chain chain_spec.json genesis\n</code></pre> <p>Although you can use the WebAssembly within <code>wbuild</code>, for ease of access you can also regenerate your WebAssembly blob with the following:</p> <pre><code>polkadot-parachain export-genesis-wasm --chain chain_spec.json genesis-wasm\n</code></pre> <p>Within your project folder, you should now have two files:</p> <ul> <li><code>genesis</code> - the initial state of your parachain.</li> <li><code>genesis-wasm</code> - the initial runtime WebAssembly blob of your parachain.</li> </ul>"},{"location":"build/build-guides-template-basic/#running-your-collator","title":"Running Your Collator","text":"<p>Make sure you have the <code>polkadot-parachain</code> binary installed!</p> <p>Before you are able to connect your collator, you must sync the relay chain. Depending on your download speed, the time to sync may vary. In order to avoid storing the full state of the relay chain, be sure to run with the appropriate pruning flags (<code>blocks-pruning</code> and <code>state-pruning</code>):</p> <p>Explaining <code>blocks-pruning</code> and <code>state-pruning</code></p> <p>A Polkadot SDK-based node has two pruning modes:</p> <ul> <li><code>blocks-pruning</code> - Prunes block bodies (the list of extrinsics in the block) from a specified   height (default: <code>256</code>)</li> <li><code>state-pruning</code> - Prunes the overall state from a specified height</li> </ul> <p>Both of these flags aid in reducing the amount of disk space taken up by the relay chain. Note that <code>state-pruning</code> is only used for the first initial sync for the database.</p> <pre><code>polkadot-parachain --collator \\\n--alice \\\n--chain chain_spec.json \\\n--force-authoring \\\n--base-path &lt;your-base-path-here&gt; \\\n-- \\\n--chain=paseo \\\n--sync warp \\\n--blocks-pruning 256 \\\n--state-pruning 256\n</code></pre> <p>Fun fact: This command really spins up two nodes: your collator node for your parachain, along with an embedded relay chain node, hence the separation in the command via <code>--</code>.</p> <p>You should now see your relay chain syncing, reaching the same target that your target relay chain is currently at:</p> <pre><code>2024-05-07 11:43:18 [Relaychain] \u2699\ufe0f  Syncing 490.8 bps, target=#10342815 (9 peers), best: #10013784 (0x91d7\u2026aeb2), finalized #10013704 (0x8556\u2026e679), \u2b07 8.3MiB/s \u2b06 1.2kiB/s\n</code></pre>"},{"location":"build/build-guides-template-basic/#register-the-parachain-as-a-parathread","title":"Register the Parachain as a Parathread","text":"<p>With your <code>genesis</code> and <code>genesis-wasm</code> created, you can now create your parathread. Head back to Network &gt; Parachains &gt; Parathreads (the tab) in PolkadotJS, and click + Parathread in the top right. Now, you can upload your runtime and genesis accordingly:</p> <ol> <li>Upload <code>genesis-wasm</code> in the <code>code</code> field</li> <li>Upload <code>genesis</code> in the <code>initial state</code> field</li> </ol> <p></p> <p>Pay the deposit, and you're good to go! Keep in mind the parathread takes around ~2 hours to onboard. You can scroll down to your ParaId to see it onboarding, for example:</p> <p></p>"},{"location":"build/build-guides-template-basic/#procure-coretime","title":"Procure Coretime","text":"<p>** Your node should be synced with the relay before this step.**</p> <p>Procuring a core is easy with coretime marketplaces already available. Visit The Coretime Marketplaces page to learn more about them, and purchase a core!</p> <p>We have two options:</p> <ol> <li>Bulk - obtain a set amount of coretime in    bulk.</li> <li>On-demand - pay as we go for our block    production.</li> </ol> <p>With bulk coretime, we assign a core to our ParaId, and as long as that core is valid, our parachain will produce blocks and finalize them via the relay chain until we have to renew the core.</p> <p>It's worth noting that you can easily experiment using on-demand extrinsics, then later switch to a bulk coretime model. For now, let's start with on-demand coretime to get our first blocks going.</p> <p>It is recommended that you first try an on-demand assignment, then move to a bulk assignment after you confirm your chain can create blocks!</p>"},{"location":"build/build-guides-template-basic/#on-demand-coretime","title":"On-Demand Coretime","text":"<p>Provided your collator is synced, you can create a block using an on-demand extrinsic.</p> <ol> <li>Head to PolkadotJS &gt; Extrinsics</li> <li>Issue the <code>onDemandAssignmentProvider.placeOrderAllowDeath</code> extrinsic</li> <li>Set the <code>max_amount</code> to at least <code>1000000000000</code> and <code>paraId</code> to your ParaId.</li> <li>As long as your collator is running, you should see your block height increase from 0 to 1!</li> </ol> <p></p>"},{"location":"build/build-guides-template-basic/#bulk-coretime-assigning-your-core","title":"Bulk Coretime: Assigning your Core","text":"<p>If everything is working as intended, you can now choose to assign bulk coretime to your parachain for persistent block generation. For this assignment, RegionX's CoreHub will be used to purchase and assign cores.</p> <p>Getting Coretime ROC</p> <p>In the upper right, you will see two balances: one for the relay chain, and one for the coretime chain. Before you can purchase a core, you need ROC on the coretime chain. RegionX includes a tool for doing so:</p> <ol> <li>Head to General &gt; Cross Chain Transfer on the right, and transfer 10 ROC:</li> </ol> <p></p> <ol> <li>Sign the transaction with Polkadot-JS. If all goes well, you should see the balance update in the   upper right:</li> </ol> <p></p> <ol> <li>Connect your wallet and make sure you select Paseo as your network:</li> </ol> <p></p> <ol> <li>Click Purchase a Core on the left:</li> </ol> <p></p> <ol> <li>In the lower right, click \"Purchase Core\":</li> </ol> <p></p> <ol> <li>Go to My Regions, and click to select your region, then click Assign on the right side:</li> </ol> <p></p> <ol> <li>Click Add Task, and input your ParaId along with a name for your chain:</li> </ol> <p></p> <ol> <li>Select your task, and select Provisional Assignment, and sign using Polkadot JS:</li> </ol> <p></p> <ol> <li>Once the transaction is confirmed, provided everything is synced, your collator is running, and    the region has begun, you should see blocks being persistently created as they were with the    on-demand extrinsic:</li> </ol> <p></p>"},{"location":"build/build-guides-template-basic/#whats-next","title":"What's Next?","text":"<p>Now that you can launch a layer one blockchain, the possibilities are endless:</p> <ul> <li>Setup a local development environment for your parachain</li> <li>Create a pallet</li> <li>Take a look at the OpenZepplin template - which has a lot more pallets configured.</li> <li>Upgrade your network</li> </ul>"},{"location":"build/build-hackathon/","title":"Hackathons","text":""},{"location":"build/build-hackathon/#join-a-hackathon","title":"Join a Hackathon","text":"<p>Web3 Foundation regularly supports developer focused events! Be the first to know by signing up for the Polkadot newsletter and the Kusama newsletter.</p>"},{"location":"build/build-hackathon/#host-a-hackathon","title":"Host a Hackathon","text":"<p>As one of our objectives in the Web3 Foundation is promoting the Web3 technology stack, we would like to support any individual or team who wants to organize a hackathon that gets more developers to understand Polkadot and Substrate in your city or online.</p> <p>We are not only providing technical resources for you, but we can have someone from our team give a hands-on workshop/presentation about the technology to help participants get started hacking on it more quickly.</p>"},{"location":"build/build-hackathon/#why-you-should-host-a-hackathon","title":"Why you should host a hackathon?","text":"<ul> <li>Connect with the Web3 Foundation team and larger community</li> <li>Support Web 3.0 education, opportunities, and more</li> <li>Learn the bleeding-edge technology</li> <li>Make lasting impact and gain connections in the community</li> </ul>"},{"location":"build/build-hackathon/#how-do-hackathons-differ-from-workshops","title":"How do hackathons differ from workshops?","text":"<p>Hackathons (AKA Buildathons) are aimed at participants who want to deliver their prototype and demonstrate their ideas to reality in a short period (few hours - one day), or online in a few weeks. Workshops are more for getting developers familiar with the tooling and understanding more about what are the resources currently available and how they can make use of it.</p>"},{"location":"build/build-hackathon/#how-can-you-run-a-hackathon-in-your-city","title":"How can you run a hackathon in your city?","text":"<p>Get in touch with the W3F team by email or ask us via our Matrix chat.</p>"},{"location":"build/build-hackathon/#how-we-can-help","title":"How we can help","text":"<ul> <li>Provide technical resources/materials</li> <li>Help sourcing funding for facilitation and prizes.</li> <li>Finding a venue</li> <li>Marketing the event</li> <li>Ensure the hackathon runs smoothly</li> </ul>"},{"location":"build/build-hackathon/#project-event-theme-ideas","title":"Project &amp; Event Theme Ideas","text":"<ul> <li>NFTs</li> <li>Bonded tokens</li> <li>New governance pallets with different styles of voting &amp; democracy</li> <li>Upgrade the TCR pallet</li> <li>IPFS integrations</li> <li>Decentralized identity solutions</li> <li>Oracle pallets</li> <li>Implement Generalized State Channel/Plasma Chain</li> <li>Decentralized Exchanges</li> <li>Tools for monitoring validator performance</li> <li>dApps across different parachains</li> </ul>"},{"location":"build/build-hackathon/#previous-hackathons","title":"Previous Hackathons","text":"<p>Here are a few examples of hackathons W3F has facilitated and supported:</p> <ul> <li> <p>Polkadot Buildathon: India - This India-focused   hackathon was a 9-week online event.</p> </li> <li> <p>Encode Hackathon -   an externally facilitated event with a mix of learning challenges and prize pools for dApps as   well as stand-alone blockchain project submissions.</p> </li> <li> <p>Hello World! by Polkadot - A collaborative   hackathon celebrating the integration of Polkadot and Kusama into the Gitcoin platform. Has many   sets of smaller challenges that will reward in either DOT or KSM.</p> </li> <li> <p>Hackusama - A 7-week online hackathon for developers to \"Build a   Blockchain\" and submit your wildest tools, visualizations, and ideas to the \"Open Hack\" category.</p> </li> </ul>"},{"location":"build/build-hackathon/#resources","title":"Resources","text":"<ul> <li>Polkadot Docs - many introductory learning material lives here,   that can be a feature of you hackathon or suggested prerequisite for those joining to use.</li> </ul>"},{"location":"build/build-hackathon/#support-contact","title":"Support / Contact","text":"<p>If you have any questions regarding organizing a hackathon, please free feel to contact us by email or ask us via Element chat.</p>"},{"location":"build/build-hrmp-channels/","title":"Opening HRMP Channels","text":"<p>In order to communicate over HRMP, parachains must establish channels by registering them on the relay chain. Like XCMP, HRMP is a message transport protocol, but passes all messages via the relay chain. When XCMP is implemented on Polkadot, HRMP is planned to be deprecated and phased out.</p> <p>HRMP channels are uni-directional. Bi-directional communication between two parachains will require two channels, one in each direction.</p>"},{"location":"build/build-hrmp-channels/#opening-hrmp-channels","title":"Opening HRMP Channels","text":"<p>Opening a channel between two parachains is a two-phase process, with one chain first initiating a channel request and then the second chain accepting it. When neither chain is a system chain, they will use the <code>hrmpInitOpenChannel</code> and <code>hrmpAcceptOpenChannel</code> calls, respectively.</p> <p>Each chain must dispatch the following calls on the relay chain from its parachain origin.</p> <ol> <li> <p><code>hrmp &gt; hrmpInitOpenChannel(recipient, proposedMaxCapacity, proposedMaxMessageSize)</code>: Initiates    channel establishment by creating a channel request with a given configuration. Note that the max    capacity and max message size must be within the <code>configuration</code>'s limits.</p> </li> <li> <p><code>hrmp &gt; hrmpAcceptOpenChannel(sender)</code>: Accept the channel open request from the given sender.</p> </li> </ol> <p>In order to dispatch a call from its sovereign origin, a parachain may use governance to send the encoded call in a <code>Transact</code> instruction to the relay chain, but it may also execute this logic autonomously (e.g. on the notification that a channel was requested).</p>"},{"location":"build/build-hrmp-channels/#examples-of-hrmp-channel-management","title":"Examples of HRMP Channel Management","text":"<p>There are several ways to trigger a specific message from a parachain's origin. The naive way is to write the program off-chain and submit it using the XCM pallet's <code>send</code> extrinsic. Sending arbitrary programs is gated by a privileged origin, so who can initiate that depends on each chain's configuration. The chain may need to go through governance to dispatch the extrinsic.</p> <p>Another option is to write the programs that a chain will send ahead of time and incorporate them into the runtime. These programs could be behind extrinsics with their own privileged origins, or even unprivileged origins. As the extrinsic can perform any checks prior to sending the message, the runtime developer can program things like allowing any signed origin to dispatch a call accepting an open HRMP channel request with another parachain.</p> <p>Note that this is actually how other extrinsics (e.g. to teleport assets) in the XCM pallet work; they construct XCM programs locally from a user's inputs and, assuming all checks pass, send the program to the destination.</p> <p>In addition, the logic could be autonomous and react to other instructions that the chain receives. For example, see Polimec's implementation of the <code>XcmExecutor</code>, which handles notifications of channel requests and acceptance.</p>"},{"location":"build/build-hrmp-channels/#opening-hrmp-channels-with-system-parachains","title":"Opening HRMP Channels with System Parachains","text":"<p>The <code>establish_channel_with_system</code> call can be used to establish a bi-directional channel between any parachain and a system chain. This call needs to be dispatched from the parachain via an XCM program to execute on the Relay Chain.</p> <p>For instance, the call to be executed on the relay chain to establish a bi-directional channel between a parachain and the Asset Hub with <code>ParaID</code> 1000 is <code>0x3c0ae8030000</code></p> <p></p> <p>Here is an example call with an XCM program sent from the parachain to Paseo relay chain to establish channel a bi-directional channel with Paseo Asset Hub - <code>0x0f001f000301000314000400000000070010a5d4e81300000000070010a5d4e80006000300c16678419c183c0ae8030000140d01000001003145</code></p> <p></p>"},{"location":"build/build-hrmp-channels/#opening-hrmp-channels-between-two-system-parachains","title":"Opening HRMP Channels Between Two System Parachains","text":"<p>As of Polkadot and Kusama runtimes 1,001,000, anyone can call an <code>establishSystemChannel</code> extrinsic with two system parachains as arguments in order to establish a channel from the given sender to receiver.</p>"},{"location":"build/build-integrate-assets/","title":"Using AssetHub","text":"<p>The relay chain does not natively support assets beyond its native token. This functionality exists in parachains. On both Polkadot and Kusama, this parachain is called Asset Hub.</p> <p>The Asset Hub provides a first-class interface for creating, managing, and using fungible and non-fungible assets. The fungible interface is similar to Ethereum's ERC-20 standard. However, the data structures and stateful operations are encoded directly into the chain's runtime, making operations fast and fee-efficient.</p> <p>Beyond merely supporting assets, integrating an Asset Hub into your systems has several benefits for infrastructure providers and users:</p> <ul> <li>Support for on-chain assets.</li> <li>Significantly lower transaction fees (about 1/10) than the relay chain.</li> <li>Significantly lower deposits (1/100) than the relay chain. This includes the existential deposit   and deposits for proxy/multisig operations.</li> <li>Ability to pay transaction fees in certain assets. As in, accounts would not need DOT to exist   on-chain or pay fees.</li> </ul> <p>The Asset Hub will use DOT as its native currency. Users can transfer DOT from the relay chain into the Asset Hub and use it natively. The relay chain will also accept DOT transfers from the Asset Hub back to the relay chain for staking, governance, or any other activity.</p> <p>Using the Asset Hub for DOT/KSM balance transfers will be much more efficient than the relay chain and is highly recommended. Until domain-specific parachains are built, the relay chain will still need to be used for staking and governance.</p>"},{"location":"build/build-integrate-assets/#assets-basics","title":"Assets Basics","text":"<p>See the Assets pallet for the most up-to-date info and reference documentation.</p> <p>Assets are stored as a map from an ID to information about the asset, including a management team, total supply, total number of accounts, its sufficiency for account existence, and more. Additionally, the asset owner can register metadata like the name, symbol, and number of decimals for representation.</p> <p>Some assets, as determined by on-chain governance, are regarded as \u201csufficient\u201d. Sufficiency means that the asset balance is enough to create the account on-chain, with no need for the DOT/KSM existential deposit. Likewise, you cannot send a non-sufficient asset to an account that does not exist. Sufficient assets can be used to pay transaction fees (i.e. there is no need to hold DOT/KSM on the account).</p> <p>Assets do have a minimum balance (set by the creator), and if an account drops below that balance, the dust is lost.</p>"},{"location":"build/build-integrate-assets/#asset-operations","title":"Asset Operations","text":"<p>The Assets pallet has its interface for dealing with assets. See the Integration section below for how to fetch information and construct transactions.</p> <p>The main functions you will probably interact with are <code>transfer</code> and <code>transfer_keep_alive</code>. These functions transfer some <code>amount</code> (balance) of an <code>AssetId</code> (a <code>u32</code>, not a contract address) to another account.</p> <p>The Assets pallet also provides an <code>approve_transfer</code>, <code>cancel_approval</code>, and <code>transfer_approved</code> interface for non-custodial operations.</p> <p>Asset transfers will result in an <code>assets.transferred</code> event. The same instructions for monitoring events and not transactions applies to asset transfers.</p> <p>Note that you can use the same addresses (except pure proxies) on the Asset Hub that you use on the relay chain. The SS58 encodings are the same; only the chain information (genesis hash, etc.) will change on transaction construction.</p>"},{"location":"build/build-integrate-assets/#paying-transaction-fees-in-another-asset","title":"Paying Transaction Fees in Another Asset","text":"<p>Users in the Asset Hub can pay the fees of their transactions with assets other than DOT. The only requirement is that a liquidity pool of the relevant asset against DOT should already exist as a storage entry of the Asset Conversion pallet.</p> <p>Technically speaking, this is enabled by the <code>ChargeAssetTxPayment</code> signed-extension implemented in the Asset Hub runtime. This signed-extension extends transactions to include an optional <code>AssetId</code> that specifies the asset to be used for payment of both the execution fees and the optional tip. It defaults to the native token when it is set to <code>None</code>. In case it is given, this <code>AssetId</code> has to be an XCM <code>Multilocation</code>. Once the transaction is executed in the block, it will emit an <code>AssetTxFeePaid</code> event, informing of the account paying the fees, the amount in the asset paid as fee, the tip (if any), and the asset ID of the asset paying the fees.</p> <p>Handling Pools with Low Liquidity</p> <p>Wallets and UIs enabling this functionality should ensure that the user is prompted with the necessary warnings, such that they do not accidentally spend all of their funds to perform a swap on a pool with no or low liquidity.</p>"},{"location":"build/build-integrate-assets/#how-to-build-transactions-paying-fees-with-other-assets","title":"How to Build Transactions Paying Fees with Other Assets","text":"<ul> <li>This repository contains the   complete workflow on how to create a liquidity pool for a given asset, add liquidity to it and   then build a transaction to pays fees with this asset (including fees estimation). It is done with   several libraries: Polkadot-JS API and Subxt.</li> <li>Example using Asset Transfer API   to do a cross-chain transfer in Polkadot Asset Hub paying fees with GLMR.</li> <li>A simple script   using Polkadot-JS API to do a local transfer of bridged KSM in Polkadot Asset Hub paying fees with   USDT.</li> </ul>"},{"location":"build/build-integrate-assets/#foreign-assets","title":"Foreign Assets","text":"<p>Foreign assets are those assets in Asset Hub whose native blockchain is not Asset Hub. These are mainly native tokens from other parachains or bridged tokens from other consensus systems (such as Ethereum). Once a foreign asset has been registered in Asset Hub (by its root origin), users are enabled to send this token from its native blockchain to Asset Hub and operate with it as if it were any other asset.</p> <p>Practically speaking, foreign assets are handled by the <code>foreign-assets</code> pallet in Asset Hub, which is an instance of the Assets pallet. Hence, this pallet exposes the same interface to users and other pallets as the Assets pallet.</p> <p>The main difference to take into account for foreign assets is their identifier. Instead of using integers as identifiers like in the Assets pallet, assets stored in the <code>foreign-assets</code> pallet are identified by their XCM multilocation.</p>"},{"location":"build/build-integrate-assets/#integration","title":"Integration","text":"<p>The Asset Hub will come with the same tooling suite that Parity Technologies provides for the Relay Chain, namely API Sidecar and TxWrapper Polkadot, as well as the Asset Transfer API. If you have a technical question or issue about how to use one of the integration tools, please file a GitHub issue so a developer can help.</p>"},{"location":"build/build-integrate-assets/#parachain-node","title":"Parachain Node","text":"<p>Using the Asset Hub will require running a parachain node to sync the chain. This is very similar to running a relay chain node, with the addition of some extra flags. You can follow these guidelines to set up an Asset Hub node.</p>"},{"location":"build/build-integrate-assets/#asset-transfer-api","title":"Asset Transfer API","text":"<p>Asset-transfer-api is a library focused on simplifying the construction of asset transfers for Substrate-based chains that involve system parachains like Asset Hub (Polkadot and Kusama). It exposes a reduced set of methods that facilitate users to send transfers to other (para) chains or locally. You can refer to this table for the current cross-chain support and here for the complete documentation, including installation guide and usage examples.</p>"},{"location":"build/build-integrate-assets/#sidecar","title":"Sidecar","text":"<p>API Sidecar is a REST service for relay chain and parachain nodes. It comes with endpoints to query information about assets and asset balances on the Asset Hub.</p> <ul> <li>Asset lookups always use the <code>AssetId</code> to refer to an asset class. On-chain metadata is subject to   change and thus unsuitable as a canonical index.</li> <li>Please refer to docs for full usage   information. Details on options like how to make a historical query are not included here.</li> </ul> <p>Here are the available public instances:</p> <ul> <li>Sidecar connected to Polkadot Asset Hub   and</li> <li>Sidecar connected to Kusama Asset Hub</li> </ul> <p>The purpose of these instances is to allow anyone to check and get a quick overview of the info that the asset-related endpoints provide.</p> <p>Caution</p> <p>These instances should only be used for ad-hoc checks or tests and not for production, heavy testing or any other critical purpose.</p>"},{"location":"build/build-integrate-assets/#tx-wrapper-polkadot","title":"Tx Wrapper Polkadot","text":"<p>TxWrapper Polkadot is a library designed to facilitate transaction construction and signing in offline environments. It comes with asset-specific functions to use on the Asset Hub. When constructing parachain transactions, you can use <code>txwrapper-polkadot</code> exactly as on the relay chain, but construct transactions with the appropriate parachain metadata like genesis hash, spec version, and type registry.</p>"},{"location":"build/build-integrate-assets/#xcm-transfer-monitoring","title":"XCM Transfer Monitoring","text":""},{"location":"build/build-integrate-assets/#monitoring-of-xcm-deposits","title":"Monitoring of XCM deposits","text":"<p>Thanks to XCM and a growing number of parachains, the relay chain native token can exist across several blockchains, which means the providers need to monitor cross-chain transfers on top of local transfers and corresponding <code>balances.transfer</code> events.</p> <p>Usually, DOT is sent and received in the relay chain and in the Asset Hub either with a Teleport from system parachains or with a Reserve Backed Transfer from any other parachain. In both cases, the event emitted when processing the transfer is the <code>balances.minted</code> event. Hence, providers should listen to these events, pointing to an address in their system. For this, the service provider must query every new block created, loop through the events array, filter for any <code>balances.minted</code> event, and apply the appropriate business logic.</p> <p>In some special cases, DOT may be sent to the relay chain or the Asset Hub using other XCM instructions,  like <code>Transact</code>. In these cases, the event emitted when processing the transact instruction in the destination chain is  <code>balances.transfer</code>, which is usually emitted during the finalization of the block execution process.</p>"},{"location":"build/build-integrate-assets/#tracking-back-xcm-information","title":"Tracking back XCM information","text":"<p>What has been mentioned earlier should be sufficient to confirm that DOT has arrived in a given account via XCM. However, in some cases, it may be interesting to identify the cross-chain message that emitted the relevant <code>balances.minted</code> event. This can be done as follows:</p> <ol> <li>Query the relevant chain <code>at</code> the block the <code>balances.minted</code> event was emitted.</li> <li>Filter for <code>messageQueue(Processed)</code> events. These can be emitted during any phase of the block,    not just initialization. This event has a parameter <code>Id</code>. The value of <code>Id</code> identifies the    cross-chain message received in the relay chain or in the Asset Hub. It can be used to track back    the message in the origin parachain if needed. Note that a block may contain several    <code>messageQueue(Processed)</code> events corresponding to several cross-chain messages processed for this    block.</li> </ol>"},{"location":"build/build-integrate-assets/#additional-examples-of-monitoring-xcm-transfers","title":"Additional Examples of Monitoring XCM Transfers","text":"<p>The two previous sections outline the process of monitoring XCM deposits to specific account(s) and then tracing back the origin of these deposits. However, the process of tracking an XCM transfer (hence the events to look for) may vary based on the direction of the XCM message. Here are some examples to showcase the slight differences:</p> <ol> <li>For an XCM transfer from a Parachain to a relay chain    (example):</li> </ol> <ul> <li>The event to look for in the      Parachain side is called <code>parachainsystem (UpwardMessageSent)</code>, and the parameter      <code>message_hash</code> in this event identifies the XCM transfer.</li> <li>The event to track in      the relay chain side is called <code>messagequeue (Processed)</code>, and the parameter <code>id</code> of the event      should be the same as the <code>message_hash</code> found in the Parachain event.</li> </ul> <ol> <li>For an XCM transfer from a relay chain to a parachain    (example):</li> </ol> <ul> <li>The event to look for in      the relay chain side is called <code>xcmPallet (sent)</code>, and the parameter <code>message_id</code> in this event      identifies the XCM transfer.</li> <li>The event to look for in the      Parachain side is called <code>dmpqueue (ExecutedDownward)</code>, and the parameter that identifies the      XCM message is either called <code>message_hash</code> or <code>message_id</code>.</li> </ul> <ol> <li>For an XCM transfer from a System Parachain to a Parachain    (example):</li> </ol> <ul> <li>The event to look      for in the System Parachain side is called <code>xcmpqueue (XcmpMessageSent)</code>, and again the      <code>message_hash</code> is one of the parameters of the event.</li> <li>The corresponding event in      the Parachain side is the <code>xcmpqueue (Success)</code> and the <code>message_hash</code> found in that event      should have the same value as the one in the System parachain.</li> </ul>"},{"location":"build/build-integrate-assets/#monitoring-of-failed-xcm-transfers","title":"Monitoring of Failed XCM Transfers","text":"<p>In case that an XCM transfer fails to complete successfully, then we will notice some different parameters in the events emitted or different events. Below are some examples:</p> <ol> <li>From a relay chain to a System Parachain    (example):</li> </ol> <ul> <li>We will see the      event <code>dmpqueue (ExecutedDownward)</code> in the System Parachain side with the following parameters:<ul> <li><code>outcome</code> with value <code>Incomplete</code> and with the type of error which in this example is    UntrustedReserveLocation.</li> <li><code>message_id</code> which shows the hash of the XCM Transfer.</li> </ul> </li> </ul> <ol> <li>From a Parachain to another Parachain    (example):</li> </ol> <ul> <li>We will see the event <code>xcmpqueue (Fail)</code> in the destination Parachain with the following parameters:<ul> <li><code>error</code> which in this example is    TooExpensive.</li> <li><code>message_hash</code> which identifies the XCM Transfer.</li> </ul> </li> <li>Note: there might be another      event called      <code>polkadotxcm (AssetsTrapped)</code> which indicates that some assets have been trapped (and hence can      be claimed).</li> </ul> <p>A great resource to learn more about Error Management in XCM is the Polkadot blog post from Gavin Wood, XCM Part III: Execution and Error Management.</p>"},{"location":"build/build-integration/","title":"Polkadot Integration Guide","text":"<p>Welcome to the Polkadot integration guide. This guide will provide all the information you need to get started on your integration. The target audiences for this guide are wallets and custodians, but it will be useful to any infrastructure provider such as validators or chain indexers.</p>"},{"location":"build/build-integration/#structure","title":"Structure","text":"<p>The guide focuses on Polkadot and Kusama, but the principles will apply to parachains and other Substrate-based chains. The guide contains four sections:</p> <ol> <li>Protocol Info: The entry point to the guide. Please read it carefully    as it provides information about Polkadot that differentiates it from other blockchains. Use this    page to check your assumptions.</li> <li>Assets: The guide to integrating assets on Polkadot into your    systems.</li> <li>Node Management: This page will guide you to starting and monitoring    a node.</li> <li>Node Interaction: This page will teach you to interact with your    node via multiple RPC tooling options.</li> <li>Transaction Construction: A guide to transaction    construction, signing, decoding, and serialization using several available tools.</li> </ol>"},{"location":"build/build-integration/#recommendation","title":"Recommendation","text":"<p>Each page in the guide, especially the Node Interaction and Transaction Construction pages, tries to list several options to accomplish the same thing. We want you to know your options and choose the solution that is best for you.</p> <p>That said, the easiest path to integration is almost always to use Substrate API Sidecar to interact with your node and TxWrapper Core to construct and sign transactions. Parity and Web3 Foundation will be able to provide the best support if you use these tools.</p> <p>If your team would like support, join some of our community channels or contact support@polkadot.network.</p>"},{"location":"build/build-light-clients/","title":"Using Light Clients","text":""},{"location":"build/build-light-clients/#blockchain-user-interfaces-are-still-centralized","title":"Blockchain User Interfaces are still Centralized","text":"<p>The communication between a standard user interface (UI) and a network node is through a JSON RPC protocol. Generally, the UI will showcase the information that is available on the node, and this is done through two main approaches:</p> <ol> <li>User-Controlled Nodes: The UI connects to a node client that the user has installed on their    machine.    - These nodes are secure, but installation and maintenance of these nodes tend to be an      inconvenience.</li> <li>Publicly-Accessible Nodes: The UI connects to a third-party-owned publicly-accessible node    client.    - While these nodes are more prevalent in their usage as they are convenient to use, they are      centralized and insecure.</li> </ol> <p>There is now a new paradigm: instead of specifying a centralized RPC node, developers just need to define the blockchain's chain specification for their application to synchronize with the chain. This is possible with Substrate connect.</p>"},{"location":"build/build-light-clients/#what-is-substrate-connect","title":"What is Substrate Connect?","text":""},{"location":"build/build-light-clients/#replacing-rpc-node-reliance-with-light-clients","title":"Replacing RPC node reliance with light clients","text":"<p>Substrate connect is a JavaScript library and browser extension that builds on the PolkadotJS API to enable developers to build application-specific light clients for Substrate chains. There is no installation required or optional extension with minimal or no maintenance. The node is run by the JavaScript engine.</p> <p>Simply put, Substrate connect is a Substrate client that runs in JavaScript.</p> <p>Application developers no longer need to rely on single RPC nodes to allow end-users to interact with their applications.</p>"},{"location":"build/build-light-clients/#substrate-full-node-vs-substrate-connect-light-client","title":"Substrate (full node) vs. Substrate connect (light client)","text":"<p>A light client lets you utilize all basic features of the chain such as fetching data and transferring tokens, but it does not require you to run a full copy of the entire blockchain or having to trust remote peers. Light clients fetch the required data that they need from a Polkadot node with an associated proof to validate the data.</p> Substrate: Full node Substrate connect: Light client full verification of all blocks of the chain only verifies the authenticity of blocks of the chain holds all of the previous block data and the chain's storage in database no database installation, maintenance, and execution tend to be exhaustive and require system administration expertise. no installation; has an optional extension with minimal or no maintenance. Initializes in five to ten seconds"},{"location":"build/build-light-clients/#how-to-use-substrate-connect","title":"How to use Substrate Connect","text":""},{"location":"build/build-light-clients/#as-a-javascript-library","title":"As a JavaScript library","text":"<p>Substrate connect provides a PolkadotJS API connected to a bundled node. Through the use of the library, a user can run an actual Substrate-compatible node.</p>"},{"location":"build/build-light-clients/#a-node-bundled-with-its-user-interface-ready-to-use-light-clients","title":"A node bundled with its user interface: ready-to-use light clients","text":"<p>The UI connects to a node client that is directly integrated: convenient, secure, and decentralized. This is accomplished through Substrate connect using a smoldot Wasm light client to securely connect to the blockchain network without relying on specific third parties.</p> <p>Application developers can now run a Substrate light client in any NodeJS environment (@substrate/connect). Currently, Substrate connect supports Polkadot, Kusama, and Westend; because light clients are part of the overall Substrate framework, they are available for Substrate-based blockchains.</p>"},{"location":"build/build-light-clients/#as-a-browser-extension","title":"As a browser extension","text":"<p>Establishing a sufficient number of peers is difficult due to browser limitations on WebSockets from HTTPS pages, as many nodes need to be available with TLS. The browser extension provided by Substrate connect helps to overcome this limitation and keeps the chains synced in the background, allowing applications to run faster.</p>"},{"location":"build/build-light-clients/#bundling-light-clients-of-multiple-chains","title":"Bundling light-clients of multiple chains","text":"<p>The browser extension allows end-users to interact with applications connected to multiple blockchains or connect their own blockchains to applications that support it.</p> <p>Note</p> <p>Substrate Connect will auto-detect whether a user is using the extension. If not, the Wasm light client will be created in-page for them.</p>"},{"location":"build/build-light-clients/#resources","title":"Resources","text":"<ul> <li>What is a light client and why you should care?</li> <li>Introducing Substrate Connect: Browser-Based Light Clients for Connecting to Substrate Chains</li> <li>Substrate connect GitHub Repo</li> </ul>"},{"location":"build/build-network-overview/","title":"Development Networks","text":"<p>While Polkadot itself is the mainnet, there are several networks that can cater to different development or application-driven contexts.</p> <p>Looking for faucets?</p> <p>See here for all available faucets and how to obtain testnet tokens.</p>"},{"location":"build/build-network-overview/#polkadot-ecosystem-networks","title":"Polkadot Ecosystem Networks","text":"<ul> <li>Mainnet: Polkadot</li> <li>Canary network: Kusama</li> <li>Kusama is a value-bearing canary network that gets features before     Polkadot does. Expect Chaos.</li> <li>Official testnets:</li> <li>Westend - Functionality equal to the current Polkadot mainnet, with possible next-generation     testing of features from time to time that will eventually migrate onto Polkadot. Perma-testnet     (is not reset back to genesis block).</li> <li>Paseo - A community-run testnet which mirrors the Polkadot runtime. It is maintained by the     community.</li> </ul> <p>Polkadot mainnet has been running since May 2020 and has implementations in various programming languages ranging from Rust to JavaScript. The leading implementation is built in Rust and uses the Substrate framework.</p> <p>Tooling is rapidly evolving to interact with the network; there are many ways to get started!</p> <p>But before you jump head-first into the code, you should consider the kind of decentralized application you want to make and understand the different paradigms available to developers who want to build on Polkadot.</p>"},{"location":"build/build-network-overview/#interfacing-polkadotjs","title":"Interfacing - PolkadotJS","text":"<p>PolkadotJS is the most widely used developer tool in the Polkadot ecosystem. It provides a web app to interact with various parachains, nodes, and their RPCs, as well as a Javascript API for use within front-end contexts. You can view more on PolkadotJS and its resources here.</p> <p>For other programmatic ways of interacting with these networks (including PolkadotJS), please view the Node Interactions page.</p>"},{"location":"build/build-network-overview/#testnet-faucets","title":"Testnet Faucets","text":"<p>Almost all tesnets either have a web-based interface for getting test currency or a Matrix room which you can post <code>!drip &lt;ADDRESS&gt;</code></p> <p>See here for all available faucets and how to obtain testnet tokens.</p>"},{"location":"build/build-node-interaction/","title":"Node Interaction","text":"<p>This page will guide you through some basic interactions with your node. This guide should guide you to the proper tools, not be seen as canonical reference. Always refer to the proper documentation for the tool you are using:</p> <ul> <li>Substrate RPC API</li> <li>Polkadot-JS RPC</li> <li>Substrate API Sidecar</li> </ul> <p>Polkadot-JS RPC is a JavaScript library for interacting with the Substrate RPC API endpoint, distributed as <code>@polkadot/api</code> Node.js package. Substrate API Sidecar is using the Polkadot-JS RPC to provide separately runnable REST services.</p>"},{"location":"build/build-node-interaction/#polkadot-rpc","title":"Polkadot RPC","text":"<p>The Parity Polkadot client exposes HTTP and WS endpoints for RPC connections. The default ports are 9933 for HTTP and 9944 for WS.</p> <p>To get a list of all RPC methods, the node has an RPC endpoint called <code>rpc_methods</code>.</p> <p>For example, using websocat:</p> <pre><code>echo '{\"id\":1,\"jsonrpc\":\"2.0\",\"method\":\"rpc_methods\",\"params\":[]}' | websocat -n1 -B 99999999 ws://127.0.0.1:9944\n\n{\"jsonrpc\":\"2.0\",\"result\":{\"methods\":[\"account_nextIndex\",\"author_hasKey\",\"author_hasSessionKeys\",\"author_insertKey\",\"author_pendingExtrinsics\",\"author_removeExtrinsic\",\"author_rotateKeys\",\"author_submitAndWatchExtrinsic\",\"author_submitExtrinsic\",\"author_unwatchExtrinsic\",\"babe_epochAuthorship\",\"beefy_getFinalizedHead\",\"beefy_subscribeJustifications\",\"beefy_unsubscribeJustifications\",\"chain_getBlock\",\"chain_getBlockHash\",\"chain_getFinalisedHead\",\"chain_getFinalizedHead\",\"chain_getHead\",\"chain_getHeader\",\"chain_getRuntimeVersion\",\"chain_subscribeAllHeads\",\"chain_subscribeFinalisedHeads\",\"chain_subscribeFinalizedHeads\",\"chain_subscribeNewHead\",\"chain_subscribeNewHeads\",\"chain_subscribeRuntimeVersion\",\"chain_unsubscribeAllHeads\",\"chain_unsubscribeFinalisedHeads\",\"chain_unsubscribeFinalizedHeads\",\"chain_unsubscribeNewHead\",\"chain_unsubscribeNewHeads\",\"chain_unsubscribeRuntimeVersion\",\"childstate_getKeys\",\"childstate_getKeysPaged\",\"childstate_getKeysPagedAt\",\"childstate_getStorage\",\"childstate_getStorageEntries\",\"childstate_getStorageHash\",\"childstate_getStorageSize\",\"grandpa_proveFinality\",\"grandpa_roundState\",\"grandpa_subscribeJustifications\",\"grandpa_unsubscribeJustifications\",\"mmr_generateBatchProof\",\"mmr_generateProof\",\"offchain_localStorageGet\",\"offchain_localStorageSet\",\"payment_queryFeeDetails\",\"payment_queryInfo\",\"state_call\",\"state_callAt\",\"state_getChildReadProof\",\"state_getKeys\",\"state_getKeysPaged\",\"state_getKeysPagedAt\",\"state_getMetadata\",\"state_getPairs\",\"state_getReadProof\",\"state_getRuntimeVersion\",\"state_getStorage\",\"state_getStorageAt\",\"state_getStorageHash\",\"state_getStorageHashAt\",\"state_getStorageSize\",\"state_getStorageSizeAt\",\"state_queryStorage\",\"state_queryStorageAt\",\"state_subscribeRuntimeVersion\",\"state_subscribeStorage\",\"state_traceBlock\",\"state_trieMigrationStatus\",\"state_unsubscribeRuntimeVersion\",\"state_unsubscribeStorage\",\"subscribe_newHead\",\"sync_state_genSyncSpec\",\"system_accountNextIndex\",\"system_addLogFilter\",\"system_addReservedPeer\",\"system_chain\",\"system_chainType\",\"system_dryRun\",\"system_dryRunAt\",\"system_health\",\"system_localListenAddresses\",\"system_localPeerId\",\"system_name\",\"system_nodeRoles\",\"system_peers\",\"system_properties\",\"system_removeReservedPeer\",\"system_reservedPeers\",\"system_resetLogFilter\",\"system_syncState\",\"system_unstable_networkState\",\"system_version\",\"unsubscribe_newHead\"],\"version\":1},\"id\":1}\n</code></pre> <p>Note that this call will show even those RPC methods which are disabled by a safety flag like <code>--rpc-methods Safe</code>. This is being worked on.</p> <p>Add parameters in the call, for example get a block by its hash value:</p> <pre><code>echo '{\"id\":1,\"jsonrpc\":\"2.0\",\"method\":\"chain_getBlock\",\"params\":[\"0x7d4ef171d483d37aa2339877524f0731af98e367c38f8fa27f133193ed2b5615\"]}' | websocat -n1 -B 99999999 ws://127.0.0.1:9944\n\n{\"jsonrpc\":\"2.0\",\"result\":{\"block\":{\"header\":{\"parentHash\":\"0xb5e10293122a3c706dfcf5c0e89d5fb90929e7ee580c5167e439afa330fae2c7\",\"number\":\"0xbb07fe\",\"stateRoot\":\"0x872dfbb3516a6e3b9becf01bb2192e53a1d77ef6c37e426f03ebf64b33a68ede\",\"extrinsicsRoot\":\"0xe131e6af57c503ca6c6a151b2e621d05f65ef7be07e24abc2444fa1eb67c444a\",\"digest\":{\"logs\":[\"0x0642414245b50103b9000000ebdf8810000000002621c85fe312c4b8b9db111b9311a2857e265a62c7bd5a9b08f3e0989e51ea619481408decdc83f0f1322b706b50904f692f3c2dd505e7633dc029ca38a3f40072e7378760cf44e83566ec92ee330042d916684e957399badba91ed342a3270d\",\"0x0542414245010190e94b9f1af95ae7645f85dc3d49f4c73dcce31083c9e1f712523a9b132aff798f89e0e6146429a869dde4ee060e7630831890f15942d5889ac4dfa24150368a\"]}},\"extrinsics\":[\"0x280403000bd61300888301\",\"...\"]},\"justifications\":null},\"id\":1}\n</code></pre> <p>Some return values may not appear meaningful at first glance. Polkadot uses SCALE encoding as a format that is suitable for resource-constrained execution environments. You will need to decode the information and use the chain metadata (<code>state_getMetadata</code>) to obtain human-readable information.</p>"},{"location":"build/build-node-interaction/#tracking-the-chain-head","title":"Tracking the Chain Head","text":"<p>Use the RPC endpoint <code>chain_subscribeFinalizedHeads</code> to subscribe to a stream of hashes of finalized headers, or <code>chain_FinalizedHeads</code> to fetch the latest hash of the finalized header. Use <code>chain_getBlock</code> to get the block associated with a given hash. <code>chain_getBlock</code> only accepts block hashes, so if you need to query intermediate blocks, use <code>chain_getBlockHash</code> to get the block hash from a block number.</p>"},{"location":"build/build-node-interaction/#substrate-api-sidecar","title":"Substrate API Sidecar","text":"<p>Parity maintains an RPC client, written in TypeScript, that exposes a limited set of endpoints. It handles the metadata and codec logic so that you are always dealing with decoded information. It also aggregates information that an infrastructure business may need for accounting and auditing, e.g. transaction fees.</p> <p>The sidecar can fetch blocks, get the balance of an address atomically (i.e., with a corresponding block number), get the chain's metadata, get a transaction fee prediction, calculate outstanding staking rewards for an address, submit transactions to a node's transaction queue, and much more.</p> <p>The client runs on an HTTP host. The following examples use python3, but you can query any way you prefer at <code>http://HOST:PORT/</code>. The default is <code>http://127.0.0.1:8080</code>.</p>"},{"location":"build/build-node-interaction/#fetching-a-block","title":"Fetching a Block","text":"<p>Fetch a block using the <code>block/number</code> endpoint. To get the chain tip, omit the block number.</p> <pre><code>import requests\nimport json\n\nurl = 'http://127.0.0.1:8080/blocks/7409038'\nresponse = requests.get(url)\nif response.ok:\n    block_info = json.loads(response.text)\n    print(block_info)\n</code></pre> <p>This returns a fully decoded block.</p> <p>In the <code>balances.transfer</code> extrinsic, the <code>partialFee</code> item is the transaction fee. It is called \"partial fee\" because the total fee would include the <code>tip</code> field. Notice that some extrinsics do not have a signature. These are inherents.</p> <p>Tracking transaction fees</p> <p>When tracking transaction fees, the <code>extrinsics.paysFee</code> value is not sufficient for determining if    the extrinsic had a fee. This field only means that it would require a fee if submitted as a    transaction. In order to charge a fee, a transaction also needs to be signed. So in the following    example, the <code>timestamp.set</code> extrinsic does not pay a fee because it is an inherent, put in the    block by the block author.</p> <pre><code>{\n   \"number\":\"7409038\",\n   \"hash\":\"0x0e9610f3c89fac046ef83aa625ad414d5403031faa026b7ab2a918184e389968\",\n   \"parentHash\":\"0xba308541eb207bc639f36d392706309a031c21622f883fb07411060389c5ffdd\",\n   \"stateRoot\":\"0x4426383b64a944ad7222a4019aefd558c749da0c6920cfcdfd587741d54abbe2\",\n   \"extrinsicsRoot\":\"0x74749e5f5aeb610bc23fd6d8d79fd8bbf5e4b6053f70ba94ea6b3cc271df4b3a\",\n   \"authorId\":\"Fvvz6Ej1D5ZR5ZTK1vE1dCjBvkbxE1VncptEtmFaecXe4PF\",\n   \"logs\":[\n      {\n         \"type\":\"PreRuntime\",\n         \"index\":\"6\",\n         \"value\":[\n            \"BABE\",\n            \"0x023a0200009c7d191000000000\"\n         ]\n      },\n      {\n         \"type\":\"Seal\",\n         \"index\":\"5\",\n         \"value\":[\n            \"BABE\",\n            \"0x2296a50fa4fea3a46a95ad5b1f09de76d22c6ed3dc6755718c976e2d14c63e4dd3c6257813d9bdc03bb180b1e20393f1558ae1204982e5c7570df393e11f908b\"\n         ]\n      }\n   ],\n   \"onInitialize\":{\n      \"events\":[\n\n      ]\n   },\n   \"extrinsics\":[\n      {\n         \"method\":{\n            \"pallet\":\"timestamp\",\n            \"method\":\"set\"\n         },\n         \"signature\":null,\n         \"nonce\":null,\n         \"args\":{\n            \"now\":\"1620636072000\"\n         },\n         \"tip\":null,\n         \"hash\":\"0x8b853f49b6543e4fcbc796ad3574ea5601d2869d80629e080e501da4cb7b74b4\",\n         \"info\":{\n\n         },\n         \"events\":[\n            {\n               \"method\":{\n                  \"pallet\":\"system\",\n                  \"method\":\"ExtrinsicSuccess\"\n               },\n               \"data\":[\n                  {\n                     \"weight\":\"185253000\",\n                     \"class\":\"Mandatory\",\n                     \"paysFee\":\"Yes\"\n                  }\n               ]\n            }\n         ],\n         \"success\":true,\n         \"paysFee\":false\n      },\n      {\n         \"method\":{\n            \"pallet\":\"balances\",\n            \"method\":\"transfer\"\n         },\n         \"signature\":{\n            \"signature\":\"0x94b63112648e8e692f0076fa1ccab3a04510c269d1392c1df2560503865e144e3afd578f1e37e98063b64b98a77a89a9cdc8ade579dcac0984e78d90646a052001\",\n            \"signer\":{\n               \"id\":\"Gr5sBB1EgdmQ7FG3Ud2BdECWQTMDXNgGPfdHMMtDsmT4Dj3\"\n            }\n         },\n         \"nonce\":\"12\",\n         \"args\":{\n            \"dest\":{\n               \"id\":\"J6ksma2jVeHRcRoYPZBkJRzRbckys7oSmgvjKLrVbj1U8bE\"\n            },\n            \"value\":\"100000000\"\n         },\n         \"tip\":\"0\",\n         \"hash\":\"0xfbc5e5de75d64abe5aa3ee9272a3112b3ce53710664f6f2b9416b2ffda8799c2\",\n         \"info\":{\n            \"weight\":\"201217000\",\n            \"class\":\"Normal\",\n            \"partialFee\":\"2583332634\"\n         },\n         \"events\":[\n            {\n               \"method\":{\n                  \"pallet\":\"balances\",\n                  \"method\":\"Transfer\"\n               },\n               \"data\":[\n                  \"Gr5sBB1EgdmQ7FG3Ud2BdECWQTMDXNgGPfdHMMtDsmT4Dj3\",\n                  \"J6ksma2jVeHRcRoYPZBkJRzRbckys7oSmgvjKLrVbj1U8bE\",\n                  \"100000000\"\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"balances\",\n                  \"method\":\"Deposit\"\n               },\n               \"data\":[\n                  \"Fvvz6Ej1D5ZR5ZTK1vE1dCjBvkbxE1VncptEtmFaecXe4PF\",\n                  \"2583332634\"\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"system\",\n                  \"method\":\"ExtrinsicSuccess\"\n               },\n               \"data\":[\n                  {\n                     \"weight\":\"201217000\",\n                     \"class\":\"Normal\",\n                     \"paysFee\":\"Yes\"\n                  }\n               ]\n            }\n         ],\n         \"success\":true,\n         \"paysFee\":true\n      },\n      {\n         \"method\":{\n            \"pallet\":\"utility\",\n            \"method\":\"batch\"\n         },\n         \"signature\":{\n            \"signature\":\"0x8aa2fc3f0cff52533745679523705720cff42d0e7258b9797feed193deb0ca73474726e148af0a0b096d44c07f20e5292819ec92279cffb2897e95cc337e638e\",\n            \"signer\":{\n               \"id\":\"F4gmSZGiM9pMYPsKW7xnGktDr4zRmN2jqy5Ze678y9YWR7F\"\n            }\n         },\n         \"nonce\":\"687\",\n         \"args\":{\n            \"calls\":[\n               {\n                  \"method\":{\n                     \"pallet\":\"staking\",\n                     \"method\":\"payoutStakers\"\n                  },\n                  \"args\":{\n                     \"validator_stash\":\"Cfish3zJiFnTvR9jscCap7imeA9ep3cH1wZfcZwAp2gdZHo\",\n                     \"era\":\"2229\"\n                  }\n               },\n               {\n                  \"method\":{\n                     \"pallet\":\"staking\",\n                     \"method\":\"payoutStakers\"\n                  },\n                  \"args\":{\n                     \"validator_stash\":\"Cfish3zJiFnTvR9jscCap7imeA9ep3cH1wZfcZwAp2gdZHo\",\n                     \"era\":\"2230\"\n                  }\n               },\n               {\n                  \"method\":{\n                     \"pallet\":\"staking\",\n                     \"method\":\"payoutStakers\"\n                  },\n                  \"args\":{\n                     \"validator_stash\":\"Cfish3zJiFnTvR9jscCap7imeA9ep3cH1wZfcZwAp2gdZHo\",\n                     \"era\":\"2231\"\n                  }\n               },\n               {\n                  \"method\":{\n                     \"pallet\":\"staking\",\n                     \"method\":\"payoutStakers\"\n                  },\n                  \"args\":{\n                     \"validator_stash\":\"DifishR4auphofhzxsy2aupgYo4NaUECH7qgt71CgiB2o6P\",\n                     \"era\":\"2231\"\n                  }\n               },\n               {\n                  \"method\":{\n                     \"pallet\":\"staking\",\n                     \"method\":\"payoutStakers\"\n                  },\n                  \"args\":{\n                     \"validator_stash\":\"J1fishfH94nFZLNScHgC2HorWpFD2xdPxd96wtTCHLvKxfa\",\n                     \"era\":\"2231\"\n                  }\n               }\n            ]\n         },\n         \"tip\":\"0\",\n         \"hash\":\"0x69171ec3f4e5e4dfd27f4d1c5b5dbc884932c5d9a078c84495bb7ab875c8785f\",\n         \"info\":{\n            \"weight\":\"629782467000\",\n            \"class\":\"Normal\",\n            \"partialFee\":\"5150837715\"\n         },\n         \"events\":[\n            {\n               \"method\":{\n                  \"pallet\":\"staking\",\n                  \"method\":\"Reward\"\n               },\n               \"data\":[\n                  \"Cfish3zJiFnTvR9jscCap7imeA9ep3cH1wZfcZwAp2gdZHo\",\n                  \"40730624074\"\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"staking\",\n                  \"method\":\"Reward\"\n               },\n               \"data\":[\n                  \"FhLcXuFkTwyc3o9K82VBahpain1YHWyGeNMDTTyeDJKfm5b\",\n                  \"4296071738\"\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"staking\",\n                  \"method\":\"Reward\"\n               },\n               \"data\":[\n                  \"F1NyXFUayqmVMdjNK45hcaTCE3JiqdU83sEGhQ3HQXn2Rpq\",\n                  \"1770904403\"\n               ]\n            },\n\n            // ...\n\n            {\n               \"method\":{\n                  \"pallet\":\"utility\",\n                  \"method\":\"BatchCompleted\"\n               },\n               \"data\":[\n\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"balances\",\n                  \"method\":\"Deposit\"\n               },\n               \"data\":[\n                  \"Fvvz6Ej1D5ZR5ZTK1vE1dCjBvkbxE1VncptEtmFaecXe4PF\",\n                  \"5150837715\"\n               ]\n            },\n            {\n               \"method\":{\n                  \"pallet\":\"system\",\n                  \"method\":\"ExtrinsicSuccess\"\n               },\n               \"data\":[\n                  {\n                     \"weight\":\"629782467000\",\n                     \"class\":\"Normal\",\n                     \"paysFee\":\"Yes\"\n                  }\n               ]\n            }\n         ],\n         \"success\":true,\n         \"paysFee\":true\n      }\n   ],\n   \"onFinalize\":{\n      \"events\":[\n\n      ]\n   },\n   \"finalized\":true\n}\n</code></pre> <p>The JS number type is a 53 bit precision float</p> <p>There is no guarantee that the numerical values in the response will have a numerical type. Any    numbers larger than <code>2**53-1</code> will have a string type.</p>"},{"location":"build/build-node-interaction/#submitting-a-transaction","title":"Submitting a Transaction","text":"<p>Submit a serialized transaction using the <code>transaction</code> endpoint with an HTTP POST request.</p> <pre><code>import requests\nimport json\n\nurl = 'http://127.0.0.1:8080/transaction/'\ntx_headers = {'Content-type' : 'application/json', 'Accept' : 'text/plain'}\nresponse = requests.post(\n    url,\n    data='{\"tx\": \"0xed0...000\"}', # A serialized tx.\n    headers=tx_headers\n)\ntx_response = json.loads(response.text)\n</code></pre> <p>If successful, this endpoint returns a JSON with the transaction hash. In case of error, it will return an error report, e.g.:</p> <pre><code>{\n    \"error\": \"Failed to parse a tx\" | \"Failed to submit a tx\",\n    \"cause\": \"Upstream error description\"\n}\n</code></pre>"},{"location":"build/build-node-management/","title":"Node Management","text":"<p>This page contains basic information about running a Parity Polkadot client. There are a lot of ways to obtain/run a client, e.g. compiling from source, running in Docker, or downloading a binary. This guide will always refer to the executable as <code>polkadot</code>.</p> <p>Always refer to the client's help <code>polkadot --help</code> for the most up-to-date information.</p> <p>Note</p> <p>Other client implementation teams: Feel free to make a PR to this page with instructions (or a link to instructions) for your client.</p> <p>If you are trying to run a validator, refer to this tutorial here.</p>"},{"location":"build/build-node-management/#basic-node-operations","title":"Basic Node Operations","text":"<p>Selecting a chain</p> <p>Use the <code>--chain &lt;chainspec&gt;</code> option to select the chain. Can be <code>polkadot</code>, <code>kusama</code>, <code>westend</code>, or a custom chain spec. By default, the client will start Polkadot. Watch How a single codebase can power four different blockchains to learn more about how the chain selection works internally.</p> <p>Archive node</p> <p>An archive node does not prune any block or state data. Use the <code>--pruning archive</code> flag. Certain types of nodes like validators must run in archive mode. Likewise, all events are cleared from state in each block, so if you want to store events then you will need an archive node.</p> <p>Explainer video on upgrading a node</p> <p>To upgrade a node, please refer to this video</p> <p>Exporting blocks</p> <p>To export blocks to a file, use <code>export-blocks</code>. Export in JSON (default) or binary (<code>--binary true</code>).</p> <pre><code>polkadot export-blocks --from 0 &lt;output_file&gt;\n</code></pre> <p>RPC ports</p> <p>Use the <code>--rpc-external</code> flag to expose RPC ports. Not all RPC calls are safe to allow and you should use an RPC proxy to filter unsafe calls. Select ports with the <code>--rpc-port</code> option. To limit the hosts who can access, use the <code>--rpc-cors</code> option.</p> <p>Execution</p> <p>The Parity Polkadot client implements a Polkadot Host and a native runtime. The runtime must compile to WebAssembly and is stored on-chain. If the client's runtime is the same spec as the runtime that is stored on-chain, then the client will execute blocks using the client binary. Otherwise, the client will execute the Wasm runtime from the chain.</p> <p>Therefore, when syncing the chain, the client will execute blocks from past runtimes using their associated Wasm binary. This feature also allows forkless upgrades: the client can execute a new runtime without updating the client.</p> <p>Parity's Polkadot client has two Wasm execution methods, interpreted (default) and compiled. Set the preferred method to use when executing Wasm with <code>--wasm-execution &lt;Interpreted|Compiled&gt;</code>. Compiled execution will run much faster, especially when syncing the chain, but is experimental and may use more memory/CPU. A reasonable tradeoff would be to sync the chain with compiled execution and then restart the node with interpreted execution.</p>"},{"location":"build/build-node-management/#file-structure","title":"File Structure","text":"<p>The node stores a number of files in: <code>/home/$USER/.local/share/polkadot/chains/&lt;chain name&gt;/</code>. You can set a custom path with <code>--base-path &lt;path&gt;</code>.</p> <p><code>keystore</code></p> <p>The keystore stores session keys, which are important for validator operations.</p> <ul> <li>Polkadot documentation</li> <li>Substrate documentation</li> </ul> <p><code>db</code></p> <p>The database stores blocks and the state trie. If you are running a validator node, it also stores GRANDPA pre-votes and pre-commits and the offchain-worker DB. Use caution when migrating validator nodes to avoid equivocation. If you want to start a new machine without resyncing, you can stop your node, back up the DB, and move it to a new machine.</p> <p>To delete your DB and re-sync from genesis, run:</p> <pre><code>polkadot purge-chain\n</code></pre> <p>!!!note Va\"lidators should sync using the RocksDb backend\"     This is implicit by default, but can be explicit by passing the <code>--database RocksDb</code> flag. In the     future, it is recommended to switch to using the faster and more efficient ParityDb option.     Switching between database backends will require a resync.</p> <pre><code>If you want to test out ParityDB you can add the flag `--database paritydb`.\n</code></pre>"},{"location":"build/build-node-management/#monitoring-and-telemetry","title":"Monitoring and Telemetry","text":"<p>Node status</p> <p>You can check the node's health via RPC with websocat:</p> <pre><code>echo '{\"id\":1,\"jsonrpc\":\"2.0\",\"method\":\"system_health\",\"params\":[]}' | websocat -n1 -B 99999999 ws://127.0.0.1:9944\n\n{\"jsonrpc\":\"2.0\",\"result\":{\"peers\":50,\"isSyncing\":false,\"shouldHavePeers\":true},\"id\":1}\n</code></pre> <p>Logs</p> <p>The Polkadot client has a number of log targets. The most interesting to users may be:</p> <ul> <li><code>afg</code> (Al's Finality Gadget - GRANDPA consensus)</li> <li><code>babe</code></li> <li><code>telemetry</code></li> <li><code>txpool</code></li> <li><code>usage</code></li> </ul> <p>Other targets include: <code>db, gossip, peerset, state-db, state-trace, sub-libp2p, trie, wasm-executor, wasm-heap</code>.</p> <p>The log levels, from least to most verbose, are:</p> <ul> <li><code>error</code></li> <li><code>warn</code></li> <li><code>info</code></li> <li><code>debug</code></li> <li><code>trace</code></li> </ul> <p>All targets are set to <code>info</code> logging by default. You can adjust individual log levels using the <code>--log (-l short)</code> option, for example <code>-l afg=trace,sync=debug</code> or globally with <code>-ldebug</code>.</p> <p>Telemetry &amp; Metrics</p> <p>The Parity Polkadot client connects to telemetry by default. You can disable it with <code>--no-telemetry</code>, or connect only to specified telemetry servers with the <code>--telemetry-url</code> option (see the help options for instructions). Connecting to public telemetry may expose information that puts your node at higher risk of attack. You can run your own, private telemetry server or deploy a <code>substrate-telemetry</code> instance to a Kubernetes cluster using this Helm chart.</p> <p>The node also exposes a Prometheus endpoint by default (disable with <code>--no-prometheus</code>). Substrate has a monitor node metrics tutorial which uses this endpoint.</p>"},{"location":"build/build-open-source/","title":"Open Source Polkadot Stack","text":"<p>Do your research before using open-source tools</p> <p>The tools listed here are open-source and are linked directly to their source code. Before using these tools to build your projects, always do your research and be aware of scams.</p> <p>This page aims to provide an overview of the open-source Polkadot Tech Stack.</p> <p>This is a living document, and we rely on everyone to contribute and help maintain it. Please feel free to make edits and additions via pull requests. We apologize if we missed your project!</p> <ul> <li>About</li> <li>Layers of Polkadot Stack</li> <li>Wallets</li> <li>User Interface</li> <li>Tools, APIs, and Languages</li> <li>ink! Smart Contracts</li> <li>Chains and Pallets</li> <li>Host</li> <li>Network Maintenance Tools</li> <li>Signatures</li> <li>Consensus</li> <li>Networking</li> <li>Primitives</li> <li>Contributing</li> </ul>"},{"location":"build/build-open-source/#about","title":"About","text":"<p>The Polkadot Tech Stack is a subset of the Web 3.0 Tech Stack, which consists of the open-source technologies contributing to and relying on Polkadot. It is meant to be used for decentralized application (Dapp) development within numerous verticals, including DeFi, Gaming, Provenance and many others not pictured below.</p> <pre><code>|------|--------|------------|\n| DeFi | Gaming | Provenance |\n|______|________|____________|\n            Dapps\n|--------------------------/-|\n| Explorers, Wallets      /  |\n|------------------------/---|\n| Tools, Apis, Languages/    |\n|----------------------/-----|\n| 2nd layer protocols /      |\n|--------------------/-------|\n| Chains            /  other |\n|------------------/---    --|\n| *Polkadot*      |   tech   |\n|------------------\\---------|\n| P2P, Crypto, Wasm \\        |\n|--------------------\\-------|\n</code></pre>"},{"location":"build/build-open-source/#layers-of-polkadot-stack","title":"Layers of Polkadot Stack","text":"<p>In the below sections, you can find a list of different layers of the Polkadot Stack.</p> <p>Maintenance Status:</p> <ul> <li>\ud83d\udfe2 Actively maintained</li> <li>\ud83d\udfe1 Stale (no activity on the main branch for one month)</li> <li>\u26aa Unmaintained (no activity on the main branch for more than three months)</li> </ul>"},{"location":"build/build-open-source/#wallets","title":"Wallets","text":"Components Existing projects Potentially interesting projects Web Wallets Multix \ud83d\udfe2, Polkasafe \u26aa, polkadot-js/apps \ud83d\udfe2, Talisman Web Application \ud83d\udfe2, mydotwallet \u26aa, Sub ID \u26aa, Primis \u26aa, Sakura \u26aa, Web3Box \u26aa, Coong Wallet \u26aa, Subscan Multisig UI - React \ud83d\udfe2, Subscan Multisig UI \u26aa, Dorafactory-Multisig \u26aa, Capi Multisig App \u26aa User-friendly Wallet based on the Recovery Pallet, Web wallets focused on user-onboarding (e.g. using localStorage) Desktop Wallets nova-spektr \ud83d\udfe2, Omni desktop \u26aa Enterprise Wallets Browser Extensions Talisman-Extension \ud83d\udfe2, SubWallet-Extension \ud83d\udfe2, Enkrypt \ud83d\udfe2, Polkadot-JS \ud83d\udfe2, PolkaGate \ud83d\udfe1, Trust Wallet Extension \ud83d\udfe2, Doter \u26aa, Speckle OS \u26aa, Kuma Cross-chain Wallet \u26aa Sign-in with your Polkadot, Kusama, etc. account. Mobile Wallets Nova Wallet iOS \ud83d\udfe2, Nova Wallet Android \ud83d\udfe2, Polkadot Vault \ud83d\udfe2, Fearless Wallet Android \ud83d\udfe2, Fearless Wallet iOS \u26aa, Trust Wallet \ud83d\udfe2, SubWallet-Mobile \u26aa, Kampela \ud83d\udfe1, AirGap \ud83d\udfe2, Interstellar Network \u26aa, Lunie \u26aa, Polkawallet \u26aa, imToken \u26aa, Stylo \u26aa, Fractapp \u26aa, Hashed Wallet \u26aa Burner Wallets/Faucet/Gifts dotdrop \u26aa, KodaDot \u26aa, Astar Faucet Bot \u26aa, Generic sybil-resistant faucet \u26aa, sybil-resistant Chat Bot Faucet Faucet (a sybil-resistant way to receive free tokens) Wallet Plugins Metamask-Snap by Chainsafe \u26aa CLI Wallet Subwallet \u26aa, Proxy-hot-wallet \u26aa Hardware Wallets Ledger Polkadot \u26aa, Ledger Kusama \u26aa, Ledger Statemint \u26aa, Ledger Statemine \u26aa Trezor OAuth2-compatible Wallets DOT Login \u26aa"},{"location":"build/build-open-source/#user-interface","title":"User Interface","text":"Components Existing projects Potentially interesting projects Block Explorers Calamar \u26aa, Polkascan \u26aa, Polkastats \u26aa, Subscan \u26aa, Statescan \ud83d\udfe2, Edgscan \u26aa, Sirato \u26aa, ink! Explorer API \u26aa, Substats \u26aa, Hybrid Block Explorer \u26aa Mempool focused explorer (including parachain transaction) Validator Dashboards Polkadot Telemetry \ud83d\udfe1, Polkacube \u26aa, YieldScan \u26aa, Hubble \u26aa, Cyclops \ud83d\udfe1, Web3Go \u26aa, 1kv insights \u26aa Node Explorers Polkadot Node Explorer \u26aa NFT Explorer NFT Explorer for Kusama &amp; Polkadot \ud83d\udfe2 Governance Dashboards Polkadot Delegation Dashboard \u26aa, Polkassembly \u26aa, dotreasury \ud83d\udfe2, Bright Treasury \u26aa, OpenSquare offchain voting \ud83d\udfe2, OpenGov Insights \u26aa, Treasury Tracker \u26aa, OpenGov CLI \ud83d\udfe2 UI for the Kusama and/or Polkadot treasury (see bounty module), UI for Parachain Lease Offering (PLO) Staking Staking Rewards Collector \ud83d\udfe1, Staking Rewards Viewer \u26aa, Polkadot Staking Site \u26aa, Polkadot Staking Dashboard \ud83d\udfe2, Polkadot/Kusama Validator Selector \u26aa, Staking Income CSV Generator \u26aa Bridge UI Parity Bridges UI \u26aa, Donut Interface (Steem - Dot) \u26aa, Plutonication \ud83d\udfe2 Parachain/Crowdloan Parachains.Network , PolkAuction \u26aa, Crowdloan Front End Template \u26aa, Slothunter \u26aa Identicon Polkicon \ud83d\udfe2, PolkadotWebIdenticon \u26aa, Polkadot Angular IdentIcon \u26aa, Bird Identicon \u26aa Coretime Lastic \ud83d\udfe1, RegionX \ud83d\udfe1 Other Polkadot Cloud \ud83d\udfe2, \u0110\u00d3TConsole \ud83d\udfe2, KappaSigmaMu Fratority \u26aa, DAOSign \u26aa, Quadratic Funding Webapp \u26aa, Polkawatch, Bytepay \u26aa, charging-management-platform \u26aa, subidentity-webapp \u26aa, OpenSquare Paid QA \u26aa, DotPulse \u26aa, Rubeus Keeper \u26aa, Polkaflow \u26aa, ChainViz \ud83d\udfe2, Dotsight \u26aa zkLogin, Portfolio Viewer like Zapper or Zerion"},{"location":"build/build-open-source/#tools-apis-and-languages","title":"Tools, APIs, and Languages","text":"Components Existing projects Potentially interesting projects Runtime/Parachain frameworks Polkadot Blockchain SDK \ud83d\udfe2, Gosemble \ud83d\udfe1, Subsembly \u26aa, Parachain utilities \u26aa, Gantree \u26aa, Cryptex \ud83d\udfe2 Tools to create parachains with other frameworks, like the Cosmos SDK or Polygon CDK Client Libraries Polkadot-API - Typescript \ud83d\udfe2, Reactive DOT - Typescript \ud83d\udfe2, Capi - Typescript \u26aa, sub-api \u26aa, Go \u26aa, .Net \u26aa, .NET Standard 2.0 \u26aa, Substrate .NET Toolchain \ud83d\udfe1, C++ \u26aa, C \u26aa, Haskell \u26aa, Javascript \ud83d\udfe2, Substrate API Sidecar - TypeScript \ud83d\udfe2, Python \u26aa, Java (+ Android) \u26aa, Substrate Client Java \u26aa, Rust SCS \ud83d\udfe2, Rust Parity (subxt) \ud83d\udfe2, subxtpy \u26aa, Rust pdotc PHP (gmajor-encrypt) \u26aa, PHP (neha0921) \u26aa, RPC-Ethereum \ud83d\udfe2, Swift \u26aa, Kotlin \u26aa, substrate-client-kotlin \u26aa, substrate-client-swift \u26aa, Dart \ud83d\udfe2, Substrate Core Polywrapper \u26aa, Substrate SDK iOS \ud83d\udfe1, Substrate SDK Android \u26aa, Dedot - Typescript \ud83d\udfe2 RPC Gateway Subway \ud83d\udfe1 Substrate Contract clients PatractGo \u26aa Easy Runtime Development Subalfred \u26aa, substrate-stencil \u26aa, Play Substrate \u26aa, substrate-node-template , Substrate Playground \u26aa, AssemblyScript Runtime Generation \u26aa, Substrate Package Manager \u26aa, Subsembly: Framework for developing AssemblyScript Substrate Runtimes \u26aa, dependency diener \u26aa IDE Plugins Substrate Marketplace VS Code Plugin \u26aa, VS Code Plugin \u26aa, Atom Code Plugin \u26aa, zombienet extension \u26aa Runtime/Pallet Security Substrate Runtime Fuzzer \ud83d\udfe1, Substrate Toml Lint \u26aa, K specifications \ud83d\udfe2, PolPatrol - Polkadot Runtime Checker \u26aa, pallet-verifier \ud83d\udfe2 Automated Runtime checking tools, economic audit simulator such as gauntlet.network Smart Contract Languages ink! \ud83d\udfe2, Ask! \u26aa, Subscript \u26aa, Solang \ud83d\udfe2, pallet-move \ud83d\udfe1, Move VM Substrate \u26aa, Move smart contract by Neatcoin \u26aa, eBPF Contracts Hackathon \u26aa, PolkaVM \ud83d\udfe2 Functional Programming Languages, other languages with developed toolchains Testing Polkadot introspector \ud83d\udfe1, Subshell \ud83d\udfe1, substrate-simnode \ud83d\udfe1, Halva \u26aa, Redspot \u26aa, MixBytes Tank \u26aa, sub-flood \u26aa, Substrate debug-kit \u26aa, Asset CLI tool \ud83d\udfe1, sub_crash \u26aa, subwasm \ud83d\udfe1, subsee \u26aa, polkadot-lab \u26aa,  RPC-perf \u26aa Static Analysis Substrace \u26aa, Static analyzer for Substrate FRAME's pallets \u26aa, CoinFabrik Scout \ud83d\udfe2, pallet-verifier \ud83d\udfe2 Formal Verification pallet-verifier \ud83d\udfe2, K specifications \ud83d\udfe2 Testnet Zombienet \ud83d\udfe2, Chopsticks \ud83d\udfe2, Polkadot Launch \u26aa, polkadot-starship \u26aa, Fork off Substrate \u26aa, try-runtime-cli \u26aa, Parachain Launch \ud83d\udfe1, Larch Zombienet GUI \u26aa Benchmarking Benchmarking CLI \ud83d\udfe2, Polkadot sTPS \u26aa, Clockchain \u26aa, Substrate Graph Benchmarks \u26aa, ink! &amp; pallet benchmarking template \u26aa, smart-bench \u26aa Blockchain Indexing Engine Squid SDK \ud83d\udfe2, Hybrid Indexer \u26aa, Substrate Archive \u26aa, PSQL Indexer \u26aa, Substrate Graph \u26aa, Subquery \ud83d\udfe2, MBELT3 \ud83d\udfe1, stick \ud83d\udfe2, Hyperdot \u26aa Blockchain/Event Monitoring Web3 Guardian \u26aa, Aurras Event Manager \u26aa, @commonwealth/chain-events \u26aa, Massbit \u26aa, Polkadot Basic Notifications \u26aa, Ocelloids \ud83d\udfe1, Tracking Chain \u26aa, Gaming Polkadot SDK for Unity \u26aa, Crossbow \u26aa Unity Asset Store, Amethyst + Substrate No-code Platforms EzCode's Polkadot-JS plugin on Bubble.io \u26aa, Blackprint Visual Programming Polkadot-JS module \u26aa, SubRelay \u26aa Wallets DOT Connect \ud83d\udfe2, Talisman Connect \u26aa, SubWallet-SubConnect \u26aa, Metadata Portal \ud83d\udfe2, Tesseract \u26aa, WalletConnect \u26aa, BitGoJS \ud83d\udfe2 XCM Trappist \u26aa, XCM-tools \ud83d\udfe2, XCM-tools Golang \u26aa,ParaSpell XCM Tools \ud83d\udfe2, XBI \u26aa, XCM TS/JS SDK \u26aa, XCMSend \ud83d\udfe1, XCM Monitoring Server \ud83d\udfe2, Moonbeam Foundation XCM-SDK \ud83d\udfe2 Other asset-transfer-api \ud83d\udfe2, txwrapper-core \ud83d\udfe1, open-web3 JS library \u26aa, VM-Bridge \u26aa, srtool \ud83d\udfe1, srtool-cli \u26aa, Substrate Tip Bot \ud83d\udfe1, ORI (Onchain Risk Intelligence) \u26aa, PolkaTools \ud83d\udfe2, polkadot-scripts \u26aa, Sube \ud83d\udfe2, data-store-sidecar \u26aa, SugarFunge \u26aa, substrate-wasmedge \u26aa, EightFish \u26aa, Sandox \u26aa, APK verifier \u26aa"},{"location":"build/build-open-source/#ink-smart-contracts","title":"ink! Smart Contracts","text":"Components Existing projects Potentially interesting projects Core Libraries ink! \ud83d\udfe2, cargo-contract \ud83d\udfe2, pallet-contracts \ud83d\udfe2 Local Nodes substrate-contracts-node \ud83d\udfe1, Swanky \u26aa Smart Contract Development DRink! \ud83d\udfe1, contracts-ui \u26aa, SmartBeaver, OpenBrush , Sol2Ink \u26aa, Polkadot Contract Wizard \u26aa, ink-wrapper \u26aa, ink-playground \u26aa, ink! Remix Plugin \u26aa, Signac \u26aa, ink!-boxes \u26aa, ink!-smart-contract-wizard \u26aa Security &amp; Testing ink! Waterfall \u26aa, Verifier Image for ink! \u26aa, Patron \u26aa, Inkscope Fuzzer \u26aa Frontend Development ink!athon Boilerplate \ud83d\udfe1, useink \u26aa, useInkathon \ud83d\udfe1, ink-typegen \ud83d\udfe2, Typechain Polkadot \u26aa, Typink! \ud83d\udfe2 IDE Plugins ink! Analyzer \ud83d\udfe2 Bridges Dante Protocol \u26aa DeFi Pendulum-Ink-Wrapper \u26aa, Panorama Swap \u26aa, ink_bank \u26aa, Polkadot AMM \u26aa, Vera \u26aa, Nsure Insurance , Everlasting Cash \u26aa, Coinversation \u26aa, zenlink-dex-contract \u26aa, AlgoCash \u26aa New seigniorage-style stable coins Gaming Open Emoji Battler \u26aa, NewOmega \u26aa DAO SyncraDAO , subDAO \u26aa, RainbowDAO \u26aa, MangoBox \u26aa, MangoSale \u26aa Identity/DID Dotflow \ud83d\udfe2 Oracles DIA WASM Oracle \u26aa Spam Protection Prosopo \ud83d\udfe2 Governance Abax Governance \u26aa NFT ArtZero \u26aa Other Polkadot Smart Account \u26aa, magink \u26aa, ink-test-contracts \u26aa, Candle Auctions \u26aa, polkasign-contract \u26aa, OCEX \u26aa, Roloi \u26aa, OpenPayroll \u26aa, BlockchainFoodOrder \u26aa"},{"location":"build/build-open-source/#chains-and-pallets","title":"Chains and Pallets","text":"Components Existing projects Potentially interesting projects Scalable Transactions Perun channels \u26aa, CLI demo of Perun \u26aa, Astar \ud83d\udfe2, Celer \u26aa, Gunclear \u26aa, TPScore \u26aa, proof-of-contract-stake \u26aa roll-ups, DAG-based consensus mechanisms, side chains Bridges and Interoperability interBTC \u26aa, DKG Substrate \u26aa, Sygma \u26aa, EOS by Bifrost \u26aa, POA - Substrate \u26aa, Substrate - Ethereum DAI Bridge \u26aa, Substrate - Substrate Bridge \u26aa, BTC by ChainX \u26aa, Cosmos-Substrate bridge \u26aa, Substrate IBC Pallet \u26aa, Polkadot Ethereum Bridge \ud83d\udfe2, Darwinia \ud83d\udfe2, Spacewalk: a Stellar bridge \ud83d\udfe2, Filecoindot \u26aa, Axelar-Substrate \u26aa, Hyperbridge \ud83d\udfe2, t3rn \ud83d\udfe2 ZCash Privacy ZeroChain \u26aa, xx network \u26aa, pLibra (Phala Network) \ud83d\udfe2, Automata Network \u26aa, Zero Network \u26aa, Silent Data \u26aa Multi-Asset Shielded Pool (MASP) , Zkay, Zexe ZKP ZeroPool \u26aa, Megaclite \u26aa, zkMega \u26aa, PLONK for Substrate \u26aa, Webb Anchor Protocol \u26aa, zk-SNARKs tutorial \u26aa, substrate-zk \u26aa, hyperfridge-r0 \u26aa, Cyborg Network \ud83d\udfe2, Manta \ud83d\udfe2 TEE Acurast \u26aa, Integritee \ud83d\udfe2, substraTEE \u26aa, WeTEE \ud83d\udfe2 Keysafe Protocol \u26aa DeFi PrivaDEX \u26aa, Fusotao \u26aa, Reef \u26aa, Diora \u26aa, Pendulum Chain \ud83d\udfe2, Compound Gateway \u26aa, Parallel Finance \u26aa, PINT \u26aa, Laminar Chain \u26aa, Acala \ud83d\udfe2, Centrifuge \ud83d\udfe1, Stafi \u26aa, Definex \u26aa, OAX Foundation \u26aa, Cybex \u26aa, Zenlink \u26aa, Swaps Pallet \u26aa, Polkadex \u26aa, SubDEX \u26aa, Hydration \ud83d\udfe2, Substrate Stablecoin \u26aa, Standard protocol \u26aa, Polkaswap \ud83d\udfe2, Curve AMM \u26aa, Konomi Network \u26aa, Stable Asset \u26aa, Libra Payment \u26aa, Mangata \u26aa, Tidechain \u26aa, Basilisk \ud83d\udfe2, Polymesh \ud83d\udfe2, Bifrost \ud83d\udfe2, Clover \u26aa, Composable Finance  \u26aa, OmniBTC \u26aa, Polimec \ud83d\udfe1 DEX with privacy and confidentiality features such as those found in a dark pool Smart contract chains moonbeam \ud83d\udfe2, Magnet \u26aa, Aleph-node \ud83d\udfe2, Edgeware \u26aa, ParaState \u26aa, gear \ud83d\udfe2, CENNZnet \u26aa, SkyeKiwi \u26aa, OAK-blockchain \u26aa, ICE Blockchain \u26aa, Polkadot Smart Chain \u26aa, Madara - Cairo/Starknet \u26aa smart contract chains with novel security approaches, smart contract chains based on existing toolchains Oracle Tellor \u26aa, Laminar \ud83d\udfe2, Chainlink-polkadot \u26aa, Ares Protocol \u26aa, Kylin Network \u26aa, interbtc-clients oracle \u26aa, Anonima \u26aa, SaaS3 \u26aa, Tellor \u26aa, Bridgestate Oracle \u26aa Identity/DID Parami \u26aa, Litentry \ud83d\udfe2, pallet-did \u26aa, dot-id \u26aa IoT Nodle \u26aa, MXC/DataHighway \u26aa, peaq-network-node \ud83d\udfe2 Verifiable Claims KILT \ud83d\udfe2, Dock \ud83d\udfe2 Supply chain DSCP Node \ud83d\udfe2 Health care Music Industry Allfeat Network \ud83d\udfe2 Data Availability Avail \ud83d\udfe2, Melodot \u26aa Social Networking Frequency \ud83d\udfe2, Social Network \u26aa, SubSocial \ud83d\udfe1, ZeroDAO \u26aa, Myriad Node \ud83d\udfe2, Wika Network \u26aa, Listen \u26aa, Tribal Protocol \u26aa, Five Degrees on Substrate \u26aa, Acuity Social \u26aa Private instant messenger that uses on-chain identity Governance/DAO Aisland Node \u26aa, Hashed Network \u26aa, Sunshine DAO \u26aa, Governance OS \u26aa, Idavoll Network \u26aa, Substrate Moloch \u26aa, QRUCIAL-DAO \u26aa, Societal \u26aa, DAOs \u26aa, Shivarthu \u26aa, Faterium \ud83d\udfe2, Supersig \u26aa, GenesisDAO \u26aa, DAO Entrance , Liberland \ud83d\udfe2 Consul - Open Government and E-Participation Web Software Prediction Markets and Futarchy Zeitgeist \ud83d\udfe2, X Predict Market \u26aa Messaging HOPR \u26aa, Nolik \u26aa, Uke \u26aa, Diffy Chat \u26aa, Fennel Protocol \u26aa File Storage, Cloud Subsocial-Offchain \u26aa, DatDot \u26aa, Crust Network \ud83d\udfe2, offchain::ipfs \u26aa, Canyon Network \u26aa, CESS \ud83d\udfe2, CESS Proving Subsystem , Iris \u26aa, fmd-cess \u26aa, IPFS Frame V3 \u26aa, Threefold Chain \ud83d\udfe1, Apron \u26aa, IPFS Utilities \u26aa, DINFRA \ud83d\udfe2 Name Service Substrate Names \u26aa, ENS on Substrate \u26aa, PNS-Pallets \u26aa, Faceless \u26aa, Anchor \u26aa Gaming Bit.country \ud83d\udfe2, SubGame \u26aa, subzero \u26aa, Web3Games \u26aa, Ajuna Pallets \ud83d\udfe2, Gafi Network \u26aa, Asylum \ud83d\udfe2, 3DPass \ud83d\udfe1, Polket \u26aa Computation/AI Deitos Network \u26aa, DeepBrain Chain \ud83d\udfe2, AI Infrastructure on Blockchain \u26aa, NeuroWeb \u26aa, Infimum \ud83d\udfe1 Enable specific use-cases pallet-hookpoints \u26aa, Robonomics \ud83d\udfe2, UniversalDOT \u26aa, Evercity Sustainable Finance Protocol \u26aa, logion \u26aa, Me Protocol \u26aa, QSTN \u26aa, Subcoin \ud83d\udfe2, Aventus \ud83d\udfe2, Frontier POS template \ud83d\udfe2 NFT ternoa \u26aa, FRAME Pallet: NFTs for Substrate \u26aa, Unique NFT Parachain \u26aa, DNFT \u26aa, RMRK-Substrate \u26aa, NT-NFTs \u26aa, Green Lemon \u26aa, Basilisk \ud83d\udfe2, LAOS \ud83d\udfe2 Randomness DKG and Randomness Beacon \u26aa, drand-substrate-client \u26aa Licensing Anagolay Network Banking Integration FIAT on-off-ramp \u26aa Crowdfunding Imbue Network \u26aa, Quadratic Funding pallet by Dora \u26aa, Quadratic Funding pallet by OAK \u26aa Minimum Anti-Collusion Infrastructure (MACI) Collection of Pallets Substrate Open Runtime Module Library \ud83d\udfe2, warehouse \u26aa, InvArch FRAME Pallet Library \u26aa Marketplaces Dot Marketplace \u26aa, Gated Marketplace \u26aa, Ventur \u26aa, Futur Protocol Carbon Credits BitGreen \u26aa, Carbon Assets Pallet \u26aa, Sequester Pallets \u26aa UTXO Tuxedo \u26aa Other Moonkit \ud83d\udfe1, Substrate Account Filter \u26aa, Subtensor \ud83d\udfe2, AdMeta \u26aa, Chocolate Node \u26aa, Virto Network \ud83d\udfe2, Substrate Validator Set \u26aa, DEIP \u26aa, DeBio \u26aa, MathChain \u26aa, encointer \ud83d\udfe2, Grassland \u26aa, Substrate-Tutorials \ud83d\udfe2, Fair Squares \u26aa, Totem Live Accounting \u26aa, Escrow Pallet \u26aa, TREX \u26aa, Relation Graph \u26aa, Decentralized Invoice \u26aa, Redstone Network \u26aa, Access Control Pallet \u26aa, Omniverse DLT \u26aa, ISMP \u26aa, XCMP \u26aa, CORD Chain \ud83d\udfe2, Educhain \u26aa Decentralized review/reputation system"},{"location":"build/build-open-source/#host","title":"Host","text":"Components Existing projects Potentially interesting projects Rust Substrate \ud83d\udfe2, Cumulus \ud83d\udfe2 C++ Kagome \ud83d\udfe2, Mayon \u26aa Go Gossamer \ud83d\udfe2 Java Fruzhin \ud83d\udfe2, Java Host Research \u26aa AssemblyScript Light Client smoldot \ud83d\udfe2, Substrate Connect \ud83d\udfe2, C++ Polkadot Light Client \u26aa Testing Polkadot Conformance \u26aa, Polkafuzz \u26aa"},{"location":"build/build-open-source/#network-maintenance-tools","title":"Network Maintenance Tools","text":"Components Existing projects Potentially interesting projects Secure validator setup Polkadot Validation Node Ansible Setup \u26aa, W3F Polkadot Validator Setup \u26aa, polkadot-ansible \ud83d\udfe1 High availability setup Archipel \u26aa, Polkadot Failover Mechanism \u26aa, Datagen \u26aa, High Availability Validator Setup \u26aa Load Balanced Endpoints terragrunt-polkadot \u26aa, Geometry Labs' Substrate Meta repo \u26aa Deployment Tools Polkadot Package Manager \u26aa, PolkaHub \u26aa, Avado \u26aa, Polkadot Deployer \u26aa, Unified Collator Deployment \u26aa Validator monitoring ONE-T \ud83d\udfe1, SubVT \ud83d\udfe1, P.A.N.I.C. \u26aa, Polkalert \u26aa, B-Harvest \u26aa, nmonpolkadot \u26aa, Polkadot-K8s-Monitor \u26aa, Polkadot-Watcher \ud83d\udfe1, 1KV Telegram Bot \u26aa Validator payout management Substrate validator auto payout \u26aa, Polkadot Payouts \u26aa, staking-payouts CLI \ud83d\udfe1, Payctl \u26aa, crunch \ud83d\udfe1 Staking Miner Staking Miner v2 \ud83d\udfe2 Nominator Tools Validator Selection \u26aa, Polkanalyzer \u26aa, Polkanalyzer-app \u26aa"},{"location":"build/build-open-source/#signatures","title":"Signatures","text":"Components Existing projects Potentially interesting projects SR25519 rust \u26aa(contains partial bindings for C, JavaScript, and Python), .Net bindings \u26aa, C \u26aa(old), C \u26aa(new), C/C++ \u26aa, C# \u26aa, Go \ud83d\udfe1, java \u26aa, PHP \u26aa Signature Aggregation apk-proofs \u26aa Distributed key generation (DKG) or management keygen.rs \u26aa, Secure Wallet Origin Distribution (SWORD) \u26aa Validator HSMs Zondax Remote Signer \u26aa MPC Orochi Network \ud83d\udfe2"},{"location":"build/build-open-source/#consensus","title":"Consensus","text":"Components Existing projects Potentially interesting projects PoC Spartan \u26aa PoW PoW consensus for Substrate \ud83d\udfe2, RandomX \u26aa, Sha3 PoW \u26aa Block production BABE \ud83d\udfe2, Aura \ud83d\udfe2 Finality GRANDPA \ud83d\udfe2, AlephBFT \ud83d\udfe2 Other Nimbus: Upgradeable consensus framework \u26aa"},{"location":"build/build-open-source/#networking","title":"Networking","text":"Components Existing projects Potentially interesting projects SCALE Codec Rust \ud83d\udfe2, TypeScript \u26aa, Python \u26aa, Golang Chainsafe \ud83d\udfe2, Golang Itering \ud83d\udfe1, C \u26aa, C++ \ud83d\udfe2, JavaScript \ud83d\udfe2, AssemblyScript \u26aa, Haskell \u26aa, Java \u26aa, Ruby \u26aa, Dart \u26aa, Swift \u26aa, scale-codec-swift \u26aa, scale-codec-kotlin \u26aa, PHP \u26aa, JavaScript by Soramitsu \u26aa, Scale Codec Comparator \ud83d\udfe1, ScaleCodec.sol by Darwinia \u26aa, ScaleCodec.sol by Snowfork \ud83d\udfe2, Dotscale \u26aa Networking Framework libp2p \u26aaSwarmNL \ud83d\udfe2 DHT Crawler Go \u26aa, Kotlin \u26aa RPC Tor-like access WhiteNoise \u26aa"},{"location":"build/build-open-source/#primitives","title":"Primitives","text":"Components Existing projects Potentially interesting projects Storage Merkle Tree DB \u26aa Merkle Proofs Solidity Trie Verifier \ud83d\udfe1 ## Contributing <p>Pull requests, issues, or other contributions from the community are encouraged! You can not only add specific projects, but also potentially interesting fields/areas which are currently missing in the tech stack.</p> <p>:heavy_exclamation_mark: All technologies listed above need to be open-source. Ideally, the links lead directly to the code.</p> <p>Note: You will need a GitHub account to suggest changes or open issues. If you do not have one, you may sign up for free.</p>"},{"location":"build/build-oracle/","title":"Oracles","text":"<p>In the blockchain context, an oracle is a way to bring real-world data onto the blockchain so that it can be used by a decentralized application.</p> <p>Oracles serve many purposes for application builders. For example:</p> <ul> <li>Most stablecoin designs use an oracle to bring in data of the exchange rate of assets, in order to   peg their value to a real world currency.</li> <li>Synthetic assets use oracles as price feeds in order to determine if the underlying cryptocurrency   can sufficiently collateralize the debt position.</li> <li>Prediction markets use oracles to decide the outcome of real world events and determine the payout   of the prediction shares.</li> <li>Decentralized insurance markets use oracles to bring in information about whether a claim is valid   or not.</li> </ul> <p>Oracle solutions range from centralized and trusted to decentralized and game-theory based. On the centralized end of the spectrum, an oracle could be a single account that has the authority to dictate the real-world data on-chain. On the decentralized end, a complex game of \"chicken\" can be played among various staked actors who risk getting slashed if they don't submit the same data as everyone else. Solutions such as Chainlink fit somewhere in the middle, where the amount of trust you put into the reporting oracles can be adjusted based on your preferences. A Chainlink Feed Pallet was recently released to allow smart contract applications across Polkadot to access price reference data, made available as a Substrate oracle pallet. Acurast is another solution that enables developers to define their off-chain data and computation requirements and receive the outputs to the Acurast Pallet and EVM or WASM environments.</p> <p>When using an oracle in your application you should be aware of the benefits and risks that are baked into its specific model. As the Polkadot ecosystem develops and oracle parachains begin to appear, this article will be updated with a comparison of the different solutions and the benefits and drawbacks that each provide.</p>"},{"location":"build/build-parachains/","title":"Parachain Development","text":"<p>Parachains are connected to and secured by the relay chain. They benefit from the pooled security, thought-through governance, and overall scalability of the heterogeneous sharding approach of the network. Creating a parachain can be seen as creating a Layer-1 blockchain, which has its own logic and runs in parallel within the Polkadot ecosystem.</p> <p>Developers can focus on creating state-of-the-art chains that take advantage of Polkadot's next-generation approach. Some examples of what a parachain could be are:</p> <ul> <li>DeFi (Decentralized Finance) Applications</li> <li>Digital Wallets</li> <li>IoT (Internet of Things) Applications</li> <li>Gaming</li> <li>Web 3.0 Infrastructure</li> </ul> <p>and more.</p> <p>Polkadot aims to be a bet against blockchain maximalism, where the success of Polkadot's heterogeneous multi-chain approach will play a key part in the overall advancement of Web 3.0 and decentralized systems. As a result, Polkadot's parachain model was designed with the belief that the internet of the future will have many different types of blockchains working together.</p>"},{"location":"build/build-parachains/#what-are-the-benefits-of-deploying-a-parachain","title":"What are the Benefits of Deploying a Parachain?","text":"<p>The parachain model attempts to alleviate five key build failures of present technology stacks, as described in the Polkadot Whitepaper:</p> <ul> <li>Scalability: How much is spent on resources and will the network be subject to bottlenecks?</li> <li>Isolatability: Are the needs of many accounted for under the same framework?</li> <li>Developability: Is the system tooling, system support, and overall system integrity   dependable?</li> <li>Governance: Can the network remain flexible to evolve and adapt over time? Can decisions be   made with sufficient inclusivity, legitimacy, and transparency to provide effective leadership of   a decentralised system?</li> <li>Applicability: Does the technology address a burning need on its own? Is other \u201cmiddleware\u201d   required to bridge the gap to actual applications?</li> </ul>"},{"location":"build/build-parachains/#shared-security-pooled-security","title":"Shared Security (Pooled Security)","text":"<p>Parachains can lease the security and interoperability of the Polkadot network purchasing coretime with DOT. This means that the social costs of building a community around your project and convincing validators to participate in your network security are reduced. Polkadot has strong security, and decentralised application projects wishing to benefit from this security would want to become a parachain to share in that pooled security.</p>"},{"location":"build/build-parachains/#on-chain-governance-thought-through-governance","title":"On-Chain Governance (Thought-through Governance)","text":"<p>Most governance systems in blockchains use an off-chain governance mechanism. Polkadot's on-chain governance encourages maximum participation of token holders and is frictionless and transparent. It also enables forkless upgrades.</p>"},{"location":"build/build-parachains/#scalability","title":"Scalability","text":"<p>The sharded multichain network approach allows for what is essentially parallel computation (processing power) that can process several transactions in parallel. Isolated blockchains are often faced with the network constraint of processing transactions in sequence, causing bottlenecks.</p>"},{"location":"build/build-parachains/#interoperability","title":"Interoperability","text":"<p>Any decentralised application or chain that wants to enable trustless messaging to other parachains already connected to the relay chain would want to become a parachain. Interoperability between sovereign chains involves certain constraints and complex protocols to enable across a wide breadth of chains.</p> <p>With Polkadot, you will get this feature out of the box if you build your application as a parachain. The XCM format allows any parachains to communicate by passing messages between them. Furthermore, as bridges to other chains are connected (such as those to Bitcoin or Ethereum), Polkadot's parachains will be able to communicate with these as well.</p> <p>Note</p> <p>Despite the benefits of becoming a parachain, developers should be conscious of the challenges in becoming a parachain, and whether building a blockchain with an end goal of becoming a parachain is a viable one for their project.</p> <p>On Polkadot, you are able to put your blockchain\u2019s latest block head onto the relay chain. As a parachain, the blocks you submit are verified by validators with a Wasm runtime, which can be stored on the relay chain. You also get the ability to communicate with other parachains using the XCM format: an abstract message passing system. Message passing is tracked on the relay chain - as such, you can prove the delivery of messages and facilitate trustless interactions.</p> <p>As you can place your blockchain\u2019s latest block head, you can achieve deterministic finalization for your chain. The hard part of reaching finalization for blockchains tends to be the consensus, where, in the parachain model, a blockchain can offload consensus to the overall shared network, and focus on block production. Since the validators have the Wasm runtime for all the parachains, your parachain shares the security of the validator pool with everyone on the relay chain.</p> <p>Any validator in the validator pool can help validate your blockchain.</p>"},{"location":"build/build-parachains/#things-to-consider","title":"Things to Consider","text":""},{"location":"build/build-parachains/#para-nomics","title":"Para-nomics","text":""},{"location":"build/build-parachains/#digital-nation-states","title":"Digital Nation States","text":"<p>Parachains can be seen as autonomous agents; networks that act as decentralised digital nation states. Parachains have their own communities, rules, economies, governance, treasuries, and relationships with external chains. As a result, the economic policies within parachain ecosystems are subject to the developers and overall community of that parachain ecosystem; there isn't necessarily a go-to economic model a parachain should follow.</p> <p>Moreover, becoming a parachain has an opportunity cost associated. Ideally, you can increase the value of the network by participating in the parachain selection process, and this should serve as a good return on investment.</p>"},{"location":"build/build-parachains/#connecting-digital-economies","title":"Connecting Digital Economies","text":"<p>Collators act as network maintainers and maintain a full node of a parachain. They can be incentivized with a native token payout from:</p> <ul> <li>Transaction fees collected</li> <li>Parachain token sponsorship</li> </ul>"},{"location":"build/build-parachains/#para-objects","title":"Para-objects","text":"<p>!!!info The relay chain can host arbitrary state machines, not just blockchains.     The Polkadot network will encourage the connection and interoperability between different     para-objects.</p> <pre><code>Here, para-objects are referring to objects on the network that operate in parallel, generally,\nparallelizable objects.\n</code></pre> <p>These could be in the form of:</p> <ul> <li>System level chains (permanent chains)</li> <li>Bridge Hubs</li> <li>Nested relay chains</li> </ul>"},{"location":"build/build-parachains/#migration","title":"Migration","text":"<p>Projects that are already functioning as \"solochains\" or in isolated environments may be interested in migrating onto the relay chain as a para-object. While the parachain model has its benefits, it may not be the go-to strategy for some projects.</p> <p>As a path for migration onto Polkadot, it may be more viable to migrate to one of the chains in one of the reserved cores.</p> <p>For instance, there are currently options for smart contract deployment on Kusama through the networks that have secured coretime.</p>"},{"location":"build/build-parachains/#implement-a-parachain","title":"Implement a Parachain","text":"<p>The Parachain Implementer's Guide is a significant work in progress and maintained by Parity Tech. The live version is built from the source located in the official Polkadot repository.</p>"},{"location":"build/build-parachains/#parachain-development-kit","title":"Parachain Development Kit","text":"<p>The Parachain Development Kit or PDK is a set of tools that allows developers to easily create a parachain. In practice, the PDK will consist of the following key components:</p> <ul> <li>State transition function : a way for your application to move from one state to another state.</li> <li>Collator node : a type of peer-to-peer node in the Polkadot network with certain   responsibilities regarding parachains.</li> </ul>"},{"location":"build/build-parachains/#key-components","title":"Key Components","text":"<p>The state transition function (STF) can be an abstract way for an application to go from one state to another state. The only constraint that Polkadot places on this STF is that it must be easily verifiable -- usually through what we call a witness or proof. It must be so because the Relay Chain validators will need to check that each state it receives from the collator node is correct without actually running through the entire computation. Some examples of these proofs include the Proof-of-Validity blocks or zk-SNARKs, which require less computational resources to verify than they do to generate. The verification asymmetry in the proof generation of the STF is one of the integral insights that allows Polkadot to scale while keeping high-security guarantees.</p> <p>A collator node is one of the types of network maintainers in the protocol. They are responsible for keeping availability of the state of the parachain and the new states returned from the iteration of the state transition function. They must remain online to keep track of the state and also of the XCMP messages that it will route between itself and other parachains. Collator nodes are responsible for passing the succinct proofs to the relay chain's validators and tracking the latest blocks from the relay chain. In essence, a collator node also acts as a light client for the relay chain. For more on collator nodes, see the collator page.</p>"},{"location":"build/build-parachains/#what-pdks-exist","title":"What PDKs Exist?","text":"<p>Currently, the only PDK is the Polkadot SDK and Cumulus.</p> <p>Substrate is a blockchain framework that provides the basic building blocks of a blockchain (things like the networking layer, consensus, a Wasm interpreter) while providing an intuitive way to construct your runtime. Substrate is made to ease the process of creating a new chain, but it does not provide support for relay chain compatibility directly. For this reason, <code>Cumulus</code>, an added library contains all of the Polkadot compatibility glue code.</p>"},{"location":"build/build-parachains/#cumulus","title":"Cumulus","text":"<p>Info</p> <p>Cumulus clouds are shaped sort of like dots. Together, they form an intricate system that is beautiful and functional.</p> <p>Cumulus is an extension to Substrate that makes it easy to make any Substrate-built runtime into a Polkadot-compatible parachain.</p> <p>Cumulus Consensus is a consensus engine for Substrate that follows a relay chain. This runs a Relay Chain node internally, and dictates to the client and synchronization algorithms which chain to follow, finalize, and treat as correct.</p> <p>See the Cumulus overview for a more detailed description of Cumulus.</p> <p>Cumulus is still in development, but the idea is that it should be simple to take a Substrate chain and add the parachain code by importing the crates and adding a single line of code. Keep up-to-date with the latest Cumulus developments from the Cumulus section.</p> <p>Info</p> <p>Substrate and Cumulus provide a PDK from the abstraction of the blockchain format, but it is not necessary that a parachain even needs to be a blockchain. For example, a parachain just needs to satisfy the two constraints listed above: state transition function and collator node.</p> <p>Everything else is up to the implementer of the PDK.</p> <p>Cumulus handles the network compatibility overhead that any parachain would need to implement to be connected to the relay chain. This includes:</p> <ul> <li>Cross-chain message passing (XCMP)</li> <li>Out-of-the-box Collator node setup</li> <li>An embedded full client of the relay chain</li> <li>Block authorship compatibility</li> </ul> <p>Are you interested in building a PDK? See the future PDKs section for details.</p>"},{"location":"build/build-parachains/#how-to-set-up-your-parachain","title":"How to set up your parachain","text":"<p>After creating your chain runtime logic with Substrate, you will be able to compile it down to a Wasm executable. This Wasm code blob will contain the entire state transition function of your chain, and is what you will need to deploy your project to the relay chain as a parachain.</p> <p>Validators on the relay chain will use the submitted Wasm code to validate the state transitions of your chain or thread, but doing this requires some additional infrastructure. A validator needs some way to stay up to date with the most recent state transitions, since relay chain nodes will not be required to also be nodes of your chain.</p> <p>This is where the collator node comes into play. A collator is a maintainer of your parachain and performs the critical action of producing new block candidates for your chain and passing them to relay chain validators for inclusion in the relay chain.</p> <p>Substrate comes with its own networking layer built-in but unfortunately only supports solo chains (that is, chains that do not connect to the relay chain). However, there is the Cumulus extension that includes a collator node and allows for your Substrate-built logic to be compatible with the relay chain as a parachain.</p>"},{"location":"build/build-parachains/#future-pdks","title":"Future PDKs","text":"<p>Call to action</p> <p>Do you want to build a Parachain Development Kit from scratch? The Web3 Foundation is giving grants to teams who are doing this, learn more and apply on the W3F grants page.</p> <p>One example of a PDK W3F is interested in supporting is a roll-up kit that allowed developers to create SNARK-based parachains. If we review the roll-up write-up, we see that the system uses two roles: users that update state and an operator that aggregates the state updates into a single on-chain update. It should be straightforward to see how we can translate this to the parachain terms. The state transition function for a roll-up-like parachain would be updating the state (in practice, most likely a Merkle tree, which would be easily verifiable) from the user inputs. The operator would act as the collator node, which would aggregate the state and create the zk-SNARK proof that it would hand to a relay chain's validators for verification.</p> <p>If you or your team are interested in developing a PDK feel free to apply for a grant on the W3F Grants Program repository. There may be grants available for this type of work.</p>"},{"location":"build/build-parachains/#testing-a-parachain","title":"Testing a Parachain","text":""},{"location":"build/build-parachains/#paseo-testnet","title":"Paseo Testnet","text":"<p>Paseo is a testnet built for testing parachains. Paseo utilizes Cumulus and HRMP (Horizontal Relay-routed Message Passing) in order to send transfers and messages between parachains.</p> <p>Paseo runs a few test system parachains and externally developed parachains.</p> <p>If you would like to start deploying a parachain and trying out Coretime on Paseo, refer to the Coretime Guides.</p>"},{"location":"build/build-parachains/#what-parachains-are-on-paseo-now","title":"What Parachains are on Paseo Now?","text":"<p>You can see the list of included parachains here.</p>"},{"location":"build/build-parachains/#obtaining-pas","title":"Obtaining PAS","text":"<p>Follow the instructions here to get PAS tokens.</p>"},{"location":"build/build-parachains/#how-to-connect-to-a-parachain","title":"How to Connect to a Parachain","text":"<p>If you would like to connect to a parachain via Polkadot-JS Apps, you may do so by clicking on the network selection at the top left-hand corner of the navigation and selecting any parachain of choice.</p> <p></p> <p>For the purpose of these following examples, we will be using the Paseo testnet \"Custom Node\" underneath \"Development\", following the parachain and coretime tutorials.</p>"},{"location":"build/build-parachains/#parachain-playground","title":"Parachain Playground","text":"<p>You can also take advantage of the account functions offered on Polkadot-JS Apps to test the entire Parachain onboarding process (e.g. registration and coretime purchase).</p> <p>Start a local node on Westend by running:</p> <pre><code>polkadot --chain=westend-dev --alice\n</code></pre> <p>Then, connect your local node with Polkadot-JS Apps.</p> <p></p>"},{"location":"build/build-parachains/#deploy","title":"Deploy","text":"<p>Substrate-based chains, including the Polkadot and Kusama relay chains, use an SS58 encoding for their address formats. This page serves as the canonical registry for teams to see which chain corresponds to a given prefix, and which prefixes are available.</p>"},{"location":"build/build-parachains/#parachain","title":"Parachain","text":"<p>To include your parachain into the Polkadot network, you will need to reserve a core on the relay chain.</p> <p>Coretime can be purchased with DOT to produce blocks continuously or on-demand while benefiting from Polkadot's security. See these guides to learn how to purchase coretime.</p>"},{"location":"build/build-parachains/#resources","title":"Resources","text":"<ul> <li>Getting started with the Polkadot SDK for parachain development</li> <li>Polkadot Bridges</li> <li>The Path of a Parachain Block</li> <li>The Path of a Parachain Block (Parachain Protocol page)</li> <li>How to become a parachain on Polkadot (Video)</li> <li>Trusted Execution Environments and the Polkadot Ecosystem</li> </ul>"},{"location":"build/build-protocol-info/","title":"Polkadot Protocol Overview","text":"<p>This page serves as a high-level introduction to the Polkadot protocol with terminology that may be specific to Polkadot, notable differences to other chains that you may have worked with, and practical information for dealing with the chain.</p> <p>If the below does not offer a sufficient amount of information regarding the Polkadot protocol, be sure to visit the Polkadot Spec, which is more verbose than this Wiki page.</p>"},{"location":"build/build-protocol-info/#tokens","title":"Tokens","text":"<ul> <li>Token decimals:</li> <li>Polkadot (DOT): 10</li> <li>Kusama (KSM): 12</li> <li>Base unit: \"Planck\"</li> <li>Balance type: <code>u128</code></li> </ul>"},{"location":"build/build-protocol-info/#redenomination","title":"Redenomination","text":"<p>Polkadot conducted a poll, which ended on 27 July 2020 (block 888_888), in which the stakeholders decided to redenominate the DOT token. The redenomination does not change the number of base units (called \"plancks\" in Polkadot) in the network. The only change is that a single DOT token will be 1e10 plancks instead of the original 1e12 plancks. See the Polkadot blog posts explaining the details and the results of the vote.</p> <p>The redenomination took effect 72 hours after transfers were enabled, at block 1_248_326, which occurred at approximately 16:50 UTC on 21 Aug 2020. You can find more information about the redenomination here.</p>"},{"location":"build/build-protocol-info/#addresses","title":"Addresses","text":"<p>In Polkadot (and most Substrate chains), user accounts are identified by a 32-byte (256-bit) <code>AccountId</code>. This is often, but not always, the public key of a cryptographic key pair.</p> <p>Polkadot (and Substrate) use the SS58 address format. This is a broad \"meta-format\" designed to handle many different cryptographic schemes and chains. It has much in common with Bitcoin's Base58Check format such as a version prefix, a hash-based checksum suffix, and base-58 encoding.</p> <p>See the SS58 page in the Substrate documentation for encoding information and a more comprehensive list of network prefixes.</p> <p>Do not use regular expressions (regex) to validate addresses</p> <p>Always verify using the prefix and checksum of the address. Substrate API Sidecar provides an <code>accounts/{accountId}/validate</code> path that returns a boolean <code>isValid</code> response for a provided address.</p> <p>Relevant SS58 prefixes for this guide:</p> <ul> <li>Polkadot: 0</li> <li>Kusama: 2</li> <li>Westend: 42</li> </ul>"},{"location":"build/build-protocol-info/#cryptography","title":"Cryptography","text":"<p>Polkadot supports the following cryptographic key pairs and signing algorithms:</p> <ul> <li>Ed25519</li> <li>Sr25519 - Schnorr signatures on the Ristretto group</li> <li>ECDSA signatures on secp256k1</li> </ul> <p>Note that the address for a secp256k1 key is the SS58 encoding of the hash of the public key in order to reduce the public key from 33 bytes to 32 bytes.</p>"},{"location":"build/build-protocol-info/#extrinsics-and-events","title":"Extrinsics and Events","text":""},{"location":"build/build-protocol-info/#block-format","title":"Block Format","text":"<p>A Polkadot block consists of a block header and a block body. The block body is made up of extrinsics representing the generalization of the concept of transactions. Extrinsics can contain any external data the underlying chain wishes to validate and track.</p> <p>The block header is a 5-tuple containing the following elements:</p> <ul> <li><code>parent_hash</code>: a 32-byte Blake2b hash of the SCALE encoded parent block header.</li> <li><code>number</code>: an integer representing the index of the current block in the chain. It is equal to the   number of the ancestor blocks. The genesis state has number 0.</li> <li><code>state_root</code>: the root of the Merkle tree, used as storage for the system.</li> <li><code>extrinsics_root</code>: field which is reserved for the Runtime to validate the integrity of the   extrinsics composing the block body.</li> <li><code>digest</code>: field used to store any chain-specific auxiliary data, which could help the light   clients interact with the block without the need of accessing the full storage as well as   consensus-related data including the block signature.</li> </ul> <p>A node creating or receiving a block must gossip that block to the network (i.e. to the other nodes). Other nodes within the network will track this announcement and can request information about the block. Additional details on the process are outlined here in the Polkadot Spec.</p>"},{"location":"build/build-protocol-info/#extrinsics","title":"Extrinsics","text":"<p>An extrinsic is a SCALE encoded array consisting of a <code>version number</code>, <code>signature</code>, and varying <code>data</code> types indicating the resulting runtime function to be called, including the parameters required for that function to be executed.</p> <p>Extrinsics constitute information from the outside world and take on three forms:</p> <ul> <li>Inherents</li> <li>Signed Transactions</li> <li>Unsigned Transactions</li> </ul> <p>As an infrastructure provider, you will deal almost exclusively with signed transactions. You will, however, see other extrinsics within the blocks that you decode. Find more information in the Substrate documentation.</p> <p>Inherent extrinsics are unsigned and contain information that is not provably true, but validators agree on based on some measure of reasonability. For example, a timestamp cannot be proved, but validators can agree that it is within some time difference on their system clock. Inherents are broadcasted as part of the produced blocks rather than being gossiped as individual extrinsics.</p> <p>Signed transactions contain a signature of the account that issued the transaction and stands to pay a fee to have the transaction included on chain. Because the value of including signed transactions on-chain can be recognized prior to execution, they can be gossiped on the network between nodes with a low risk of spam. Signed transactions fit the concept of a transaction in Ethereum or Bitcoin.</p> <p>Some transactions cannot be signed by a fee-paying account and use unsigned transactions. For example, when a user claims their DOT from the Ethereum DOT indicator contract to a new DOT address, the new address doesn't yet have any funds with which to pay fees.</p> <p>The Polkadot Host does not specify or limit the internals of each extrinsics and those are defined and dealt with by the Runtime.</p>"},{"location":"build/build-protocol-info/#transaction-mortality","title":"Transaction Mortality","text":"<p>Extrinsics can be mortal or immortal. The transaction payload includes a block number and block hash checkpoint from which a transaction is valid and a validity period (also called \"era\" in some places) that represents the number of blocks after the checkpoint for which the transaction is valid. If the extrinsic is not included in a block within this validity window, it will be discarded from the transaction queue.</p> <p>The chain only stores a limited number of prior block hashes as reference. You can query this parameter, called <code>BlockHashCount</code>, from the chain state or metadata. If the validity period is larger than the number of blocks stored on-chain, then the transaction will only be valid as long as there is a block to check it against, i.e. the minimum value of validity period and block hash count.</p> <p>Setting the block checkpoint to zero, using the genesis hash, and a validity period of zero will make the transaction \"immortal\".</p> <p>NOTE: If an account is reaped and a user re-funds the account, then they could replay an immortal transaction. Always default to using a mortal extrinsic.</p>"},{"location":"build/build-protocol-info/#unique-identifiers-for-extrinsics","title":"Unique Identifiers for Extrinsics","text":"<p>Transaction Hash is not a unique identifier</p> <p>The assumption that a transaction's hash is a unique identifier is the number one mistake that indexing services and custodians make. This error will cause major issues for your users. Make sure that you read this section carefully.</p> <p>Many infrastructure providers on existing blockchains, e.g. Ethereum, consider a transaction's hash as a unique identifier. In Substrate-based chains like Polkadot, a transaction's hash only serves as a fingerprint of the information within a transaction, and there are times when two transactions with the same hash are both valid. In the case that one is invalid, the network properly handles the transaction and does not charge a transaction fee to the sender nor consider the transaction in the block's fullness.</p> <p>Imagine this contrived example with a reaped account. The first and last transactions are identical, and both valid.</p> Index Hash Origin Nonce Call Results 0 0x01 Account A 0 Transfer 5 DOT to B Account A reaped 1 0x02 Account B 4 Transfer 7 DOT to A Account A created (nonce = 0) 2 0x01 Account A 0 Transfer 5 DOT to B Successful transaction <p>In addition, not every extrinsic in a Substrate-based chain comes from an account as a \"pure\" public/private key pair. The concept of dispatch \u201cOrigin\u201d, which could represent different contexts for a particular, signed extrinsic.</p> <p>For example, the origin could befrom a public key account, but could also represent a collective. These origins do not have a nonce associated with them the way that an account does. For example, governance might dispatch the same call with the same arguments multiple times, like \u201cincrease the validator set by 10%.\u201d This dispatch information (and therefore its hash) would be the same, and the hash would be a reliable representative of the call, but its execution would have different effects depending on the chain\u2019s state at the time of dispatch.</p> <p>The correct way to uniquely identify an extrinsic on a Substrate-based chain is to use the block ID (height or hash) and the extrinsic's index. Substrate defines a block as a header and an array of extrinsics; therefore, an index in the array at a canonical height will always uniquely identify a transaction. This methodology is reflected in the Substrate codebase itself, for example to reference a previous transaction from the Multisig pallet.</p>"},{"location":"build/build-protocol-info/#events","title":"Events","text":"<p>While extrinsics represent information from the outside world, events represent information from the chain. Extrinsics can trigger events. For example, the Staking pallet emits a <code>Reward</code> event when claiming staking rewards to tell the user how much the account was credited.</p> <p>If you want to monitor deposits into an address, keep in mind that several transactions can initiate a balance transfer (such as <code>balances.transferKeepAlive</code> and a <code>utility.batch</code> transaction with a transfer inside of it). Only monitoring <code>balances.transfer</code> transactions will not be sufficient. Make sure that you monitor events in each block for events that contain your addresses of interest. Monitor events instead of transaction names to ensure that you can properly credit deposits.</p>"},{"location":"build/build-protocol-info/#fees","title":"Fees","text":"<p>Polkadot uses weight-based fees that, unlike gas, are charged pre-dispatch. Users can also add a \"tip\" to increase transaction priority during congested periods. See the transaction fee page for more info.</p>"},{"location":"build/build-protocol-info/#encoding","title":"Encoding","text":"<p>Parity's integration tools should allow you to deal with decoded data. If you'd like to bypass them and interact directly with the chain data or implement your own codec, Polkadot encodes block and transaction data using the SCALE codec.</p>"},{"location":"build/build-protocol-info/#runtime-upgrades","title":"Runtime Upgrades","text":"<p>Runtime upgrades allow Polkadot to change the logic of the chain without the need for a hard fork. You can find a guide for how to properly perform a runtime upgrade here.</p>"},{"location":"build/build-protocol-info/#runtime-versioning","title":"Runtime Versioning","text":"<p>There are a number of fields that are a part of the overall <code>RuntimeVersion</code>.</p> <p>Apart the <code>runtime_version</code> there is also the <code>transaction_version</code> which denotes how to correctly encode/decode calls for a given runtime (useful for hardware wallets). The reason <code>transaction_version</code> is separate from <code>runtime_version</code> is that it explicitly notes that the call interface is broken/not compatible.</p>"},{"location":"build/build-protocol-info/#smart-contracts","title":"Smart Contracts","text":"<p>The Polkadot relay chain does not support smart contracts, but a number of its parachains do, see here for more.</p>"},{"location":"build/build-protocol-info/#other-faq","title":"Other F.A.Q.","text":"<p>Can an account's balance change without a corresponding, on-chain transaction?</p> <p>No, but not all balance changes are in a transaction, some are in events. You will need to run an archive node and listen for events and transactions to track all account activity. This especially applies to locking operations if you are calculating balance as the spendable balance, i.e. free balance minus the maximum lock.</p> <p>What chain depth is considered \"safe\"?</p> <p>Polkadot uses a deterministic finality mechanism. Once a block is finalized, it cannot be reverted except by a hard fork. Kusama has had hard forks that had to revert four finalized blocks in order to cancel a runtime upgrade. Using a finalized depth of ten blocks should be safe.</p> <p>Note that block production and finality are isolated processes in Polkadot, and the chain can have a long unfinalized head.</p> <p>Do users need to interact with any smart contracts?</p> <p>No, users interact directly with the chain's logic.</p> <p>Does Polkadot have state rent?</p> <p>No, Polkadot uses the existential deposit to prevent dust accounts and other economic mechanisms like locking or reserving tokens for operations that utilize state.</p> <p>What is an external source to see the current chain height?</p> <ul> <li>Polkadot-JS explorer</li> <li>Subscan block explorer</li> </ul>"},{"location":"build/build-smart-contracts/","title":"Smart Contracts","text":"<p>The relay chain which is a layer 0 blockchain, does not support smart contracts natively. However, parachains which are layer 1 blockchains are equipped with the functionality to support smart contracts.</p> <p>The two primary supported smart contract environments are ink! and EVM. There are multiple parachains that support both environments.</p>"},{"location":"build/build-smart-contracts/#difference-between-developing-a-smart-contract-and-a-parachain","title":"Difference between developing a smart contract and a parachain","text":""},{"location":"build/build-smart-contracts/#layer-of-abstraction","title":"Layer of Abstraction","text":"<p>When you write a smart contract, you are creating the instructions that associate with and deploy on a specific chain address.</p> <p>In comparison, a runtime module on a parachain is the entire logic of a chain's state transitions (what's called a state transition function).</p> <p>Smart contracts must consciously implement upgradeability while parachains have the ability to swap out their code entirely through a root command or via the governance pallet.</p> <p>When you build a smart contract, it will eventually be deployed to a target chain with its own environment. Parachains allow the developer to declare the environment of their own chain, even allowing others to write smart contracts for it.</p>"},{"location":"build/build-smart-contracts/#gas-fees","title":"Gas Fees","text":"<p>Smart contracts must find a way to limit their own execution, or else full nodes are vulnerable to DOS attacks. An infinite loop in a smart contract, for example, could consume the computational resources of an entire chain, preventing others from using it. The halting problem shows that even with a powerful enough language, it is impossible to know ahead of time whether or not a program will ever cease execution. Some platforms, such as Bitcoin, get around this constraint by providing a very restricted scripting language. Others, such as Ethereum, \"charge\" the smart contract \"gas\" for the rights to execute their code. If a smart contract does get into a state where execution will never halt, it eventually runs out of gas, ceases execution, and any state transition that the smart contract would have made is rolled back.</p> <p>Parachains can implement arbitrarily powerful programming languages and contain no gas notion for their own native logic. This means that some functionality is easier to implement for the developer, but some constructs, such as a loop without a terminating condition, should never be implemented. Leaving certain logic, such as complex loops that could run indefinitely, to a non-smart contract layer, or even trying to eliminate it, will often be a wiser choice. Parachains try to be proactive, while smart contract platforms are event-driven.</p> <p>Relay chain and parachains typically use the weight-fee model and not a gas-metering model.</p>"},{"location":"build/build-smart-contracts/#building-a-smart-contract","title":"Building a Smart Contract","text":"<p>The relay chain does not natively support smart contracts. However, since the parachains that connect to the relay chain can support arbitrary state transitions, they support smart contracts.</p> <p>Substrate presently supports smart contracts out-of-the-box in several ways:</p> <ul> <li>The EVM pallet offered by Frontier.</li> <li>The   Contracts pallet   in the FRAME library for Wasm-based contracts.</li> </ul>"},{"location":"build/build-smart-contracts/#frontier-evm-contracts","title":"Frontier EVM Contracts","text":"<p>Frontier is the suite of tools that enables a Substrate chain to run Ethereum contracts (EVM) natively with the same API/RPC interface, Ethereum exposes on Substrate. Ethereum Addresses can also be mapped directly to and from Substrate's SS58 scheme from existing accounts.</p>"},{"location":"build/build-smart-contracts/#substrate-contracts","title":"Substrate Contracts","text":"<p>Substrate offers a built-in contract pallet; parachains can also support WebAssembly smart contracts. Additionally, there is the EVM Pallet, which allows a parachain to implement the Ethereum Virtual Machine, thereby supporting almost direct ports of Ethereum contracts.</p> <p>A video version of the recap of the smart contract situation is available on the Polkadot YouTube channel.</p>"},{"location":"build/build-smart-contracts/#resources","title":"Resources","text":"<p>When should I build a Substrate runtime versus a Substrate smart contract? This post answers the question more technically of when a developer might choose to develop a runtime versus a smart contract.</p> <p>Here is the list of current resources available to developers who want to get started writing smart contracts to deploy on parachains based on Substrate.</p> <ul> <li>ink! - Parity's ink to write smart contracts.</li> <li>Substrate ink! Workshop - Walks you   through the basics of writing and deploying an ERC-20 token using <code>ink!</code>.</li> </ul>"},{"location":"build/build-smart-contracts/#contracts-pallet","title":"Contracts Pallet","text":"<p>The experience of deploying to an EVM-based chain may be more familiar to developers that have written smart contracts before. However, the Contracts pallet makes some notable improvements to the design of the EVM:</p> <ol> <li> <p>Wasm. The Contracts pallet uses WebAssembly as its compilation target. Any language that    compiles to Wasm can potentially be used to write smart contracts. Nevertheless, it is better to    have a dedicated domain-specific language, and for that reason Parity offers the ink!    language.</p> </li> <li> <p>Deposit. Contracts must hold a deposit (named ContractDeposit ) suitably large enough in    order to justify their existence on-chain. A deployer needs to deposit this into the new contract    on top of the ExistentialDeposit.</p> </li> <li>Caching. Contracts are cached by default and therefore means they only need to be deployed    once and afterward be instantiated as many times as you want. This helps to keep the storage load    on the chain down to the minimum. On top of this, when a contract is no longer being used and the    existential deposit is drained, the code will be erased from storage (known as reaping).</li> </ol>"},{"location":"build/build-smart-contracts/#storage-rent-deprecated","title":"Storage Rent: Deprecated","text":"<p><code>pallet_contracts</code> was initially designed to combat unbounded state growth by charging contracts for the state they consume but has since been deprecated.</p> <p>See the associated pull request for more details.</p>"},{"location":"build/build-smart-contracts/#polkadot-standards-proposals-psps","title":"Polkadot Standards Proposals (PSPs)","text":"<p>Web3 Foundation supports proposals for Polkadot that define a set standards to fit ecosystem needs. These standards go through several acceptance phases, where the engagement of the whole community is needed to build valuable and future-proof standards. All the teams who will benefit from a standard need to agree on its content.</p> <p>Some of these PSPs are targeting Substrate's <code>contracts</code> pallet:</p> <ul> <li>PSP22 - Fungible Token Standard Please   visit Polkadot Standards Proposals (PSPs) Github for more   information.</li> </ul>"},{"location":"build/build-smart-contracts/#ink","title":"Ink","text":"<p>ink! is a domain specific language for writing smart contracts in Rust and compiles to Wasm code. As it states in its README, it is still in an experimental phase so brave developers should be aware that they might have a bumpy - but workable - development experience. There are some projects that have built projects in ink! with a decent level of complexity such as Plasm's Plasma contracts, so it is mature enough to start building interesting things.</p> <p>For interested developers, they can get started writing smart contracts using ink! by studying the examples that were already written. These can be used as guideposts to writing more complex logic that will be deployable on smart contract parachains.</p> <p>ink! has laid much of the groundwork for a new smart contract stack that is based on a Wasm virtual machine and compatible with Substrate chains.</p>"},{"location":"build/build-smart-contracts/#libraries-for-smart-contracts-in-ink","title":"Libraries for Smart Contracts in <code>ink!</code>","text":"<p>Collected below are some community examples of smart contracts in <code>ink!</code>. Are you working on a smart contract example? Ask us to add it to this page!</p> <ul> <li>OpenBrush: an <code>ink!</code> library providing standard contracts based on   PSP with useful contracts and macros for building.</li> <li>ink!athon: Starterkit for full-stack dApps with ink! smart contracts &amp;   frontend.</li> <li>Metis: a Wasm contract standard library, developed by   Patract Labs.</li> </ul>"},{"location":"build/build-smart-contracts/#smart-contract-environments","title":"Smart Contract Environments","text":"<p>It is still early for smart contracts on the relay chain and the development is only now stabilizing. We are actively producing content to help developers get up to speed and will maintain the Wiki with the latest resources. You should also keep up to date with the following links:</p>"},{"location":"build/build-smart-contracts/#parity-tech","title":"Parity Tech","text":"<ul> <li>ink!</li> <li>Substrate contracts pallet</li> </ul>"},{"location":"build/build-smart-contracts/#parachains","title":"Parachains","text":"<ul> <li>Moonbeam</li> <li>Astar</li> <li>Acala</li> <li>Phala</li> <li>Darwinia</li> </ul> <p>Many smart contract platforms are building to become a parachain in the ecosystem. A community created and maintained list of different smart contract platforms building on Polkadot can be found at PolkaProjects. Additionally, information about ink smart contracts can be accessed at use.ink.</p>"},{"location":"build/build-smart-contracts/#moonbeam","title":"Moonbeam","text":"<ul> <li>ink!: Unsupported</li> <li>EVM (Solidity): Supported</li> </ul> <p>Moonbeam is another project that is planning to deploy to Polkadot as a parachain and will support Ethereum compatible smart contracts. Since Moonbeam uses Frontier, an interoperability layer with existing Ethereum tooling, it will support all applications that are written to target the EVM environment with little friction.</p> <p>Moonriver, a companion network to Moonbeam, launched as a parachain on Kusama. Parachain functionality is live, and features are being incrementally released. The final phase of the launch will include EVM functionality and balance transfers.</p> <p>Try deploying a smart contract to Moonbeam by following their documentation.</p>"},{"location":"build/build-smart-contracts/#astar","title":"Astar","text":"<ul> <li>ink!/Wasm: Supported</li> <li>EVM (Solidity):  Supported</li> </ul> <p>Astar Network supports the building of dApps with EVM and WASM smart contracts and offers developers true interoperability. True interoperability with cross-consensus messaging XCM and cross-virtual machine XVM. We are made by developers and for developers. Astar\u2019s unique Build2Earn model empowers developers to get paid through a dApp staking mechanism for the code they write and dApps they build.</p> <p>Shiden Network is the canary network of Astar Network, live as a parachain on Kusama, and supports the EVM and WASM environment for all developers who want to build out use-cases in a canary network with economic value. Shiden acts as a playground for developers.</p> <p>Try deploying an Ethereum or ink! smart contract by following their documentation.</p>"},{"location":"build/build-smart-contracts/#acala","title":"Acala","text":"<ul> <li>ink!: Unsupported</li> <li>EVM (Solidity): Supported</li> </ul> <p>Acala is a decentralized finance consortium and DeFi infrastructure chain delivering a set of protocols to serve as the DeFi hub on Polkadot. Karura, Acala's canary network is live as a parachain on Kusama. Interested teams are now able to deploy DApps and smart contracts on Karura's platform. Acala is also implementing the Acala EVM.</p> <p>Try deploying an Acala EVM smart contract by following their documentation.</p>"},{"location":"build/build-smart-contracts/#phala","title":"Phala","text":"<ul> <li>ink!: Unsupported</li> <li>EVM (Solidity): Unsupported</li> <li>See: Phat Contracts powered by ink!</li> </ul> <p>Phala is an off-chain trustless compute infrastructure that provides fully verifiable computation. Using Phat contracts, developers can write smart contracts that can interact with web2 services. Khala is Phala's canary network and is live as a parachain on Kusama.</p> <p>Try deploying a smart contract that interacts with Etherscan's web2 API by following their documentation.</p>"},{"location":"build/build-smart-contracts/#darwinia","title":"Darwinia","text":"<ul> <li>ink!: Unsupported</li> <li>EVM (Solidity) Support:   Supported</li> </ul> <p>Darwinia is a community-run technology and service powering the cross-chain capabilities of decentralized applications. By crafting secure and efficient cross-chain messaging protocols, Darwinia is at the forefront of facilitating seamless communication between disparate blockchain networks. The newest addition to the suite of protocols is <code>Darwinia Msgport</code>, an innovative messaging abstraction that has been successfully implemented across a wide array of mainstream smart contract platforms, broadening the potential for interoperability and enabling developers to create more versatile and connected blockchain ecosystems.</p> <p>Try deploying a smart contract to Darwinia by following their documentation.</p>"},{"location":"build/build-smart-contracts/#keep-in-touch","title":"Keep In Touch","text":"<p>Even though the tooling is still maturing, the advantage of being early will be the familiarity and head start on your project, allowing you to innovate and create something truly new.</p> <p>If you have interesting ideas for smart contracts on Polkadot feel free to drop into the Polkadot Watercooler to talk about them. Developers may be interested in joining the Polkadot Beginners Lounge or Substrate and Polkadot StackExchange to ask their questions. As always, keep up to date with Polkadot and Kusama by following the social channels.</p>"},{"location":"build/build-storage/","title":"Decentralized Storage","text":"<p>Storage is an integral part of modern computer systems, and the same is true for distributed and decentralized systems like a blockchain. When interacting with the Polkadot ecosystem, it will be helpful if you familiarize yourself with the current Web3 approach towards decentralized storage.</p>"},{"location":"build/build-storage/#dcs-decentralized-cloud-storage","title":"DCS (Decentralized Cloud Storage)","text":"<p>The key attribute that characterizes centralized cloud storage is the location of data.</p> <p>In decentralized cloud storage, the key attribute becomes the data itself instead of the data's location.</p> <p>This can be viewed as the shift from the centralized location-centric storage approach to the decentralized content-centric approach.</p>"},{"location":"build/build-storage/#ipfs-interplanetary-file-system","title":"IPFS (Interplanetary File System)","text":"<p>IPFS is a peer-to-peer distributed file system that seeks to connect all computing devices with the same system of files, by utilizing features such as content-addressing, content-signing, and enhanced security methods through encryption. IPFS aims to address the current hurdles of the HTTP-based Internet.</p>"},{"location":"build/build-storage/#brief-comparison-of-ipfs-http","title":"Brief comparison of IPFS &amp; HTTP:","text":"IPFS HTTP network: peer-to-peer model (decentralized) network: client-server model (centralized) requests: use a cryptographic hash of that data requests: use the address on which data is hosted accessibility: data is distributed to multiple nodes and can be accessed at any time. Bandwidth is high: nearest peer can serve the data accessibility: data can only be accessed if the server is live and there are no interruptions in transmission. Bandwidth is limited: clients send requests to the same server"},{"location":"build/build-storage/#crust-storage","title":"Crust Storage","text":"<p>Crust Network provides a Web3.0 decentralized storage network for the Metaverse. It is designed to realize core values of decentralization, privacy, and assurance. Crust supports multiple storage-layer protocols such as IPFS, and exposes instant accessible on-chain storage functions to users. Crust\u02bcs technical stack is also capable of supporting data manipulating and computing.</p> <p>Crust provides a native cross-chain communication pallet based on XCMP, called xStorage.</p> <p>The protocol also supports most smart contract platforms, including Ethereum, with its cross-chain dStorage solution.</p> <p>Learn more about Crust</p> <pre><code>To learn more about Crust, check out the [Crust Network Wiki](https://wiki.crust.network/en). Try\nintegrating with Crust by following their\n[Crust Storage 101](https://wiki.crust.network/docs/en/build101) guide.\n</code></pre>"},{"location":"build/build-storage/#filebase","title":"Filebase","text":"<p>Filebase is the first S3-compatible object storage platform that allows you to store data in a secure, redundant, and performant manner across multiple decentralized storage networks.</p> <p>Filebase offers a geo-redundant IPFS pinning service that allows you to pin files to IPFS across multiple diverse geographic locations. All files uploaded to IPFS through Filebase are automatically pinned to the Filebase infrastructure with 3x replication across the globe. This ensures that your data is globally available and redundant at all times.</p> <p>Filebase acts as an easy on-ramp to IPFS and decentralized storage by offering a user-friendly web console dashboard, making drag-and-dropping files onto Web3 simple and easy. Filebase also provides an S3-compatible API for widespread integrations and configurations in current workflows.</p> <p>Learn more about Filebase</p> <pre><code>To learn more about Filebase, check out the [Filebase Documentation](https://docs.filebase.com), and\nspecifically the documentation on\n[deploying Polkadot dApp on decentralized storage.](https://docs.filebase.com/web3-education/web3-tutorials/polkadot/polkadot-deploy-a-polkadot-dapp-on-decentralized-storage)\nYou can get started with Filebase by signing up [here.](https://filebase.com/signup)\n</code></pre>"},{"location":"build/build-storage/#using-polkadot-js-files-ipfs-module","title":"Using Polkadot-JS Files (IPFS) module","text":"<p>Polkadot-JS UI includes a decentralized storage module that allows Substrate-based chain users to upload their files to an IPFS W3Auth Gateway and use the IPFS W3Auth Pinning Service to pin their files on Crust Network.</p> <p>Start by uploading a single file or folder:</p> <p></p> <p>Choose a Gateway:</p> <p></p> <p>Sign the message:</p> <p></p> <p>You should be able to view the file info, as follows:</p> <p></p> <p>As well as the file status:</p> <p></p> <p>Note</p> <pre><code>The whole files module is decentralized, so your file directory is only cached in browser. The file\ndirectory info will not be visible if you switch to a new browser or clear the browser cache. The\nstorage module allows you to export file directory info from the current browser and import it to\nthe new browser.\n</code></pre> <p></p> <p>Note</p> <pre><code>These above images are taken from this [pull request](https://github.com/polkadot-js/apps/pull/6106)\n</code></pre>"},{"location":"build/build-tools-index/","title":"Tool Index","text":"<p>Here, we provide a list of tools available for your development needs. They are sorted by context. If you're actively maintaining a tool that might be useful to other Polkadot, Kusama or Substrate developers, feel free to add it in.</p>"},{"location":"build/build-tools-index/#wallets","title":"Wallets","text":"<p>Please see the Wallets page on the official website or the Wallets page on the Wiki for detailed information.</p>"},{"location":"build/build-tools-index/#block-explorers","title":"Block Explorers","text":"<ul> <li>Polkadot-JS Apps Explorer - Polkadot dashboard block   explorer. Supports dozens of other networks, including Kusama, Westend, and other remote or local   endpoints. Access via IPFS</li> <li>Subscan - Blockchain explorer for Substrate chains.   Repo.</li> <li>3xpl.com - Fastest ad-free universal block explorer and JSON API with   Polkadot support.</li> <li>Blockchair.com - Universal blockchain explorer and search   engine with Polkadot support.</li> <li>Statescan.io - Polkadot &amp; Kusama Blockchain explorer.</li> </ul>"},{"location":"build/build-tools-index/#blockchain-analytics","title":"Blockchain Analytics","text":"<ul> <li>Dune Analytics - Community dashboards and analytics</li> <li>DotLake - data visualizations for the Polkadot Ecosystem   maintained by Parity</li> <li>Web3go - An open platform for everyone to play with, curate and   visualize multi-blockchain data</li> <li>Polkawatch - Polkadot Decentralization Analytics</li> </ul>"},{"location":"build/build-tools-index/#network-monitoring-reporting","title":"Network Monitoring &amp; Reporting","text":"<ul> <li>Polkadot Telemetry Service - Network information including what   nodes are running the chain, what software versions they are running, sync status, and location.</li> <li>Polkabot - Polkadot network monitoring and reporting using Matrix   (Riot / Element) chat. Users may create custom bot plugins.   Blogpost.</li> <li>Ryabina's Telegram Bot - A Telegram bot for   monitoring on-chain events of Substrate chains.   GitHub Repository GitHub Repository.</li> <li>Panic - A node monitoring and alert server for validators.</li> <li>OpenWeb3/Guardian - A CLI tool and JS library to   monitor on chain states and events.</li> <li>Ocelloids SDK - Typescript SDK for multi-chain monitoring   that supports domain-specific logic for different pallets.</li> <li>Cyclops Dashboard - a validator dashboard application   that helps Polkadot network validators keep track of all their validators, their staking rewards,   and performance.</li> </ul>"},{"location":"build/build-tools-index/#clients","title":"Clients","text":"<ul> <li>Polkadot - The original Rust   implementation of the Polkadot Host.</li> <li>Kagome - A C++ Polkadot implementation of the Polkadot Host   developed by Soramitsu.</li> <li>Gossamer - A Go implementation of the Polkadot Host   developed by ChainSafe Systems.</li> <li>TxWrapper-core - Helper functions for offline   transaction generation.</li> </ul>"},{"location":"build/build-tools-index/#tools","title":"Tools","text":"<ul> <li>Substrate - Blockchain   development platform written in Rust. The Rust version of the Polkadot Host is being built with   Substrate.</li> <li>Substrate Docs - Comprehensive documentation and tutorials for   building a blockchain using Substrate.</li> <li>Substrate VSCode plugin (deprecated).</li> <li>Substrate Debug Kit (deprecated) - A   collection of debug tools and libraries around substrate chains. Includes tools to calculate NPoS   elections offline, disk usage monitoring, test templates against chain state and other   pallet-specific helper.</li> <li>POP CLI - An all-in-one tool for Polkadot development.</li> <li>Zombienet - Testing framework for Substrate based   blockchains</li> <li>Diener - A tool for easy changing of Polkadot or Substrate   dependency versions.</li> <li>Polkadot Launch (deprecated) - A tool to easily   launch custom local parachain-enabled Polkadot versions.</li> <li>Fork-off Substrate - Copies the state of an   existing chain into your local version and lets you further experiment on it.</li> <li>srtool - A tool for verifying runtime versions against   on-chain proposal hashes.</li> <li>sub-bench - A tool to spam your node with transactions for   the sake of benchmarking.</li> <li>substrate-devhub-utils - A set of   JavaScript utilities making life with Substrate a little easier.</li> <li>sub-flood (archived) - A tool to benchmark Substrate by   flooding it with requests.</li> <li>Apillon - A Web3 development platform with a complete toolbox and   access to Polkadot\u2019s technology stack.</li> </ul>"},{"location":"build/build-tools-index/#ides","title":"IDEs","text":"<ul> <li>Astar IDE by   Chain IDE is a tool for lightning-speed smart contracts and dApp   development for Wasm and   EVM.</li> <li>Sandox IDE is an integrated development environment (IDE)   with tools for building in the Polkadot environment. Currently helpful for creating applications   in JS.</li> </ul>"},{"location":"build/build-tools-index/#ui","title":"UI","text":"<ul> <li>Polkadash - VueJS-based starter kit for custom user   interfaces for Substrate chains.</li> <li>Polkadot JS Apps UI - Repository of the   polkadot.js.org/apps UI.</li> <li>Substrate Front-end Template -   ReactJS-based starter UI for custom user interfaces for Substrate chains.</li> <li>Polkadot JS Browser Extension - Key management in a   Chrome extension.</li> <li>PAPI Developer Console</li> <li>Polkadot Developer Console</li> </ul>"},{"location":"build/build-tools-index/#libraries","title":"Libraries","text":""},{"location":"build/build-tools-index/#polkadot-js-api","title":"Polkadot-JS API","text":"<p>The Polkadot-JS API provides various utility functions that are used across all projects in the <code>@polkadot</code> namespace and is split into a number of internal utility packages. The documentation and usage instructions are provided at Polkadot-JS API Documentation.</p> <ul> <li>@polkadot/keyring This allows you to create and load   accounts in JavaScript. It is helpful for creating wallets or any application that will require   the user to write to chain. Examples.</li> <li>@polkadot/util Utility   functions like checking if a string is hex-encoded.</li> <li>@polkadot/util-crypto Useful cryptographic utilities   for developing with Polkadot.</li> </ul>"},{"location":"build/build-tools-index/#alternative-libraries","title":"Alternative Libraries","text":"<p>The following libraries/SDKs allow for interfacing with a Substrate node in other languages:</p> <ul> <li>Python Library by Polkascan</li> <li>Go Library by Centrifuge</li> <li>Java Library by StrategyObject</li> <li>Fearless Utils iOS Swift SDK</li> <li>Nova Wallet iOS/Swift Substrate SDK</li> <li>Kotlin SDK</li> <li>Dart/Flutter Library</li> </ul>"},{"location":"build/build-tools-index/#cli-tools","title":"CLI Tools","text":"<ul> <li>@polkadot/api-cli Command   line interface for the polkadot API. Documentation.</li> <li>@polkadot/monitor-rpc An   RPC monitor for Polkadot. See the RPC tools below for additional information.</li> <li>@polkadot/signer-cli A   Tool to construct, sign, and broadcast transactions. Signing can be done offline.</li> <li>Polkadot API Cpp - A \u0421++ API for Polkadot, can   build <code>clip</code>, a command line tool.</li> <li>Subkey - Command line utility   for generating and inspecting key pairs.</li> </ul>"},{"location":"build/build-tools-index/#wasm","title":"WASM","text":"<p>WebAssembly related tools and projects.</p> <ul> <li>ink! - An eDSL to write WebAssembly based smart contracts   using the Rust programming language.</li> <li>parity-wasm - Low-level WebAssembly format library.</li> <li>wasm-utils - Collection of WebAssembly utilities used   in pwasm-ethereum and substrate contract development.</li> <li>wasmi - A WebAssembly interpreter conceived as a component   of parity-ethereum (Ethereum-like contracts in Wasm) and Substrate.</li> </ul>"},{"location":"build/build-tools-index/#rpc-and-api-tools","title":"RPC and API Tools","text":"<ul> <li>@polkadot/api/rpc-provider   Demonstrates how the JS tools interact with the node over RPC.</li> <li>RPC documentation - Documentation of Substrate RPC   methods.</li> <li>Polkadot API Server by SimplyVC - A wrapper   around the Polkadot API which makes it easier to make Polkadot API calls from any programming   language.</li> <li>Go: Subscan API - Go API for Polkadot.</li> <li>C++ Polkadot API - \u0421++ API for Polkadot.</li> <li>.NET Polkadot/Substrate API - Core   Framework for Substrate in .NET and connect to nodes.</li> <li>.NET Toolchain Polkadot/Substrate API -   Toolchain to generate Polkadot/Substrate API &amp; Service Layer for .NET.</li> <li>.NET Polkadot API - Polkadot Substrate API   for .NET.</li> <li>Python Polkadot API - Polkadot library for   Python.</li> <li>GSRPC - Substrate RPC client in Go,   a.k.a. GSRPC.</li> <li>Substrate API Sidecar - An HTTP wrapper for   Substrate, abstracting some complex RPC calls into simple REST calls.</li> <li>Subxt - A Rust library to submit extrinsics to a   Substrate node via RPC.</li> </ul>"},{"location":"build/build-tools-index/#game-engine-sdk","title":"GAME ENGINE SDK","text":"<ul> <li>Polkadot SDK for Unity - A powerful toolkit   that integrates substrate seamless into Unity projects.   (AssetStore,   wiki).</li> </ul>"},{"location":"build/build-tools-index/#scale-codec","title":"SCALE Codec","text":"<p>The SCALE (Simple Concatenated Aggregate Little-Endian) Codec is a lightweight, efficient, binary serialization and deserialization codec.</p> <p>It is designed for high-performance, copy-free encoding and decoding of data in resource-constrained execution contexts, such as the Substrate runtime. It is not self-describing in any way and assumes the decoding context has all type knowledge about the encoded data.</p> <p>It is used in almost all communication to/from Substrate nodes, so implementations in different languages exist:</p> <ul> <li>Substrate Awesome   maintains a list of SCALE codex implementations.</li> </ul>"},{"location":"build/build-tools-index/#data-crawling-and-conversion","title":"Data Crawling and Conversion","text":"<p>The following tools help you extract and structure data from a Substrate node.</p> <ul> <li>Parity's Substrate Archive - Can be run   alongside a Substrate node to archive all blocks, state, and extrinsic data into PostgreSQL   database.</li> <li>SQD Archives - Generate a GraphQL database   from a Substrate chain's data with rich filtering and querying capabilities. The data (events,   extrinsics, blocks) for most parachains is readily available though public archive GraphQL   endpoints, kept in   Squid Archive Registry</li> <li>Polka-store - A tool which scans a Substrate chain   and stores balance-relevant transactions in an SQLite database.</li> <li>Substrate-graph - A compact indexer for Substrate   based nodes providing a GraphQL interface.</li> </ul>"},{"location":"build/build-transaction-construction/","title":"Transaction Construction and Signing","text":"<p>This page will discuss the transaction format in Polkadot and how to create, sign, and broadcast transactions. Like the other pages in this guide, this page demonstrates some of the available tools. Always refer to each tool's documentation when integrating.</p>"},{"location":"build/build-transaction-construction/#transaction-format","title":"Transaction Format","text":"<p>Polkadot has some basic transaction information that is common to all transactions.</p> <ul> <li>Address: The SS58-encoded address of the sending account.</li> <li>Block Hash: The hash of the checkpoint block.</li> <li>Block Number: The number of the checkpoint block.</li> <li>Genesis Hash: The genesis hash of the chain.</li> <li>Metadata: The SCALE-encoded metadata for the runtime when submitted.</li> <li>Nonce: The nonce for this transaction.*</li> <li>Spec Version: The current spec version for the runtime.</li> <li>Transaction Version: The current version for transaction format.</li> <li>Tip: Optional, the tip to increase transaction priority.</li> <li>Mode: The flag indicating whether to verify the metadata hash or not.</li> <li>Era Period: Optional, the number of blocks after the checkpoint for which a transaction is valid.   If zero, the transaction is immortal</li> <li>MetadataHash: Optional, the metadata hash which should match the RUNTIME_METADATA_HASH environment   variable.</li> </ul> <p>Caution</p> <p>There are risks to making a transaction immortal. If an account is reaped and a user re-funds the account, then they could replay an immortal transaction. Always default to using a mortal extrinsic.</p> <p>*The nonce queried from the System module does not account for pending transactions. You must track and increment the nonce manually if you want to submit multiple valid transactions at the same time.</p> <p>Each transaction will have its own (or no) parameters to add. For example, the <code>transferKeepAlive</code> function from the Balances pallet will take:</p> <ul> <li><code>dest</code>: Destination address</li> <li><code>#[compact] value</code>: Number of tokens (compact encoding)</li> </ul> <p>Refer to the protocol specifications, for the concrete specifications and types to build a transaction.</p> <p>Mode and MetadataHash</p> <p>The mode and metadataHash fields were introduced in transaction construction to support the optional <code>CheckMetadataHash</code> Signed Extension. This enables trustless metadata verification by allowing the chain to verify the correctness of the metadata used without the need of a trusted party. This functionality was included in v1.2.5 runtime release by the Fellowship. A user may up out of this functionality by setting the mode to <code>0</code>. When the mode is 00, the <code>metadataHash</code> field is empty/None.</p> <p>Serialized transactions and metadata</p> <p>Before being submitted, transactions are serialized. Serialized transactions are hex encoded SCALE-encoded bytes. The relay chain runtimes are upgradable and therefore any interfaces are subject to change, the metadata allows developers to structure any extrinsics or storage entries accordingly. The metadata provides you with all of the information required to know how to construct the serialized call data specific to your transaction. You can read more about the metadata, its format and how to get it in the Substrate documentation.</p> <p>Summary</p> <p>The typical transaction workflow is as follows:</p> <ol> <li>Construct an unsigned transaction.</li> <li>Create a signing payload.</li> <li>Sign the payload.</li> <li>Serialize the signed payload into a transaction.</li> <li>Submit the serialized transaction.</li> </ol> <p>Parity provides the following tools to help perform these steps.</p>"},{"location":"build/build-transaction-construction/#polkadot-js-tools","title":"Polkadot-JS Tools","text":"<p>Polkadot-JS Tools contains a set of command line tools for interacting with a Substrate client, including one called \"Signer CLI\" to create, sign, and broadcast transactions.</p> <p>This example will use the <code>signer submit</code> command, which will create and submit the transaction. The <code>signer sendOffline</code> command has the exact same API, but will not broadcast the transaction. <code>submit</code> and <code>sendOffline</code> must be connected to a node to fetch the current metadata and construct a valid transaction. Their API has the format:</p> <pre><code>yarn run:signer &lt;submit|sendOffline&gt; --account &lt;from-account-ss58&gt; --ws &lt;endpoint&gt; &lt;module.method&gt; [param1] [...] [paramX]\n</code></pre> <p>Signing:</p> <pre><code>yarn run:signer sign --account &lt;from-account-ss58&gt; --seed &lt;seed&gt; --type &lt;sr25519|ed25519&gt; &lt;payload&gt;\n</code></pre> <p>For example, let's send 0.5 DOT from <code>121X5bEgTZcGQx5NZjwuTjqqKoiG8B2wEAvrUFjuw24ZGZf2</code> to <code>15vrtLsCQFG3qRYUcaEeeEih4JwepocNJHkpsrqojqnZPc2y</code>.</p> <pre><code>yarn run:signer submit --account 121X5bEgTZcGQx5NZjwuTjqqKoiG8B2wEAvrUFjuw24ZGZf2 --ws ws://127.0.0.1:9944 balances.transferKeepAlive 15vrtLsCQFG3qRYUcaEeeEih4JwepocNJHkpsrqojqnZPc2y 5000000000\n</code></pre> <p>This will return a payload to sign and an input waiting for a signature. Take this payload and use your normal signing environment (e.g. air gapped machine, VM, etc.). Sign the payload:</p> <pre><code>yarn run:signer sign --account 121X5bEgTZcGQx5NZjwuTjqqKoiG8B2wEAvrUFjuw24ZGZf2 --seed \"pulp gaze fuel ... mercy inherit equal\" --type sr25519 0x040300ff4a83f1...a8239139ff3ff7c3f6\n</code></pre> <p>Save the output and bring it to the machine that you will broadcast from, enter it into <code>submit</code>'s signature field, and send the transaction (or just return the serialized transaction if using <code>sendOffline</code>).</p>"},{"location":"build/build-transaction-construction/#tx-wrapper","title":"Tx Wrapper","text":"<p>If you do not want to use the CLI for signing operations, Parity provides an SDK called TxWrapper Core to generate and sign transactions offline. For Polkadot, Kusama, and select parachains, use the <code>txwrapper-polkadot</code> package. Other Substrate-based chains will have their own <code>txwrapper-{chain}</code> implementations. See the examples for a guide.</p> <p>Import a private key</p> <pre><code>import { importPrivateKey } from '@substrate/txwrapper-polkadot';\n\nconst keypair = importPrivateKey(\u201cpulp gaze fuel ... mercy inherit equal\u201d);\n</code></pre> <p>Derive an address from a public key</p> <pre><code>import { deriveAddress } from '@substrate/txwrapper-polkadot';\n\n// Public key, can be either hex string, or Uint8Array\nconst publicKey = \u201c0x2ca17d26ca376087dc30ed52deb74bf0f64aca96fe78b05ec3e720a72adb1235\u201d;\nconst address = deriveAddress(publicKey);\n</code></pre> <p>Construct a transaction offline</p> <pre><code>import { methods } from \"@substrate/txwrapper-polkadot\";\n\nconst unsigned = methods.balances.transferKeepAlive(\n  {\n    dest: \"15vrtLsCQFG3qRYUcaEeeEih4JwepocNJHkpsrqojqnZPc2y\",\n    value: 5000000000,\n  },\n  {\n    address: \"121X5bEgTZcGQx5NZjwuTjqqKoiG8B2wEAvrUFjuw24ZGZf2\",\n    blockHash: \"0x1fc7493f3c1e9ac758a183839906475f8363aafb1b1d3e910fe16fab4ae1b582\",\n    blockNumber: 4302222,\n    genesisHash: \"0xe3777fa922cafbff200cadeaea1a76bd7898ad5b89f7848999058b50e715f636\",\n    metadataRpc, // must import from client RPC call state_getMetadata\n    nonce: 2,\n    specVersion: 1019,\n    tip: 0,\n    eraPeriod: 64, // number of blocks from checkpoint that transaction is valid\n    transactionVersion: 1,\n  },\n  {\n    metadataRpc,\n    registry, // Type registry\n  }\n);\n</code></pre> <p>Construct a signing payload</p> <pre><code>import { methods, createSigningPayload } from '@substrate/txwrapper-polkadot';\n\n// See \"Construct a transaction offline\" for \"{...}\"\nconst unsigned = methods.balances.transferKeepAlive({...}, {...}, {...});\nconst signingPayload = createSigningPayload(unsigned, { registry });\n</code></pre> <p>Serialize a signed transaction</p> <pre><code>import { createSignedTx } from \"@substrate/txwrapper-polkadot\";\n\n// Example code, replace `signWithAlice` with actual remote signer.\n// An example is given here:\n// https://github.com/paritytech/txwrapper-core/blob/b213cabf50f18f0fe710817072a81596e1a53cae/packages/txwrapper-core/src/test-helpers/signWithAlice.ts\nconst signature = await signWithAlice(signingPayload);\nconst signedTx = createSignedTx(unsigned, signature, { metadataRpc, registry });\n</code></pre> <p>Decode payload types</p> <p>You may want to decode payloads to verify their contents prior to submission.</p> <pre><code>import { decode } from \"@substrate/txwrapper-polkadot\";\n\n// Decode an unsigned tx\nconst txInfo = decode(unsigned, { metadataRpc, registry });\n\n// Decode a signing payload\nconst txInfo = decode(signingPayload, { metadataRpc, registry });\n\n// Decode a signed tx\nconst txInfo = decode(signedTx, { metadataRpc, registry });\n</code></pre> <p>Check a transaction's hash</p> <pre><code>import { getTxHash } from \u2018@substrate/txwrapper-polkadot\u2019;\nconst txHash = getTxHash(signedTx);\n</code></pre>"},{"location":"build/build-transaction-construction/#submitting-a-signed-payload","title":"Submitting a Signed Payload","text":"<p>There are several ways to submit a signed payload:</p> <ol> <li>Signer CLI (<code>yarn run:signer submit --tx &lt;signed-transaction&gt; --ws &lt;endpoint&gt;</code>)</li> <li>Substrate API Sidecar</li> <li>RPC with <code>author_submitExtrinsic</code> or    <code>author_submitAndWatchExtrinsic</code>, the latter of which will subscribe you to events to be notified    as a transaction gets validated and included in the chain.</li> </ol>"},{"location":"build/build-transaction-construction/#notes","title":"Notes","text":"<p>Some addresses to use in the examples. See Subkey documentation.</p> <pre><code>$ subkey --network polkadot generate\nSecret phrase `pulp gaze fuel ... mercy inherit equal` is account:\n  Secret seed:      0x57450b3e09ba4598 ... ... ... ... ... ... ... .. 219756eeba80bb16\n  Public key (hex): 0x2ca17d26ca376087dc30ed52deb74bf0f64aca96fe78b05ec3e720a72adb1235\n  Account ID:       0x2ca17d26ca376087dc30ed52deb74bf0f64aca96fe78b05ec3e720a72adb1235\n  SS58 Address:     121X5bEgTZcGQx5NZjwuTjqqKoiG8B2wEAvrUFjuw24ZGZf2\n\n$ subkey --network polkadot generate\nSecret phrase `exercise auction soft ... obey control easily` is account:\n  Secret seed:      0x5f4bbb9fbb69261a ... ... ... ... ... ... ... .. 4691ed7d1130fbbd\n  Public key (hex): 0xda04de6cd781c98acf0693dfb97c11011938ad22fcc476ed0089ac5aec3fe243\n  Account ID:       0xda04de6cd781c98acf0693dfb97c11011938ad22fcc476ed0089ac5aec3fe243\n  SS58 Address:     15vrtLsCQFG3qRYUcaEeeEih4JwepocNJHkpsrqojqnZPc2y\n</code></pre>"},{"location":"build/archive/","title":"Archive","text":"<ul> <li>Transaction Construction - Guide on Transaction Construction.</li> <li>Integration - Guide on Integration.</li> <li>Node Management - Guide on Node Management.</li> <li>Parachains - Guide on Parachains.</li> </ul>"},{"location":"build/client/","title":"Client-side Development","text":"<ul> <li>Client-side Development - Guide on Client-side Development.</li> <li>Light Clients - Guide on Light Clients.</li> <li>Node Interaction - Guide on Node Interaction.</li> </ul>"},{"location":"build/protocol/","title":"Protocol Development","text":"<ul> <li>Install Dependencies - Guide to Install Dependencies.</li> <li>Basic Template - Basic Template Guide.</li> <li>Coretime Troubleshooting - Guide for Coretime Troubleshooting.</li> <li>Coretime Swap - Guide for Coretime Swap.</li> <li>Protocol Information - Information on Protocol.</li> <li>Integrate Assets - Guide to Integrate Assets.</li> <li>HRMP Channels - Guide for HRMP Channels.</li> </ul>"},{"location":"build/tooling/","title":"Tooling","text":"<ul> <li>Data - Guide on Data.</li> <li>Open Source - Guide on Open Source.</li> </ul>"},{"location":"general/","title":"Explore","text":"<ul> <li>Wallets - Information about wallets.</li> <li>Apps - Details on various apps.</li> <li>Dashboards - Access to dashboards.</li> <li>Community &amp; Contributors - Community and contributor information.</li> <li>Funding - Funding opportunities and details.</li> <li>Programs - Information on various programs.</li> </ul>"},{"location":"general/alpha-program/","title":"Polkadot Alpha Program","text":"<p>Over 150 projects are using the Polkadot SDK to create the next generation of blockchain infrastructure and application-specific chains.</p> <p>The Polkadot Alpha Program is an initiative by Parity Technologies to take your Polkadot SDK-powered project to the next level.</p> <p>Take your project from idea to market with comprehensive resources and collaborative development while seizing the opportunity to shape the future of the Polkadot ecosystem.</p>"},{"location":"general/alpha-program/#who-can-join-the-program","title":"Who can join the program?","text":"<p>The Polkadot Alpha Program is for teams with a project they want to take into production and business execution. If your team is working on something that\u2019s not yet live, and you are ready to experiment while receiving and providing feedback, get involved now.</p> <ul> <li> <p>Parachain teams - Focused on developing new chains or products within the Polkadot network,   aiming to transition from prototypes to fully operational parachains and accessing coretime.</p> </li> <li> <p>Infrastructure providers - Dedicated to enhancing the ecosystem's underlying architecture,   including node services, security solutions, API interfaces, and testing for robustness and   integration.</p> </li> <li> <p>Dapp teams - Engaged in exploring and validating innovative blockchain concepts, leveraging   the program's resources to refine and scale their ideas into viable projects.</p> </li> </ul>"},{"location":"general/alpha-program/#why-join-the-polkadot-alpha-program","title":"Why join the Polkadot Alpha Program?","text":"<p>The term \"Alpha\" comes from alpha testing, a form of pre-production testing and iteration of product development. The program aims to enable your team to tap into Polkadot\u2019s ecosystem of resources and bring your product into production while contributing to feedback for Polkadot\u2019s ecosystem.</p> <p>Check out the official Polkadot Alpha Program site for more information and steps on how to apply.</p>"},{"location":"general/ambassadors/","title":"Polkadot Ambassador Program","text":"<p>Polkadot Ambassador On-chain Collective</p> <p>Polkadot Ambassador Program is transitioning into an on-chain, rank-based, system collective after the approval of Polkadot OpenGov referenda 487.</p> <p>If you are enthusiastic about Polkadot and Web3 and are willing to help the community grow, you can join the program and receive funding for hosting events, gain access to communication channels of core team members, and gain access to Polkadot events.</p> <p>There are many ways you can get involved in expanding Polkadot\u2019s ecosystem, such as:</p> <ul> <li>Contributing code and documentation related to the ecosystem</li> <li>Speaking about Polkadot at events, workshops, and meetups</li> <li>Writing blog posts</li> <li>Representing Polkadot in your region</li> <li>Mentoring and onboarding newcomers</li> <li>Identifying partnerships and opportunities for the Polkadot ecosystem</li> <li>Participating in calls and tasks that help drive the ecosystem forward</li> </ul>"},{"location":"general/bug-bounty/","title":"Bug Bounty Program","text":"<p>If you discover a bug, we appreciate your cooperation in responsibly investigating and reporting it as per instructions on Web3 Foundation website. Disclosure to any third parties disqualifies bug bounty eligibility.</p> <p>Bug bounty program scope</p> <p>The bug bounty program does not cover bugs on code bases that are external to or, written on top of Polkadot, or that use Polkadot. To be eligible for the bug bounty program the bug has to be a part of the Polkadot codebase, this includes protocols that Polkadot uses such as AnV, XCM, GRANDPA, etc.</p> <p>We call on our community and all bug bounty hunters to help identify bugs in Polkadot.</p>"},{"location":"general/bug-bounty/#eligibility","title":"Eligibility","text":"<p>Generally speaking, any bug that poses a significant vulnerability, either to the soundness of protocols and protocol/implementation compliance to network security, to classical client security, as well as security of cryptographic primitives, could be eligible for a reward. Please note that it's entirely our discretion to decide whether a bug is significant enough to qualify for a reward.</p> <p>Note</p> <p>The submission quality will be a significant factor in the level of considered compensation. A high-quality submission includes explaining how the bug can be reproduced, how it was discovered, and otherwise critical details. Please disclose responsibly; disclosure to any third parties disqualifies bug bounty eligibility.</p> <p>Examples:</p> <ul> <li>An attack that could disrupt the entire network and harm the validity to the network would be considered a critical threat.</li> <li>An attack that would disrupt service to others would be regarded as a high threat.</li> </ul> <p>Responsible investigation and reporting</p> <p>Responsible investigation and reporting include, but isn't limited to, the following:</p> <ul> <li>Don't violate the privacy of other users, destroy data, etc.</li> <li>Don't defraud or harm Polkadot network or its users during your research; you should make a good faith effort not to interrupt or degrade our services.</li> <li>Don't target the validators' physical security measures, or attempt to use social engineering, spam, distributed denial of service (DDoS) attacks, etc.</li> <li>Initially, report the bug only to us and not to anyone else.</li> <li>Give us a reasonable amount of time to fix the bug before disclosing it to anyone else, and give us adequate written warning before disclosing it to anyone else.</li> <li>In general, please investigate and report bugs in a way that makes a reasonable, good-faith effort not to be disruptive or harmful to our users or us. Otherwise, your actions might be interpreted as an attack rather than an effort to be helpful.</li> </ul>"},{"location":"general/bug-bounty/#how-to-report-a-bug","title":"How to report a bug","text":"<p>Please follow the instructions at web3.foundation/security-report/.</p>"},{"location":"general/build-open-source/","title":"Open Source Polkadot Stack","text":"<p>Do your research before using open-source tools</p> <p>The tools listed here are open-source and are linked directly to their source code. Before using these tools to build your projects, always do your research and be aware of scams.</p> <p>This page aims to provide an overview of the open-source Polkadot Tech Stack.</p> <p>This is a living document, and we rely on everyone to contribute and help maintain it. Please feel free to make edits and additions via pull requests. We apologize if we missed your project!</p> <ul> <li>About</li> <li>Layers of Polkadot Stack</li> <li>Wallets</li> <li>User Interface</li> <li>Tools, APIs, and Languages</li> <li>ink! Smart Contracts</li> <li>Chains and Pallets</li> <li>Host</li> <li>Network Maintenance Tools</li> <li>Signatures</li> <li>Consensus</li> <li>Networking</li> <li>Primitives</li> <li>Contributing</li> </ul>"},{"location":"general/build-open-source/#about","title":"About","text":"<p>The Polkadot Tech Stack is a subset of the Web 3.0 Tech Stack, which consists of the open-source technologies contributing to and relying on Polkadot. It is meant to be used for decentralized application (Dapp) development within numerous verticals, including DeFi, Gaming, Provenance and many others not pictured below.</p> <pre><code>|------|--------|------------|\n| DeFi | Gaming | Provenance |\n|______|________|____________|\n            Dapps\n|--------------------------/-|\n| Explorers, Wallets      /  |\n|------------------------/---|\n| Tools, Apis, Languages/    |\n|----------------------/-----|\n| 2nd layer protocols /      |\n|--------------------/-------|\n| Chains            /  other |\n|------------------/---    --|\n| *Polkadot*      |   tech   |\n|------------------\\---------|\n| P2P, Crypto, Wasm \\        |\n|--------------------\\-------|\n</code></pre>"},{"location":"general/build-open-source/#layers-of-polkadot-stack","title":"Layers of Polkadot Stack","text":"<p>In the below sections, you can find a list of different layers of the Polkadot Stack.</p> <p>Maintenance Status:</p> <ul> <li>\ud83d\udfe2 Actively maintained</li> <li>\ud83d\udfe1 Stale (no activity on the main branch for one month)</li> <li>\u26aa Unmaintained (no activity on the main branch for more than three months)</li> </ul>"},{"location":"general/build-open-source/#wallets","title":"Wallets","text":"Components Existing projects Potentially interesting projects Web Wallets Multix \ud83d\udfe2, Polkasafe \u26aa, polkadot-js/apps \ud83d\udfe2, Talisman Web Application \ud83d\udfe2, mydotwallet \u26aa, Sub ID \u26aa, Primis \u26aa, Sakura \u26aa, Web3Box \u26aa, Coong Wallet \u26aa, Subscan Multisig UI - React \u26aa, Subscan Multisig UI \u26aa, Dorafactory-Multisig \u26aa, Capi Multisig App \u26aa User-friendly Wallet based on the Recovery Pallet, Web wallets focused on user-onboarding (e.g. using localStorage) Desktop Wallets nova-spektr \ud83d\udfe2, Omni desktop \u26aa Enterprise Wallets Browser Extensions Talisman-Extension \ud83d\udfe2, SubWallet-Extension \ud83d\udfe2, Enkrypt \ud83d\udfe2, Polkadot-JS \ud83d\udfe2, PolkaGate \ud83d\udfe2, Trust Wallet Extension \ud83d\udfe2, Doter \u26aa, Speckle OS \u26aa, Kuma Cross-chain Wallet \ud83d\udfe1 Sign-in with your Polkadot, Kusama, etc. account. Mobile Wallets Nova Wallet iOS \ud83d\udfe2, Nova Wallet Android \ud83d\udfe2, Polkadot Vault \u26aa, Fearless Wallet Android \ud83d\udfe2, Fearless Wallet iOS \u26aa, Trust Wallet \ud83d\udfe2, SubWallet-Mobile \u26aa, Kampela \ud83d\udfe1, AirGap \ud83d\udfe1, Interstellar Network \u26aa, Lunie \u26aa, Polkawallet \u26aa, imToken \u26aa, Stylo \u26aa, Fractapp \u26aa, Hashed Wallet \u26aa Burner Wallets/Faucet/Gifts dotdrop \u26aa, KodaDot \u26aa, Astar Faucet Bot \u26aa, Generic sybil-resistant faucet \u26aa, sybil-resistant Chat Bot Faucet Faucet (a sybil-resistant way to receive free tokens) Wallet Plugins Metamask-Snap by Chainsafe \u26aa CLI Wallet Subwallet \u26aa, Proxy-hot-wallet \u26aa Hardware Wallets Ledger Polkadot \u26aa, Ledger Kusama \ud83d\udfe1, Ledger Statemint \ud83d\udfe1, Ledger Statemine \ud83d\udfe1 Trezor OAuth2-compatible Wallets DOT Login \u26aa"},{"location":"general/build-open-source/#user-interface","title":"User Interface","text":"Components Existing projects Potentially interesting projects Block Explorers Calamar \u26aa, Polkascan \u26aa, Polkastats \u26aa, Subscan \u26aa, Statescan \ud83d\udfe1, Edgscan \u26aa, Sirato \u26aa, ink! Explorer API \u26aa, Substats \u26aa, Hybrid Block Explorer \u26aa Mempool focused explorer (including parachain transaction) Validator Dashboards Polkadot Telemetry \ud83d\udfe2, Polkacube \u26aa, YieldScan \u26aa, Hubble \u26aa, Cyclops \ud83d\udfe1, Web3Go \u26aa, 1kv insights \u26aa Node Explorers Polkadot Node Explorer \u26aa NFT Explorer NFT Explorer for Kusama &amp; Polkadot \ud83d\udfe2 Governance Dashboards Polkadot Delegation Dashboard \u26aa, Polkassembly \u26aa, dotreasury \ud83d\udfe2, Bright Treasury \u26aa, OpenSquare offchain voting \ud83d\udfe2, OpenGov Insights \u26aa, Treasury Tracker \u26aa, OpenGov CLI \u26aa UI for the Kusama and/or Polkadot treasury (see bounty module), UI for Parachain Lease Offering (PLO) Staking Staking Rewards Collector \ud83d\udfe2, Staking Rewards Viewer \u26aa, Polkadot Staking Site \u26aa, Polkadot Staking Dashboard \ud83d\udfe2, Polkadot/Kusama Validator Selector \u26aa, Staking Income CSV Generator \u26aa Bridge UI Parity Bridges UI \u26aa, Donut Interface (Steem - Dot) \u26aa, Plutonication \u26aa Parachain/Crowdloan Parachains.Network , PolkAuction \u26aa, Crowdloan Front End Template \u26aa, Slothunter \u26aa Identicon Polkicon \ud83d\udfe2, PolkadotWebIdenticon \u26aa, Polkadot Angular IdentIcon \u26aa, Bird Identicon \u26aa Coretime Lastic \ud83d\udfe1, RegionX \ud83d\udfe2 Other Polkadot Cloud \ud83d\udfe2, \u0110\u00d3TConsole \ud83d\udfe2, KappaSigmaMu Fratority \ud83d\udfe1, DAOSign \ud83d\udfe1, Quadratic Funding Webapp \u26aa, Polkawatch, Bytepay \u26aa, charging-management-platform \u26aa, subidentity-webapp \u26aa, OpenSquare Paid QA \u26aa, DotPulse \u26aa, Rubeus Keeper \u26aa, Polkaflow \u26aa, ChainViz \ud83d\udfe1, Dotsight \u26aa zkLogin, Portfolio Viewer like Zapper or Zerion"},{"location":"general/build-open-source/#tools-apis-and-languages","title":"Tools, APIs, and Languages","text":"Components Existing projects Potentially interesting projects Runtime/Parachain frameworks Polkadot Blockchain SDK \ud83d\udfe2, Gosemble \ud83d\udfe2, Subsembly \u26aa, Parachain utilities \u26aa, Gantree \u26aa, Cryptex \ud83d\udfe2 Tools to create parachains with other frameworks, like the Cosmos SDK or Polygon CDK Client Libraries Polkadot-API - Typescript \ud83d\udfe2, Reactive DOT - Typescript \ud83d\udfe1, Capi - Typescript \u26aa, sub-api \ud83d\udfe1, Go \u26aa, .Net \u26aa, .NET Standard 2.0 \ud83d\udfe1, Substrate .NET Toolchain \ud83d\udfe2, C++ \u26aa, C \u26aa, Haskell \ud83d\udfe1, Javascript \ud83d\udfe2, Substrate API Sidecar - TypeScript \ud83d\udfe2, Python \ud83d\udfe1, Java (+ Android) \u26aa, Substrate Client Java \u26aa, Rust SCS \ud83d\udfe1, Rust Parity (subxt) \ud83d\udfe2, subxtpy \ud83d\udfe1, Rust pdotc PHP (gmajor-encrypt) \ud83d\udfe1, PHP (neha0921) \u26aa, RPC-Ethereum \ud83d\udfe2, Swift \u26aa, Kotlin \u26aa, substrate-client-kotlin \u26aa, substrate-client-swift \u26aa, Dart \ud83d\udfe2, Substrate Core Polywrapper \u26aa, Substrate SDK iOS \ud83d\udfe1, Substrate SDK Android \u26aa, Dedot - Typescript \ud83d\udfe2 RPC Gateway Subway \ud83d\udfe1 Substrate Contract clients PatractGo \u26aa Easy Runtime Development Subalfred \ud83d\udfe1, substrate-stencil \u26aa, Play Substrate \u26aa, substrate-node-template , Substrate Playground \u26aa, AssemblyScript Runtime Generation \u26aa, Substrate Package Manager \u26aa, Subsembly: Framework for developing AssemblyScript Substrate Runtimes \u26aa, dependency diener \u26aa IDE Plugins Substrate Marketplace VS Code Plugin \u26aa, VS Code Plugin \u26aa, Atom Code Plugin \u26aa, zombienet extension \u26aa Runtime/Pallet Security Substrate Runtime Fuzzer \ud83d\udfe2, Substrate Toml Lint \u26aa, K specifications \ud83d\udfe2, PolPatrol - Polkadot Runtime Checker \u26aa, pallet-verifier \ud83d\udfe2 Automated Runtime checking tools, economic audit simulator such as gauntlet.network Smart Contract Languages ink! \ud83d\udfe2, Ask! \u26aa, Subscript \u26aa, Solang \ud83d\udfe2, pallet-move \u26aa, Move VM Substrate \u26aa, Move smart contract by Neatcoin \u26aa, eBPF Contracts Hackathon \u26aa, PolkaVM \ud83d\udfe2 Functional Programming Languages, other languages with developed toolchains Testing Polkadot introspector \ud83d\udfe2, Subshell \ud83d\udfe2, substrate-simnode \ud83d\udfe2, Halva \u26aa, Redspot \u26aa, MixBytes Tank \u26aa, sub-flood \u26aa, Substrate debug-kit \u26aa, Asset CLI tool \ud83d\udfe1, sub_crash \u26aa, subwasm \u26aa, subsee \u26aa, polkadot-lab \u26aa,  RPC-perf \u26aa Static Analysis Substrace \u26aa, Static analyzer for Substrate FRAME's pallets \u26aa, CoinFabrik Scout \ud83d\udfe2, pallet-verifier \ud83d\udfe2 Formal Verification pallet-verifier \ud83d\udfe2, K specifications \ud83d\udfe2 Testnet Zombienet \ud83d\udfe2, Chopsticks \ud83d\udfe2, Polkadot Launch \u26aa, polkadot-starship \u26aa, Fork off Substrate \u26aa, try-runtime-cli \u26aa, Parachain Launch \ud83d\udfe2, Larch Zombienet GUI \u26aa Benchmarking Benchmarking CLI \ud83d\udfe2, Polkadot sTPS \u26aa, Clockchain \u26aa, Substrate Graph Benchmarks \u26aa, ink! &amp; pallet benchmarking template \u26aa, smart-bench \ud83d\udfe1 Blockchain Indexing Engine Squid SDK \ud83d\udfe2, Hybrid Indexer \u26aa, Substrate Archive \u26aa, PSQL Indexer \u26aa, Substrate Graph \u26aa, Subquery \ud83d\udfe2, MBELT3 \ud83d\udfe1, stick \ud83d\udfe1, Hyperdot \u26aa Blockchain/Event Monitoring Web3 Guardian \u26aa, Aurras Event Manager \u26aa, @commonwealth/chain-events \u26aa, Massbit \u26aa, Polkadot Basic Notifications \u26aa, Ocelloids \ud83d\udfe2, Tracking Chain \u26aa, Gaming Polkadot SDK for Unity \u26aa, Crossbow \u26aa Unity Asset Store, Amethyst + Substrate No-code Platforms EzCode's Polkadot-JS plugin on Bubble.io \u26aa, Blackprint Visual Programming Polkadot-JS module \u26aa, SubRelay \u26aa Wallets DOT Connect \ud83d\udfe1, Talisman Connect \ud83d\udfe1, SubWallet-SubConnect \u26aa, Metadata Portal \ud83d\udfe2, Tesseract \u26aa, WalletConnect \u26aa, BitGoJS \ud83d\udfe2 XCM Trappist \u26aa, XCM-tools \ud83d\udfe2, XCM-tools Golang \u26aa,ParaSpell XCM Tools \ud83d\udfe2, XBI \u26aa, XCM TS/JS SDK \u26aa, XCMSend \ud83d\udfe2, XCM Monitoring Server \ud83d\udfe2, Moonbeam Foundation XCM-SDK \ud83d\udfe2 Other asset-transfer-api \ud83d\udfe2, txwrapper-core \ud83d\udfe2, open-web3 JS library \u26aa, VM-Bridge \u26aa, srtool \ud83d\udfe2, srtool-cli \u26aa, Substrate Tip Bot \ud83d\udfe1, ORI (Onchain Risk Intelligence) \u26aa, PolkaTools \ud83d\udfe1, polkadot-scripts \u26aa, Sube \u26aa, data-store-sidecar \u26aa, SugarFunge \u26aa, substrate-wasmedge \u26aa, EightFish \u26aa, Sandox \u26aa, APK verifier \u26aa"},{"location":"general/build-open-source/#ink-smart-contracts","title":"ink! Smart Contracts","text":"Components Existing projects Potentially interesting projects Core Libraries ink! \ud83d\udfe2, cargo-contract \ud83d\udfe2, pallet-contracts \ud83d\udfe2 Local Nodes substrate-contracts-node \ud83d\udfe1, Swanky \u26aa Smart Contract Development DRink! \ud83d\udfe1, contracts-ui \u26aa, SmartBeaver, OpenBrush , Sol2Ink \u26aa, Polkadot Contract Wizard \u26aa, ink-wrapper \u26aa, ink-playground \u26aa, ink! Remix Plugin \u26aa, Signac \u26aa, ink!-boxes \u26aa, ink!-smart-contract-wizard \u26aa Security &amp; Testing ink! Waterfall \u26aa, Verifier Image for ink! \u26aa, Patron \u26aa, Inkscope Fuzzer \u26aa Frontend Development ink!athon Boilerplate \ud83d\udfe1, useink \u26aa, useInkathon \ud83d\udfe1, ink-typegen \ud83d\udfe2, Typechain Polkadot \u26aa IDE Plugins ink! Analyzer \ud83d\udfe2 Bridges Dante Protocol \u26aa DeFi Pendulum-Ink-Wrapper \u26aa, Panorama Swap \u26aa, ink_bank \u26aa, Polkadot AMM \u26aa, Vera \u26aa, Nsure Insurance , Everlasting Cash \u26aa, Coinversation \u26aa, zenlink-dex-contract \u26aa, AlgoCash \ud83d\udfe1 New seigniorage-style stable coins Gaming Open Emoji Battler \u26aa, NewOmega \u26aa DAO SyncraDAO , subDAO \u26aa, RainbowDAO \u26aa, MangoBox \u26aa, MangoSale \u26aa Identity/DID Dotflow \ud83d\udfe2 Oracles DIA WASM Oracle \u26aa Spam Protection Prosopo \ud83d\udfe2 Governance Abax Governance \u26aa NFT ArtZero \u26aa Other Polkadot Smart Account \u26aa, magink \u26aa, ink-test-contracts \u26aa, Candle Auctions \u26aa, polkasign-contract \u26aa, OCEX \u26aa, Roloi \u26aa, OpenPayroll \u26aa, BlockchainFoodOrder \u26aa"},{"location":"general/build-open-source/#chains-and-pallets","title":"Chains and Pallets","text":"Components Existing projects Potentially interesting projects Scalable Transactions Perun channels \u26aa, CLI demo of Perun \u26aa, Astar \ud83d\udfe2, Celer \u26aa, Gunclear \u26aa, TPScore \u26aa, proof-of-contract-stake \u26aa roll-ups, DAG-based consensus mechanisms, side chains Bridges and Interoperability interBTC \u26aa, DKG Substrate \u26aa, Sygma \u26aa, EOS by Bifrost \u26aa, POA - Substrate \u26aa, Substrate - Ethereum DAI Bridge \u26aa, Substrate - Substrate Bridge \u26aa, BTC by ChainX \u26aa, Cosmos-Substrate bridge \u26aa, Substrate IBC Pallet \u26aa, Polkadot Ethereum Bridge \ud83d\udfe2, Darwinia \ud83d\udfe2, Spacewalk: a Stellar bridge \ud83d\udfe2, Filecoindot \u26aa, Axelar-Substrate \u26aa, Hyperbridge \ud83d\udfe2, t3rn \ud83d\udfe2 ZCash Privacy ZeroChain \u26aa, xx network \u26aa, pLibra (Phala Network) \ud83d\udfe1, Automata Network \u26aa, Zero Network \u26aa, Silent Data \u26aa Multi-Asset Shielded Pool (MASP) , Zkay, Zexe ZKP ZeroPool \u26aa, Megaclite \u26aa, zkMega \u26aa, PLONK for Substrate \u26aa, Webb Anchor Protocol \u26aa, zk-SNARKs tutorial \u26aa, substrate-zk \u26aa, hyperfridge-r0 \u26aa, Cyborg Network \ud83d\udfe2, Manta \ud83d\udfe1 TEE Acurast \u26aa, Integritee \ud83d\udfe2, substraTEE \u26aa, WeTEE \ud83d\udfe2 Keysafe Protocol \u26aa DeFi PrivaDEX \u26aa, Fusotao \u26aa, Reef \u26aa, Diora \u26aa, Pendulum Chain \ud83d\udfe1, Compound Gateway \u26aa, Parallel Finance \u26aa, PINT \u26aa, Laminar Chain \u26aa, Acala \ud83d\udfe2, Centrifuge \ud83d\udfe2, Stafi \u26aa, Definex \u26aa, OAX Foundation \u26aa, Cybex \u26aa, Zenlink \u26aa, Swaps Pallet \u26aa, Polkadex \u26aa, SubDEX \u26aa, Hydration \ud83d\udfe2, Substrate Stablecoin \u26aa, Standard protocol \u26aa, Polkaswap \ud83d\udfe2, Curve AMM \u26aa, Konomi Network \u26aa, Stable Asset \u26aa, Libra Payment \u26aa, Mangata \u26aa, Tidechain \u26aa, Basilisk \ud83d\udfe1, Polymesh \ud83d\udfe2, Bifrost \ud83d\udfe2, Clover \u26aa, Composable Finance  \ud83d\udfe1, OmniBTC \u26aa, Polimec \ud83d\udfe2 DEX with privacy and confidentiality features such as those found in a dark pool Smart contract chains moonbeam \ud83d\udfe2, Magnet \u26aa, Aleph-node \ud83d\udfe2, Edgeware \u26aa, ParaState \u26aa, gear \ud83d\udfe2, CENNZnet \u26aa, SkyeKiwi \u26aa, OAK-blockchain \u26aa, ICE Blockchain \u26aa, Polkadot Smart Chain \u26aa, Madara - Cairo/Starknet \u26aa smart contract chains with novel security approaches, smart contract chains based on existing toolchains Oracle Tellor \u26aa, Laminar \ud83d\udfe2, Chainlink-polkadot \u26aa, Ares Protocol \u26aa, Kylin Network \u26aa, interbtc-clients oracle \u26aa, Anonima \u26aa, SaaS3 \u26aa, Tellor \u26aa, Bridgestate Oracle \u26aa Identity/DID Parami \u26aa, Litentry \ud83d\udfe2, pallet-did \u26aa, dot-id \u26aa IoT Nodle \ud83d\udfe1, MXC/DataHighway \u26aa, peaq-network-node \ud83d\udfe2 Verifiable Claims KILT \ud83d\udfe2, Dock \ud83d\udfe1 Supply chain DSCP Node \ud83d\udfe2 Health care Music Industry Allfeat Network \ud83d\udfe2 Data Availability Avail \ud83d\udfe2, Melodot \u26aa Social Networking Frequency \ud83d\udfe2, Social Network \u26aa, SubSocial \ud83d\udfe2, ZeroDAO \u26aa, Myriad Node \u26aa, Wika Network \u26aa, Listen \u26aa, Tribal Protocol \u26aa, Five Degrees on Substrate \u26aa, Acuity Social \ud83d\udfe1 Private instant messenger that uses on-chain identity Governance/DAO Aisland Node \u26aa, Hashed Network \u26aa, Sunshine DAO \u26aa, Governance OS \u26aa, Idavoll Network \u26aa, Substrate Moloch \u26aa, QRUCIAL-DAO \u26aa, Societal \u26aa, DAOs \u26aa, Shivarthu \u26aa, Faterium \ud83d\udfe2, Supersig \u26aa, GenesisDAO \u26aa, DAO Entrance , Liberland \ud83d\udfe1 Consul - Open Government and E-Participation Web Software Prediction Markets and Futarchy Zeitgeist \ud83d\udfe1, X Predict Market \u26aa Messaging HOPR \u26aa, Nolik \u26aa, Uke \u26aa, Diffy Chat \u26aa, Fennel Protocol \u26aa File Storage, Cloud Subsocial-Offchain \u26aa, DatDot \u26aa, Crust Network \ud83d\udfe2, offchain::ipfs \u26aa, Canyon Network \u26aa, CESS \ud83d\udfe2, CESS Proving Subsystem , Iris \u26aa, fmd-cess \u26aa, IPFS Frame V3 \u26aa, Threefold Chain \ud83d\udfe1, Apron \u26aa, IPFS Utilities \u26aa, DINFRA \ud83d\udfe2 Name Service Substrate Names \u26aa, ENS on Substrate \u26aa, PNS-Pallets \u26aa, Faceless \u26aa, Anchor \u26aa Gaming Bit.country \u26aa, SubGame \u26aa, subzero \u26aa, Web3Games \u26aa, Ajuna Pallets \ud83d\udfe2, Gafi Network \u26aa, Asylum \ud83d\udfe2, 3DPass \ud83d\udfe2, Polket \ud83d\udfe1 Computation/AI Deitos Network \u26aa, DeepBrain Chain \ud83d\udfe2, AI Infrastructure on Blockchain \u26aa, NeuroWeb \ud83d\udfe1, Infimum \ud83d\udfe2 Enable specific use-cases pallet-hookpoints \u26aa, Robonomics \u26aa, UniversalDOT \u26aa, Evercity Sustainable Finance Protocol \u26aa, logion \u26aa, Me Protocol \u26aa, QSTN \u26aa, Subcoin \ud83d\udfe2, Aventus \ud83d\udfe2 NFT ternoa \u26aa, FRAME Pallet: NFTs for Substrate \u26aa, Unique NFT Parachain \u26aa, DNFT \u26aa, RMRK-Substrate \u26aa, NT-NFTs \u26aa, Green Lemon \u26aa, Basilisk \ud83d\udfe1, LAOS \ud83d\udfe2 Randomness DKG and Randomness Beacon \u26aa, drand-substrate-client \u26aa Licensing Anagolay Network Banking Integration FIAT on-off-ramp \u26aa Crowdfunding Imbue Network \u26aa, Quadratic Funding pallet by Dora \u26aa, Quadratic Funding pallet by OAK \u26aa Minimum Anti-Collusion Infrastructure (MACI) Collection of Pallets Substrate Open Runtime Module Library \ud83d\udfe2, warehouse \u26aa, InvArch FRAME Pallet Library \u26aa Marketplaces Dot Marketplace \u26aa, Gated Marketplace \u26aa, Ventur \u26aa, Futur Protocol Carbon Credits BitGreen \u26aa, Carbon Assets Pallet \u26aa, Sequester Pallets \u26aa UTXO Tuxedo \u26aa Other Moonkit \ud83d\udfe2, Substrate Account Filter \u26aa, Subtensor \ud83d\udfe2, AdMeta \u26aa, Chocolate Node \u26aa, Virto Network \ud83d\udfe2, Substrate Validator Set \u26aa, DEIP \u26aa, DeBio \u26aa, MathChain \u26aa, encointer \ud83d\udfe2, Grassland \u26aa, Substrate-Tutorials \u26aa, Fair Squares \u26aa, Totem Live Accounting \u26aa, Escrow Pallet \u26aa, TREX \u26aa, Relation Graph \u26aa, Decentralized Invoice \u26aa, Redstone Network \u26aa, Access Control Pallet \u26aa, Omniverse DLT \u26aa, ISMP \u26aa, XCMP \u26aa, CORD Chain \ud83d\udfe2, Educhain \ud83d\udfe1 Decentralized review/reputation system"},{"location":"general/build-open-source/#host","title":"Host","text":"Components Existing projects Potentially interesting projects Rust Substrate \ud83d\udfe2, Cumulus \ud83d\udfe2 C++ Kagome \ud83d\udfe2, Mayon \u26aa Go Gossamer \ud83d\udfe2 Java Fruzhin \ud83d\udfe2, Java Host Research \u26aa AssemblyScript Light Client smoldot \ud83d\udfe1, Substrate Connect \ud83d\udfe2, C++ Polkadot Light Client \u26aa Testing Polkadot Conformance \u26aa, Polkafuzz \u26aa"},{"location":"general/build-open-source/#network-maintenance-tools","title":"Network Maintenance Tools","text":"Components Existing projects Potentially interesting projects Secure validator setup Polkadot Validation Node Ansible Setup \u26aa, W3F Polkadot Validator Setup \u26aa, polkadot-ansible \ud83d\udfe2 High availability setup Archipel \u26aa, Polkadot Failover Mechanism \u26aa, Datagen \u26aa, High Availability Validator Setup \u26aa Load Balanced Endpoints terragrunt-polkadot \u26aa, Geometry Labs' Substrate Meta repo \u26aa Deployment Tools Polkadot Package Manager \u26aa, PolkaHub \u26aa, Avado \u26aa, Polkadot Deployer \u26aa, Unified Collator Deployment \u26aa Validator monitoring ONE-T \ud83d\udfe2, SubVT \ud83d\udfe1, P.A.N.I.C. \u26aa, Polkalert \u26aa, B-Harvest \u26aa, nmonpolkadot \u26aa, Polkadot-K8s-Monitor \u26aa, Polkadot-Watcher \ud83d\udfe1, 1KV Telegram Bot \u26aa Validator payout management Substrate validator auto payout \u26aa, Polkadot Payouts \u26aa, staking-payouts CLI \ud83d\udfe1, Payctl \u26aa, crunch \ud83d\udfe1 Staking Miner Staking Miner v2 \ud83d\udfe2 Nominator Tools Validator Selection \u26aa, Polkanalyzer \u26aa, Polkanalyzer-app \u26aa"},{"location":"general/build-open-source/#signatures","title":"Signatures","text":"Components Existing projects Potentially interesting projects SR25519 rust \u26aa(contains partial bindings for C, JavaScript, and Python), .Net bindings \u26aa, C \u26aa(old), C \u26aa(new), C/C++ \u26aa, C# \u26aa, Go \ud83d\udfe1, java \u26aa, PHP \u26aa Signature Aggregation apk-proofs \u26aa Distributed key generation (DKG) or management keygen.rs \u26aa, Secure Wallet Origin Distribution (SWORD) \u26aa Validator HSMs Zondax Remote Signer \u26aa MPC Orochi Network \ud83d\udfe2"},{"location":"general/build-open-source/#consensus","title":"Consensus","text":"Components Existing projects Potentially interesting projects PoC Spartan \u26aa PoW PoW consensus for Substrate \ud83d\udfe2, RandomX \u26aa, Sha3 PoW \u26aa Block production BABE \ud83d\udfe2, Aura \ud83d\udfe2 Finality GRANDPA \ud83d\udfe2, AlephBFT \ud83d\udfe2 Other Nimbus: Upgradeable consensus framework \u26aa"},{"location":"general/build-open-source/#networking","title":"Networking","text":"Components Existing projects Potentially interesting projects SCALE Codec Rust \ud83d\udfe2, TypeScript \u26aa, Python \u26aa, Golang Chainsafe \ud83d\udfe2, Golang Itering \ud83d\udfe2, C \u26aa, C++ \ud83d\udfe1, JavaScript \ud83d\udfe2, AssemblyScript \u26aa, Haskell \ud83d\udfe1, Java \u26aa, Ruby \u26aa, Dart \u26aa, Swift \u26aa, scale-codec-swift \u26aa, scale-codec-kotlin \u26aa, PHP \u26aa, JavaScript by Soramitsu \u26aa, Scale Codec Comparator \ud83d\udfe2, ScaleCodec.sol by Darwinia \u26aa, ScaleCodec.sol by Snowfork \ud83d\udfe2, Dotscale \u26aa Networking Framework libp2p \u26aaSwarmNL \ud83d\udfe2 DHT Crawler Go \u26aa, Kotlin \u26aa RPC Tor-like access WhiteNoise \u26aa"},{"location":"general/build-open-source/#primitives","title":"Primitives","text":"Components Existing projects Potentially interesting projects Storage Merkle Tree DB \u26aa Merkle Proofs Solidity Trie Verifier \ud83d\udfe1"},{"location":"general/build-open-source/#contributing","title":"Contributing","text":"<p>Pull requests, issues, or other contributions from the community are encouraged! You can not only add specific projects, but also potentially interesting fields/areas which are currently missing in the tech stack.</p> <p>All technologies listed above need to be open-source. Ideally, the links lead directly to the code.</p> <p>Note: You will need a GitHub account to suggest changes or open issues. If you do not have one, you may sign up for free.</p>"},{"location":"general/chain-state-values/","title":"Macro Rendering Error","text":"<p>File: <code>general/chain-state-values.md</code></p> <p>KeyError: 'ENABLE_RPC'</p> <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/mkdocs_macros/plugin.py\", line 688, in render\n    return md_template.render(**page_variables)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/jinja2/environment.py\", line 1295, in render\n    self.environment.handle_exception()\n  File \"/opt/hostedtoolcache/Python/3.12.9/x64/lib/python3.12/site-packages/jinja2/environment.py\", line 942, in handle_exception\n    raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 6, in top-level template code\n  File \"/home/runner/work/polkadot-wiki-mkdocs/polkadot-wiki-mkdocs/main.py\", line 65, in rpc\n    if enable_rpc():\n       ^^^^^^^^^^^^\n  File \"/home/runner/work/polkadot-wiki-mkdocs/polkadot-wiki-mkdocs/main.py\", line 9, in enable_rpc\n    return os.environ[\"ENABLE_RPC\"] == \"true\"\n           ~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"&lt;frozen os&gt;\", line 714, in __getitem__\nKeyError: 'ENABLE_RPC'\n</code></pre>"},{"location":"general/community/","title":"Community","text":"<p>Below are the most essential links to the community channels for Polkadot and Kusama.</p> <p>Caution</p> <p>Keep in mind that no admin or moderator will ever DM you for any reason whatsoever without prior contact and anyone doing so is likely trying to scam you.</p>"},{"location":"general/community/#general","title":"General","text":"PolkadotKusama <ul> <li>Polkadot Forum - a place for thoughtful comments and discussions on the future of Polkadot, and the steps we can take to get there together.</li> <li>Polkadot GitHub - Parity maintained repository that houses the Rust implementation of the Polkadot Host.</li> <li>Polkadot Support Knowledgebase and Polkadot Support Contact.</li> <li>Polkadot's Latest Research (news).</li> <li>Polkadot Meetup Hub - Information on hosting meetups, applying for funding, and materials for running it.</li> <li>Polkadot Discussion and Governance on Polkassembly.</li> <li>Polkadot Discussion and Governance on Subsquare.</li> </ul> <ul> <li>Kusama Discussion and Governance on Polkassembly.</li> <li>Kusama Discussion and Governance on Subsquare.</li> </ul>"},{"location":"general/community/#events","title":"Events","text":"<p>Polkadot Meetup Platform - Information on hosting meetups, applying for funding, and materials for running it.</p> <p>Community Events - Information on events funded by the Treasury and organized by the Polkadot community (candidates or ambassadors) focused on promoting Polkadot, Kusama, and related technologies. The events are educational and informative, and their goal is to create an impact in the community.</p>"},{"location":"general/community/#matrix-chats","title":"Matrix Chats","text":"<p>We primarily use Matrix across the organization and to communicate with community members. The application we use most often to interact with the Matrix protocol is the Element messenger client.</p> PolkadotKusamaTechnical <ul> <li>Polkadot Space - Space containing all official rooms below. Note that this is a newer feature and may not be supported by your Matrix client. If you face any issues, join the rooms individually.</li> <li>Polkadot Watercooler - General room for talk about Polkadot.</li> <li>Polkadot Validator Lounge - Room for validators learning about setting up a node.</li> <li>Polkadot Direction - Governance, and a place to discuss the future of Polkadot.</li> <li>Polkadot Digest - News about what is happening in the Polkadot ecosystem, published every weekday except holidays.</li> <li>Polkadot Wiki - The official matrix room about the Polkadot Wiki.</li> </ul> <ul> <li>Kusama Space - Space containing all official rooms below. Note that this is a newer feature and may not be supported by your Matrix client. If you face any issues, join the rooms individually.</li> <li>Kusama Watercooler - General room for talk about Kusama.</li> <li>Kusama Validator Lounge - Room for validators learning about setting up a node.</li> <li>Kusama Direction - Governance, and a place to discuss the future of Kusama.</li> </ul> <ul> <li>Substrate Developers Chat - A Matrix chat room for Substrate development.</li> <li>Substrate Developers Telegram Chat - A Telegram chat room for Substrate development, bridged to Matrix Substrate Developers Chat linked above.</li> <li>Substrate and Polkadot StackExchange - More advanced room for technical questions on building with Substrate.</li> <li>Smart Contracts &amp; Parity Ink! - A room to discuss developing Substrate smart contracts using Parity Ink!</li> </ul>"},{"location":"general/community/#socials","title":"Socials","text":""},{"location":"general/community/#chat","title":"Chat","text":"<ul> <li>Polkadot Discord (RECOMMENDED)</li> <li>Kusama Discord</li> </ul>"},{"location":"general/community/#social-media","title":"Social media","text":"Web3 FoundationPolkadotKusama <ul> <li>Web3 Foundation Twitter</li> <li>Web3 Foundation YouTube</li> </ul> <ul> <li>Polkadot Twitter</li> <li>Polkadot Reddit</li> <li>Polkadot YouTube</li> </ul> <ul> <li>Kusama Twitter</li> <li>Kusama Reddit</li> <li>Kusama YouTube Channel</li> </ul>"},{"location":"general/community/#blogs-and-tutorials","title":"Blogs and tutorials","text":"<ul> <li>Web3 Medium Blog</li> <li>Polkadot Blog</li> <li>Gavin Wood's Medium Blog</li> <li>Dotleap.com Newsletter</li> </ul>"},{"location":"general/community/#newsletters","title":"Newsletters","text":"<ul> <li>Subscribe to the Polkadot newsletter -   official, infrequent</li> <li>Dot Leap Newsletter - less official, weekly</li> <li>NFT Review - Covering the evolution of the NFT ecosystem on Kusama</li> </ul>"},{"location":"general/community/#ecosystem","title":"Ecosystem","text":"<ul> <li>Polkadot &amp; Kusama Ecosystem Map - Comprehensive list of   projects building in the ecosystem made by SubWallet with support from Parity Technologies.</li> <li>Polkadot Deep Dive Quarterly Report -   A quarterly report series that dives deep into the growth of the whole ecosystem. Made by   SubWallet with sections focused on Ecosystem Overview, DeFi, NFT &amp;   Web3.</li> <li>Polkadot Stack - if you're interested in seeing what's under   development and where there's room for your contributions.</li> <li>Teams Building on Polkadot - Community maintained list of teams   building on Polkadot and/or Substrate. (Note that this may contain inaccuracies, as it's   unofficial).</li> <li>Jobs in Polkadot Ecosystem - Join the Polkadot Talent Network.</li> <li>Polkadot Blockchain Academy - a   classroom-based educational program covering the conceptual underpinnings and the hands-on   application of blockchain technology, using Polkadot and Substrate as its foundations.</li> <li>Polkadot Communities and Campaigns by AirLyft One -   Discover thriving communities and participate in engaging campaigns.</li> <li>DotAppStore - Discover featured projects and apps upvoted by the   Polkadot community.</li> <li>Awesome Dot - community curated resources,   projects, and learning material about the Polkadot and Kusama ecosystems.</li> </ul>"},{"location":"general/contributing/","title":"Contributing to the Polkadot Wiki","text":"<p>The wiki was started and is maintained by the Web3 Foundation. It is an open-source project and aims to be the most extensive knowledge resource on the Polkadot and Kusama ecosystems. Much of the material currently focuses on Polkadot and Kusama directly, but is open to covering informational material for community projects.</p> <p>Marketing Material</p> <p>Please do not try to pull request any marketing material as this will be rejected.</p> <p>Nonetheless, pull requests, discussions, and contributions from the community are encouraged. Active community members who demonstrate a record of good contributions may be given <code>write</code> access to the repository.</p> <p>Otherwise, the Web3 Foundation holds the administrative position and has the final say on the included content. Specifically, the foundation\u2019s Technical Education team is most directly involved.</p> <p>Contributing Explainer</p> <p>Check out the How to Contribute to the Polkadot Wiki   video for steps on contributions.</p>"},{"location":"general/contributing/#how-to-contribute","title":"How to Contribute","text":"<p>You can contribute to the wiki on the w3f/polkadot-wiki GitHub repository. Every page is a MarkDown file, which is an easy-to-learn syntax extension to plain text that makes creating links, rendering images, and nice-looking formatting simple.</p> <p>Each page has an \"Edit this page\" link at the bottom of the content. By clicking it, you are taken to the GitHub sign-in page, where you can either log in or create an account.</p> <p>Once logged in, you'll be taken to the GitHub built-in text editor, where you can make your edits directly. When you've completed your changes, you can add any specific details on what was changed and commit to a new branch to create a new Pull Request to the repository. From there, one of the maintainers will review your changes and either merge them or request changes.</p> <p> </p> <p>Remember that after you click \"Propose Changes\", you must also click on \"Create Pull Request\" on the next page.</p> <p></p>"},{"location":"general/contributing/#ground-rules-for-contributing","title":"Ground Rules for Contributing","text":"<p>There are a few basic ground rules for contributors:</p> <ol> <li>No <code>--force</code> pushes or modifying the Git history in any way.</li> <li>Pull requests are preferred to issues, especially for small changes such as typos. Issues should    be used for generic or broad-based changes or missing content. Suggestions and requests are    encouraged.</li> <li>Only use non-master branches.</li> <li>Significant modifications, even by contributors, ought to be subject to a pull request to    solicit feedback from other contributors.</li> <li>Pull requests to solicit feedback are encouraged for any other non-trivial contribution but    left to the contributor\u2019s discretion.</li> <li>Contributors should adhere to the prevailing <code>MarkDown</code> style, language, and layout.</li> <li>Correct grammar should be used at all times. Pull requests with typos will not be merged until    fixed.</li> <li>Care should be taken to remain as objective and informative as possible. There should be no    editorializing, and external bias should not be present.</li> <li>We use the Prettier plugin to standardize the style across documents. You can run this on your    local copy with <code>npx lint-staged</code>, but for simplicity, we also have a bot that runs this for us    in your PRs.</li> </ol>"},{"location":"general/contributing/#style-guides","title":"Style Guides","text":"<p>Wiki General Style Guides</p> <p>The style guide from the Substrate Knowledge Base provides general guidelines about how to write your Wiki contribution. See also the Wiki readme file.</p> <p>The Polkadot Wiki is powered by Docusaurus. Docusaurus 3 was a major version upgrade that caused MDX errors. As a general rule, avoid using curly brackets and special characters. If you must use them, for example, to get the \\&lt;-&gt; symbol, you can escape the error with a <code>\\</code>.</p> <p>Avoid using exclamation marks <code>!</code> and informal sentences, which are usually more appropriate for blog posts. Running a grammar check before submitting your pull request for review can save reviewers time and speed up the review process.</p> <p>To ensure consistency across pages, note the following general terms:</p> <ul> <li><code>relay chain</code> in text and <code>Relay chain</code> at the beginning of a sentence.</li> <li><code>parachain</code> in text and <code>Parachain</code> at the beginning of a sentence.</li> </ul> <p>The Polkadot Wiki has multiple moving parts. To ensure your contribution does not introduce compilation errors and that your page is properly rendered in production, we encourage you to build and render the Wiki on your local machine before submitting a pull request for review. Rendering the Wiki locally also adds the benefit of checking for broken links.</p>"},{"location":"general/contributing/#render-the-wiki-locally","title":"Render the Wiki Locally","text":"<p>The Polkadot Wiki is built from the source files in this GitHub repository. The Wiki uses Algolia search, which can be accessed locally by providing the correct App ID and API key. The <code>app_id</code> and <code>api_key</code> environment variables are needed to build the Wiki successfully. If you are an external contributor, set the variables with some values like shown below, which lets the Wiki repo build successfully (but disables the search bar).</p> <pre><code>export app_id=\"xxxxxx\" api_key=\"xxxxxxx\"\n</code></pre> <p>After cloning the source locally, you can start the website with the commands below (ensure you run <code>yarn</code> at the root of the repository first to install dependencies).</p> <p>Using yarn, run:</p> <pre><code>yarn install\n</code></pre> <p>Then you can build the Wiki:</p> <pre><code>yarn polkadot:build\n</code></pre> <p>And finally, you can start the Wiki:</p> <pre><code>yarn polkadot:start\n</code></pre>"},{"location":"general/contributing/#rendering-on-chain-values","title":"Rendering On-chain Values","text":"<p>The Polkadot Wiki can render chain state values via RPC as shown here and display them directly in the docs without the need to recompile or even reload the web app. The rendering of on-chain values is reserved only in the Chain State page.</p> <p>See the example for a react component below:</p> <pre><code>&lt;RPC network=\"polkadot\" path=\"query.staking.validatorCount\" defaultValue=\"400\"/&gt;\n</code></pre> <p>Where <code>network</code> can be set to <code>polkadot</code>, <code>kusama</code>, <code>statemint</code> (Polkadot Asset Hub), <code>statemine</code> (Kusama Asset Hub), <code>polkadotpeople</code>, and <code>kusamapeople</code>. The <code>path</code> is composed by:</p> <ul> <li><code>query</code> or <code>const</code></li> <li>pallet and call</li> </ul> <p>The example above shows the path to query the number of validators within the staking pallet. For more information, see pallets and extrinsics. The <code>defaultValue</code> is the value the react component shows if there is an issue with fetching data on-chain. A <code>filter</code> flag is also available to make values human readable, covert block number to days, etc.</p>"},{"location":"general/contributing/#heritage","title":"Heritage","text":"<p>This document is based on the Level contribution guidelines.</p>"},{"location":"general/contributors/","title":"Contributors","text":""},{"location":"general/contributors/#current-contributors","title":"Current Contributors","text":"<p>The following is a list of regular contributors to the Wiki. Each contributor's contact information is listed as a precaution - if one of these people ever contacts you directly, first check the contact information to see that it matches the origin of the message, and then feel free to get in touch with someone else on this list to verify the legitimacy of the original inquiry.</p> <p>Employee impersonation is a common type of scam</p> <p>For other ways of protecting yourself, please see the How to Protect Yourself from Scams guide.</p>"},{"location":"general/contributors/#technical-education","title":"Technical Education","text":""},{"location":"general/contributors/#bill-laboon","title":"Bill Laboon","text":"<ul> <li>email: bill@web3.foundation</li> <li>matrix: @bill:web3.foundation</li> <li>twitter: @BillLaboon</li> <li>telegram: @BillLaboon</li> </ul> <p>Bill Laboon is the Head of Education and Grants at Web3 Foundation. Prior to Web3 Foundation, he spent five years teaching Computer Science at the University of Pittsburgh. Bill also has several years of experience in software engineering and management.</p> <p>He is the author of two books: A Friendly Introduction to Software Testing, an undergraduate textbook; and Strength in Numbers, a near-future novel set in a world in which cryptocurrency has eliminated traditional money.</p>"},{"location":"general/contributors/#radhakrishna-dasari","title":"Radhakrishna Dasari","text":"<ul> <li>email: radha@web3.foundation</li> <li>matrix: @radha:web3.foundation</li> <li>twitter: @DrW3RK</li> </ul> <p>Radha leads Technical Education at Web3 Foundation. Radha has a PhD in Computer Science and has three years of experience teaching Computer Science courses. He also taught a Massively Open Online Course (MOOC) on Coursera. Radha is excited to contribute to Web3 Foundation's vision by educating professionals and the general public about the Web3 Technology Stack.</p>"},{"location":"general/contributors/#filippo-franchini","title":"Filippo Franchini","text":"<ul> <li>email: filippo@web3.foundation</li> <li>matrix: @filippo:web3.foundation</li> <li>twitter: @filippoweb3</li> </ul> <p>Filippo is a Technical Educator at the Web3 Foundation. Filippo has a PhD in Statistics and has 6 years of experience in teaching statistical computing and data analysis. Filippo strongly believes in the Web3 vision of having a privacy-focused, secure, decentralized internet where power is given back to users. The complexity of Web3 technology can be intimidating and is still a major blocking element behind mainstream adoption. Filippo is excited to contribute to Web3 Foundation's vision by educating professionals and the general public about Web3 and blockchain technology. Filippo enjoys learning about Polkadot and regularly contributes to Wiki articles. He got certified as a blockchain analyst and is currently learning about Rust and Substrate.</p>"},{"location":"general/contributors/#bader-youssef","title":"Bader Youssef","text":"<ul> <li>email: bader@web3.foundation</li> <li>matrix: @bader:web3.foundation</li> <li>twitter: @baderyo_o</li> </ul> <p>Bader is a Technical Educator at the Web3 Foundation. He has been an avid blockchain and web3 advocate, full-stack software engineer, and technical writer for the past 4 years. He has used a multitude of technologies to create disruptive and unique applications, mostly centering around eliminating intermediary servers in applications and creating trust-free digital interactions for the betterment of humanity. Real technology needs to solve real problems, and Bader is very strong on creating practical solutions to those problems using Web3.</p> <p>Bader has a strong passion for ensuring that this technology can be understood and utilized to its fullest potential and focuses on making it as simple and useful to digest as possible.</p>"},{"location":"general/contributors/#technical-integrations","title":"Technical Integrations","text":""},{"location":"general/contributors/#joe-petrowski","title":"Joe Petrowski","text":"<ul> <li>email: joe@web3.foundation</li> <li>matrix: @joe:web3.foundation</li> <li>telegram: @joepetrowski</li> <li>twitter: @joepetrowski</li> </ul> <p>Joe leads Technical Integrations at Web3 Foundation and was previously a Research Analyst at Parity Technologies. He focuses on making Substrate chain integration as smooth as possible, from educating users on Substrate and Polkadot fundamentals to building tools to create great user experiences and occasionally writing a bit of code. He also hosts the relay chain podcast.</p> <p>Prior to working at Parity, Joe worked in shock and vibration simulation for satellite launch, algorithmic trading, and professional cycling. He has a Bachelor of Science in Aeronautical and Mechanical Engineering.</p>"},{"location":"general/contributors/#past-contributors","title":"Past Contributors","text":"<p>The following contributors are no longer participating in an official capacity.</p>"},{"location":"general/contributors/#keith-alfaro","title":"Keith Alfaro","text":"<p>Keith was a member of the TechEd team at the Web3 Foundation. He has worked professionally as a software engineer since completing his graduate studies. Keith holds bachelor's and master's degrees in Architecture (buildings not computers). It was during this time that he discovered his passion for computational design. He was previously employed in the CAD/3D graphics software development domains. Keith is passionate about learning, developing and sharing decentralized and peer-to-peer technologies.</p>"},{"location":"general/contributors/#emre-surmeli","title":"Emre Surmeli","text":"<ul> <li>twitter: @semres8</li> </ul> <p>Emre was a Technical Educator at Web3 Foundation. His background is in full-stack software development, education, and blockchain technology consulting. He is passionate about learning and teaching and has always kept a foot in education by designing and delivering software development and blockchain classes at General Assembly, Code Fellows, and Columbia University.</p>"},{"location":"general/contributors/#danny-salman","title":"Danny Salman","text":"<ul> <li>email: danny.f.salman@gmail.com</li> <li>matrix: @dannysalman:matrix.org</li> <li>telegram: @dannysalman</li> <li>twitter: @dannysalman_</li> </ul> <p>Danny was a Technical Educator at Web3 Foundation who has a keen interest in blockchain and trust-free technologies. As a Technical Educator, Danny taught and documented Polkadot. He has a Bachelor of Engineering in Computer Engineering and a background in philosophy &amp; politics.</p>"},{"location":"general/contributors/#alex-chau","title":"Alex Chau","text":"<ul> <li>matrix: @a-jwc:\u200bmatrix.org</li> </ul> <p>Alex was a Technical Education Intern at Web3 Foundation. He has developed a deep passion for educating others on decentralized systems and pushing forward the WEB3 vision. Alex has educational experience in cryptography, data privacy, and enterprise security. He has a Bachelor of Science in Computer Science from San Francisco State University.</p>"},{"location":"general/contributors/#jake-hemmerle","title":"Jake Hemmerle","text":"<ul> <li>matrix: @jake:hemmerle.dev</li> <li>twitter: @jakehemmerle</li> <li>telegram: @jakehemmerle</li> </ul> <p>Jake was a Technical Education Intern at Web3 Foundation and studied Computer Science at the University of Cincinnati. He has been learning about blockchain technology since 2018 and has personal interests in peer-to-peer systems, network protocols, applied cryptography and privacy-enhancing technologies.</p> <p>You can now find Jake cracking the code at the multi-chain Polkadot dApp hub, Astar Network.</p>"},{"location":"general/contributors/#bruno-skvorc","title":"Bruno Skvorc","text":"<ul> <li>telegram: @swader</li> <li>matrix: @bitfalls:matrix.org</li> <li>twitter: @bitfalls</li> </ul> <p>Bruno joined the crypto ecosystem full time in 2015 with the advent of Ethereum and created educational resources, tutorials, and newsletters for budding developers of the industry.</p> <p>From 2019, he was a Technical Educator at Web3 Foundation. He is passionate about decentralization, censorship resistance, and transparency coupled with accountability, so he has found his passion in immutable ledgers of the present and future.</p> <p>In a previous life, he was a web developer and senior PHP editor at SitePoint, which culminated in a book about web-dev-friendly virtual environments. In his quest for developer health, he likes to combine fitness and gaming and can be found in VR on Oculus and Steam as TheSwader. He also runs a weekly newsletter covering all things Web3 at DotLeap.</p> <p>You can now find Bruno hacking the metaverse by leading the way at RMRK to create the next-generation NFT standard.</p>"},{"location":"general/contributors/#anson-lau","title":"Anson Lau","text":"<ul> <li>matrix: @anson-lau:matrix.org</li> <li>twitter: @Anson_LauHK</li> </ul> <p>Anson was a Technical Educator at Web3 Foundation. Before that, he worked as a Hyperledger Blockchain Developer to deliver B2B applications at IBM. He is passionate about staking, governance, cryptoeconomics, and privacy areas. Anson has been actively participating in the blockchain space since 2017 and creating video content to help different people understand how decentralization could deliver us a better future.</p>"},{"location":"general/contributors/#kirsten-richard","title":"Kirsten Richard","text":"<p>Kirsten was a Technical Educator Intern at Web3 Foundation from Canada. She focused on curating educational content around blockchain and Polkadot network concepts. Kirsten has a Bachelor's degree in Computer Science and is passionate about teaching and technology.</p>"},{"location":"general/contributors/#logan-saether","title":"Logan Saether","text":"<ul> <li>matrix: @logansaether:matrix.org</li> <li>twitter: @logansaether</li> </ul> <p>Logan was a Technical Educator at Web3 Foundation, where he worked on creating material for supporting the development of the next generation of distributed technologies. At Web3 Technical Education, Logan focused on creating the Polkadot Wiki as the central source of truth and knowledge for the Polkadot protocol. He contributed in creating written content and example applications that demonstrate how to use these new technologies.</p> <p>You can now find Logan leading efforts to define the prediction market space at Zeitgeist.</p>"},{"location":"general/decentralized-futures/","title":"Decentralized Futures Program","text":"<p>The new Decentralized Futures Program supplements the Grants Program, and (as the name suggests) it strengthens the decentralization of the Polkadot ecosystem.</p>"},{"location":"general/decentralized-futures/#overview","title":"Overview","text":"<p>This program is set to distribute 20 million USD and 5 million DOT tokens to support individuals and teams as they launch new initiatives to grow the Polkadot ecosystem. The main objective is to expand the network by adding self-sustaining participants. Funding is available for Polkadot-focused organizations aim to generate profit and for non-profit ventures that have a strategy to secure ongoing financing through Polkadot's on-chain treasury system beyond 2024.</p> <p>The Program is run by the Web3 Foundation, which is a not-for-profit organization that supports Web3 teams and open-source projects through funding, advocacy, research, and collaboration.</p>"},{"location":"general/decentralized-futures/#program-goal","title":"Program Goal","text":"<p>The goal of the Decentralized Futures Program is to kickstart economically independent, active participants in the Polkadot ecosystem.</p>"},{"location":"general/decentralized-futures/#applications","title":"Applications","text":"<p>To apply for funding to the Decentralized Futures fill this form. The form will guide you through each step of the application. You are also encouraged to post the idea in the Polkadot forum upfront. If you have any questions, you can reach out to the W3F Decentralized Futures Community on Element.</p> <p>Proposals have to be submitted before July 1<sup>st</sup>, 2024. Applications will be reviewed from Dec 1<sup>st</sup>, 2023 - Jul 31<sup>st</sup>, 2024 on a rolling basis.</p>"},{"location":"general/decentralized-futures/#selection-criteria","title":"Selection Criteria","text":"<p>In the current phase, we intentionally maintain openness in our approach. This deliberate choice stems from recognizing that specific initiatives demand substantial and bold efforts, often incurring significant costs, particularly in areas where traditional go-to-market functions are no longer in play. Conversely, there are instances where individuals require relatively modest funding in the tens of thousands to initiate their projects. This broad approach avoids constraining people's creativity and allows for many possibilities. However, it does come with the drawback of prolonged application processing times.</p> <p>Several factors significantly enhance the likelihood of application success:</p> <ul> <li>A well-thought-out and compelling plan outlining the project\u2019s sustainability beyond 2024 is   crucial. While injecting funds into the ecosystem is straightforward, convincing customers or the   community of the value behind that financial investment poses a more substantial challenge.</li> <li>Applicants are encouraged to provide a detailed breakdown of how the requested funds will be   utilized, with granularity increasing proportionally with the amount sought. This meticulous   approach ensures transparency and accountability in the allocation of resources.</li> <li>A demonstrated willingness to receive a more significant portion of the value in long-term DOT   rather than immediate FIAT, aligning with the broader ecosystem's goals.</li> </ul>"},{"location":"general/decentralized-voices/","title":"Decentralized Voices Program","text":"<p>The Decentralized Voices program empowers broader community participation in Polkadot OpenGov by delegating 42 Million DOT and 80,000 KSM of voting power.</p>"},{"location":"general/decentralized-voices/#decentralized-votes","title":"Decentralized Votes","text":"<p>Building on the success of previous initiatives like the Decentralized Nodes Program and the Decentralized Futures Program, Web3 Foundation is working on decentralizing governance within the Polkadot ecosystem to ensure a fair decision-making process. In line with the Foundation's ethos, this program seeks to amplify the voices of passionate and knowledgeable participants who may lack significant holdings, aiming to mitigate potential marginalization. This initiative does not impact existing programs like Decentralize Nodes, as the tokens allocated can be used for both staking and governance.</p>"},{"location":"general/decentralized-voices/#how-to-apply","title":"How to Apply","text":"<p>Please fill out this application provided by Web3 Foundation. Information requested in the form includes the following:</p> <ul> <li>The account address to which you would like to have DOT or KSM delegated. This account must have a   verified identity, including at least one of the following fields: X (formerly Twitter), Matrix   (Element), or email.</li> <li>A link to a publicly accessible declaration of your Polkadot \u201cpolitical philosophy\u201d and/or   agenda on the Polkadot Forum. This can include an actual   philosophical statement, analogies to other political philosophies, opinions on previous Referenda   or governance decisions, or any other way you would like to explain to people how you would vote   in the future. This should be at least one paragraph.</li> <li>A description of why you would be a good choice for this program. This can include such   information as previous votes (including votes with other accounts if you can prove you own them),   as well as commentary, blog posts, etc. on Polkadot OpenGov or specific referenda. It can also   include other information that you would consider relevant to decision making, e.g. being part of   other political groups or legislative bodies.</li> </ul> <p>The Decentralized Voices program initially designates delegates who will be receiving delegated funds. In addition to the platforms mentioned above, to expand their reach, participants can showcase their governance contributions and political philosophy through public declarations and active engagement (optionally) on other social media platforms such as:</p> <ul> <li>Reddit</li> <li>Discord</li> <li>PolkaVerse</li> </ul> <p>Delegations are subject to review, and non-compliance may result in revocation.</p> <p>The Decentralized Voices program commenced on February 6, 2024, offering an opportunity for dedicated community members to shape the future of the Polkadot ecosystem. For more detailed information, see the original Medium article.</p>"},{"location":"general/dev-heroes/","title":"Developer Heroes Program","text":"<p>For more information about the Developer Heroes Program, see the Polkadot blog post.</p> <p>Sign up</p> <p>Use this form to sign up and become a candidate for the Polkadot Developer Heroes Program.</p>"},{"location":"general/dev-heroes/#goal","title":"Goal","text":"<p>Build a strong community of Polkadot developers of different levels of expertise to drive the growth and evolution of the Polkadot ecosystem. Developers need to have some degree of experience with the Polkadot technology stack.</p> <p>The program provides:</p> <ul> <li>Opportunities for personal and professional growth.</li> <li>Resources and support to boost the growth and evolution of developers.</li> <li>Chance to showcase and enhance skills.</li> <li>Establish yourself as a valued contributor to the Polkadot ecosystem and pull someone else up on   stage at the same time. Each one, teach one!</li> </ul>"},{"location":"general/dev-heroes/#rookies-and-heroes","title":"Rookies and Heroes","text":"<p>A rookie is a beginner or first-timer developer. Someone who has previous experience in programming but needs to gain in-depth knowledge about the Polkadot technology.</p> <p>The technology includes but is not limited to independent Substrate chains and ink! development, and Polkadot-related tooling. Rookies will need to learn these concepts and tools so that they can deliver the tasks required to be a Hero.</p> <p>A rookie becomes a hero by continuously advocating for the technology used in the Polkadot ecosystem as well as spreading awareness and educating a broader audience about the technology.</p> <p>Depending on what you enjoy doing, you can become a hero by doing some of the following things:</p> <ul> <li> <p>Offer mentoring: Offer 1:1 or group mentoring to fellow community members.</p> </li> <li> <p>Help out in the community forums: Answer questions from the community on the   Substrate and Polkadot StackExchange   or on the Polkadot Forum.</p> </li> <li> <p>Contribute to the Polkadot stack: Have a look at the   open source technology stack list and contribute with a pull   request, an issue, or find and fix bugs.</p> </li> <li> <p>Create content: Write a blog post, record a video tutorial, and write a Twitter thread. Share   about your latest coding success, something you learned and are excited about.</p> </li> <li> <p>Speak at events: Do a workshop or talk at meetups and conferences.</p> </li> </ul>"},{"location":"general/ecosystem-funds/","title":"Polkadot Ecosystem Development Funds","text":"<p>The Polkadot has Ecosystem Development Funds aiming to support the development of parachains and applications aiming to use the Polkadot Tech Stack:</p> <ul> <li>Scytale Digital</li> <li>Harbour Industrial Capital</li> </ul>"},{"location":"general/ecosystem-funds/#scytale-digital","title":"Scytale Digital","text":"<p>The Polkadot Ecosystem Fund by Scytale is going to be a venture initiative focused on strategically investing in and supporting projects within the Polkadot and Kusama ecosystems. With over USD 75 million in assets under management, Scytale has built a portfolio of over 20 projects spanning three continents. The fund will provide early-stage ventures with mentorship, liquidity, and access to a network of strategic partners. Through its rigorous due diligence process, it selects only the most promising projects. The fund\u2019s value proposition includes offering technical advisory, KPI, and OKR oversight, and fostering active ecosystem participation, ensuring sustainable growth for its portfolio companies.</p>"},{"location":"general/ecosystem-funds/#harbour-industrial-capital","title":"Harbour Industrial Capital","text":"<p>Harbour Industrial Capital (HIC) is a Polkadot-focused VC fund managed by Max Rebol and Mario Altenburger. The fund launched in early 2022, held its final closing at the end of 2023, and, as of 2024, reached an AUM of ~US$10m. LPs are primarily family offices and institutional investors from Asia, Europe, and the Middle East.</p>"},{"location":"general/ecosystem-funds/#contact-for-projects","title":"Contact for Projects","text":"<p>Projects building on Polkadot that want to raise investment from HIC can contact info@harbourindustrial.com. Please note that projects building in different ecosystems will be outside HIC\u2019s investment scope.</p>"},{"location":"general/ecosystem-funds/#legal-disclaimer","title":"Legal Disclaimer","text":"<p>The information provided herein is for informational purposes only and should not be construed as an endorsement, recommendation, or advice regarding any specific products, services, or investment funds. Web 3.0 Technologies Foundation (\u201cW3F\u201d) does not make any representations or warranties, either express or implied, regarding the suitability, performance, or potential outcomes of any products referenced.</p> <p>Nothing contained in this communication constitutes financial, legal, or investment advice, nor does it take into account your specific objectives, financial situation, or needs. Decisions based on the information provided are your responsibility, and W3F strongly advises that you seek professional advice from licensed financial, legal, or other relevant experts before making any decisions. W3F disclaims any liability for any loss or damage that may arise from your reliance on the information provided.</p>"},{"location":"general/faq/","title":"Frequently Asked Questions (FAQs)","text":"<p>Info</p> <p>This FAQ focuses on technical questions for users interested in developing applications for Polkadot. If you have a more general question, you may wish to search for the answer on our support Knowledge Base or the main Polkadot network FAQ. If you have a question that is not answered, please feel free to ask on the Polkadot Watercooler Element channel or contact Polkadot Support.</p>"},{"location":"general/faq/#polkadot-launch","title":"Polkadot Launch","text":"<p>The Genesis block of the Polkadot network was launched on May 26, 2020 at 15:36:21 UTC, as a Proof of Authority (PoA) network, with governance controlled by the single Sudo (super-user) account. During this time, validators started joining the network and signaling their intention to participate in consensus.</p> <p>The network evolved to become a Proof of Stake (PoS) network on June 18, 2020. With the chain secured by the decentralized community of validators, the Sudo module was removed on July 20, 2020, transitioning the governance of the chain into the hands of the token (DOT) holders. This is the point where Polkadot became decentralized.</p> <p>The final step of the transition to full-functioning Polkadot was the enabling of transfer functionality, which occurred on Polkadot at block number 1_205_128 on August 18, 2020, at 16:39 UTC.</p> <p>On August 21, 2020, Redenomination of DOT occurred. From this date, one DOT (old) equals 100 new DOT.</p>"},{"location":"general/faq/#polkadot-roadmap","title":"Polkadot Roadmap","text":"<p>For more information on the Polkadot roadmap please visit the official Polkadot website.</p>"},{"location":"general/faq/#consensus","title":"Consensus","text":""},{"location":"general/faq/#why-do-we-need-consensus","title":"Why do we need Consensus?","text":"<p>Consensus is a method for coming to agreement over a shared state. In order for the state of the blockchain to continue to build and move forward, all nodes in the network must agree and come to consensus. It is the way that the nodes in a decentralized network are able to stay synced with each other. Without consensus for the decentralized network of nodes in a blockchain, there is no way to ensure that the state one node believes is true will be shared by the other nodes. Consensus aims to provide the objective view of the state amid participants who each have their own subjective views of the network. It is the process by which these nodes communicate and come to agreement, and are able to build new blocks.</p>"},{"location":"general/faq/#what-are-pow-and-pos","title":"What are PoW and PoS?","text":"<p>Proof of Work (PoW) and Proof of Stake (PoS) have been inaccurately used as short hand to refer to consensus mechanisms of blockchains, but that does not capture the full picture. PoW is the method for agreeing on a block author and part of the fuller Nakamoto consensus that also encompasses a chain selection algorithm (longest chain rule in Bitcoin). Similarly, PoS is a set of rules for selecting the validator set and does not specify a chain selection rule or how a chain might reach finality. PoS algorithms have traditionally been paired with an algorithm for coming to Byzantine agreement between nodes. For example, Tendermint is a practical Byzantine fault tolerant algorithm that uses PoS as its validator set selection method.</p>"},{"location":"general/faq/#why-not-proof-of-work","title":"Why not Proof of Work?","text":"<p>Although simple and effective in coming to a decentralized consensus on the next block producer, proof of work with Nakamoto consensus consumes an incredible amount of energy, has no economic or provable finality, and has no effective strategy in resisting cartels.</p>"},{"location":"general/faq/#validators","title":"Validators","text":""},{"location":"general/faq/#how-do-i-apply-to-be-a-validator","title":"How do I apply to be a validator?","text":"<p>There is no central authority that decides on validators, so there is not per se an application that you can fill out. Registering as a validator is permissionless; in order to become one you must only set up a validator node and mark your intention to validate on chain. For detailed instruction on how to do validate you can consult the validator guide.</p> <p>However, once you've set up a validator and have registered your intention it does not mean that you will be included in the active set right away. The validators are elected to the active set based on the results of an election algorithm known as Phragm\u00e9n's method. Phragm\u00e9n's method tries to accomplish two goals: 1) select <code>n</code> members from a larger set based on stake-weighted votes and 2) equalize the stake backing each validator as much as possible.</p> <p>You will likely want to campaign your validator to the community in order to get more backing. You are looking for nominators that will put up their tokens to increase the stake for your validator. For validators who cannot acquire the minimum stake from the community, Parity and Web3 Foundation also run a joint programme called Decentralized Nodes that will nominate validators if they apply and fit the requirements.</p>"},{"location":"general/faq/#how-are-validators-rewarded","title":"How are validators rewarded?","text":"<p>Validators are rewarded from the inflation of the relay chain, transaction fees, and tips. However, they only take a percentage of the former two. More details can be read on the page for validator payouts.</p>"},{"location":"general/faq/#what-is-the-minimum-stake-necessary-to-be-elected-as-an-active-validator","title":"What is the minimum stake necessary to be elected as an active validator?","text":"<p>The minimum stake that is necessary to be elected as an active validator is dynamic and can change over time. It depends not only on how much stake is being put behind each validator, but also the size of the active set and how many validators are waiting in the pool.</p> <p>There are a few ways to estimate the minimum stake.</p> <p>One way can be to navigate to the Polkadot Apps Targets tab. The value at the top of the screen saying \"Lowest\" is the least staked validator. You need at least this much + 1 to enter the set.</p> <p>You can also use some tools some to perform estimations.</p> <ul> <li> <p>Offline Election   can provide exact results of running an election on the current set of validators using the same   Rust code that is ran in Polkadot.</p> </li> <li> <p>Validator stats script can give you an estimate that is   based on the currently elected set, as well as some statistics about Kusama validators.</p> </li> </ul>"},{"location":"general/faq/#why-polkadot-targets-1000-validators-while-other-projects-have-hundreds-of-thousands","title":"Why Polkadot targets 1000 validators while other projects have hundreds of thousands?","text":"<p>Polkadot's goal to have 1000 validators is set to be something that is practically achievable in the short term with high confidence of good performance in a live environment. Furthermore, validators in Polkadot are not the only stakers, and if we consider the number of stakers that can be possible on Polkadot the number can scale up to hundreds of thousands. Since validators are performing critical consensus work to maintain the security of the chain including all of its shards, a more modest number of validators is estimated to start. Upon later improvements, such as implementing signature aggregation for finalization messages, the number of validators could reasonably scale up. However, increasing validators above one thousand remains a goal for later iterations of Polkadot.</p> <p>Additionally, other projects sometimes have a different definition of validator that approximates more closely to remote signing keys without the full operation of a validating node. On Polkadot, each validator is running their own validating node and performing full verification of the Relay Chain, voting on finality, producing blocks in their decided slots, and verifying parachain state transitions. Other projects may consider validators and \"validating nodes\" as separate entities.</p> <p>Finally, individuals may participate in the block production process indirectly by nominating validators. In this way, individuals who are not running a node can still share in staking rewards.</p>"},{"location":"general/faq/#relay-chain","title":"Relay Chain","text":""},{"location":"general/faq/#what-is-the-block-time-of-the-relay-chain","title":"What is the block time of the relay chain?","text":"<p>Both the Kusama and Polkadot networks are currently operating at a rate of one block every six seconds.</p> <p>This may be changed in the future. It may go as low as two to three seconds after optimizations, or potentially increase in order to handle the capacity of the parachain networking in a live environment.</p>"},{"location":"general/faq/#does-polkadot-have-smart-contracts","title":"Does Polkadot have smart contracts?","text":"<p>No - and yes. The Polkadot relay chain does not implement smart contracts natively. The reason for not having smart contracts on the relay chain is part of the design philosophy for Polkadot that dictates that the relay chain should be the minimal logic required to accomplish its job.</p> <p>While the Polkadot relay chain does not implement smart contracts directly, there are numerous parachains that do. It's possible for parachains to enable smart contract functionality and then benefit from the security and interoperability features of Polkadot. Additionally, existing smart contract chains can connect to Polkadot as a parachain, or via a bridge.</p> <p>So it's better to say that the Polkadot ecosystem has smart contracts versus \"Polkadot has smart contracts.\"</p>"},{"location":"general/faq/#how-does-the-polkadot-relay-chain-connect-to-external-chains-in-the-ecosystem","title":"How does the Polkadot relay chain connect to external chains in the ecosystem?","text":"<p>One of the cornerstone interoperability technologies being researched and developed for deployment on Polkadot is cross-chain bridges. Bridges come in a variety of flavors with varying levels of trust associated with them. Polkadot is predominantly researching the trust-minimized flavor that imposes economic costs on the operators of the bridge, and therefore makes it economically secure. Bridge efforts are being worked on in concert with other projects in the ecosystem.</p>"},{"location":"general/faq/#what-is-polkadots-transactions-per-second-tps","title":"What is Polkadot's Transactions Per Second (TPS)?","text":"<p>Polkadot is a heterogeneous sharded network comprising a relay chain and numerous parachains, which are all individual blockchains built on Substrate executing in parallel. Hence, the Transactions Per Second (TPS) of Polkadot is a number that encompasses all the transactions on the relay chain as well as parachains. As the transactions on these Substrate-based blockchains are weights based, it makes sense to use TPS as a measure for the network performance if all the transactions carry the same weight. Performance benchmark tests show that Substrate-based blockchains can achieve over 1000 TPS for balance transfer transactions. Assuming Polkadot is running over 100 parachains; the projected TPS is well over 100,000. With asynchronous backing upgrade, the TPS is expected to increase tenfold to 1,000,000.</p> <p>It is essential to realize that TPS is inherently a subjective measurement with numerous factors that can contribute to it. It's hard to gauge the usefulness of TPS in isolation (when compared to other chains), as it depends on what a transaction does for a particular network. To view how Polkadot measures TPS see the Polkadot sTPS (Standard Transaction Per Second) to consider precisely how benchmarking was performed for Polkadot.</p>"},{"location":"general/faq/#dot","title":"DOT","text":""},{"location":"general/faq/#what-is-the-difference-between-dot-old-and-new-dot","title":"What is the difference between DOT (old) and new DOT?","text":"<p>The DOT (old) unit on Polkadot was at twelve decimal places, otherwise known as 1e12 Plancks. On 21 August, 2020, Denomination Day, the DOT (old) value was redenominated to 1e10 (10_000_000_000, or ten billion) Plancks, meaning that the new DOT was valued at ten decimal places. Following the redenomination, the new DOT is called DOT.</p>"},{"location":"general/faq/#what-is-the-inflation-rate-of-the-dot","title":"What is the inflation rate of the DOT?","text":"<p>The inflation rate is approximately 120,000,000 DOT per year.</p> <p>The 85% of inflation is rewarded to validators for performing their duties, while the 15% goes to the treasury. Please see the article on inflation for more information.</p>"},{"location":"general/faq/#why-cant-crowdloaned-dot-be-staked","title":"Why can't crowdloaned DOT be staked?","text":"<p>DOTs contributed to a successful crowdloan campaign by a parachain are bonded for the entire lease period, which is two years on Polkadot. The crowdloaned DOT cannot be used for any other DOT utility functionalities like staking and democracy. In exchange to the lost staking rewards or liquidity of DOTs, the parachain team may offer rewards to the contributor.</p> <p>The utility of crowdloaned DOT is to provide a lease for a parachain. The utility of staked DOT is to secure the network through a reward/slash mechanism. Allowing crowdloaned DOT to be staked results in complex consequences like applying a slash on crowdloaned DOT that was meant to be bonded for the entire lease period of a parachain. In a way, the inaccessibility of crowdloaned DOTs and the lack of staking rewards for the entire lease duration encourages the contributors to back projects that are valuable to the ecosystem.</p>"},{"location":"general/faq/#governance","title":"Governance","text":""},{"location":"general/faq/#what-prevents-polkadot-governance-from-failing","title":"What prevents Polkadot governance from failing?","text":"<p>Polkadot's governance has already been shown to work. Examples can be found in the runtime upgrades that have successfully taken place through on the testnets as well as in a real economic environment on Kusama and Polkadot itself.</p> <p>It is fair to say that the field of on-chain blockchain governance is still new, and no one can claim to know exactly what the optimal version of on-chain governance is yet. However, Polkadot takes a brave step forward in pioneering thought-through mechanisms for evolving a blockchain.</p> <p>Blockchains need a method to adapt and evolve. Therefore, an on-chain governance system was necessary for the long-term success of Polkadot. Ultimately, it is the token holders that are responsible for preventing Polkadot's governance from failing by using their economic value and conviction to sway the progression of the protocol.</p>"},{"location":"general/faq/#what-prevents-polkadot-governance-from-becoming-plutocratic","title":"What prevents Polkadot governance from becoming plutocratic?","text":"<p>A savvy reader might have noticed that the answer to the previous question endowed the token holder with the ultimate responsibility to ensure that Polkadot's governance does not fail. By following the train of this assertion, one might assume that Polkadot's governance is susceptible to becoming ruled by a few large token holders (called whales in trading parlance) and therefore become a mere plutocracy (rule of the rich).</p> <p>There are several other mechanisms that are built-in to the governance system to resist this plutocratic tendency. One of these mechanisms is called conviction voting, and imbues greater voting power to token holders who are willing to lock their tokens on the protocol for longer lengths of time. Longer lock-ups display conviction in a vote. Conviction voting could allow a highly determined minority to overrule the vote of an apathetic majority in certain situations. Another mechanism is known as Adaptive Quorum Biasing. This makes proposals have a varying threshold for approval or rejection based on what part of the governance protocol the proposal originated in. For details on the subtleties of Polkadot's governance system, please see the governance page.</p>"},{"location":"general/faq/#parachains","title":"Parachains","text":""},{"location":"general/faq/#how-do-parachain-economics-work","title":"How do parachain economics work?","text":"<p>Parachains have the flexibility to implement their own monetary system or incentive structure for collators. However, this is not strictly necessary. Since the collator's job is to continue to give recent state transitions to the validators on the relay chain who validate each transition, the security of the parachain and the Polkadot network is completely separate from parachain economics. Parachains need collators to continue to progress, so it wouldn't be unreasonable to see them incentivize collator nodes in some way, but the specific mechanism is completely up to parachain implementers.</p>"},{"location":"general/faq/#are-parachains-ephemeral-what-happens-when-a-parachain-fails-to-renew-its-coretime","title":"Are parachains ephemeral? What happens when a parachain fails to renew its coretime?","text":"<p>Parachains are not ephemeral. As long as someone is keeping the data for a parachain, the parachain can move between being a parachain, an on-demand parachain, or a separate sovereign chain at different points of its lifetime. Especially with on-demand parachains, parachains can produce blocks when their usage and throughput makes it necessary.</p> <p>When a parachain could not renew its bulk coretime and needs to keep its chain live, there are a couple of options to consider. One option is to explore secondary coretime marketplaces on Lastic or RegionX. The other option is run as an on-demand parachain, and purchase coretime to produce one block at a time. On-demand parachains are still secured by the relay chain but don't need to hold a core and can produce a block when it's economically feasible for them. For more information, please refer to the parachains page.</p>"},{"location":"general/faq/#networking","title":"Networking","text":""},{"location":"general/faq/#what-is-libp2p","title":"What is libp2p?","text":"<p>Libp2p is a modular and extensible networking stack that is used by IPFS, Substrate, and many other projects. It is a collection of peer-to-peer protocols for finding peers and connecting to them. Its modules have logic for content routing, peer routing, peer discovery, different transports, and NAT traversals. It is intended to be used by applications for building large scale peer-to-peer networks by only selecting the parts of the protocol suite that are needed.</p> <p>The Rust implementation of the specification was built and primarily maintained by a team of contributors at Parity Technologies. The Go and JavaScript versions are maintained by Protocol Labs as well as community contributors. A Nim version of the library also exists. Libp2p as a whole is an open source project that is actively developed and expanded on various code repositories hosted on their GitHub.</p>"},{"location":"general/faq/#does-polkadot-use-libp2p","title":"Does Polkadot use libp2p?","text":"<p>Yes, since Polkadot is built with Substrate. Substrate uses a networking protocol that is based on libp2p (specifically the Rust libp2p library). However, Substrate uses a mix of standard libp2p protocols and protocols that are homegrown and not official libp2p standards. Of the standards protocols, those which are shared with other implementations of libp2p such as IPFS, are connection-checking (ping), asking for information on a peer (identity), and Kademlia random walks (kad).</p> <p>Of the protocols that are custom to Substrate, there are the legacy Substrate stream, a request-response for getting information on blocks (sync), a light client protocol, a notification protocol for transactions, and block announcement. For detailed information on how Substrate uses libp2p and the standard and custom protocols, please see the networking documentation.</p>"},{"location":"general/faq/#how-does-libp2p-differ-from-ipfs","title":"How does libp2p differ from IPFS?","text":"<p>The Interplanetary File System (IPFS) is a peer-to-peer hypermedia protocol used primarily for storage of files. It allows one to upload a file onto the network and share it with its content addressable URI. IPFS, like Substrate, is an application of libp2p and exists higher on the technology stack. Although both IPFS and Substrate use libp2p, it cannot be said that Substrate \"uses\" IPFS since besides sharing the underlying library for networking there is no native integration between the two applications.</p>"},{"location":"general/faq/#kusama","title":"Kusama","text":""},{"location":"general/faq/#what-is-the-minimum-amount-of-ksm-dot-i-can-have-in-my-account","title":"What is the minimum amount of KSM / DOT I can have in my account?","text":"<p>Please see information about Existential Deposits.</p>"},{"location":"general/faq/#what-are-the-transfer-fees-for-kusama","title":"What are the transfer fees for Kusama?","text":"<p>It is important to note that the cost of transferring KSM is dynamic. Currently, the minimum cost of transferring KSM is 0.01 KSM (the base fee), although this can be changed via governance. However, actual transaction fees vary based on a variety of factors. Specifically, fee calculation follows the following formula:</p> <pre><code>base_fee + (tx_length * length_fee) + WeightToFee(weight)\n</code></pre> <p>Please see the fee calculation page in the Substrate documentation for more detailed information.</p>"},{"location":"general/faq/#answered-by-gav-series","title":"Answered by Gav series","text":"<p>The \"Answered by Gav\" series is a collection of posts uploaded to Reddit of questions that have been asked in the Polkadot Watercooler Riot channel and answered by Polkadot founder Gavin Wood.</p> <ul> <li>Reason for using asynchronous rather than synchronous communication? Difference in terms of TPS?</li> <li>How exactly do validators in an ETH parachain keep moving around and how is communication between zones trustless?</li> <li>What are the main issues with Bitcoin integration and will it ever be possible? Same problem with other POW chains? Is Polkadot only going to work with POS chains? How is it trust-less in comparison to Cosmos though?</li> <li>What are the current thoughts around governance especially since projects have to be voted in to receive the parachains security?</li> <li>Also is there any detailed overview of how exactly a token transfer from ETH could be exchanged with another chain's currency?</li> <li>Can I run multiple Validators with the same Session Key?</li> <li>How to tackle the concentration risk of Validators in data centers?</li> </ul>"},{"location":"general/getting-started/","title":"Getting Started","text":""},{"location":"general/getting-started/#what-is-polkadot","title":"What is Polkadot?","text":"<p>Polkadot is the first layer-0 (L0) blockchain that provides shared security and secure interoperability to layer-1 (L1) blockchains. Those L1 blockchain attached to Polkadot are also called parachains as their transactions are processed in parallel by Polkadot. For more information about Polkadot see the dedicated page about the state of Polkadot 1.0 released in mid 2023.</p> <p>Polkadot has an on-chain open governance (also called Polkadot OpenGov) to orchestrate decisions, including accessing funds from the treasury.</p> <p>The DOT token gives you the power to participate in Polkadot OpenGov, and staking.</p> <p>The level of abstraction and generalization of Polkadot allows to build applications that are specific to their use cases, and for those applications to communicate securely leveraging each other value proposition. The trustless cooperation between applications is what makes Polkadot an ideal ecosystem to build a web3 future.</p> <p>Polkadot: Are You Ready to Start Building?</p> <p>What is Polkadot?</p>"},{"location":"general/getting-started/#what-can-i-do-with-my-dot","title":"What can I do with my DOT?","text":"<p>DOT is the native token of the Polkadot Network. DOT can be used for transaction fees, staking, governance, acquisition of coretime and for enabling several key functionalities on Polkadot. See more information on the Chain State Values page.</p> <p>Info</p> <p>Explore Polkadot with a secure and user-friendly wallets listed on the Polkadot website.</p> <p>DOT has utility in Polkadot's OpenGov where you can vote, delegate your voting power, and place deposits for your referenda or referenda proposed by others. DOT can also enable you to participate in programs like the Decentralized Nodes program.</p>"},{"location":"general/getting-started/#polkadot-gifts","title":"Polkadot Gifts","text":"<p>Polkadot Gifts provide an easy way to:</p> <ul> <li>Onboard friends or family who are curious about blockchain but haven\u2019t made the leap yet.</li> <li>Share your love of Polkadot and send any amount of DOT.</li> <li>Say \u2018thank you\u2019 or send someone tokens when you don\u2019t know their address.</li> <li>Get friends and family set up to participate in crowdloans.</li> </ul> <p>Learn more about how you can create and send Polkadot Gifts here.</p>"},{"location":"general/getting-started/#why-should-you-use-polkadot","title":"Why should you use Polkadot?","text":"<p>Whether you're a blockchain developer or if you're interested in taking part of Polkadot's community, Polkadot offers a platform for everyone.</p>"},{"location":"general/getting-started/#where-to-start-learning","title":"Where to start learning?","text":"<p>The Blockchain Fundamentals MOOC course is a great introduction to start familiarizing yourself with blockchain concepts such as cryptography and networks, and how these play into things like decentralization and cryptocurrency.</p> <p>This is recommended for users with backgrounds of all levels, and the course is free!</p>"},{"location":"general/getting-started/#brand-new-polkadot-learners","title":"Brand-New Polkadot learners","text":"<ul> <li>Polkadot's original white paper is a technical   summary around one possible direction of implementing the Polkadot network. This paper uses   rationale and technical details to support why this direction is beneficial. This original white   paper also explains how Polkadot's core components work together to build this decentralized   network.</li> <li>Polkadot's light paper is a visual, easy to   read, and less technical introduction into its blockchain technology. This paper dives into the   components of Polkadot but is understandable for both a non-technical and technical reader.</li> <li>Polkadot's overview paper is an updated version of the white   paper that describes the protocol in more technical terms. We would recommend reading this   overview paper if you are interested in digging more into the protocol itself.</li> <li>The Web3 Foundation's research site contains details and   up-to-date technical research on Polkadot in general, including scalability, cryptographic,   economic, and security aspects of the protocol.</li> <li>Polkadot for Beginners: A non-technical guide to decentralization, blockchains &amp; Polkadot -   a book funded by the Polkadot Treasury</li> <li>Polkadot's specification is a GitHub repository that holds   the latest Polkadot Host protocol specification, Polkadot's specification tests of the many   components of the network, and the Polkadot Runtime specification. This repo holds algorithms and   explores how various processes function in the Polkadot network. The Polkadot specification takes   Polkadot's ideas and concepts from the light and the white paper but focuses on the technical   specs of the technology.</li> <li>Watching the Technical Explainer Videos:   These are great introductory videos that explain and demonstrate how to use Polkadot and its   User Interface.</li> <li>Reading   What is Polkadot? A Brief Introduction   on Medium. There are also other great articles to read on   Polkadot's Medium or   Web3 Foundation's Medium.</li> <li>Polkadot Study is a platform where developers can write tutorials for   the Polkadot ecosystem. Part of the development of the platform was funded by the   Kusama treasury. The platform also hosts   Substrate in Bits, a technical content   series aimed at solving the pain points of developers building with   Substrate and Rust.</li> </ul> <p>For brand-new learners of Kusama, Polkadot's canary cousin network: To learn more about how to build and maintain on the Kusama network, please head over to our Kusama Guide.</p>"},{"location":"general/getting-started/#resources","title":"Resources","text":"<ul> <li>Polkadot Crowdcast - List of all Crowdcast webinars that the   Web3 Foundation has done.</li> <li>Polkadot Explorer - Browser for the Polkadot network;   can be used for Polkadot, Kusama, or any Substrate-based chain.</li> <li>Subscan.io - Explorer for Substrate based chains.</li> <li>Polkadot Overview - Dr. Gavin Wood presents an overview of   Polkadot. (Video)</li> <li>Polkadot Overview -   Dr. Jutta Steiner presents Polkadot. (Video)</li> <li>Polkadot &amp; Substrate Overview -   Dr. Gavin Wood presents Substrate (blockchain in-a-box + VM) and Polkadot, and builds a blockchain   on-stage in 30 minutes using Substrate. (Video)</li> <li>Community / Ecosystem - List of community rooms and channels to talk to others   about Polkadot.</li> <li>Contributing Guide - Rules for contributing to the wiki.</li> <li>Polkadot Knowledge Base - Troubleshooting resources for   specific errors and problems.</li> </ul>"},{"location":"general/glossary/","title":"Glossary","text":""},{"location":"general/glossary/#active-nomination","title":"Active Nomination","text":"<p>A validator (or validators) that a nominator has selected to nominate and is actively validating this era. The nominator is placing their stake behind this validator for this era and will potentially receive staking rewards in return for doing so.</p>"},{"location":"general/glossary/#alexander","title":"Alexander","text":"<p>The fourth (now defunct) proof of concept (PoC-4) testnet for Polkadot.</p>"},{"location":"general/glossary/#asset-hub","title":"Asset Hub","text":"<p>A system parachain used for asset management.</p>"},{"location":"general/glossary/#attestation","title":"Attestation","text":"<p>In the network's validity system, an attestation is a type of message that validators broadcast that says whether they think a parachain candidate block is valid or invalid.</p>"},{"location":"general/glossary/#auction-parachain","title":"Auction (Parachain)","text":"<p>Parachain auctions were used by non-system parachains to access Polkadot. The current method is through purchase of coretime.</p>"},{"location":"general/glossary/#aura","title":"Aura","text":"<p>Authority-based round-robin scheduling (AURA) provides a slot-based block authoring mechanism, where a known set of authorities take turns producing blocks.</p>"},{"location":"general/glossary/#authority","title":"Authority","text":"<p>An authority is a generic term for the role in a blockchain that can participate in the consensus mechanisms. In GRANDPA, the authorities vote on chains they consider final. In BABE, the authorities are block producers. Authority sets can be chosen to be mechanisms such as Polkadot's NPoS algorithm.</p>"},{"location":"general/glossary/#availability-cores","title":"Availability Cores","text":"<p>Slots used to process parachains. The runtime assigns each parachain to an availability core and validators can fetch information about the cores, such as parachain block candidates, by calling the appropriate Runtime API.</p>"},{"location":"general/glossary/#babe","title":"BABE","text":"<p>Blind Assignment for Blockchain Extension (BABE) is Polkadot's block production mechanism.</p>"},{"location":"general/glossary/#bitfield-array","title":"Bitfield Array","text":"<p>A bitfield array contains single-bit values which indicate whether a candidate is available. The number of items is equal of to the number of availability cores and each bit represents a vote on the corresponding core in the given order.</p>"},{"location":"general/glossary/#block","title":"Block","text":"<p>A collection of data, such as transactions, that together indicate a state transition of the blockchain.</p>"},{"location":"general/glossary/#blockspace","title":"Blockspace","text":"<p>Blockspace is the capacity of a blockchain to finalize and commit operations. It represents a blockchain's security, computing, and storage capability as an end product. Blockspace produced by different blockchains can vary in quality, availability, and flexibility. Polkadot has a blockspace-centric architecture.</p>"},{"location":"general/glossary/#block-explorer","title":"Block Explorer","text":"<p>An application that allows a user to explore the different blocks on a blockchain.</p>"},{"location":"general/glossary/#blocks-nominations","title":"Blocks Nominations","text":"<p>This indicates that a validator does not currently allow any more nominations. This is controlled by the validator.</p>"},{"location":"general/glossary/#bls","title":"BLS","text":"<p>Boneh-Lynn-Shacham (BLS) signatures have a slow signing, very slow verification, require slow and much less secure pairing friendly curves, and tend towards dangerous malleability. Yet, BLS permits a diverse array of signature aggregation options far beyond any other known signature scheme, which makes BLS a preferred scheme for voting in consensus algorithms and threshold signatures.</p>"},{"location":"general/glossary/#bonding","title":"Bonding","text":"<p>A process by which tokens can be \"frozen\" in exchange for some other benefit. For example, staking is a form of bonding for which you receive rewards in exchange for securing the network.</p>"},{"location":"general/glossary/#bounty","title":"Bounty","text":"<p>A mechanism that allows network participants to access treasury funding without going through the process of submitting an OpenGov referendum. Note that a bounty got funds through OpenGov in the first place, but the subsequent disbursement of those funds is controlled by curators based on achieved milestones by the recipient.</p>"},{"location":"general/glossary/#bridge","title":"Bridge","text":"<p>A parachain that acts as an intermediary between the relay chain and an external chain, in such a way that it appears to the relay chain that the external chain is a parachain (i.e., meets the network Host's requirements of parachains). Bridges allow for interaction between other blockchains, such as Ethereum and Bitcoin, that are not natively compatible with the relay chain.</p>"},{"location":"general/glossary/#byzantine-fault-tolerance","title":"Byzantine Fault Tolerance","text":"<p>The property of a system that is tolerant of Byzantine faults; a system where not only may individual subsystems fail, but it may not be clear if a particular subsystem has failed or not. That is, different observers on the system may not agree on whether or not the system has failed. Ensuring Byzantine fault tolerance is an important part of developing any distributed system.</p>"},{"location":"general/glossary/#capacity","title":"Capacity","text":"<p>The maximum number of nominators signalling intent to nominate a validator (and thus could potentially actively nominate that validator in the next session).</p>"},{"location":"general/glossary/#candidate","title":"Candidate","text":"<p>A candidate is a submitted parachain block to the relay chain validators. A parachain block stops being referred to as a candidate as soon it has been finalized.</p>"},{"location":"general/glossary/#collations","title":"Collations","text":"<p>Parachain blocks or candidates that are being proposed to the relay chain validators. More specifically, a collation is a data structure which contains the proposed parachain candidate, including an optional validation parachain Runtime update and upward messages.</p>"},{"location":"general/glossary/#collator","title":"Collator","text":"<p>A node that maintains a parachain by collecting parachain transactions and producing state transition proofs for the validators.</p>"},{"location":"general/glossary/#collectives","title":"Collectives","text":"<p>The Polkadot Collectives parachain was added in Referendum 81 and exists only on Polkadot (i.e., there is no Kusama equivalent). The Collectives chain hosts on-chain collectives that serve the Polkadot network, such as the Fellowship and Polkadot Alliance.</p>"},{"location":"general/glossary/#commission","title":"Commission","text":"<p>Validators and nominators get paid from block production on the network, where validators can set a variable commission rate, which is initially subtracted from the total rewards that validator is entitled to (for that period), where the commission determines the rate of distribution for the remaining rewards set out for the nominators that are backing that validator.</p>"},{"location":"general/glossary/#common-good-parachain","title":"Common Good (Parachain)","text":"<p>See System Parachains, which is generally preferred over the term \"common good\".</p>"},{"location":"general/glossary/#community-queue","title":"Community Queue","text":"<p>The queue for proposals originating from individual accounts (i.e. not the Council) which are waiting to become referenda. Compare the External queue.</p>"},{"location":"general/glossary/#consensus","title":"Consensus","text":"<p>The process of a group of entities to agree on a particular data value (such as the ordering and makeup of blocks on a blockchain). There are a variety of algorithms used for determining consensus. The consensus algorithm used by Polkadot is GRANDPA.</p>"},{"location":"general/glossary/#coretime","title":"Coretime","text":"<p>The time allocated for utilizing a core that can be purchased in bulk or on demand. It is measured in relay chain blocks.</p>"},{"location":"general/glossary/#crowdloan","title":"Crowdloan","text":"<p>A mechanism used in the past for potential parachains to temporarily source tokens to win an auction for a relay chain core. Tokens gathered in this way were programmatically returned to the lender after the lease period was over or the crowdloan period ended.</p>"},{"location":"general/glossary/#curator","title":"Curator","text":"<p>A person, group, or other entity charged with judging and verifying the successful completion of a Bounty.</p>"},{"location":"general/glossary/#dapps","title":"Dapps","text":"<p>A generic term for a decentralized application, that is, one that runs as part of a distributed network as opposed to being run on a specific system or set of systems.</p>"},{"location":"general/glossary/#dot","title":"DOT","text":"<p>The native token for Polkadot. DOT serves three purposes: network governance (allowing them to vote on-chain upgrades and other exceptional events), general operation (rewarding good actors and punishing bad actors), and bonding (adding new parachains by \"freezing\" DOT while they are connected the relay chain).</p>"},{"location":"general/glossary/#duty-roster","title":"Duty Roster","text":"<p>A lookup table that specifies the job that a particular validator is required to do (i.e. attest to the validity of a specific parachain). The duty roster routinely shuffles the validator set into different subsets per parachain.</p>"},{"location":"general/glossary/#epoch","title":"Epoch","text":"<p>An epoch is a time duration in the BABE protocol that is broken into smaller time slots. Each slot has at least one slot leader who has the right to propose a block. In Kusama, it is the same duration as a session.</p>"},{"location":"general/glossary/#era","title":"Era","text":"<p>A (whole) number of sessions, which is the period that the validator set (and each validator's active nominator set) is recalculated and where rewards are paid out.</p>"},{"location":"general/glossary/#equivocation","title":"Equivocation","text":"<p>Providing conflicting information to the network. BABE equivocation entails creating multiple blocks in the same slot. GRANDPA equivocation would consist of signing multiple conflicting chains.</p>"},{"location":"general/glossary/#external-queue","title":"External Queue","text":"<p>Not applicable to OpenGov. The queue for proposals originating with the Council which are waiting to become referenda. Compare the Community queue.</p>"},{"location":"general/glossary/#extrinsic","title":"Extrinsic","text":"<p>A SCALE encoded array consisting of a version number, signature, and varying data types indicating the resulting runtime function to be called, including the parameters required for that function to be executed. These state changes are invoked from the outside world, i.e. they are not part of the system itself. Extrinsics can take two forms, \"inherents\" and \"transactions\". For more technical details see the polkadot spec</p>"},{"location":"general/glossary/#technical-fellowship","title":"Technical Fellowship","text":"<p>A mostly self-governing expert body with a primary goal of representing humans who embody and contain the technical knowledge base of the Kusama and/or Polkadot networks and protocols.</p>"},{"location":"general/glossary/#finality","title":"Finality","text":"<p>The property of a block that cannot be reverted. Generally, created blocks are not final until some point in the future - perhaps never, in the case of \"probabilistic finality\". The relay chain uses a deterministic finality gadget known as GRANDPA.</p>"},{"location":"general/glossary/#finality-gadget","title":"Finality Gadget","text":"<p>A mechanism that determines finality.</p>"},{"location":"general/glossary/#frame","title":"Frame","text":"<p>The collection of Substrate-provided pallets (Substrate Runtime Modules).</p>"},{"location":"general/glossary/#genesis","title":"Genesis","text":"<p>The origin of a blockchain, also known as block 0. It can also be used to reference the initial state of the blockchain at origination.</p> <p>Example</p> <p>In the genesis state Alice, Bob, and Charlie had 30 tokens each.</p>"},{"location":"general/glossary/#governance","title":"Governance","text":"<p>The process of determining what changes to the network are permissible, such as modifications to code or movement of funds. The governance system is on-chain and revolves around stakeholder voting.</p>"},{"location":"general/glossary/#governance-council","title":"Governance Council","text":"<p>An on-chain entity that consists of several on-chain accounts (starting at 6, eventually moving to the final value of 24). The Council can act as a representative for \"passive\" (non-voting) stakeholders. Council members have two main tasks: proposing referenda for the overall stakeholder group to vote on and cancelling malicious referenda.</p>"},{"location":"general/glossary/#grandpa-finality-gadget","title":"GRANDPA Finality Gadget","text":"<p>GHOST-based Recursive ANcestor Deriving Prefix Agreement. It is the finality gadget allows asynchronous, accountable, and safe finality to the blockchain. For an overview of GRANDPA, see this Medium post.</p>"},{"location":"general/glossary/#hard-fork","title":"Hard Fork","text":"<p>A permanent diversion of a blockchain occurs quickly due to a high priority change in a consensus rule. Clients who follow a hard fork always need to upgrade their clients to continue following the upgraded chain. Hard forks are considered permanent divergences of a chain for which non-upgraded clients are following consensus rules incompatible to the ones followed by upgraded clients.</p>"},{"location":"general/glossary/#hard-spoon","title":"Hard Spoon","text":"<p>Defined by Jae Kwon of Cosmos as \"a new chain that takes into account state from an existing chain; not to compete, but to provide broad access.\" A non-contentious blockchain that inherits the state of the underlying blockchain and creates a new branch of the same blockchain.</p>"},{"location":"general/glossary/#horizontal-relay-routed-message-passing","title":"Horizontal Relay-routed Message Passing","text":"<p>Horizontal Relay-routed Message Passing, also known as HRMP, is a precursor to the complete XCMP implementation, that mimics the same interface and semantics of XCMP. It is similar to XCMP except for how it stores all messages in the relay chain storage, therefore making it more expensive and demanding more resources than XCMP. The plan is to retire HRMP once the implementation of XCMP is complete.</p>"},{"location":"general/glossary/#inactive-nomination","title":"Inactive Nomination","text":"<p>A validator (or validators) that a nominator has selected to nominate, but is not actively validating this era. This type of nomination may become active in a future era.</p>"},{"location":"general/glossary/#inherent","title":"Inherent","text":"<p>Extrinsics that are \"inherently true.\" Inherents are not gossiped on the network and are put into blocks by the block author. They are not provably true the way that the desire to send funds is, therefore they do not carry a signature. A blockchain's runtime must have rules for validating inherents. For example, timestamps are inherents. They are validated by being within some margin that each validator deems reasonable.</p>"},{"location":"general/glossary/#injected-account","title":"Injected Account","text":"<p>An account that is not directly managed by the Polkadot UI but can be accessed through it, such as accounts controlled by the Polkadot-JS extension.</p>"},{"location":"general/glossary/#interoperability","title":"Interoperability","text":"<p>The ability for some sort of system to exchange and make use of information often compared to \"cross-chain\" technologies.</p>"},{"location":"general/glossary/#keep-alive-check","title":"Keep-Alive Check","text":"<p>The keep-alive check is used to indicate whether or not a transfer can allow the sending account to be reduced to less than the existential deposit, causing it to be reaped.</p>"},{"location":"general/glossary/#ksm","title":"KSM","text":"<p>The abbreviation for Kusama network tokens.</p>"},{"location":"general/glossary/#kusama","title":"Kusama","text":"<p>The \"canary network\" for Polkadot. It consists of an early-release, unaudited version of the Polkadot software. It is not a testnet - after the transition to NPoS, the network is entirely in the hands of the community (i.e., Kusama token holders).</p>"},{"location":"general/glossary/#lease-period","title":"Lease Period","text":"<p>A particular amount of time that a parachain for which the parachain can connect to the relay chain.</p>"},{"location":"general/glossary/#libp2p","title":"LIBP2P","text":"<p>An open-source library for encrypted peer-to-peer communications and other networking functions. More information at: https://libp2p.io/</p>"},{"location":"general/glossary/#liveness","title":"Liveness","text":"<p>The property of a distributed system is that it will eventually come to some sort of consensus. A system stuck in an infinite loop would not be considered live, even if computations are taking place; a system that eventually provides a result, even if incorrect or it takes a long time, is considered to have liveness.</p>"},{"location":"general/glossary/#mainnet","title":"Mainnet","text":"<p>Short for \"main network\": the fully functional and acting chain that runs its own network.</p>"},{"location":"general/glossary/#message","title":"Message","text":"<p>In Polkadot's XCMP protocol, a message is arbitrary data that is sent from one parachain (the egress chain) to another (the ingress chain) through a channel and ensured delivery by the validator set.</p>"},{"location":"general/glossary/#message-queue","title":"Message Queue","text":"<p>In Polkadot's XCMP protocol, a message queue is the list of messages waiting to be processed by a particular receiving parachain over a channel.</p>"},{"location":"general/glossary/#metadata","title":"Metadata","text":"<p>Data that includes information about other data, such as information about a specific transaction.</p>"},{"location":"general/glossary/#motion","title":"Motion","text":"<p>A motion is essentially a \"referendum\" or \"decision\" being considered by the Council. The Council can vote on motions like approving Treasury Proposals or making proposals for the community to vote on.</p>"},{"location":"general/glossary/#next-session","title":"Next Session","text":"<p>This indicates that the validator will be a member of the active set in the next session.</p>"},{"location":"general/glossary/#node-explorer","title":"Node Explorer","text":"<p>A tool that gives you information about a node, such as the latest blocks sealed, finalized, and the current chain state as known by that node.</p>"},{"location":"general/glossary/#nominated-proof-of-stake-npos","title":"Nominated Proof of Stake (NPoS)","text":"<p>A Proof-of-Stake system where nominators back validators with their own stake as a show of faith in the good behavior of the validator. Nominated Proof-of-Stake differs from the more generic concept Delegated Proof-of-Stake in that nominators are subject to loss of stake if they nominate a bad validator; delegators are not subject to loss of stake based on the behavior of the validator. Note that some other blockchain technologies may use the term Delegated Proof-of-Stake, even if delegators can be slashed. Polkadot uses the Phragm\u00e9n method to allocate stake to nominees.</p>"},{"location":"general/glossary/#nominator","title":"Nominator","text":"<p>Accounts that select a set of validators to nominate by bonding their tokens. Nominators receive some of the validators' rewards, but are also liable for slashing if their nominated validators misbehave.</p>"},{"location":"general/glossary/#non-fungible-token-nft","title":"Non-fungible Token (NFT)","text":"<p>A non-fungible token is a token that does not hold the property of fungibility, which, in turn, means that it cannot be interchangeable and indistinguishable from other tokens. NFTs allow the tokenization of unique items and provide exclusive ownership for those tokens.</p>"},{"location":"general/glossary/#on-chain-governance","title":"On-chain Governance","text":"<p>A governance system of a blockchain that is controlled by mechanisms on the blockchain. On-chain governance allows decisions to be made transparently. Note that there are a variety of different algorithms for making these decisions, such as simple majority voting, adaptive quorum biasing, or identity-based quadratic voting.</p>"},{"location":"general/glossary/#polkadot-opengov","title":"Polkadot OpenGov","text":"<p>Previously known as Governance v2 (Gov2) during early development, Polkadot OpenGov serves as the current governance protocol for both Kusama and Polkadot.</p>"},{"location":"general/glossary/#origin","title":"Origin","text":"<p>The initiator of an extrinsic. A simple origin would be the account that is sending a token to another account. Polkadot also supports more complex origin types, such as the root origin, from which privileged functions can be called.</p>"},{"location":"general/glossary/#pallet","title":"Pallet","text":"<p>A Substrate runtime module.</p>"},{"location":"general/glossary/#parachain","title":"Parachain","text":"<p>A blockchain that meets several characteristics that allow it to work within the confines of the network Host. Also known as \"parallelized chain\". All parachains start their life-cycle as a parathread.</p>"},{"location":"general/glossary/#parachain-development-kit-pdk","title":"Parachain Development Kit (PDK)","text":"<p>Similar to an SDK, parachain development kits (PDK) is a set of tools that make it easy for developers to create Polkadot-compatible parachains.</p>"},{"location":"general/glossary/#paraid","title":"ParaID","text":"<p>A unique numeric (non-negative integer) identifier for a parachain.</p>"},{"location":"general/glossary/#parathread","title":"Parathread","text":"<p>Historically, the term \"parathread\" has been used in two contexts: a chain registered with a <code>ParaID</code> on the relay chain that has not yet become a parachain (i.e. not connected to a relay chain core), or as an on-demand parachain (i.e. a parachain using on-demand coretime) which does not produce blocks at regular intervals.</p>"},{"location":"general/glossary/#parachain-registry","title":"Parachain Registry","text":"<p>A relatively simple database-like construct that holds both static and dynamic information on each chain.</p>"},{"location":"general/glossary/#parity-technologies","title":"Parity Technologies","text":"<p>A company, founded by Dr. Gavin Wood and Dr. Jutta Steiner, that is developing Substrate, Kusama and Polkadot. It has also released several other projects including Parity Ethereum and Parity Secret Store.</p>"},{"location":"general/glossary/#people-chain","title":"People Chain","text":"<p>A system parachain for identity management.</p>"},{"location":"general/glossary/#polkadot","title":"Polkadot","text":"<p>A heterogeneous, multi-chain network allowing various blockchains of different characteristics to perform arbitrary, cross-chain communication under shared security.</p>"},{"location":"general/glossary/#polkadot-alliance","title":"Polkadot Alliance","text":"<p>The Polkadot Alliance is an on-chain collective founded by Acala, Astar, Interlay, Kilt, Moonbeam, Phala, and Subscan, to establish standards and ethics for open-source development in referendum #94. It aims to support development standards and expose bad actors within the ecosystems of Polkadot.</p>"},{"location":"general/glossary/#host","title":"Host","text":"<p>The environment in which a runtime module can be executed. Parachains must support the network Host - external chains that do not will have to use a bridge. Previously known as the Polkadot Runtime Environment.</p>"},{"location":"general/glossary/#runtime-environment","title":"Runtime Environment","text":"<p>The previous name for the Polkadot Host.</p>"},{"location":"general/glossary/#paseo","title":"Paseo","text":"<p>Paseo testnet provisions testing on Polkadot's \"production\" runtime, which means less chance of feature/code mismatch when developing parachain apps. Specifically, after the Polkadot Technical fellowship proposes a runtime upgrade for Polkadot, this testnet is updated, giving a period where the testnet will be ahead of Polkadot to allow for testing.</p>"},{"location":"general/glossary/#preimage","title":"Preimage","text":"<p>The on-chain proposals do not require the entire image of extrinsics and data (for instance the WASM code, in case of upgrades) to be submitted, but would rather just need that image's hash. That preimage can be submitted and stored on-chain against the hash later, upon the proposal's dispatch.</p>"},{"location":"general/glossary/#proof-of-stake-pos","title":"Proof of Stake (PoS)","text":"<p>A method of selecting participation in a consensus system, in which participants are chosen based on how many tokens they have at stake (at risk of loss due to misbehavior). Normally, Proof-of-Stake systems limit the number of participants.</p>"},{"location":"general/glossary/#proof-of-validity","title":"Proof of Validity","text":"<p>A proof produced by parachain collators. Based on this proof and the parachain registry, a validator can verify that a parachain has properly executed its state transition function. Proofs of Validity go into the relay chain blocks.</p>"},{"location":"general/glossary/#proof-of-work-pow","title":"Proof of Work (PoW)","text":"<p>A method of selecting participants in a consensus system, typically the longest chain rule, in which participants try to solve a puzzle like finding a partial pre-image of a hash. Normally, a Proof-of-Work system can have any number of participants.</p>"},{"location":"general/glossary/#proposal","title":"Proposal","text":"<p>A potential function call to be voted on in a referendum. Proposals can modify the behavior of the network, from minor parameter tuning up to replacing the runtime code.</p>"},{"location":"general/glossary/#protocol","title":"Protocol","text":"<p>A system of rules that allows two or more entities of a communications system to transmit information. The protocol defines the rules, syntax, semantics, and synchronization of communication and possible recovery methods.</p>"},{"location":"general/glossary/#random-seed","title":"Random Seed","text":"<p>A random seed is a pseudo-random number available on-chain. It is used in various places of the protocol, most prominently in BABE, the block production mechanism.</p>"},{"location":"general/glossary/#referendum","title":"Referendum","text":"<p>A vote on whether or not a proposal should be accepted by the network. Referenda may be initiated by the Governance Council, by a member of the public, or as the result of a previous proposal. Stakeholders vote on referenda, weighted by both the size of their stake (i.e. number of DOT held) and the amount of time they are willing to lock their tokens.</p>"},{"location":"general/glossary/#re-genesis","title":"Re-Genesis","text":"<p>Re-Genesis is the process of exporting the current chain state, and creating a new chain that builds on it. Re-Genesis will involve stop-the-world migration, which results in a period of time when no actual blocks are added to the blockchain. In a way, re-genesis can be viewed as a hard fork process. A formal design of Re-Genesis on Substrate is still under development - Re-Genesis Rationale and Design.</p>"},{"location":"general/glossary/#relay-chain","title":"Relay Chain","text":"<p>The chain that coordinates consensus and communication between parachains (and external chains, via bridges).</p>"},{"location":"general/glossary/#remarks","title":"Remarks","text":"<p>Remarks are extrinsics with no effect. They provide additional information to external inputs, acting as notes. Remarks are stored alongside block records and do not change the chain's storage; the information is not stored in the chain's trie, but along blocks.</p>"},{"location":"general/glossary/#rococo","title":"Rococo","text":"<p>Rococo was a testnet set aside for testing parachains, cumulus, and related technology. Please refer to Paseo test network.</p>"},{"location":"general/glossary/#root-origin","title":"Root Origin","text":"<p>A system-level origin in Substrate. This is the highest privilege level and can be thought of as the superuser of the runtime origin. To learn about more raw origins in Substrate, visit Substrate Docs</p>"},{"location":"general/glossary/#runtime","title":"Runtime","text":"<p>The state transition function of a blockchain. It defines a valid algorithm for determining the state of the next block given the previous state.</p>"},{"location":"general/glossary/#runtime-module","title":"Runtime Module","text":"<p>A module that implements specific transition functions and features one might want to have in their runtime. Each module should have domain-specific logic. For example, a Balances module has logic to deal with accounts and balances. In Substrate, modules are called \"pallets\".</p>"},{"location":"general/glossary/#safety","title":"Safety","text":"<p>The property of a distributed system indicating that a particular state transition will not be reverted. GRANDPA provides deterministic safety. That is, for a state changed marked as \"safe\" or \"final\", one would require a hard fork to revert that change.</p>"},{"location":"general/glossary/#scalability","title":"Scalability","text":"<p>While an ambiguous concept, [blockchain] scalability can be understood as the ability for the network to scale in capabilities (e.g. processing more transactions) when needed.</p>"},{"location":"general/glossary/#sealing","title":"Sealing","text":"<p>The process of adding a block to the relay chain. Note that finalization is a separate process - blocks are finalized sometime after they are sealed.</p>"},{"location":"general/glossary/#session","title":"Session","text":"<p>A session is a Substrate implementation term for a period that has a constant set of validators. Validators can only join or exit the validator set at a session change.</p>"},{"location":"general/glossary/#session-certificate","title":"Session Certificate","text":"<p>A message containing a signature on the concatenation of all the Session keys.</p>"},{"location":"general/glossary/#session-key","title":"Session Key","text":"<p>Hot keys that are used for performing network operations by validators, for example, signing GRANDPA commit messages.</p>"},{"location":"general/glossary/#shared-security","title":"Shared Security","text":"<p>The security model used whereby all chains are equally secured. This is achieved by placing proofs of the validity of parachain blocks into the relay chain such that, in order to revert finality of a single parachain, an attacker would need to attack the entire system.</p>"},{"location":"general/glossary/#slashing","title":"Slashing","text":"<p>The removal of a percentage of an account's DOT as a punishment for a validator acting maliciously or incompetently. For more information, see the page about offenses.</p>"},{"location":"general/glossary/#soft-fork","title":"Soft Fork","text":"<p>A backward compatible change to client code causes upgraded clients to start mining a new chain. Requires a \"vote-by-hashrate\" of a majority of miners to enact successfully. Soft forks are considered temporary divergences in a chain since non-upgraded clients do not follow the new consensus rules but upgraded clients are still compatible with old consensus rules.</p>"},{"location":"general/glossary/#software-development-kit-sdk","title":"Software Development Kit (SDK)","text":"<p>A collection of software tools (and programs) packaged together that can be used to develop software.</p>"},{"location":"general/glossary/#spend-period","title":"Spend Period","text":"<p>Successfully enacted Treasury track referenda will get funded at the end of the spending period. Treasury funds are directly sent to the beneficiary account at the end of the spend period.</p>"},{"location":"general/glossary/#staking","title":"Staking","text":"<p>The act of bonding tokens by putting them up as \"collateral\" for a chance to produce a valid block (and thus obtain a block reward). Validators and nominators stake their tokens in order to secure the network.</p>"},{"location":"general/glossary/#state-transition-function","title":"State transition function","text":"<p>A function that describes how the state of a blockchain can be transformed. For example, it may describe how tokens can be transferred from one account to another.</p>"},{"location":"general/glossary/#substrate","title":"Substrate","text":"<p>A modular framework for building blockchains. Polkadot is built using Substrate. Chains built with Substrate will be easy to connect as parachains. For developers, see the Substrate GitHub repository.</p>"},{"location":"general/glossary/#system-parachains","title":"System Parachains","text":"<p>Parachains that are part of the Polkadot core protocol. These are allocated a parachain execution core by governance rather than by coretime purchase. Examples of system parachains include Asset Hub, Bridge Hub, Collectives and People Chain.</p>"},{"location":"general/glossary/#tabling","title":"Tabling","text":"<p>In governance, bringing a proposal to a vote via referendum. Note that this is the British meaning of \"tabling\", which is different from the US version, which means \"to postpone\" a measure.</p>"},{"location":"general/glossary/#teleport","title":"Teleport","text":"<p>Send an asset from an account on one chain to an account on a different chain. This occurs by burning an amount on the sending chain and minting an equivalent amount on the destination chain.</p>"},{"location":"general/glossary/#testnet","title":"Testnet","text":"<p>Short for \"test network\": an experimental network where testing and development takes place. Networks are often executed on a testnet before they are deployed to a mainnet.</p>"},{"location":"general/glossary/#tokenization","title":"Tokenization","text":"<p>The process of replacing sensitive data with non-sensitive data.</p>"},{"location":"general/glossary/#tracks","title":"Tracks","text":"<p>Each Origin is associated with a single referendum class and each class is associated with a Track. The Track outlines the lifecycle for the proposal and is independent from other class's tracks. Having independent tracks allows the network to tailor the dynamics of referenda based upon their implied privilege level.</p>"},{"location":"general/glossary/#tranche","title":"Tranche","text":"<p>Validators use a subjective, tick-based system to determine when the approval process should start. A validator starts the tick-based system when a new availability core candidates have been proposed, which can be retrieved via the Runtime API, and increments the tick every 500 milliseconds. Each tick/increment is referred to as a \u201ctranche\u201d, represented as an integer, starting at 0.</p>"},{"location":"general/glossary/#transfer","title":"Transfer","text":"<p>Send an asset from one account to another. This generally refers to transfers that occur only on the same chain.</p>"},{"location":"general/glossary/#transaction","title":"Transaction","text":"<p>An extrinsic that is signed. Transactions are gossiped on the network and incur a transaction fee. Transactions are \"provably true\", unlike inherents. For example, one can prove that Alice wants to send funds to Bob by the fact that she signed a transfer-funds message with her private key.</p>"},{"location":"general/glossary/#validator","title":"Validator","text":"<p>A node that secures the relay chain by staking DOT, validating proofs from collators on parachains and voting on consensus along with other validators.</p>"},{"location":"general/glossary/#vertical-message-passing","title":"Vertical Message Passing","text":"<p>Vertical message passing consists of two separate types of message passing, Downward Message Passing (DMP) and Upward Message Passing (UMP). Downward messages pass from the relay chain to a parachain, although they may also originate from another parachain via HRMP. Upward messages originate from parachains and go up to the relay chain via runtime entry points.</p>"},{"location":"general/glossary/#voting","title":"Voting","text":"<p>The process of stakeholders determining whether or not a referendum should pass. Votes are weighted both by the number of DOT that the stakeholder account controls and the amount of time they are willing to lock their DOT.</p>"},{"location":"general/glossary/#waiting-nomination","title":"Waiting Nomination","text":"<p>The nominator has nominated this validator, but the validator was not elected into the active validator set this era and thus cannot produce blocks for the canonical chain. If the validator does get into the active set in a future era, this may turn into an active or inactive nomination.</p>"},{"location":"general/glossary/#wallet","title":"Wallet","text":"<p>A program that allows one to store private keys and sign transactions for Polkadot or other blockchain networks.</p>"},{"location":"general/glossary/#wasm","title":"Wasm","text":"<p>The abbreviation for WebAssembly.</p>"},{"location":"general/glossary/#watermark","title":"Watermark","text":"<p>In Polkadot's parachain messaging scheme, the watermark is the minimum processed send-height of the receiving parachain. All messages on all channels that are sending to this parachain at or before the watermark are guaranteed to be processed.</p>"},{"location":"general/glossary/#web3-foundation","title":"Web3 Foundation","text":"<p>A Switzerland-based foundation that nurtures and stewards technologies and applications in the fields of decentralized web software protocols, particularly those that utilize modern cryptographic methods to safeguard decentralization, to the benefit and for the stability of the Web3 ecosystem.</p>"},{"location":"general/glossary/#webassembly","title":"WebAssembly","text":"<p>An instruction format for a virtual, stack-based machine. Polkadot Runtime Modules are compiled to WebAssembly. Also known as Wasm.</p>"},{"location":"general/glossary/#weights","title":"Weights","text":"<p>A permission-less system needs to implement a mechanism to measure and limit usage in order to establish an economic incentive structure, to prevent the network overload, and to mitigate DoS vulnerabilities. This mechanism must enforce a limited time-window for block producers to create a block and include limitations on block size, to prevent execution of certain extrinsics which are deemed too expensive and could decelerate the network. This is handled by the weight system, where the cost of the transactions (referred to as extrinsics) are determined before execution. Checkout this section of the Substrate docs covering transaction weights and fees.</p>"},{"location":"general/glossary/#westend","title":"Westend","text":"<p>The testnet is set aside for testing the Polkadot relay chain. Contrary to the Paseo testnet, the Westend testnet is used by the core developers to iterate on protocol-level features like asynchronous backing, etc, that are not relevant for parachain developers.</p>"},{"location":"general/glossary/#witness","title":"Witness","text":"<p>Cryptographic proof statements of data validity.</p>"},{"location":"general/glossary/#whitelist-pallet","title":"Whitelist Pallet","text":"<p>Allows one Origin  to escalate the privilege level of another Origin for a certain operation. In terms of OpenGov, it allows the Fellowship to authorise a new origin (which we will call Whitelisted-Root) to be executed with Root-level privileges.</p>"},{"location":"general/governance-apps/","title":"Polkadot Governance Apps","text":"<p>Community Page</p> <p>This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your Governance app to this page.</p> <ul> <li>Polkassembly</li> <li>SubSquare</li> <li>Delegation Dashboard</li> </ul>"},{"location":"general/governance-apps/#polkassembly","title":"Polkassembly","text":"<p>Polkassembly is a platform specifically designed to foster open, transparent discussions around Polkadot and Kusama governance proposals. By bridging on-chain decisions with off-chain discussions, Polkassembly ensures that the community remains at the heart of the decision-making process.</p> <p>1. Getting Started with Polkassembly</p> <ul> <li>Registration: Begin by registering on Polkassembly. Choose between email/password sign-up or use   web3 enabled wallets.</li> <li>Authentication: To provide maximum security, Polkassembly enables a two-factor authentication   process.</li> <li>Linking Your Polkadot or Kusama Account:<ol> <li>Connect your Polkadot or Kusama account from Subwallet, Talisman, Nova, PolkaGate, Polkadot-JS  for seamless proposal tracking and voting.</li> <li>Polkasafe (for multisigs) - vote and create proposals with Multisigs by logging in with Polkasafe</li> </ol> </li> </ul> <p>2. Navigating the Polkassembly Interface</p> <ul> <li>Dashboard: Provides a snapshot of active proposals, treasury motions, referenda, and public   discussions.</li> <li>User Profile: Customize your profile settings, manage notifications, and view your activity.</li> </ul> <p>3. Proposals, Motions, and Referenda</p> <ul> <li>Viewing Details: Access comprehensive details of each proposal, including current status, voting   tally, and associated discussions.</li> <li>Participating in Discussions: Engage with the community, share insights, ask questions, and contribute to a transparent decision-making process.</li> </ul> <p>4. Delegating on Polkassembly</p> <ul> <li>Understanding Delegation: Delegate your voting power to community members you trust, enhancing the   democratic process.</li> <li>How to Delegate: Navigate to the Delegation section, choose a delegate, specify the amount, and confirm the delegation.</li> </ul> <p>5. Notifications and Alerts</p> <ul> <li>Custom Notifications: Receive real-time updates on topics of interest, proposal status changes,   and more.</li> <li>Setting Alerts: Customize alert preferences to receive notifications tailored to your interests.</li> </ul> <p>6. Frequently Asked Questions (FAQs)</p> <ul> <li>Integration with Polkadot: Polkassembly fetches on-chain data directly from the Polkadot/Substrate node, ensuring real-time accuracy.</li> </ul> <p>Dive into the world of Polkadot governance with Polkassembly and be an active part of the future! For deeper insights or specific tutorials, please refer to the official documentation at https://docs.polkassembly.io.</p>"},{"location":"general/governance-apps/#subsquare","title":"SubSquare","text":"<p>SubSquare is a governance platform well-designed for substrate based chains. It monitors on-chain governance events and provides user interfaces to facilitate various governance workflow. It has supported tens of chains including polkadot, kusama, acala, centrifuge, hydradx, interlay, phala, etc. </p>"},{"location":"general/governance-apps/#delegation-dashboard","title":"Delegation Dashboard","text":"<p>The Polkadot Delegation Dashboard is a web3 application that allows you to delegate your voting power on Polkadot OpenGov.</p> <p>How to get added as a Delegate on the Dashboard?</p> <p>Anyone interested in being listed as a delegate can add their details on the Governance-UI repository.</p> <p>To make OpenGov multi-role delegation easy and intuitive, Delegation Dashboard provides an interactive interface that displays the list of delegates and their details. The video tutorial below walks through the features of the Delegation Dashboard and shows how to perform multi-role delegation.</p> <p>Delegation Dashboard Tutorial</p> <p>For detailed instructions on how to delegate your voting power using dashboard, check this support guide..</p> <p>If you become a nomination pool member or a pool admin, you cannot participate in Governance with the bonded tokens in the pool, as they are held in a system account.</p>"},{"location":"general/grants/","title":"Grants Program","text":"<p>Decentralized Futures Program</p> <p>In addition to the listed grants programs, the Web3 Foundation has launched the Decentralized Futures program to support individuals and teams as they launch new initiatives aimed at growing the Polkadot ecosystem. For details on the status of the program, see the Decentralized Futures Program.</p>"},{"location":"general/grants/#web3-foundation-grants","title":"Web3 Foundation Grants","text":"<p>Web3 Foundation offers grants for open source software development and research around Substrate, Polkadot, Kusama and ink!. Applications and deliveries are tracked transparently on GitHub. Information regarding requirements, the application process, deliveries, etc. can be found on the Grants Program website. For guidance, there is also a list of previously accepted applications and a list of frequently asked questions.</p>"},{"location":"general/grants/#alternative-funding-sources","title":"Alternative Funding Sources","text":"<p>Info</p> <p>Check the alternative funding sources section on the Web3 Foundation Grants website for comprehensive information.</p>"},{"location":"general/grants/#polkadot-treasury","title":"Polkadot Treasury","text":"<p>The Polkadot Treasury is a pot of on-chain funds collected through transaction fees, slashing, staking inefficiencies, etc. The funds held in the treasury can be spent on spending proposals. Both Polkadot and Kusama offer everyone the opportunity to apply for funding via the treasury. See:</p> <ul> <li>Treasury Wiki</li> <li>Polkadot Treasury Guide</li> <li>Kusama Treasury Guide</li> </ul> <p>Kusama Faucet</p> <p>Due to high demand and spamming issues, the Kusama faucet is no longer in operation. The Web3 Foundation has considered new ways to distribute KSM for people who need KSM to build.</p> <p>If you are interested in obtaining KSM for building or research, you can apply through the Treasury or receive a tip for doing something cool in the community.</p>"},{"location":"general/grants/#other-grant-programs","title":"Other Grant Programs","text":"<p>Below is a list of other grant programs in the Polkadot/Substrate ecosystem.</p> <ul> <li>Acala Grants Program</li> <li>Aleph Zero Funding Program</li> <li>Avail Uncharted Grants</li> <li>Darwinia Grants Program</li> <li>Decentralized Futures Program</li> <li>Decentralized JAM</li> <li>Edgeware Grants and Bounties</li> <li>HydraDX Grants and Bounties</li> <li>ink!ubator</li> <li>KodaDot RFPs</li> <li>Moonbeam Grants Program</li> <li>OAK\u2019s Developer Grants</li> <li>peaq Ecosystem Grant Program</li> <li>Pendulum / Amplitude Grant Programs</li> <li>Phala Builders Program</li> <li>Polkadot Assurance Legion</li> <li>Polkadot Pioneers Prize</li> <li>SubQuery Grants Programme</li> </ul>"},{"location":"general/how-to-dyor/","title":"How to Do Your Own Research (DYOR)","text":"<p>Many projects are being built, or intend to build, on both Polkadot and Kusama. However, many claim to do so but have either no such intention, they do not have the resources to pull it through, or they are outright trying to scam people by misusing the Polkadot and Kusama brands.</p> <p>Distinguishing legitimate projects from the dishonest ones is not always an easy task. This guide is meant to help you find out how to do your research better when you come across a project that seems interesting. What it's not meant to do, is label any single project as legitimate or not, or make that decision for you.</p> <p>Furthermore, a legitimate project does not necessarily mean it will also be successful, and this guide is not meant to be viewed as financial or investment advice.</p>"},{"location":"general/how-to-dyor/#powered-by-polkadot-or-polka-prefix-clarification","title":"Powered by Polkadot or Polka prefix clarification","text":"<p>The statement \"Powered by Polkadot\" on many projects' sites is often a cause of confusion. This usually means that the project is building, or intends to build, on the Polkadot ecosystem, using Substrate. But any project can claim that, so the existence of this statement on a project's site infers no information about the project's legitimacy, and it's certainly not a \"seal of approval\" by Web3 Foundation.</p> <p>This also applies for projects with a \"Polka\" prefix in their name. Many projects use that to associate themselves with the ecosystem, some legitimately and others only to piggyback on Polkadot's reputation.</p>"},{"location":"general/how-to-dyor/#hard-metrics-to-look-for-when-you-dyor","title":"Hard metrics to look for when you DYOR","text":""},{"location":"general/how-to-dyor/#association-with-entities-you-trust","title":"Association with Entities You Trust","text":"<p>New projects usually try to increase their credibility by associating themselves with well-known entities. The thinking is simple: \"These entities that have a good reputation trust us, so if you trust them, by association, you should trust us too\". Indeed, association with a trusted entity can be a strong indicator of the legitimacy of a project.</p> <p>For example, if a project had received a Web3 Foundation Grant, this is an indication that the project is indeed building on the Polkadot ecosystem, and if they have delivered all of their milestones, then their code is most likely of reasonable quality.</p> <p>Furthermore, Web3 Foundation is not the only entity in the ecosystem that provides grants. Other reputable teams in the ecosystem that have developed platforms or prospective parachains provide grants for projects to build on or expand their project. These are also indicators that a project is committed to building on the broader Polkadot ecosystem.</p> <p>Receiving funding from reputable VCs and are known to be involved with other reputable Polkadot projects can also be a good indicator. Or participating in the Polkadot Alpha Program.</p> <p>However, claiming such associations and having them is not always the same thing. You always need to verify any claims a project makes, and that is probably the most critical takeaway from this guide.</p> <p>For example, if a project has the Web3 Foundation Grant badge on their site or claims to have received a grant, check to see if they have received one and that it has not been terminated. The complete list of projects that have successfully applied for a grant can be found here, where you can see what each project has delivered and if, perhaps, their grant has been terminated.</p> <p>The same thing goes for VC funding or another grant, or any advertised association for that matter. Check on the corresponding sites to make sure such claims are valid.</p> <p>Also, make sure you understand the scope of the association. Going back to the Web3 grants example, they have a precise scope. They are granted for specific deliverables, and the review team only checks the code and evaluates these deliverables of the particular project. So, having received a Web3 grant provides no information about the general practices of a team, the longevity of the project besides the scope of the grant, or other projects the team might be building, which is why the badge rules clearly state that it should not be displayed on the team's landing page.</p> <p>Similarly, if a project claims to have partnered with a reputable entity, verify its scope and if it is indeed a partnership by searching their site for projects they have partnered with, their press releases, or by contacting them directly. And if you see such claims about Web3 Foundation, you can be sure they're false because Web3 Foundation does not partner with, or endorse, ecosystem projects.</p>"},{"location":"general/how-to-dyor/#open-source","title":"Open Source","text":"<p>An open-source project promotes transparency, builds trust, and potentially ensures project team honesty. Additionally, it makes it very easy to track the project's progress and see how active the team is in developing it.</p> <p>However, that does not mean that any closed source project is not legitimate or the team behind it has something to hide. Many teams choose to keep their code private to protect their intellectual property. And several teams that do so have gotten a General Grant, under which members of the grants review team review their private code.</p> <p>Another thing that an open-source project allows you to see is if they have copied any code from other open sources. This isn't necessarily bad, since no one wants to re-invents the wheel, but copied code should attribute to the source. If it doesn't, this should raise some red flags because the project team tries to feign expertise by passing someone else's code as their own.</p> <p>A forked repo is easy to spot since it points to the original repo, but partially copied code might not be as easy to find. A quick search can provide you with some ways and tools to look for plagiarism.</p> <p>So, a project being closed source is not necessarily a red flag. It just limits the ability to verify the project in that regard, but there are indirect ways as described below. However, a project being open source is undoubtedly a potentially strong indicator of its legitimacy because shady or poor practices seldom stay hidden for long in open source code.</p>"},{"location":"general/how-to-dyor/#active-development","title":"Active Development","text":"<p>If a project team constantly updates their product, it is always a good indication that they are serious and passionate about building. Regularly releasing new features and upgrades, fixing bugs, updating their site and notifying the community of these changes are good earmarks of a legitimate project.</p> <p>Additionally, active development usually also means good development to be used as an indirect indicator for a closed source project.</p> <p>An open-source project allows anyone to monitor the development activity through its code repository directly, such as through GitHub.</p>"},{"location":"general/how-to-dyor/#comprehensive-documentation","title":"Comprehensive Documentation","text":"<p>The existence of comprehensive documentation should be considered mandatory for any serious project. A couple of years ago, this meant a whitepaper, but lately, we have seen a shift to other forms of documentation, like wiki pages describing the various aspects.</p> <p>No matter the form of the documentation, its existence and completion is necessary, and the more detailed it is, the better. This is where the details of the project or parts of the project are explained in full for prospective investors or users.</p> <p>The documentation will also give you an idea of the technical expertise of the team. If the team analyses their technology and technical aspects, this is a potential indication of technical prowess. On the other hand, if the team focuses only on tokenomics or analyses their project only in broad, vague terms, this is potentially an indication that there is not a clear path to their goals.</p> <p>If you are looking for an example of good documentation, look no further than our own wiki. Of course, you should not expect to find such extensive documentation on newly launched projects. Our wiki, after all, covers a whole ecosystem and was populated over the course of multiple years. Updates are also constantly being pushed out and edits are consistently being made. Nevertheless, this wiki provides a good example of the documentation a legitimate project should provide.</p>"},{"location":"general/how-to-dyor/#reputable-team","title":"Reputable Team","text":"<p>Some teams display their team members prominently on their site, along with their social media profiles (usually LinkedIn) and GitHub accounts. This gives prospective users and investors the ability to verify the team's credentials, track records, and expertise.</p> <p>But the keyword here is verify! Do not take what you see on the project's team at face value. Look them up and verify their track record. Do a Google search for the team members mentioned. If it comes up empty, or the only results are regarding the project you are researching, it is an indication that their team members are potentially fake. Their photos on their site, if there are any, may also be stock photos, or in other words, also fake. These are usually easily recognisable, but here is a guide on how to do a reverse image search, if you want to be thorough.</p> <p>In some other cases, some developers prefer to maintain their anonymity, using pseudonyms, or the team members are not mentioned at all. This is not necessarily a bad thing. Perhaps the team is a strong proponent of privacy, or they want their work to speak for itself. Still, you should try and find out who is behind the project and what they are doing. For developers, their GitHub activity may be a stronger indicator of honesty. Other team members might be heavily engaged in their community, providing guidance and answers, which is always a good sign.</p> <p>But if the team are ghosts that do not show up anywhere and only engage with the community through proxies, this can be considered a red flag and extra precaution should be taken.</p> <p>Besides their community, projects that are serious about building on Polkadot usually engage with the community. They are active in the various Polkadot and Kusama channels, and some of them are Polkadot Ambassadors, or generally prominent members of the ecosystem.</p>"},{"location":"general/how-to-dyor/#clear-integration","title":"Clear Integration","text":"<p>There are many ways for a project to build on Polkadot. Some of the most notable Polkadot projects are parachains on Kusama or gearing up to become one. Parachains can purchase coretime and access a relay chain's core.</p> <p>Verifying which projects are currently parachains on Kusama can be quickly done by visiting the parachains page on polkadot.js.org/apps.</p> <p>But not all projects that build a chain using Substrate aim to become a parachain. Some use it simply because of its infrastructure to build their customised chain, without any plans to connect to the relay chain. And other projects may aim to become a parachain only on Kusama or directly on Polkadot.</p> <p>However, building a potential parachain is not the only way to build on Polkadot and expand its ecosystem. A project might aim to build a DeFi platform on a parachain, launch a stablecoin or other token on the Asset Hub, build a decentralized exchange, or any other dApp that one might think of, without ever touching the relay chain.</p> <p>But in all of those cases, their plans to build on Polkadot whatever they may be, should be clearly stated on their site and in their documentation. Most importantly, you should look for an explanation of how they plan to achieve that integration. A roadmap that places the integration at some point in the future means close to nothing without clearly stating the steps to get there. These plans should be evaluated in tandem with your research on the technical expertise of the team.</p> <p>This is especially true for projects that are already running on another network, like on Ethereum or Binance Smart Chain, and have issued tokens there. Many projects do that either to raise funds and test their infrastructure or because they aim to build a \"multi-chain\" solution or both. But because those projects are not currently built on Substrate, the existence of a clear and robust integration plan with the relay chain should be essential in your research to ensure that they will indeed build on it one day.</p>"},{"location":"general/how-to-dyor/#soft-metrics","title":"Soft metrics","text":"<p>The items above are what you should look at first when evaluating a project and should carry most of the weight in your decision. The reason is that they are hard to fake or manipulate, assuming that you are able to verify the information found. Hence we called them \"hard\" metrics.</p> <p>But there are other things to look for that might point to a project's legitimacy but can be more easily manipulated, so they should not affect your decision heavily. These are called \"soft\" metrics.</p>"},{"location":"general/how-to-dyor/#site-quality","title":"Site Quality","text":"<p>The quality of a project's site could sometimes provide insights into the legitimacy of a project. A poorly constructed site, may:</p> <ul> <li>have typos, grammatical errors, or poor styling</li> <li>be a template without any serious effort to improve or change it</li> <li>hold little information about the project, without links to their GitHub or other resources</li> <li>not \"feel\" professional</li> </ul> <p>These are all potential indications that the team is not serious about this project.</p> <p>But that does not mean that all well-designed sites are also solid projects. This is a soft metric, after all. Many projects that do not have any plans to build anything substantial still have excellent, or even beautiful-looking, sites. They put many resources into how they present themselves visually to mislead. So, an excellent site does not necessarily indicate a legitimate project, a poor site might indicate an illegitimate one, but the site quality alone usually is not enough to reach a conclusion. None of these metrics are sufficient alone; you need to look into all of them to make an educated decision.</p>"},{"location":"general/how-to-dyor/#social-media-presence","title":"Social Media Presence","text":"<p>Having a vibrant community is a good indication of a legitimate project. A team that engages with their community, gives updates, answers questions, holds AMAs, and posts articles, is a team that is interested in keeping their community members updated and informed.</p> <p>Though at the same time, social media presence and engagement can be easily faked and manipulated. Creating a Telegram group or a Discord server and filling it with thousands of bots is very easy. Although bot users need to be identified on Discord according to its terms, scammers have little regard for terms and conditions.</p> <p>A team that tweets five times a day or posts a Medium article every other day may not necessarily be the building something substantial.</p> <p>So, make sure that you verify that their social media presence and engagement is genuine. Join their channels, ask questions and see first-hand what the community and the admins look like. If you are seeing a lot of users posting very brief comments, like \"Good project\", \"To the moon\", \"Thank you\" etc, without really engaging, remain skeptical and maintain a critical eye, as these are probably bots. Additionally, verify any information shared by the team on social media and also verify the comments of users.</p>"},{"location":"general/how-to-dyor/#media-presence","title":"Media Presence","text":"<p>Related to social media presence is media presence: third-party articles, mentions in YouTube videos, and general promotions of the project.</p> <p>When it comes to articles, the first thing to check is if the article is genuine coverage or a paid press release, especially when a project displays this coverage prominently on their page. Or if the author has any vested interest in promoting the project. You can check their previous articles to see if they systematically \"shill\" this project or other projects in general.</p> <p>This especially applies for YouTubers and influencers in general, who may be dishonest. Many of them do this for a living or as a way to \"pump\" projects they have invested in. Finding good influencers that provide as objective info as possible usually involves its own separate research.</p> <p>That is not to say that media exposure is terrible. It is probably the most abundant source of information outside the project itself, but at the same time, it requires extensive cross-checking and verification of information.</p>"},{"location":"general/how-to-dyor/#email-communication","title":"Email Communication","text":"<p>Nowadays, many projects use Telegram, Discord, or similar apps for community engagement, as well as the sole channel for communication, updates, and support. But having an email registered with their domain, besides providing another channel of communication, can be considered an additional credibility criterion.</p> <p>Furthermore, receiving emails from the project's domain makes it easy to verify that the communication is authentic (but look out for spoofed emails!). On the other hand, communicating through personal emails or using a public email provider, like Google or Yahoo, might indicate a less serious team or one that is spread too thin.</p>"},{"location":"general/how-to-dyor/#additional-material","title":"Additional material","text":"<p>Fact-checking is a skill necessary not only for DYOR but also for filtering out the plethora of information that we come across on the internet on a daily basis. If you are interested in learning more about fact-checking and claim verification, have a look at the following material.</p> <ol> <li>A very nice YouTube series on the art of fact-checking that covers a lot of ground can be found    here.</li> <li>Another great resource on fact-checking, for those who prefer to read, can be found    here.</li> <li>Wikipedia article on fact-checking</li> </ol> <p>Finally, you should also check our complementary guide on how to identify scams, which explains how to identify outright scams and avoid them, as well as how to protect your sensitive information.</p>"},{"location":"general/how-to-dyor/#one-last-piece-of-advice","title":"One last piece of advice","text":"<p>Once you have read through this material and have done your research and have identified a project as legitimate, it is also imperative that you understand what the project does and what novelty it aims to bring to the ecosystem.</p> <p>This does not fall under fact-checking and verifying claims, but it is important to mention: fully understanding what something does and its prospective impact is an integral part of making an informed decision, so do not overlook it.</p>"},{"location":"general/learn-polkadot-opengov-treasury/","title":"Treasury","text":"<p>The Treasury is a pot of funds collected through a portion of block production rewards, transaction fees, slashing, and staking inefficiencies. Treasury funds are held in a system account that cannot be controlled by any external account; only the system internal logic can access it.</p> <p>Creating a Treasury Proposal on Polkadot OpenGov</p> <p>If you would like to create a treasury proposal on Polkadot OpenGov, follow the instructions outlined on this how-to guide.</p>"},{"location":"general/learn-polkadot-opengov-treasury/#treasury-inflow-and-outflow","title":"Treasury Inflow and Outflow","text":"<p>Tokens that are deposited into the Treasury (i.e. the inflow) is determined by the following mechanisms:</p> <ul> <li>Transaction fees: 80% of the transaction fees of every submitted extrinsic is diverted to the   Treasury, while 20% is given to the block producers.</li> <li>Inflation: 15% of DOT annual inflation is directed to the Treasury.</li> <li>Slashes: whenever validators and nominators are slashed, a share of the slashed tokens are diverted to Treasury. They are typically rare and unpredictable events.</li> <li>Transfers: everyone can send funds to the Treasury directly. This is a rare event and   typically due to grantees reimbursing some of the amount they got allocated for various reasons.</li> </ul> <p>The outflow is determined by the following mechanisms:</p> <ul> <li>Burned tokens: at the end of each spend period,   a fraction of the available funds are   burned.</li> <li>Treasury proposals &amp; Bounties: they make up the largest share of outflow tokens to the   community and need to be approved by governance. Then, payouts occur at the end of a   spend period.</li> <li>Tips: smaller payouts directly to grantees that can happen within a   spend period.</li> </ul> <p>Spend Period Schedule</p> <p>On Polkadot-JS UI, navigate to Governance &gt; Treasury to view the status of current spend period.</p> <p></p>"},{"location":"general/learn-polkadot-opengov-treasury/#treasury-tracks","title":"Treasury Tracks","text":"<p>OpenGov allows for managing funds through six tracks, each with its own origin and track parameters.</p> <ul> <li>Treasurer</li> <li>Big Spender</li> <li>Medium Spender</li> <li>Small Spender</li> <li>Big Tipper</li> <li>Small Tipper</li> </ul>"},{"location":"general/learn-polkadot-opengov-treasury/#submit-treasury-proposal-via-polkassembly","title":"Submit Treasury Proposal via Polkassembly","text":"<p>Access to Treasury funds requires successful enactment of referendum in the respective treasury track on-chain. Learn how to submit a treasury proposal for referendum using Polkassembly.</p> <p>Go to Polkassembly and click on the FAB button in the bottom right corner. Then,</p> <ul> <li>Click on \"Create Treasury Proposal\" and choose an address for the proposer</li> <li> <p>After choosing an address, you will enter a three-stage guideline:</p> </li> <li> <p>Write a proposal: you can add a detailed description for the proposal, which will be stored on     Polkassembly. Alternatively, you can link an existing discussion post.</p> </li> </ul> <p></p> <ul> <li>Create a preimage: an existing preimage can be linked, or a new one can be created. To create a     preimage, add the beneficiary address and the token amount. The track will be auto-selected and     the user can proceed with the creation of a preimage.</li> </ul> <p></p> <ul> <li>Create a proposal: final confirmation about the proposal creation. The description of the     proposal and the preimage are automatically linked to the proposal.</li> </ul>"},{"location":"general/learn-polkadot-opengov-treasury/#sub-treasuries","title":"Sub-treasuries","text":"<p>The treasury currently operates on a single account on-chain. The above tracks manage the outflow of the treasury on the network. With sub-treasuries, having treasury accounts that correspond to each collective is also possible.</p> <p>Rather than have many referenda through OpenGov, the treasury can allocate funds to each sub-treasury (through governance), from which each respective collective can spend funds (depending on their specific rule set).</p> <p>New treasuries could be added to respective system chains through governance by adding more instances of this pallet.</p>"},{"location":"general/learn-polkadot-opengov-treasury/#multi-asset-treasury-support","title":"Multi-Asset Treasury Support","text":"<p>The treasuries can support multiple asset types and thus can spend assets other than DOT (or KSM on Kusama) held within the treasury, and their transfers and interactions across the chains facilitated by cross-consensus messaging. These assets have a few requirements:</p> <ol> <li>The asset is listed on the AssetHub system parachain.</li> <li>The asset is active and has sufficient liquidity to be utilized for payouts.</li> <li>The asset has a set conversion rate, as per OpenGov referenda on the Treasurer track (set via the    asset rate pallet). This conversion rate defines a fixed-point representation for converting from    that asset to the native asset (DOT or KSM).</li> <li>The asset must be approved and onboarded via OpenGov to become spendable via the treasury as a    valid spend method.</li> </ol> <p>For example, see how USDT became approved as an asset on AssetHub, which can be used in the treasury.</p>"},{"location":"general/learn-polkadot-opengov-treasury/#bounties","title":"Bounties","text":""},{"location":"general/learn-polkadot-opengov-treasury/#parent-bounties","title":"Parent Bounties","text":"<p>Getting treasury funding through OpenGov, depending on which treasury track you submit your referendum, can be a long and uncertain process. This is not always a suitable option, for example, for event organizers who need to pay costs upfront or close to the event's date. Bounties solve this problem by procuring access to treasury funds in a single shot and using them to fund multiple events later on through child bounties. This is why bounties are also called parent bounties.</p> <p>Parent bounty proposals aim to reserve a portion of treasury funds once, which will be used later. They save proponents the time needed to create and obtain approval for several OpenGov referenda. Bounties are managed by curators, where the curator is usually a multi-signature account. Bounties can access a large amount of funds, so managing those funds with a multisig is a good practice to enhance security. Essentially, curators are multisig addresses with agency over a portion of the treasury to promote events, fix a bug or vulnerability, develop a strategy, or monitor a set of tasks related to a specific topic, all for the benefit of the ecosystem.</p> <p>A proposer can submit a bounty proposal to OpenGov, with a curator to be defined later, whose background and expertise is such that they can determine when the task is complete.</p> <p>When submitting the value of the bounty, the proposer can specify a fee that will be paid to curators willing to invest their time and expertise in the task; this amount will be included in the total value of the bounty. In this sense, the curator's fee can be defined as the difference between the amounts paid to child bounty awardees and the total value of the bounty.</p> <p>Curators are selected through OpenGov referendum after the bounty proposal passes; and they need to pay an upfront deposit to take the position. This deposit can be used to punish curators if they act maliciously. However, if they are successful in managing the bounty to completion, they will receive their deposit back, and part of the bounty funding as a payment for their efforts.</p> <p>Curators are expected to have a decent track record in addressing the issues the bounty wants to solve. They should be very knowledgeable on the topics covered by the bounty and have proven project management skills or experience. These recommendations help ensure an effective use of the bounty mechanism. A Bounty is a reward for a specified body of work or set of objectives that needs to be executed for a predefined treasury amount designated to be paid out. The responsibility of assigning a payout address once the specified set of objectives is completed is delegated to the curator.</p> <p>The bounty has a predetermined duration, with possible extension(s) to be requested by the curator. To maintain flexibility during the tasks\u2019 curation, the curator will also be able to create child bounties for more granularity in the allocation of funds and as part of a nested iteration of the bounty mechanism.</p>"},{"location":"general/learn-polkadot-opengov-treasury/#child-bounties","title":"Child Bounties","text":"<p>Child bounties are spawned from parent bounties. Child bounties are used to access funds directly from the parent bounty without going through an OpenGov referendum.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about bounties and treasury.</p>"},{"location":"general/ledger/","title":"Using the Polkadot Ledger Apps","text":"<p>     If you need help using Ledger, see            this support article.          If the problem persists, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The Polkadot Ledger application is compatible with the Ledger Nano S, Nano X, and Stax devices. Ledger devices are hardware wallets that keep your secret key secured on a physical device that does not expose it to your computer or the internet. The private keys will not be exposed even if you connect your Ledger device via USB to your computer.</p> <p>Ledger devices are hierarchical deterministic wallets (HD wallets), where:</p> <ul> <li>Deterministic means that only one seed phrase generates all the accounts for different   blockchain networks.</li> <li>Hierarchical means that the accounts are generated in a tree-like structure for different   purposes.</li> </ul>"},{"location":"general/ledger/#ledger-devices-compatibility","title":"Ledger Devices Compatibility","text":"Device Platform Battery Apps Security Status Nano S PC<sup>1</sup> No All (lite, XL<sup>2</sup>) Certified Secure Element (CC EAL5+) Discontinued Nano S Plus PC No All (lite, XL, plus) Certified Secure Element (CC EAL6+) In Production Nano X PC, Mobile via bluetooth Yes All (lite, XL, plus) Certified Secure Element (CC EAL5+) In Production Stax PC, Mobile via bluetooth Yes Dedicated Certified Secure Element (CC EAL6+) In Production <p><sup>1</sup> Because of required WebUSB support, Ledger wallets currently only work on Chromium-based browsers like Google Chrome.</p> <p><sup>2</sup> The lite version of the Polkadot Ledger App that you can install by default in the Ledger Nano S has limited functionality. The Ledger Nano S is no longer produced and has limited memory that is just right to accommodate the XL version of the Polkadot Ledger App, which gives the user more functionalities.</p> <p>If you do use a Nano S with the XL version, you will not be able to:</p> <ul> <li>Install any other Ledger application on your device</li> <li>Add Polkadot accounts to the Ledger Live App.</li> </ul> <p>But you will be able to add them to wallets and extensions that support Ledger devices.</p> <p>More information on Ledger device comparisons here.</p>"},{"location":"general/ledger/#requirements","title":"Requirements","text":"<p>Here is a list of what you will need before using Polkadot with Ledger:</p> <ul> <li>A Ledger Nano X, Stax, or Nano S plus (recommended for the Polkadot Ledger App space requirements   and functionalities).</li> <li>Ledger Live installed and up-to-date.</li> <li>The latest firmware of the Polkadot Ledger App installed (always check for updates in Ledger Live   under the \"Manager\" tab; you will need to allow access with your nano).</li> <li>A Chromium-based web browser if you use a browser extension.</li> </ul> <p>Ledger devices are tiny computers. They have an operating system (or firmware), and on top of it, you can install applications. Every blockchain needs to develop its own application to use Ledger devices. Make sure you have your Ledger devices with firmware and apps up-to-date.</p>"},{"location":"general/ledger/#polkadot-ledger-apps","title":"Polkadot Ledger Apps","text":"<p>Ledger devices can be equipped with applications that are blockchain-specific. Third parties usually develop such applications, enabling users to transact securely on the blockchain network. Polkadot Ledger apps are developed by Zondax and are available here. The Polkadot Ledger application allows you to manage Polkadot, Kusama and their parachains native tokens.</p> <p>Ledger apps may not support all the transactions</p> <p>Check the Ledger Polkadot App specification for the list of transactions supported. Some transactions are supported only on a specific app version, and others are not supported by any version. For instance, joining a nomination pool is only possible with the XL version but not on the lite version.</p>"},{"location":"general/ledger/#polkadot-migration-app","title":"Polkadot Migration App","text":"<p>For Migration Only</p> <p>This app is only meant for performing the migration to the Polkadot Generic App; do not use it frequently. </p> <p>After you migrate your assets, delete the Migration app and use the Polkadot Generic App.</p> <p>The Polkadot Migration app is for users having old Ledger accounts not on the Polkadot relay chain and Polkadot System Chains. Old Ledger accounts are accounts that have been created using the old Kusama Ledger app and any parachain Ledger apps (for both Kusama and Polkadot) except for Polkadot System Chains.</p> <p>Suppose you have accounts on any Polkadot parachain, Kusama relay chain, and Kusama parachains. In that case, you will need the Polkadot Migration app to move fungible and non-fungible assets (NFT), identities, etc., from old Ledger accounts to a new one or an existing one created with the Polkadot Ledger app.</p>"},{"location":"general/ledger/#polkadot-generic-app","title":"Polkadot (Generic) App","text":"<p>Ledger Generic Support</p> <p>See this page to see which chains support the Ledger Generic App.</p> <p>The Polkadot Ledger Generic App will allow you to use your Ledger device on the relay chain and parachains without being affected by runtime upgrades. The goal is to provide a single application for the entire Polkadot ecosystem without compromising security. This new app will also count with Clear Signing, allowing you to see what you sign on a trusted display. This way, unintentionally signing rogue transactions can be avoided. See this page to understand the importance of verifying transactions before signing them.</p> <p>The Polkadot Ledger Generic app brings the following benefits:</p> <ul> <li>Innovation Acceleration: Enabling teams to innovate and develop new features for relay chains,   parachains, and current/future users.</li> <li>Network Adoption: Facilitating a smoother and more user-friendly adoption of the Polkadot   ecosystem.</li> <li>Innovation without compromising security: The new Polkadot app comes with the highest security   standards so that users can keep their assets safe.</li> <li>Development Efficiency: The app helps developing teams save costs by having and maintaining their   app.</li> </ul> <p>The Polkadot Ledger Generic app will be supported by Ledger Live, Nova Wallet, Talisman, Subwallet, and PolkaGate.</p> <p>For more information about the Polkadot Generic App, see the Ledger FAQ, and Zondax beryx page.</p>"},{"location":"general/ledger/#migration-process","title":"Migration Process","text":"<p>The migration process is not meant for Polkadot relay chain and System Chains users. Those users can install the Polkadot app and operate it as usual. For users of Kusama relay chain, Kusama System Chains and parachains, and Polkadot parachains, see the procedure below:</p> <ul> <li>Install Polkadot Migration and Polkadot App.</li> <li>Use a browser extension or mobile wallet that supports the new apps. No application will   automatically migrate your assets. You need to manually migrate your assets,   identities, staking, etc., to the   account controlled by the Polkadot app and sign in with the Migration app (some extensions and   wallets UI will prompt which app you need to use to sign in depending on the chain you are in).</li> <li>When the migration process is finished, you can delete the Migration app, and everything will be   accessible using the Polkadot Generic app.</li> </ul> <p>Staking and Identities</p> <p>The migration process will also include removing identities from your old account and resetting them to the new one. You will also need to unstake, wait for the unbonding period, transfer the funds to the new account, and stake again.</p>"},{"location":"general/ledger/#using-ledger-live","title":"Using Ledger Live","text":"<p>See this support article to learn how to use Polkadot with ledger live.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about Ledger.</p>"},{"location":"general/metadata/","title":"Metadata Explorer","text":"<p>import Metadata from \"./../../components/Metadata\";</p> <p>The <code>Metadata Explorer</code> tool helps visualize the metadata of various parachains by retrieving the latest data directly from the chain using the polkadot-js api. The dropdown below allows you to update the chain selection to visualize. You can search all sub-categories using the provided search field. The information is categorized by the chains <code>Pallets</code>, <code>RPC</code> and <code>Runtime</code> information.</p> <p>Info</p> <p>You can enter custom RPC endpoints for Polkadot SDK based chains and explore their metadata using Parity Tech Subxt Explorer.</p>"},{"location":"general/multisig-apps/","title":"Polkadot Multisig Apps","text":"<p>Community Page</p> <p>This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your Multisig app to this page.</p> <p>List of Multisig apps in Polkadot Ecosystem</p> <ul> <li>Mimir</li> <li>Multix by Chainsafe</li> <li>Nova Spektr</li> <li>Polkadot Multisig by Signet</li> <li>Signet</li> <li>Polkasafe</li> </ul>"},{"location":"general/multisig-apps/#mimir","title":"Mimir","text":"<p>Quick Link: Demo | Website | Twitter | Telegram | Github</p> <ul> <li>Support for Various Account Types: Mimir supports a range of account types including Flexible   Multisig, Static Multisig, Nested Multisig, and Extension Wallets.</li> <li>Transaction Tracking: Offers real-time synchronization of transactions across different   account levels.</li> <li>Third-Party Application Integration: Users can access third-party applications with their   multisig identities. Mimir currently supports integration with applications like Polkadot-JS and   is planning to expand to others.</li> <li>User-Friendly Interface: Designed for ease of use, making complex multisig operations more   accessible.</li> </ul>"},{"location":"general/multisig-apps/#multix-by-chainsafe","title":"Multix by Chainsafe","text":"<p>Walk-Through Video Tutorial</p> <p>See this video tutorial and this article for more information about using Multix for multisig accounts.</p> <p>The Multix tool is an easy-to-use interface to manage complex multisigs. The tool is part of the open-source Polkadot/Kusama Tech Stack. Besides being user-friendly, Multix provides several benefits:</p> <ul> <li>When one person creates the multisig account, all the signatories see the multisig account on   their interface.</li> <li>There is no need to pass around the call data to confirm a transaction. Such information is   retrieved from the chain and displayed to the users.</li> <li>Thanks to the power of pure proxies, adding and removing signatories or adjusting the threshold is now possible without creating new multisigs and Multix provides an intuitive interface to work with pure proxies.</li> </ul> <p>The pure proxy setup used by MultiX can be seen on the pure proxy page.</p>"},{"location":"general/multisig-apps/#nova-spektr","title":"Nova Spektr","text":"<p>Nova Spektr is your all-in-one Polkadot Wallet, engineered with enterprise-grade capabilities such as multisigs, proxy accounts, hardware wallets, light clients, and much more. Nova Spektr is designed to meet the requirements of enterprises, power users, and individual users alike \u2013 funded by the Polkadot Treasury</p> <ul> <li>Multichain Wallet \u2013 Nova Spektr supports 80+ Polkadot ecosystem networks, and hundreds of tokens   consolidating them all under a single interface!</li> <li>Multisigs \u2013 Experience superior security with truly multi-chain Multisig Wallets in Nova Spektr!</li> <li>Proxy Discovery \u2013 Discover all your Proxy accounts automatically when importing your wallet into   Nova Spektr!</li> <li>Collaborative Asset Management \u2013 Manage your assets in a simple, secure, and collaborative manner,   requiring a predefined level of consensus to be reached for each transaction\u2019s authorization.</li> <li>Hardware Wallet Support \u2013 Safeguard your assets even further by pairing your hardware wallet with   Nova Spektr!</li> <li>Light Clients \u2013 Unleash an unstoppable, fast, and trustless working environment with Nova Spektr   by utilizing locally hosted blockchain nodes to manage your digital assets in the Polkadot   ecosystem!</li> <li>Data Verification \u2013 Benefit from Polkadot and Kusama Light Clients to cryptographically verify   data from public blockchain nodes!</li> <li>Open Source &amp; Trustless \u2013 Your data remains yours \u2014 Nova Spektr never stores or tracks user data!</li> </ul>"},{"location":"general/multisig-apps/#polkadot-multisig-by-signet","title":"Polkadot Multisig by Signet","text":"<p>Polkadot Multisig by Signet is user-friendly software that helps teams and businesses use multisigs in the Polkadot ecosystem. Multisigs are generally used by organizations to hold treasury assets, pay employees or service providers, receive grants or manage an organization's on-chain identity.</p> <p>Polkadot Multisig is designed to be usable by a non-technical business user and enables a user to be productive and understand multisig transactions. Further information is available on Polkadot Multisig guide.</p>"},{"location":"general/multisig-apps/#signet","title":"Signet","text":"<p>Talisman Signet supports multisig ops and enterprise workflow for onchain organisations. Enterprise features and self-hosted options are available. Signet is proprietary, where as Polkadot Multisig by Signet is free.</p>"},{"location":"general/multisig-apps/#polkasafe","title":"Polkasafe","text":"<p>Polkasafe - Your gateway to the Ultimate MultiSig experience on Polkadot.</p> <p>Gone are the days of cumbersome MultiSig transactions. PolkaSafe redefines the way you interact with the Polkadot Blockchain, making MultiSig operations not just safer but also incredibly user-friendly.</p> <ul> <li>Seamless MultiSig Transactions: With PolkaSafe, initiating, approving, and executing MultiSig   transactions is a breeze. Whether you're managing funds, delegating responsibilities, or simply   securing your assets, the platform's intuitive design ensures every step is straightforward.</li> <li>Collaborative Asset Management: Engage in collective decision-making with stakeholders, team   members, or partners. PolkaSafe's collaborative tools make it easy to propose, discuss, and   finalize MultiSig transactions, ensuring transparency and consensus. Extrinsic Management: Beyond   standard transactions, PolkaSafe simplifies extrinsics \u2013 specialized instructions or functions on   the Polkadot Blockchain.</li> <li>Whether you're interacting with smart contracts, parachains, or other advanced features,   PolkaSafe's MultiSig capabilities ensure every extrinsic is secure and efficient.</li> <li>User-Centric Design: Every feature, from initiating a transaction to diving deep into extrinsics,   is designed for clarity and ease.</li> </ul>"},{"location":"general/nft-projects/","title":"NFT projects on Polkadot and Kusama","text":"<p>Community Page</p> <p>This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your NFT app to this page.</p>"},{"location":"general/nft-projects/#list-of-nft-projects","title":"List of NFT Projects","text":"<ul> <li>List of NFT Projects</li> <li>Astar</li> <li>Basilisk</li> <li>KodaDot<ol> <li>The Team Behind KodaDot</li> <li>Ecosystem Tools by KodaDot</li> </ol> </li> <li>Moonbeam</li> <li>RMRK<ol> <li>NFT Legos</li> <li>NFT from Kanaria</li> </ol> </li> <li>Asset Hub</li> <li>Unique Network</li> </ul>"},{"location":"general/nft-projects/#astar","title":"Astar","text":"<p>Astar Network and its sister network Shiden Network are the smart contract infrastructure in the Polkadot Ecosystem. Astar Ecosystem (\"Astar\") supports NFTs developed with EVM smart contracts and WASM smart contracts.</p> <p>Astar has all toolings available that every EVM NFT developer knows. The availability of those toolings makes the onboarding to Astar networks very attractive to any developer looking to explore the Polkadot Ecosystem. Astar has an active community of artists and NFT enthusiasts. Besides supporting all EVM toolings, Astar also bootstrapped the WASM smart contract environment for NFT developers writing smart contracts with ink! based on PSP34 (Polkadot Standards Proposals).</p> <p>The main advantage of having a multi-virtual machine environment for NFT developers is that it will give more possibilities to the builders for the use case they are developing. With the support of WASM smart contracts, developers can develop solutions like RMRK with smart contracts.</p>"},{"location":"general/nft-projects/#basilisk","title":"Basilisk","text":"<p>Basilisk is a Kusama parachain that provides liquidity for the ecosystem. It also has a full-featured NFT platform based on the Uniques pallet. One of the key features of Basilisk is that it allows minting NFTs with a royalty fee. This royalty fee is distributed to the original creator of the NFT via the runtime pallet. Additionally Basilisk offers a feature that allows creating a buy order for a specific NFT.</p> <p>These NFTs can be viewed and interacted instantly on KodaDot.</p> <p></p>"},{"location":"general/nft-projects/#kodadot","title":"KodaDot","text":"<p>KodaDot is an open-source NFT marketplace that operates on the Dotsama (Kusama/Polkadot) network, striving to aggregate various NFT standards (Kusama, RMRK, Asset Hub, Basilisk, etc.) in the Dotsama ecosystem, enhancing user experience by abstracting these standards.</p> <p>KodaDot's strength lies in its commitment to open-source collaboration. It has transformed into a collaborative hub where creators, developers, and community members work collectively for decision making, amassing an extensive network of over 90 open-source contributors. This robust collaboration has earned KodaDot the number one rank as a dapp in the Polkadot ecosystem on Github.</p> <p>See below a video tutorial about how to mint your NFT on the Polkadot Asset Hub using KodaDot.</p> <p>KodaDot Tutorial on Minting NFTs</p> <p>For more information about minting using KodaDot see this step-by-step tutorial.</p>"},{"location":"general/nft-projects/#the-team-behind-kodadot","title":"The Team Behind KodaDot","text":"<p>KodaDot began as the first unofficial explorer for RMRKv0.0.1 contributing to RMRK protocol. It later received Kusama Treasury funding, which propelled the team to create the best end-user experience on the Asset hub.</p> <p>In the summer of 2022, KodaDot won the first prize at the Polkadot North American event for implementing MoonBeam and MoonRiver NFT EVM smart contracts and enabling read-only access to existing components for seamless end-user interaction.</p> <p>The team successfully launched with Basilisk NFT Marketplace pallet in Fall 2022, where an increasing number of artist collections are emerging, providing artists the opportunity to receive offers on unlisted NFTs and earn on-chain royalties.</p> <p>KodaDot's upcoming integrations are based on PSP-34, leveraging smart contracts written with ink!.</p>"},{"location":"general/nft-projects/#ecosystem-tools-by-kodadot","title":"Ecosystem Tools by KodaDot","text":"<p>KodaDot has enriched the Polkadot ecosystem by offering a comprehensive API interface for builders, based on the SQD indexer. This platform also presents searchable items and collections, translating on-chain transactions into deep insights about collection ownership dynamics for end-users. For more info about KodaDot check out link.</p>"},{"location":"general/nft-projects/#moonbeam","title":"Moonbeam","text":"<p>Moonbeam and its Kusama counterpart Moonriver are full EVM deployments with Ethereum RPC endpoints.</p> <p>This means that the entire toolkit offered to other EVM chains (stacks like Hardhat, Remix, Truffle, Metamask, etc.) are available to Moonriver / Moonbeam users and developers, giving it a noticeable head start in attracting existing userbases.</p> <p>Several dozen high profile teams are launching their products (or re-launching) on Moonriver / Moonbeam, however, it is essential to note that Moonbeam is an EVM chain and will therefore suffer from the same limitations as any other EVM chain in regards to customization and feature-richness of NFTs.</p> <p>A notable advantage, however, is that Moonriver / Moonbeam is still a Substrate chain, meaning integration of custom pallets into the runtime is still possible, making NFT specific optimizations at the chain runtime level a reliable way to keep EVM compatibility of tools while at the same time optimizing storage and interactions for rich NFTs.</p>"},{"location":"general/nft-projects/#rmrk","title":"RMRK","text":"<p>RMRK is a set of NFT 2.0 standards developed in three distinct code flavors:</p> <ol> <li>\"Colored coins\" approach, as on Bitcoin, originally    developed as a \"hack\" on the Kusama chain. This is now deprecated, and it is recommended    implementers use any of the other options.</li> <li>Solidity contracts, compatible with any EVM blockchain in and outside the Polkadot ecosystem.    Documented here</li> <li>Rust code (Substrate pallets), compatible with any Substrate chain. Code is available    here.</li> </ol> <p>Additionally, two more flavors are in development:</p> <ol> <li>Astar are developing the ink! version of RMRK:    code here.</li> <li>Gear Technologies are developing the Gear implementation:    code and docs here.</li> </ol> <p>The RMRK NFT 2.0 standards are a set of \"NFT legos\", primitives that, when put together, allow a builder to compose an NFT system of arbitrary complexity without smart contracts.</p>"},{"location":"general/nft-projects/#nft-legos","title":"NFT Legos","text":"<ol> <li>NFTs can own other NFTs, NFTs can equip other NFTs for visual change</li> <li>NFTs can have multiple resources (different outputs based on context and resource priority)</li> <li>NFTs can have on-chain emotes (reactions) for price discovery and social mechanics</li> <li>NFTs have conditional rendering (e.g. show Mona Lisa as blushing if she got 50 kissy \ud83d\ude18 emoji)</li> <li>NFTs can be governed by the community via fungible shareholder-tokens (fractionalization of NFTs)</li> </ol>"},{"location":"general/nft-projects/#nft-from-kanaria","title":"NFT from Kanaria","text":"<p>Multi-resource NFTs</p> <p>A multi-resource NFT (gif of statue, and SVG-composable dynamic NFT in one) that can also equip other NFTs from within its \"inventory\".</p> <p>Two marketplaces for RMRK-based NFTs exist with hundreds of projects already launched:</p> <ul> <li>Singular, the official marketplace</li> </ul> <p>For a complete introduction into RMRK, see this presentation or read the non-technical docs.</p>"},{"location":"general/nft-projects/#asset-hub","title":"Asset Hub","text":"<p>The Asset Hub is a generic assets parachain which provides functionality for deploying and transferring assets \u2014 both Fungible and Non-Fungible Tokens (NFTs). The Asset Hub currently hosts Uniques pallet and the NFTs pallet with NFT 2.0 functionalities.</p>"},{"location":"general/nft-projects/#unique-network","title":"Unique Network","text":"<p>Unique network, an NFT-specific blockchain offering innovations such as sponsored transactions, bundling fungible tokens with non-fungibles, and splitting NFTs into fungible tokens for partial ownership.</p> <p>Unique Network have launched two NFT projects to date: Substrapunks as part of Hackusama, and Chelobricks as a promotion during Polkadot Decoded.</p> <p>Unique Network focuses on B2B use cases, aiming to be an infrastructure provider for others to build on, rather than entering the NFT space themselves as an end-product.</p> <p>Unique Network aims to make their marketplace technology open-source and whitelabel-friendly. In theory, it should be trivial to set up a new marketplace for your project using Unique's technology. Unique network aims to be a parachain on Polkadot, and Quartz is their Kusama counterpart.</p>"},{"location":"general/parachains-apps/","title":"Polkadot Parachain Apps","text":"<p>Polkadot dApps</p> <p>Join the global Web3 movement \u2013 be among the first to try out innovative dapps running on Polkadot. You can browse the list of dApps on the official Polkadot website. This page also features a form that can be submitted to showcase dApps that are not already listed.</p> <p>Community Page</p> <p>It is recommended to have the parachain apps added to the official Polkadot website and then use this page to elaborate their key features to the Pokadot Wiki readers. This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your parachain app to this page.</p>"},{"location":"general/parachains-apps/#astar-network","title":"Astar Network","text":"<p>Astar is an interoperable smart contracts platform for Polkadot and Ethereum ecosystems supporting both Wasm and EVM smart contracts. Astar provides native access to Polkadot and Ethereum through its Polkadot parachain and Layer 2 scaling solution, while also offering bridges into other major blockchain ecosystems.</p> <p>Through the dApp staking, Astar offers a basic income to dApp developers, which allows them to continue building and enhancing their dApps without a pressing need to apply for grant programs, issue tokens and fundraise to earn money. At every block, a portion of the rewards goes to dApp staking and is then divided between operators (developers) and nominators. As a dApp grows in popularity, more members of the community nominate the dApp, and this, in turn, enables the developers who built the dApp to receive a greater percentage of the block reward.</p>"},{"location":"general/parachains-apps/#astar-portal","title":"Astar Portal","text":"<p>Astar Portal is a one-stop-place for interaction with Astar ecosystem, and an exclusive platform for Astar dApp staking \u2014 users can nominate their Astar/Shiden tokens on specific dApps they wish to support and get a portion of the rewards distributed at every block. Portal also allows unbonding, rewards compounding and nomination transfer.</p> <p>Astar Portal supports Polkadot native accounts (Polkadot-JS, Talisman, SubWallet, Clover, Math Wallet, Hana Wallet, OneKey), Multisig accounts (PolkaSafe) and EVM accounts (MetaMask, Talisman, SubWallet, Hana Wallet, OneKey).</p>"},{"location":"general/parachains-apps/#astar-dapps","title":"Astar dApps","text":"<p>Astar Network allows developers to use and build smart contracts in ways they never have before, leading to the realization of truly innovative solutions that can't be replicated in any other environment.</p> <ul> <li>ArthSwap</li> </ul> <p>ArthSwap is a one-stop DeFi protocol that aspires to be the main DEX on the Astar Network. The primary products are trading, staking, IDO launchpad, and liquidity farming, with other capabilities to be consistently added.</p> <ul> <li>Algem</li> </ul> <p>Algem is a native liquid staking DeFi dApp on top of Astar Network, offering new ways for ASTR users and holders to earn more. It empowers users to increase their earnings potential by staking while yield farming.</p> <ul> <li>AstridDao</li> </ul> <p>AstridDAO aims to be the leading decentralized money market protocol and the dominant stablecoin, $BAI, in the Astar/Polkadot ecosystem. AstridDAO is a decentralized borrowing protocol that allows users to draw interest-free loans against multiple collateral assets (e.g., ASTR, ETH, BTC).</p> <ul> <li>Starlay Finance</li> </ul> <p>Starlay Finance is a protocol for users to quickly and easily deposit and borrow assets on Astar Network. In other words, users can do \u201cLow Risk Farming on Astar Network\u201d. Depositors can provide liquidity to earn interest as a stable passive income, while borrowers can leverage their assets without selling them out.</p> <ul> <li>Zenlink</li> </ul> <p>Zenlink is an underlying cross-chain DEX protocol. By accessing the ultimate, open and universal cross-chain DEX protocol based on Substrate, Zenlink DEX Protocol enables all parachains to build DEX and achieve liquidity sharing in one click.</p> <ul> <li>XY Finance</li> </ul> <p>XY Finance is a cross-chain interoperability protocol aggregating DEXs &amp; Bridges. Based on the data from DeFi Llama, XY Finance is the top bridge protocol on Astar, opening gateways to users who have yet to experience Astar\u2019s ecosystem.</p> <ul> <li>SiO2 Finance</li> </ul> <p>SiO2 Finance is the Multi-VM Lending Hub on Astar for Polkadot, that supports both EVM and WASM. SiO2 Finance is the built of the community, by the community, for the community.</p> <ul> <li>tofuNFT</li> </ul> <p>tofuNFT is a permissionless, decentralized and full-featured NFT marketplace, providing numerous creative improvements to the existing marketplace experience like incentivized bidding, real-time notification, attributes filtering, bulk listing, and rarity explorer.</p> <ul> <li>Bluez NFT Marketplace</li> </ul> <p>Bluez is a distinctive NFT marketplace that empowers users to create, purchase, and sell NFTs with the power of XVM (Cross Virtual Machine). This community-driven platform offers a versatile and adaptable approach to NFT trading, enabling users to harness the benefits of both EVM and WASM for greater flexibility and convenience.</p> <ul> <li>Cosmize</li> </ul> <p>In Cosmize everybody can create and customize their own cosmic imagination. This platform allows for creating community activities, events, quests, and more. It is a place for making imagination become reality, to embrace the spirit of decentralization through community-driven activities.</p> <ul> <li>HEALTHREE</li> </ul> <p>HEALTHREE platform allows users to earn unique tokens ($UHT: Utility Health Token / $GHT: Governance Health Token) by engaging in ongoing healthy activities, especially diet, exercise, and sleep. In addition, users can earn additional tokens and rewards through gamification.</p> <p>Discover more Astar dApps on Astar Portal.</p>"},{"location":"general/parachains-apps/#bifrost-finance","title":"Bifrost Finance","text":"<p>Bifrost is a dedicated liquid staking middle layer built on Substrate, powered by Polkadot, providing non-custodial decentralized cross-chain liquid tokens for staked assets. By leveraging Polkadot\u2019s cross-consensus message format (XCM), Bifrost provides standardized cross-chain liquid staking solutions for multiple chains currently Polkadot (vDOT), Kusama (vKSM), Moonbeam (vGLMR), Moonriver (vMOVR) and other chains notably vASTR (Astar) and vFIL (Filecoin).</p> <p>Through Bifrost Staking Liquidity Protocol (SLP), Bifost facilitates the issuance and deployment of liquid staked assets (\u201cvTokens' '), allowing users to earn staking rewards while retaining their governance rights and participating in DeFi, such as liquidity provisioning on DEXs, providing collateral on lending/borrowing protocols and for stablecoin issuance as well as restaking for securing decentralized solutions. Bifrost vTokens are reward-bearing liquid staking tokens representing the users staked asset, including returns from staking. As staking rewards are received, vTokens increase in value without changing the quantity of tokens.</p> <p>Bifrost aims to offer seamless staking and DeFi experience for Proof of Stake (PoS) users and enable developers to build innovative applications around Bifrosts\u2019 liquid staking tokens.</p>"},{"location":"general/parachains-apps/#bifrost-dapp","title":"Bifrost dApp","text":"<p>Bifrost recent development of SLPx, is an extension pallet to Bifrost SLP that will allow users to invoke SLP's functionality on a remote chain without crossing assets into the Bifrost chain, allowing users to mint, redeem, swap vTokens remotely on the target chain. Leveraging this, developers can use and build innovative solutions around chain abstraction and solving liquidity and user fragmentation challenges.</p> <ul> <li>Omni LS</li> </ul> <p>Omni LS DApp is a front-end application that supports remote minting and redemption of Bifrost liquid staking tokens (LST) \u201cvTokens\u201d, as well as remote exchange, and swapping of vTokens from any chain. The DApp aims to simplify the cross-chain experience by providing a seamless interface for users to interact with vTokens across different chains natively.</p>"},{"location":"general/pcf/","title":"Polkadot Community Foundation","text":"<p>The Polkadot Community Foundation (PCF) is a foundation company incorporated in the Cayman Islands whose activities are directed by DOT holders via Polkadot\u2019s OpenGov.</p> <p>The PCF is an optional off-chain vehicle for OpenGov to execute tasks such as signing commercial contracts, making fiat payments, enforcing intellectual property, and contracting third-party service providers like consultants. Unlike typical companies, the PCF has no shareholders, members, trustees, or beneficiaries whose interests could conflict with those of the token holders. See more about PCF in the original OpenGov proposal.</p>"},{"location":"general/pcf/#role-of-the-polkadot-community-foundation","title":"Role of the Polkadot Community Foundation","text":"<p>The PCF is a real-world extension of the existing on-chain Polkadot governance process. It is an unopinionated entity with no agenda, roadmap, or business purpose except to take actions directed to it via OpenGov referenda.</p> <p>In cases where token holders are interested in proposing treasury expenditures or other actions that could benefit from a real-world legal presence, off-chain accounts, accountable management, and community ownership, they may author their proposals to include directions for the PCF to fulfill these functions. The PCF\u2019s functions are fulfilled by a 3<sup>rd</sup> party foundation administrator.</p> <p>So long as the PCF receives sufficient detail, funding, and authority to carry out its directions, the PCF administrators will do so within the confines of any legal, regulatory, and contractual obligations.</p>"},{"location":"general/pcf/#pcf-background","title":"PCF Background","text":"<p>Decentralized protocols and organizations increasingly require a bridge between the analog, centralized world and a more fully digital and decentralized future while complying with applicable laws and regulations.</p> <p>In the past, there has been a significant reliance on the Web3 Foundation and Parity Technologies to advance the ecosystem off-chain. While those organizations are philosophically aligned to the health and growth of Polkadot, their corporate governance structures offer no formal role or rights to DOT holders (nor are they in a good position to do so).</p> <p>As Polkadot evolves to decentralize governance further, and as Parity and the Web3 Foundation look to turn over critical functions to the community, it will benefit from a legal entity to effectuate Polkadot community governance in the \u201creal world.\u201d</p> <p>The PCF is designed to represent and explicitly serve DOT holders\u2019 interests off-chain. Its governing documents grant DOT holders permanent, irrevocable rights to guide its activities and oversee significant matters through the existing on-chain Polkadot OpenGov system.</p>"},{"location":"general/pcf/#pcf-activities","title":"PCF Activities","text":"<p>The PCF will take on activities delegated to it by Polkadot governance. The community will likely discover and evolve its thinking over time about which activities are best delegated to the Foundation, but as a rule of thumb, any activity that is best served with a legal contract that requires fiat payments or physical presence, or that requires active project management is appropriate for the Foundation to execute on the community\u2019s behalf.</p> <p>Initially, the Foundation will have a minimal scope to:</p> <ul> <li>Create and maintain a compliant off-chain organization capable of acting on directives from the   community,</li> <li>Taking custody of accounts, logins, keys, and assets as a form of community ownership,</li> <li>Executing contract agreements with partners, vendors, and service providers.</li> </ul> <p>Additional activities that require additional resources for project management, capital expenditures, business development, technical development, etc., will likely require incremental budget, staff, and legal design, which can be provisioned through subsequent line-item OpenGov treasury proposals. This allows the Foundation to adapt and grow to suit the community\u2019s directives as they become concrete.</p> <p>Some hypothetical future activities that the community may consider delegating to the Foundation can include:</p> <ul> <li>Retail marketing activities, e.g., social ad campaigns targeting developers</li> <li>Educational programs, e.g. Polkadot Blockchain Academy</li> <li>Complex grants programs, e.g., tranched or actively managed awards tied to milestones</li> <li>Community events, e.g., contracting with venues and service providers for physical gatherings</li> <li>Code management, e.g., maintain the polkadot-js GitHub repo</li> </ul> <p>As the community gains interest in various use cases, it can direct the Foundation to explore them in greater depth and report on how it can execute them.</p>"},{"location":"general/pcf/#pcf-entity-design","title":"PCF Entity Design","text":"<p>The proposed structure incorporates several features to optimize trust, risk, and efficiency. It balances community representation with professional robustness, minimizes the treasury assets at risk, maximizes the ability to adjust and evolve, and allows each proposed activity to be evaluated on its merits.</p>"},{"location":"general/pcf/#pcf-corporate-structure","title":"PCF Corporate Structure","text":"<p>Cayman Islands foundation companies offer a unique way to assign important rights to a broader stakeholder pool beyond traditional shareholders, directors, and employees. This proposal uses that feature to give DOT holders significant oversight and important powers to ensure that the Foundation carries out its business appropriately.</p> <p>Memberless: There are no members or shareholders who hold an economic claim over the Foundation. This eliminates a common source of conflict between legal entities and the communities they serve.</p> <p>Supervisor: There is a supervisor role whose primary purpose is to oversee the Board of Directors and ensure that the Foundation\u2019s governing documents are upheld. The supervisor holds legal standing to act on behalf of the foundation if directors diverge from their commitments or fail in their fiduciary duties. Given that the governing documents specifically instruct the directors to respect token holder preferences, provide adequate transparency, and not dilute the rights given to token holders, the Supervisor acts as a direct safeguard for token holder interests.</p> <p>Directors: The Foundation will have a five-member Board of Directors, divided between:</p> <ul> <li> <p>A three-director majority served by Cayman resident professional governance service providers to   ensure the Foundation is sufficiently independent of other entities in the Polkadot ecosystem and   to comply with the Cayman Islands economic substance requirements.</p> </li> <li> <p>Two seats reserved for future directors to be appointed by Polkadot governance to ensure token   holder interests are fully represented and considered in all matters.</p> </li> </ul> <p>Staff &amp; Administration: Day-to-day administration will be outsourced to a Cayman Islands-based professional services firm, reporting to the Board of Directors. These needs may fluctuate over time depending on the scope of activities delegated to the Foundation, and the Foundation will maintain flexibility to add, modify, and redirect the administrative staff as needed. The administrator\u2019s duties include:</p> <ul> <li>Operational support and project management</li> <li>Engaging and managing corporate service providers, including legal and bookkeeping</li> <li>Actively engaging and collaborating with the community to help craft, review, and execute   governance proposals for Foundation activities</li> <li>Maintaining appropriate documentation and transparency reports and</li> <li>Ensuring legal and regulatory compliance under applicable law</li> </ul> <p>DOT Holder Rights: The Foundation\u2019s bylaws ensure special voting rights and protections for DOT token holders, including:</p> <ul> <li>Polkadot OpenGov treasury proposals are the Foundation\u2019s funding source, so DOT holders can choose   to withhold future funding to cover basic operating expenses if they are unhappy with the   Foundation.</li> <li>Delegating specific activities to the Foundation. These activities will be approved as referenda   through on-chain Polkadot governance via OpenGov, using any track with adequate spending   permissions. If approved, the Foundation\u2019s Directors will review approved referenda, and if they   are appropriate and actionable, then the Foundation will execute the requested activities. The   token holder-appointed Directors have full access to represent tokenholders\u2019 interests in all   matters and may notify the Supervisor and/or the community of any improprieties.</li> <li>Token holders can vote via Polkadot OpenGov\u2019s General Admin track to remove the Supervisor or   Directors who are not serving appropriately.</li> <li>Token holders can vote via Polkadot OpenGov\u2019s General Admin track to amend the Foundation\u2019s   bylaws.</li> <li>A requirement that the Foundation cannot agree to any deliverables, responsibilities, or payments   to third parties unless they have been pre-approved by tokenholders.</li> <li>A requirement that the Foundation make public transparency reports detailing the Foundation\u2019s   activities, including but not limited to transactions, proposal status, and ongoing efforts to   carry out approved proposals.</li> <li>Token holders can vote via Polkadot OpenGov\u2019s General Admin track to wind up the Foundation or   instruct it to transfer some or all of its assets to another charitable object.</li> </ul>"},{"location":"general/pcf/#pcf-initial-personnel","title":"PCF Initial Personnel","text":"<p>Actum Node interviewed several candidates for each role, including referrals from the above-mentioned law firms, and members of the Polkadot community, and selected the following to propose as the initial office holders.</p> <p>Please note that some of the candidates requested that their names and backgrounds be partially redacted in public internet posts to prevent spam and phishing vectors that could compromise themselves or the Foundation. We extended the same level of privacy to all candidates for the same reasons.</p>"},{"location":"general/pcf/#supervisor","title":"Supervisor","text":"<p>J. Bain is a career fiduciary services professional. He has a regulatory background, having previously worked at the Cayman Islands Monetary Authority, and he has significant experience overseeing DAO foundations, other crypto-related entities, and traditional investment fund entities. Mr. Bain was introduced by our Cayman Islands counsel and recommended by the CEO of a crypto investment firm that he governs.</p>"},{"location":"general/pcf/#directors","title":"Directors","text":"<p>G. Kennedy is an experienced governance professional. He has a legal background, having served as General Counsel and outside counsel to several Cayman and European investment funds, and he sits on the board of several blockchain-related companies and foundations. Mr. Kennedy was introduced by our Cayman Islands counsel and strongly recommended by the General Counsel of an L1 development company and the CEO of a decentralized identity protocol that he also serves.</p> <p>M. Shaw is an experienced governance professional. He is a serial finance entrepreneur, having founded a DeFi protocol, a digital asset management company, and a data analytics company, among others. He has a finance background with a focus on global markets. Mr. Shaw was introduced by the proposed Supervisor J Bain and strongly recommended by the Managing Director of a crypto investment firm where he holds a director seat.</p> <p>E. Noyons is an experienced governance professional. He has an accounting background from a \u201cbig four\u201d firm and is a member of the Cayman Islands Institute of Professional Accountants. Mr. Noyons was introduced by our Cayman Islands counsel and strongly recommended by the COO of an NFT Gaming company where he holds a director seat.</p> <p>Two vacant seats, which Polkadot governance and only Polkadot governance can vote to fill at any time.</p>"},{"location":"general/pcf/#administrator","title":"Administrator","text":"<p>Autonomous Projects is a team of professionals based in the Cayman Islands with a collective 30+ years of web3 industry experience spanning legal, regulatory, finance, operations, and investment management. This includes working with clients across the asset management and web3 spectrum including Layer 1\u2019s, Layer 2\u2019s, and other scaling solutions, DeFi, infrastructure, gaming, and NFTs across multiple different blockchains where we support our clients in the development, implementation, maintenance, support and upgrade of their day-to-day operations layered with a keen understanding of the Cayman Islands\u2019 legal and regulatory landscape.</p> <p>After a competitive process, Autonomous was selected for their previous experience working with the Polkadot ecosystem, their emphasis on sound financial &amp; back office management, and their flexibility to adapt as the Foundation\u2019s operations evolve.</p>"},{"location":"general/pcf/#how-to-use-the-pcf","title":"How to use the PCF","text":"<p>To execute a proposal, the PCF needs clear, detailed instructions to ensure it acts in the community's best interest. Because not all OpenGov proposals involve the PCF, the PCF requires that proposers adopt certain requirements to identify what is and is not intended for PCF action.</p> <p>There are two types of Proposals: Foundation Funding Proposals and Foundation Resolution Proposals.</p>"},{"location":"general/pcf/#foundation-funding-proposals","title":"Foundation Funding Proposals","text":"<p>Foundation Funding Proposals are funding requests from the Polkadot treasury, specifying the amount in the preimage's value field according to the level of spend required, and setting the beneficiary to the PCF multisig wallet address. The Proposal must also include the intended use of funds in a comment on the Polkassembly website and begin with \u201c[Polkadot Community Foundation]\u201d in its name. The referenda can use any OpenGov origin with sufficient spending permission.</p> <p>Examples of Foundation Funding Proposals:</p> <ul> <li>Request funding for developing a Mobile App</li> <li>Request funding for growing the network's awareness through event attendance</li> <li>Request funding for a Polkadot-branded clothing line</li> <li>Request funding for a Polkadot-related advertisement campaign</li> <li>Request funding for developing a Web3 game on Polkadot utilizing a 3<sup>rd</sup> party game developer</li> <li>Request funding to diversify a portion of the Polkadot treasury into real-world asset investments</li> <li>Propose funding to run a Polkadot-branded competition</li> </ul> <p>Ensure that the track selected aligns with the funding requested, according to the DOT amount allocated per track.</p>"},{"location":"general/pcf/#wallet-addresses","title":"Wallet Addresses","text":"<p>DOT requested on the relay chain</p> <pre><code>13ECX4PUNHTdnpXX6KNeyd2qQHmruX6LE42iHuXcaBWVjz3e\n</code></pre> <p>USDT requested on Polkadot Asset Hub</p> <pre><code>167tDhLwaQ6kmqau1zwWx48Ux7CS1rxC9jW5kn8PeRZWAVUy\n</code></pre> <p>Please be aware that any proposals approved for funding by the foundation will require all recipients of those funds to undergo the necessary Know Your Customer (KYC) and/or Know Your Business (KYB) checks. This process may involve submitting personal information and supporting documentation. Proposals that do not meet these requirements or fail to provide the necessary documentation may be subject to rejection by the directors to avoid legal risk to the PCF and its other activities.</p>"},{"location":"general/pcf/#foundation-resolution-proposals","title":"Foundation Resolution Proposals","text":"<p>Foundation Resolution Proposals indicate token holders' wishes for the foundation without requiring funding. These must be of the type system.remark, with the remark text starting with \u201c[Polkadot Community Foundation]\u201d and submitted using the Wish For Change submission track.</p> <p>Examples of Foundation Resolution Proposals (Wish for Change)</p> <ul> <li>Propose a change to the Foundation\u2019s Bylaws</li> <li>Propose the foundation not utilize certain 3<sup>rd</sup> party service providers.</li> <li>Propose to remove/change a supervisor</li> <li>Propose to remove/change a director</li> <li>Propose the PCF transfer all or some of its assets to a charitable entity</li> <li>Propose to wind up the foundation</li> </ul>"},{"location":"general/pcf/#how-to-write-a-funding-proposal-to-pcf","title":"How to Write a Funding Proposal to PCF","text":"<p>When determining the amount of funding to request for the PCF to execute a proposal, the author must consider the PCF\u2019s costs to execute. If the instructions are unambiguous and actionable, require no further refinement, exploration, or discretion, and require minimal project management, then no overhead is required. Otherwise, the PCF will engage consultants and 3<sup>rd</sup> party service providers for specialized expertise or external support needed to fulfill its objectives, execute specific tasks, or manage complex projects that exceed the capacity or knowledge of its internal team. As the PCF sometimes incurs legal or operational costs to execute a proposal, we suggest including a greater than 5% overhead cost or $5,000 above the original funding request as a line item for PCF overhead to avoid any unforeseen issues. The PCF will always carry out its directives cost-efficiently and return any unspent budget to the treasury. Still, if a proposal has insufficient funding, the PCF may be forced to request additional follow-on funding or, in extreme cases, reject a proposal for unviability.</p> <p>When consultants or 3<sup>rd</sup> party service providers for specialized expertise or external support are needed, there are three approaches a proposal author may consider:</p> <ol> <li> <p>Submitting a proposal with fully actionable implementation instructions for the PCF, with    provisions for activities outside its remit.</p> </li> <li> <p>Submitting a proposal directing the PCF to conduct a consulting or advisory project to create a    feasibility study and implementation plan for an idea and share its findings. The community could    review the findings and then create a second proposal to execute the project according to the    suggested implementation plan.</p> </li> <li> <p>Submitting a single proposal that combines both steps in the second approach, directing the PCF    to conduct a consulting or advisory project to create an implementation plan, and then the    discretion to proceed immediately into execution.</p> </li> </ol> <p>For assistance in deciding the best option, the PCF team is happy to discuss and offer proposal assessments to advise on sufficient budget, clarity, and structure. info@polkadotcommunity.foundation</p> <p>The PCF\u2019s directors\u2019 roles include ensuring that The Foundation\u2019s actions do not create undue risk for the foundation or the Polkadot community. Following the approval of a proposal via OpenGov, the directors can potentially reject it, if they determine that implementing it would compromise their fiduciary duties, violate the foundation governing documents, the Polkadot community governance process, or any applicable laws or regulations, cause harm to the PCF or breach existing contracts. They can also reject proposals that lack sufficient detail, are too vague for implementation, or lack adequate funding. This is an action the PCF wants to avoid as much as possible; therefore, submitted proposals must be as detailed and researched as possible to have a greater chance of approval.</p>"},{"location":"general/pcf/#pcf-faq","title":"PCF FAQ","text":""},{"location":"general/pcf/#pcf-general-faq","title":"PCF General FAQ","text":"<p>Why a Cayman Foundation Company and not a Swiss Foundation?</p> <p>A Swiss Foundation structure is a valid option for this entity, but the Cayman structure offers greater operational ease and flexibility. Swiss Foundations are subject to income tax by default unless government authorities explicitly grant exceptions, which come with specific requirements. In contrast, Cayman Foundation Companies are tax-exempt by default.</p> <p>Can this Foundation service Kusama as well?</p> <p>As the Foundation reserves certain rights and powers for token holders, it is unclear how the combination of DOT and KSM holders, with differing governance instances, can jointly indicate their preferences.</p> <p>After gathering input from key members of the Polkadot community and legal counsel, we suggest moving forward with a Foundation to serve only DOT holders initially. Later, as a separate initiative we can consider creating a similar but separate foundation to serve KSM holders, and perhaps even help facilitate the creation of similar foundations for any parachain or DAO in the Polkadot ecosystem.</p> <p>How does this foundation shield token holders and governance participants from liability?</p> <p>If someone were to make a legal claim that a Polkadot OpenGov action harmed them somehow, everyone who participated in governance may be liable. However, suppose the action was taken by a legal entity with limited liability, like the Polkadot Community Foundation. In that case, it may be held liable, but it absorbs the risk and shields the liability of governance participants and token holders. This is an advantage of routing activities through the Foundation.</p> <p>How will token holders know if the foundation is doing what it\u2019s supposed to?</p> <p>Token holders can appoint 2 of the five directors and the supervisor. The idea is that this lets them choose known people who share their values and are committed to Polkadot to gain full access to everything happening inside the foundation, and the ability to represent the token holders in all decisions.</p> <p>The bylaws also require quarterly public transparency reports. Over time, that can mature to become robust real-time reporting if:</p> <ol> <li>the foundation team does that proactively,</li> <li>if token holders provide additional funding and explicit instructions to enable real-time    reporting, or</li> <li>if tokenholders vote to amend the bylaws to require real-time reporting.</li> </ol> <p>How do we avoid service providers or directors turning passive or amassing power over time?</p> <p>A vote of token holders can remove any service provider, director, or supervisor at any time. In the future, the community could decide to implement a seat rotation, term limits, or other measures to reduce the risk of bureaucratic power. These are not provisioned in the current proposal but can be decided via a proposal on the Polkadot OpenGov General Admin track at any time.</p> <p>Can a director spend the foundation\u2019s money however they want?</p> <p>No. This depends on the operating policies the foundation team puts into place, like how many people have to approve/sign any expenditures, if small expenditures are pre-authorized, etc. As with any traditional company, it is technically possible for someone to spend money they\u2019re not supposed to. But ultimately, there are several types of recourse if this were to happen.</p> <p>If a service provider spends money in a way that the directors didn\u2019t authorize, the service provider is likely in breach of their contract and subject to legal action. If a director spends money that is not properly authorized by the board, the other directors or the supervisor can act. If they don\u2019t, the token holders can replace them with someone who will.</p> <p>Finally, the design of this Foundation as an option, with funding coming only as needed, minimizes the funds at risk and ensures the Foundation stays reliant on community trust.</p> <p>What if there\u2019s a bad actor?</p> <p>We built redundant checks and balances into the governance system. No one person and no one layer of governance is immune. In addition, we selected professional governance professionals for each role, whose businesses rely heavily on maintaining a good reputation. Ultimately, all trails end with the tokenholders\u2019 ability to fire people, withhold budget, or dissolve the foundation in case of any extreme events.</p> <p>Who can fire a director?</p> <p>The bylaws allow two ways for a director to be fired. By a director vote or token holder vote via the OpenGov General Admin track. What if the directors collude?</p> <p>Colluding directors would have to do so in full sight of the tokenholder-appointed directors and the supervisor. If all those people colluded, the tokenholders could remove them, withhold the budget, or dissolve the foundation.</p> <p>Who can appoint a Cayman Professional director after one has been removed?</p> <p>The three director seats not tokenholder-appointed are filled by a director vote, meaning all the currently filled seats include both those appointed by tokenholders and those not. The supervisor can appoint one as a backstop if there are no active directors.</p> <p>Technically, these seats that are not tokenholder-appointed do not always have to be filled by Cayman professionals, but the advice we received is that having a majority based in the Cayman Islands is an important tax and regulatory consideration.</p> <p>Can the tokenholders sue?</p> <p>Potentially, but coordination to prove those bringing suit represent \u201cthe token holders\u201d as a class would likely be difficult, costly, and require doxing themselves.</p> <p>However, the supervisor has a unique role in Cayman Foundation Companies with legal standing to sue directors who violate the Foundation\u2019s governing documents. Those documents instruct the directors to respect tokenholder preferences. Suppose tokenholders ever feel that the supervisor is not acting appropriately. In that case, they can remove and replace the supervisor at any time by approving a proposal to do so on Polkadot OpenGov\u2019s General Admin track.</p>"},{"location":"general/pcf/#pcf-proposal-faq","title":"PCF Proposal FAQ","text":"<p>Who can submit a proposal to the PCF?</p> <p>Any token holder who has a valid and actionable idea that aligns with the goals and vision of the Polkadot ecosystem can submit a proposal.</p> <p>How do I ensure my proposal is appropriately funded?</p> <p>Provide a detailed budget breakdown in your proposal, including all anticipated costs. It\u2019s crucial to account for all phases of the project, potential contingencies, and any third-party costs, such as contractor, consulting, and legal fees.</p> <p>Where can I find referenda creation guidelines?</p> <p>This can be found on the Polkassembly docs website, or Polkadot-JS guides.</p> <p>What happens if the proposal isn\u2019t sufficiently funded during the execution phase?</p> <p>If additional funding is needed during the execution phase, you must submit a supplemental funding request. This request will be evaluated similarly to your original proposal, and additional funds will be allocated if approved.</p> <p>What happens to any funds remaining after a proposal has been executed?</p> <p>Any remaining funds after the successful completion of a project should be returned to the Polkadot community treasury unless otherwise agreed upon in the initial proposal.</p> <p>Are there any specific requirements for proposals that involve third parties?</p> <p>Yes, any proposals that require the PCF to engage with third parties (contractors, etc.) must include funding for contractor fees, onboarding processes, such as background checks and MSA reviews.</p> <p>Where is the foundation incorporated?</p> <p>The Polkadot Community Foundation is incorporated in the Cayman Islands.</p> <p>Are there any Cayman Islands-specific considerations I need to be aware of?</p> <p>Yes, proposals must comply with Cayman Islands laws and regulations. Activities prohibited in the Cayman Islands, such as certain financial transactions or business practices, cannot be funded or executed. E.g., Activities involving money laundering or gambling.</p> <p>Who are the signers on the PCF beneficiary multi-sig?</p> <p>The signers controlling these addresses are experienced, competent, and well-known individuals within the Polkadot ecosystem.</p> <p>Can I get feedback if my proposal is rejected?</p> <p>Yes, we provide feedback on rejected proposals to help you understand the reasons and improve future submissions.</p> <p>Who can I contact for more information or assistance?</p> <p>For any questions or assistance, please get in touch with the PCF team at info@polkadotcommunity.foundation</p> <p>What does the PCF not do?</p> <p>The PCF will not enact any proposals that create undue risk for the foundation or the Polkadot community, compromise their fiduciary duties, violate foundation governing documents, the Polkadot community governance process, or any applicable laws or regulations, cause harm to the PCF or breach existing contracts. The foundation will not enact proposals that are too broad and require discretion/opinion from the PCF.</p>"},{"location":"general/pcf/#pcf-supporting-material","title":"PCF Supporting Material","text":"<p>Info</p> <p>The supporting material listed below is temporary. Final versions will be uploaded in due time.</p> <ul> <li>Kusamarian AAG Video Discussion</li> <li>Polkadot Community Foundation Constitution</li> <li>Polkadot Community Foundation Bylaws</li> <li>Polkadot Community Foundation M&amp;A</li> <li>Terms of Service</li> <li>Forum code of conduct</li> </ul>"},{"location":"general/polkadot-direction/","title":"Polkadot Direction","text":"<p>Info</p> <p>The material on this page is based on Gavin Wood's talk at Polkadot Decoded 2023.</p> <p>Understanding what Polkadot 1.0 is about and the philosophy behind it will help us to envision the future direction of the Polkadot ecosystem toward abstraction and generalization.</p>"},{"location":"general/polkadot-direction/#polkadot-as-a-computational-resource","title":"Polkadot as a Computational Resource","text":"<p>Polkadot has been abstracted and generalized beyond what was originally proposed and envisioned in the whitepaper. Polkadot is:</p> <ul> <li>About Blockspace (the underlying resources that   chains need), not chains.</li> <li>A platform to build applications rather than chains and for people to use those applications.   Fundamentally, Polkadot is not a platform to host chains, and so far, chains happened to be one   way to build applications and grow Polkadot's utility.</li> <li>A provider of resilient general-purpose continuation computation, where the term   continuation refers to a broad, long-running task that can do something, pause, continue (or do   something else) later.</li> <li>A multicore computer where chains that continuously operate in parallel on different cores are   called parachains. One core can be reserved for one single chain   in-bulk or on-demand. On-demand cores can be accessed by multiple chains at different periods (see   the Agile Coretime page). At the time of writing (2024), there   are around 50 cores independently operating in parallel on Polkadot.</li> </ul> <p>From now on application will be used as a general term to describe anything that can use a Polkadot core to access secure and decentralized computation.</p>"},{"location":"general/polkadot-direction/#summary","title":"Summary","text":"<p>If we see Polkadot as a service provider of trustless and resilient computation through cores as well as secure interoperability between core-powered applications, the future development of Polkadot can be directed towards the following main changes.</p> <p>A paradigm shift from:</p> <ul> <li>being a chain-focused ecosystem where each parachain owned an execution core at all times   (acquired through fixed parachain auction), which allowed a simple and secure, sharded execution   environment</li> <li>to being an application-focused ecosystem where we remove the assumption that each application   owns a core, and instead that all cores are a resource to be consumed and used as needed by all   applications.</li> </ul> <p>Previously, securing a core was a competitive process through an auction mechanism. With Agile Coretime, there is no need for auctions anymore. Teams can purchase on-demand coretime or reserve bulk coretime as required. This greatly decreases the barrier-to-entry for software tinkerers and parachain teams.</p> <p>On top of those main changes, agile core usage and coretime allocation will allow any application to access Polkadot's computation based on their needs without wasting valuable blockspace. Accords will improve cross-chain communication and the security guarantees of XCM messages. Finally, Polkadot will scale by moving on-chain logic into its system parachains, allowing it to have more bandwidth for the parachains protocol and accords.</p>"},{"location":"general/polkadot-direction/#from-slot-auctions-to-coretime-marketplace","title":"From Slot Auctions to Coretime Marketplace","text":"<p>The end product of blockchains is Blockspace. Applications need to access Polkadot's blockspace, and the entry points to blockspace are the cores. Thus, applications will need to reserve some time on cores or Coretime to gain the right to access Polkadot's secure blockspace and interoperability for a finite period.</p> <p>Cores must be agile and general: they can change what job they run as easily as a modern CPU. It follows that the procurement of those cores must be agile as well.</p> <p>The auction mechanism is not agile, creates high entry barriers, and is designed for long-running single applications (i.e., the original Polkadot vision proposed in the whitepaper).</p> <p>We depart from the classic lease auctions and propose an agile marketplace for coretime, where essentially coretime becomes a commodity that can be tokenized, sold, and traded. This setup maximizes the agility of Polkadot and lets the market figure out the best solution needed for applications to be successful.</p> <p>Applications can reserve bulk coretime and on-demand coretime depending on their needs. Bulk coretime rental will be a standard rental of coretime through a broker system parachain at a fixed price for a fixed period of time. On-demand coretime rental will be available through ongoing sale of coretime for immediate use at a spot price. This system lowers the barrier to entry for prospective builders.</p> <p>For example, revenues from coretime sales can be burnt, used to fund the Treasury, or used for a mix of those options. The topic is currently under discussion. For more information, see RFC-0010 and RFC-0015.</p>"},{"location":"general/polkadot-direction/#from-chain-centricity-to-application-centricity","title":"From Chain-centricity to Application-centricity","text":"<p>Polkadot 1.0 was a chain-centric paradigm consisting of isolated chains able to exchange messages. This was not fundamentally different from having completely different chains connected to bridges, with the only difference of having the relay chain securing the network, providing message-passing capability, and doing some extra tasks such as staking, accounts, balances, and governance. Having a chain-centric system will ultimately end in chain-centric application and UX.</p> <p>The true innovation of Polkadot is about leveraging the unique value proposition offered by different chains and using those chains\u2019 collaborative potential to build inter-chain applications to solve real-world problems. Those applications will thus need to span across chains.</p> <p>Increasingly fewer tasks will be handled by the relay chain that will focus efforts only on primary tasks: securing the network and providing secure message-passing capability. System parachains will be used to take over secondary relay chain tasks such as staking, governance, etc.</p>"},{"location":"general/polkadot-direction/#xcm-and-accords","title":"XCM and Accords","text":"<p>XCMP is the transport layer for delivering XCM messages. It gives the transportation method and a secure route but not a framework for binding agreements.</p> <p>XCM is a format, a language of intention abstract over functionality common within chains. It creates an expressive language of what you intend to do or want to happen. XCM messages are transported between different chains using XCMP. Ideally, in a fully trustless environment, strong guarantees ensure chains faithfully interpret XCM messages. We can have a secure mode of delivering messages that can be interpreted across protocols, but still messages might be misinterpreted. These guarantees can be achieved with accords.</p> <p>An Accord is an opt-in treaty across many chains, where treaty logic cannot be changed or undermined by one or more of those chains, and Polkadot guarantees faithful execution of this logic. Accords will be specific to a particular function, and any chain that enters the accord will be held to it and will service that particular function. To lower the entry barrier, accords can be proposed permissionlessly, but because they are opt-in, the accord proposal will take effect until chains agree and sign up.</p> <p>To sum up, accords ensure that the receiver faithfully interprets XCM messages securely sent via XCMP channels. Accords are the missing piece of the puzzle to achieve a fully trustless and collaborative environment between applications.</p> <p>Polkadot is the only ecosystem where accords can properly exist because it has a homogenous security layer that provides a specific state transition function for each logic component. This allows patterns of cooperation between multiple logic components (i.e., trans-applications) that would not be possible to achieve over bridges.</p> <p>Accords will be implemented using SPREE technology.</p>"},{"location":"general/polkadot-direction/#core-usage-in-polkadot-10","title":"Core Usage in Polkadot 1.0","text":"<p>In Polkadot 1.0, applications produced blocks at a fixed rate of 12 seconds, whether needed or not. This led to inefficient energy allocation and economic incentives for producing full blocks under heavy traffic and empty blocks under light traffic.</p> <p>The figure below shows the core usage for Polkadot 1.0, where the horizontal axis is time, and each row represents a core. Colors show different parachains, each using one core (i.e., one parachain, one core formula).</p> <p></p> <p>The above setup allowed a simple and secure, sharded execution environment.</p> <p>However, to achieve full efficiency, blocks must be produced when needed, and the system must target full block capacity, lowering the probability of incentivizing validators to build blocks half full or, worse, empty.</p>"},{"location":"general/polkadot-direction/#agile-coretime-allocation","title":"Agile Coretime Allocation","text":"<p>In Polkadot 1.0, coretime is a fixed two-year period on one specific core. Here, we remove this limitation and generalize coretime usage to meet different application needs. For more information, see the agile coretime documentation.</p>"},{"location":"general/polkadot-direction/#split-coretime","title":"Split Coretime","text":"<p>Owners of coretime can split or trade it. An application A1 can run on core C1 for a finite period and then another application A2 can run on that core, or application A1 can continue running on another core C2. Some applications might stop running for some time and resume later on.</p> <p></p>"},{"location":"general/polkadot-direction/#strided-coretime","title":"Strided Coretime","text":"<p>Ranges can be strided (i.e., applications can take turns on a core) to share costs or decrease block production rate, for example.</p> <p></p>"},{"location":"general/polkadot-direction/#combined-coretime","title":"Combined Coretime","text":"<p>An application can be assigned to multiple cores simultaneously. Some applications can have a permanent core assignment and an intermittent one, for example, in a period of high demand to send multiple blocks to multiple cores at the same time slot to reduce latency. Combining coretime in this manner is achieved through elastic scaling.</p> <p></p>"},{"location":"general/polkadot-direction/#agile-core-usage","title":"Agile Core Usage","text":"<p>In Polkadot 1.0, one core is assigned to one application (in this case, equivalent to a parachain). Ideally, core affinity (i.e., which application operates on which core) is unimportant (see below). Cores do not have any higher friendliness to one application than another.</p> <p></p> <p>Here, we remove the assumption that each application owns a core and instead that all cores are a resource to be consumed and used as needed by all applications in the ecosystem.</p>"},{"location":"general/polkadot-direction/#compressed-cores","title":"Compressed Cores","text":"<p>The same core can secure multiple blocks of the same application simultaneously. Combining multiple application blocks in the same relay chain core will reduce latency at the expense of increased bandwidth for the fixed price of opening and closing a block.</p> <p></p>"},{"location":"general/polkadot-direction/#shared-cores","title":"Shared Cores","text":"<p>Sharing cores with other applications to share costs but with no reduction in latency. Note that this is different from the split coretime where one core is used by multiple application at different times to share costs at the expense of higher latency. Shared cores will be enabled with JAM, a semi-coherent system in which data from different shards can be scheduled within the same core.</p> <p></p>"},{"location":"general/polkadot-direction/#agile-composable-computer","title":"Agile Composable Computer","text":"<p>All the above options of agile coretime allocation and core usage can be composable and enable the creation of an agile decentralized global computing system.</p> <p></p> <p>Thus, this new vision is focused on Polkadot\u2019s resource, which is secure, flexible, and available blockspace that can be accessed by reserving some time on a core. Agility in allocating coretime and using cores allows for maximized network efficiency and blockspace usage.</p>"},{"location":"general/polkadot-direction/#polkadots-resilience","title":"Polkadot's Resilience","text":"<p>Systems that have yet to be engineered with decentralization, cryptography, and game theory in mind, are breakable and prone to cyber-attacks. Polkadot is basing its resilience on different pillars:</p> <ul> <li>Preponderance of light-client usage: Centralized RPC servers are common but susceptible to   attack and not trustless decentralized entry points to using blockchain-based applications. Light   client usage on Polkadot is possible through   Smoldot.</li> <li>Zero-Knowledge (ZK) Primitives: They can have a problematic effect on censorship and   centralization as having a big state transition function boiled down to a single proof of correct   execution is not currently a scaling solution to build resilient systems. However, a library of   richly featured and high-performance ZK primitives ready for specific use cases is being built.   The first use-case will be used to improve privacy for on-chain collectives such as   the Polkadot Technical Fellowship.</li> <li>SAFROLE consensus: New forkless block-production consensus   algorithm replacing BABE and where block are   not produced unless they are expected to be finalized. This will provide several benefits, such   as:</li> <li>Improved security, parachain performance, and UX from being forkless</li> <li>Preventing front-running attacks through high-performance transaction routing where transactions     are included in blocks in one hop instead of being gossiped, and transaction encryption.</li> <li>Internode Mixnet: Shielded transport for short messages that</li> <li>avoids leaking IP information for transactions, and</li> <li>introduces a general messaging system allowing users, chains and off-chain workers, smart     contracts, pallets, and anything else existing within a chain to exchange messages containing     signatures, intentions, etc.</li> <li>Social Decentralization: Resilience is achieved by including many participants contributing to   the system and coming to decisions through on-chain governance. Involving as many people as   possible ensures resilience against spending becoming systemically misjudged and appropriately   directs wealth for spending treasury funds, salaries, and grants. Another crucial way of   decentralizing the network is ensuring experts on which the maintenance of the system relies upon   are incentivized and recruited over time by the Polkadot network and not by organizations within   the Polkadot ecosystem.</li> </ul>"},{"location":"general/polkadot-v1/","title":"Polkadot 1.0","text":"<p>Since the release of Bitcoin in 2009, blockchain projects increased exponentially to the order of tens of thousands. Different projects have different value propositions, suggesting that the future will be multi-chain and that inter-chain communication will be crucial to establish collaborations and leveraging each other strengths.</p>"},{"location":"general/polkadot-v1/#polkadot-10","title":"Polkadot 1.0","text":"<p>Polkadot 1.0 reflected the status of Polkadot in 2023 at time of the release of the Polkadot runtime v1.0.0. This sections focuses on Polkadot 1.0 and some philosophical digressions about network resilience and blockspace.</p> <p>Polkadot is a Layer-0 blockchain that brings to the multi-chain vision the following innovations and initiatives:</p> <ul> <li>Application-specific Layer-1 (L1) blockchains (or parachains). Polkadot is a sharded network   where transactions are processed in parallel with each shard. Polkadot shards can be heterogenous   (i.e. they do not need the same state transition function as in the proposed Ethereum sharding   architecture). This allows to build L1 chains designed explicitly around their application and   value proposition.</li> <li>Shared security and financial scalability of L1 chains. Any L1 chain attached to a Polkadot   core can benefit from Polkadot shared security model. This means the Polkadot   Nominated-Proof-of-Stake (NPoS)   mechanism along with its consensus mechanism, secures L1 chains out-of-the-box without having to   bootstrap security on their own.</li> <li>Secure interoperability. Any L1 chain attached to Polkadot (as well as L2 chains built on top   of them) can benefit from Polkadot's native interoperability and will thus be able to communicate   and exchange value and information with other parachains.</li> <li>Truly resilient infrastructure. This is achieved by keeping the network decentralized without   compromising scalability and throughput and through on-chain   treasury funds that can be accessed through   governance referendum. Those funds guarantee constant sponsorship for events, initiatives,   educational material, education, software development, etc.</li> <li>Fast development and deployment of L1 chains. This is achieved through the modular and   flexible Polkadot SDK Substrate.</li> <li>Fostering next-gen of Web3 core developers. This is achieved through different initiatives   such as:</li> <li>The Polkadot Blockchain Academy</li> <li>Polkadot Alpha Program</li> <li>Polkadot Developer Heroes Program</li> <li>Edx Courses</li> <li>Rust and Substrate Courses (coming soon)</li> </ul>"},{"location":"general/polkadot-v1/#polkadots-representation","title":"Polkadot's Representation","text":"<p>Polkadot has a relay chain acting as the main chain of the system. The Polkadot relay chain is represented as a ring surrounded by multiple parachains attached to it. Based on Polkadot's design, as long as a chain's logic can compile to Wasm and adheres to the relay chain API, then it can connect to the Polkadot network as a parachain.</p> <p></p> <p>Parachains construct and propose blocks to validators on the relay chain, where the blocks undergo rigorous availability and validity checks before being added to the finalized chain. As the relay chain provides the security guarantees, collators - full nodes of these parachains - do not have any security responsibilities, and thus do not require a robust incentive system. This is how the entire network stays up to date with the many transactions that take place.</p> <p>The Cross-Consensus Messaging Format (XCM) allows parachains to send messages of any type to each other. The shared security and validation logic of the relay chain provide the environment for trust-free message passing that opens up true interoperability.</p> <p>In order to interact with chains that want to use their own finalization process (e.g. Bitcoin), Polkadot has bridges that offer two-way compatibility, meaning that transactions can be made between different parachains.</p>"},{"location":"general/polkadot-v1/#polkadots-additional-functionalities","title":"Polkadot's Additional Functionalities","text":"<p>The Polkadot relay chain managed crowdloans and auctions. Relay chain cores were leased via auctions in 3-month chunks for a maximum of two years, and crowdloans allowed users to trustlessly loan funds to teams for lease deposits in exchange for pre-sale tokens. There was no other way you could access cores on Polkadot 1.0.</p> <p>The relay chain currently manages other tasks such as staking, accounts, balances, and governance.</p>"},{"location":"general/polkadot-v1/#polkadots-resilience","title":"Polkadot's Resilience","text":"<p>Decentralization is a crucial aspect of blockchain networks, but there is a trade-off between:</p> <ul> <li>having an over-decentralized network that struggles to reach consensus and consumes a lot of   energy to operate, and</li> <li>having a network that reaches consensus fast at the expense of being centralized, making it   trivial to manipulate or attack.</li> </ul> <p>Ideally, a network should be decentralized \"enough\" to make it practically impossible for someone to exert manipulative or malicious influence on the network. So, decentralization is a tool while the goal is resilience, which is achieved by additionally providing on-chain treasury and governance mechanism allowing continuous incentives for the network's participants without relying on intermediaries or centralized entities.</p> <p>Currently, Polkadot 1.0 achieve resilience through the following strategies:</p> <ul> <li>Nominated Proof of Staking (NPoS) where the stake per validator is maximized and evenly   distributed across validators.</li> <li>The 1KV program aims to incentivize new operators to   become network participants and further increase physical (how many validator nodes per service   provider) and social decentralization (how many validator nodes per operator). Those can be   explored with the Polkawatch App.</li> <li>An on-chain treasury and governance (see: OpenGov) where   every decision goes through public referenda and any token holder can cast a vote.</li> </ul>"},{"location":"general/polkadot-v1/#polkadots-blockspace","title":"Polkadot's Blockspace","text":"<p>The design and realization of Polkadot 1.0 allowed its creators to enable commoditization of blockspace.</p> <p>A blockchain is a way to store data. The storage unit is the block, and once a block is finalized onto the chain, it is practically impossible to modify the data within that block. In addition to being tamper-proof, public permissionless blockchains like Polkadot store data that are visible to everybody (i.e. public), and anybody can become a network participant permissionlessly.</p> <p>Blockspace is the capacity of a blockchain to finalize and commit operations. It represents a blockchain's security, computing, and storage capability as an end product. Blockspace produced by different blockchains can vary in security, flexibility, and availability.</p> <ul> <li>Security, intended as how secure the blockspace is. In Proof-of-Stake (PoS) networks, this is   directly related to how much stake is locked on validator nodes, how much variance in stake there   is between validators (i.e. how easy it is to attack a single validator), and how many validators   there are securing the network (i.e. how easy it is for colluding validators to exert influence on   the network). Additionally, it is also important to look at how many validators are owned by   single operators (this will determine the degree of social centralization of the network), and how   many validators run on the same service provider (this will determine the degree of physical   centralization of the network).</li> <li>Flexibility, intended as how flexible the blockspace is, what can be done with it, and what   type of data can be stored. Data quality plays an important role depending on the type of network.   One might avoid having situations in which poor quality data flood blockspace hindering the prompt   execution of vital processes.</li> <li>Availability, intended as how available blockspace is and how difficult it is to access it. It   should not be too difficult to get your hands on it so that any business model can thrive using   it. Ideally, a marketplace must drive the blockspace price based on demand, with secondary market   options to ensure the usage of \"second-hand\" blockspace.</li> </ul> <p>Polkadot has been designed around those core blockspace principles. However, its design can be further improved such that the tasks which are currently managed on the relay chain, such as balances transfers, staking, and governance, can be delegated to system parachains to increase flexibility and to focus the use of the relay chain to provide shared security and interoperability. Blockspace is only accessible through auctions, but an auction winner has access to a \"freighter of blocks\" regardless it is needed or not. This creates high entry barriers and it can lead to waste of energy and resources.</p> <p>For more information about blockspace see this interview with Robert Habermeier as well as this article by him.</p>"},{"location":"general/polkadot-v1/#a-perspective-shift-upcoming-polkadot-features","title":"A Perspective Shift: Upcoming Polkadot Features","text":"<p>As with many other projects before Polkadot, at some point in time after achieving the initially-planned goals, a perspective shift allows you to understand better what your project is about and what you actually have built. This allows you to \"run the extra mile\" and achieve more than what was originally planned.</p> <p>The quote below by Marcel Proust must remind us that sometimes a perspective shift is crucial in understanding the world, and perhaps it is more important than seeing more of the world.</p> <p>The only true voyage of discovery, the only fountain of Eternal Youth, would be not to visit strange lands but to possess other eyes.</p> <p>Thus, if we start to see Polkadot with other eyes we can truly envision its potential and what it could become.</p> <p>Polkadot is perfecting its implementation through RFCs to continue being a decentralized, secure, ubiquitous computing engine to power the next generation of Web3 applications.</p>"},{"location":"general/polkadot-vault/","title":"Polkadot Vault (formerly Parity Signer)","text":"<p>Rebranding of Parity Signer to Polkadot Vault</p> <p>The Polkadot Vault app rebranding is live on iOS and Android devices. The source code of all versions can be downloaded on the GitHub repo.</p> <p>The Polkadot Vault app is an air-gapped cold storage solution for all users, including developers and power users. See Ledger devices for other cold storage solutions.</p> <p>Smartphone compatibility with Polkadot Vault</p> <p>Note that although the Vault app is available for old smartphones, different versions will be installed according to the phone's hardware. For example, smartphones like iPhone 6 will install Parity Signer (the old brand name of the Vault app) with limited capabilities. There will be no log or warning if the phone was connected to the internet while not using the app. Also, no metadata updates are possible, and no option to add new networks. This would not be as secure as the latest version of the app. We would recommend that you use smartphones compatible with the latest Polkadot Vault app.</p> <p>How to Use Polkadot Vault</p> <p>Polkadot Vault (formerly Parity Signer) is a cold storage solution that allows you to use a phone in airplane mode as an air-gapped wallet. The Vault app is not technically a wallet, as it does not allow to transfer funds. It is more of a key-chain tool that will enable you the create, manage, and restore accounts.</p> <p>By default, the Vault app contains chain specifications for Polkadot, Kusama, and Westend. Metadata updates are possible via a QR code fountain. It is also possible to add other Substrate-based chains and do metadata updates for those. The app allows you to securely sign extrinsics via QR codes without exposing your private keys to the internet.</p>"},{"location":"general/polkadot-vault/#vault-vs-ledger","title":"Vault vs. Ledger","text":"<p>The Polkadot Vault and Ledger are cold storage solutions because private keys of accounts created on the Vault app or Ledger device are not stored on your computer or, more in general, on a device that has an internet connection. However, the two solutions differ, and you should consider one or the other depending on your user type.</p> Ledger Polkadot Vault Hardware designed to stay offline and be secure. Certified by French cybersecurity agency ANSSI. Hardware not designed to stay offline. The user must switch off all inbound and outbound connections (network, wifi, Bluetooth, NFC). Hardware is resistant to side-channel attacks via Secure Element. The secure element will destroy itself if opened. Although there is no wired connection, side-channel attacks are possible. Without a secure element, the phone can be opened, and the keys will be accessible in its storage unit. Accounts derived from one mnemonic seed phrase. One mnemonic for each account or one mnemonic for multiple accounts via account derivation or default Substrate address format. See this support article for information on whether to use the same account or different accounts on different chains based on your needs. Easy firmware and application upgrades through the Ledger Live application. The app should never be connected to the internet after installation, so the version installed on the phone should not be updated directly. For app upgrades, users must factory reset the phone and recover all accounts through seed phrases. Metadata updates for each chain must be done via the QR code fountain. Currently, not all parachains are supported. Users can add all parachains either through a third-party provider or if they have the wss endpoint and know how to extract the chain specifications and metadata. Ledger app updates on Ledger Live sometimes lag behind chain updates resulting in users only being able to transact if they install developer versions (only for advanced users). Metadata updates are always available to install once released, either through the third-party provider or manually. In this case, the installation process requires familiarity with working on the command prompt."},{"location":"general/polkadot-vault/#create-and-import-accounts","title":"Create and Import Accounts","text":"<p>You can create a new account directly within the Vault app (Add Key Set &gt; Add new Key Set). This will generate a new mnemonic seed phrase on the app. Alternatively, you can import a new account in the app using a seed phrase generated elsewhere with a compatible account generation scheme. For example, you can have an air-gapped laptop with the Subkey tool installed and generate a new account there. The seed phrase of that account can be imported into the Vault App (Add Key Set &gt; Recover Key Set).</p> <p>For guidelines about how to create an account using Polkadot Vault, see this video tutorial and visit this support article.</p> <p>Info</p> <p>Importing an account into an extension will not import its private key. Only the public key will be imported and you must sign using your air-gapped phone which holds the private key.</p>"},{"location":"general/polkadot-vault/#restore-account-on-polkadot-vault","title":"Restore Account on Polkadot Vault","text":"<p>See this video tutorial and this support page to learn how to restore your account on the Polkadot Vault app.</p>"},{"location":"general/polkadot-vault/#signing-extrinsics","title":"Signing Extrinsics","text":"<p>Always check for Metadata Updates</p> <p>Before signing extrinsics with the Polkadot Vault app, always check for metadata updates. This video tutorial will explain how to do it.</p> <p>Remember to always check for metadata updates before signing transactions. See this article to learn how to sign transactions and this article on how to easily add new chains and do metadata updates using the Vault app.</p> <p>The procedure to sign transactions with the Vault app is as follows:</p> <ul> <li>The wallet or browser extension will show a QR code encoding the information about what you are   going to sign.</li> <li>After scanning the QR code with the Vault app, you will be presented with decoded information   about what you will sign. Make sure the information matches what you intended to sign in the first   place. If something does not feel right, do not sign. Check   this page for more information and   contact the Polkadot Support Team.</li> <li>If the information shown by the Vault app is correct, you can present the QR code (signature) to   the camera on your laptop to sign for the transaction.</li> </ul> <p>QR codes are signature-specific</p> <p>Note that QR codes are signature-specific. If someone by chance has access to the QR code signature for one of your transactions, future transactions cannot be signed with that same QR code, and it is impossible to find out the private key of your account only with that QR code.</p>"},{"location":"general/polkadot-vault/#update-the-vault-app","title":"Update the Vault App","text":"<p>Danger</p> <p>Ensure you always have your mnemonic seed phrase secure and available.</p> <p>To securely update the Polkadot Vault app follow the instructions here. Briefly,</p> <ul> <li>backup your accounts (Backup key Set &gt; write down the mnemonic seed phrase),</li> <li>factory reset your Vault app (Settings &gt; Wipe all Data),</li> <li>factory reset your phone,</li> <li>re-install the Vault app,</li> <li>go offline (airplane mode, no wifi),</li> <li>recover your accounts (Add Key Set &gt; Recover Key Set).</li> </ul>"},{"location":"general/polkadot-vault/#security-notes","title":"Security Notes","text":"<p>Remove SIM cards and Forget Networks</p> <p>To avoid unintended connection of your phone to the Internet, remove SIM cards, reset eSIM settings, and forget any added WiFi networks. In this way, the only possibility of having an unintended internet connection is either through the cellular network or through WiFi connection.</p> <p>The Vault app has a Log that will tell you all activities performed with it. It is important to mark down the last action, you did so that you can do a security check the next time you use the app. Also, the Vault app will always tell you if the phone has been (even briefly) connected to the Internet. In case of an unrecognized connection, it is recommended to:</p> <ul> <li>Backup your accounts (i.e. make sure you have the mnemonic seed phrases)</li> <li>Follow the steps in Update the Vault app</li> <li>Once offline, create a new account on the Vault app</li> <li>Import the compromised accounts and transfer the funds to the new non-compromised account.</li> </ul> <p>The Vault App has the option to export private keys</p> <p>If an account's private key has been exported from the Vault app, the public key will be marked as \"hot\" and the following message will be displayed This key is marked hot because its root private key has been exported.</p> <p>You might consider exporting the private key if you are switching air-gapped phone. If you choose to export your private key, avoid the following:</p> <ul> <li>Do not export your private key to a device that is connected to the internet, as your key will not   be \"cold\" anymore.</li> <li>Do not print private keys QR codes over an internet connection.</li> </ul>"},{"location":"general/polkadot-vault/#add-chains","title":"Add Chains","text":"<p>The Vault app contains default chain specs for Polkadot, Kusama, and Westend. It is possible to add more chains via QR-code, and update their metadata by generating your own QR-code fountain in a metadata portal similar to that signed by Parity. Alternatively, you can use a third-party provider to add chains and their metadata. Check this article for detailed instructions. If you choose this approach, you should trust the provider you choose.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about Polkadot Vault.</p>"},{"location":"general/polkadotjs-ui/","title":"Polkadot-JS UI (Wallet)","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The Polkadot-JS UI is the native application for accessing all features available on Substrate chains as Polkadot and Kusama. The UI is one of the moving parts of Polkadot-JS tool collection, and its functionalities go beyond normal wallet functionalities such as transfers.</p> <p>Note that the UI may not precisely align with the functionality of individual parachains. For more information see the Polkadot-JS Page.</p>"},{"location":"general/polkadotjs-ui/#main-functionalities","title":"Main Functionalities","text":"<p>Here we describe those functionalities that will likely be useful to most users. Those functionalities include account generation, balance transfers, and staking.</p>"},{"location":"general/polkadotjs-ui/#accounts","title":"Accounts","text":"<p>In this section of the UI, you can see accounts injected from a browser extension, such as the Polkadot-JS Extension or other in-browser wallets. It is also possible to expand balance details and see different account balance types. You can also:</p> <ul> <li>Add an account (this option must be enabled under Settings). Note that if you clear   the cache of your browser, you will lose it, and you will need to recover it through seed phrase   or JSON file.</li> <li>Recover and account from JSON file.</li> <li>Add an account from QR code.</li> <li>Add an account from a Ledger device (this option must be enabled under   Settings).</li> <li>Create a multi-signature account.</li> <li>Add a proxied account (see   Pure Proxies for more   information).</li> </ul> <p>For each account visible in the UI, you can perform different actions, including adding a proxy, setting an identity, and sending tokens.</p> <p>For more information about adding and recovering accounts, see the Account Generation page.</p>"},{"location":"general/polkadotjs-ui/#network-staking","title":"Network (Staking)","text":"<p>In this section of the UI, you can participate in staking. In the Staking menu you can access:</p> <ul> <li>The Overview tab showing active or waiting validators.</li> <li>The Accounts tab (visible only if you added an account) showing accounts that are currently   used for staking   (stash and staking proxy), bonded   amount, and nominations. In this tab, you can do staking-related transactions such as bonding more   funds or changing nominations. If you have   staking proxies here, you can use them   while signing for staking-related transactions.</li> <li>The Payouts tab (visible only if you added an account) showing any pending rewards that still   need to be paid out to you.</li> <li>The Pool tab showing all registered nomination pool   with the respective state (open, blocked, or destroying). This tab can also be used to create and   join a pool.</li> <li>The Targets tab showing detailed information about validators such as commission and return.   More information can be found in the Nominator Page.</li> <li>The Bags tab (visible only if you added an account) showing the bag you are in (\"My bags\") and   all bags within the bags list. Here (if   applicable), you can rebag accounts that do not belong to the bag you are in, and you can move   your account in front of the account having less stake than you.</li> <li>The Slashes tab showing if there are any global slashes.</li> <li>The Validator stats tab showing statistics for a chosen validator.</li> </ul>"},{"location":"general/polkadotjs-ui/#settings","title":"Settings","text":"<p>In this UI section, you can change general settings such as appearance and language. You can also:</p> <ul> <li>Allow local in-browser account storage. This is used to add accounts directly in the UI (which   differs from having an account injected from a browser extension).</li> <li>Choose to attach Ledger devices. This adds an account directly in the UI from a Ledger device.</li> </ul> <p>Under Settings you can also do the metadata update. Usually, if there is an update, this will be shown as a notification.</p>"},{"location":"general/polkadotjs-ui/#other-functionalities","title":"Other Functionalities","text":"<p>In this section, we describe those functionalities that will less likely interest the average user.</p>"},{"location":"general/polkadotjs-ui/#network","title":"Network","text":"<p>In addition to staking, in the Network section, you can also:</p> <ul> <li>See the Explorer with the most recent blocks and events.</li> <li>Inspect parachains.</li> </ul>"},{"location":"general/polkadotjs-ui/#governance","title":"Governance","text":"<p>In this section of the UI, you can participate in governance.</p>"},{"location":"general/polkadotjs-ui/#developer","title":"Developer","text":"<p>In this section of the UI, you can access advanced features such as:</p> <ul> <li>Query on-chain data</li> <li>Query the node using RPC calls</li> <li>Call extrinsics using your account (you are able to see this   option only if you have an account in the UI)</li> </ul> <p>The Extrinsic tab provides the use to access more granular functions such as pure proxies and time-delayed proxies, change nomination pool settings (nomination and roles) and use non-transfer proxies, destroy assets, and much more.</p>"},{"location":"general/polkadotjs-ui/#beginners-guide-to-polkadot-js","title":"Beginner's Guide to Polkadot-JS","text":"<ul> <li>Introduction to Polkadot-JS</li> <li>Create an account using Polkadot-JS</li> <li>Network Explorer on Polkadot-JS UI</li> </ul>"},{"location":"general/polkadotjs/","title":"Polkadot-JS Tooling","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>Polkadot-JS is a collection of tools that interfaces with Relay Chains and parachains in a granular way. Below we describe the different components of Polkadot-JS. For more information about Polkadot-JS you can consult the official documentation.</p>"},{"location":"general/polkadotjs/#polkadot-js-ui","title":"Polkadot-JS UI","text":"<p>Info</p> <p>Please note that this wallet UI is oriented toward developers and power users. Explore Polkadot with a secure and user-friendly wallets listed on the Polkadot website. If you need help using the Polkadot-JS UI you can contact the Polkadot Support Team.</p> <p>The Polkadot-JS UI is an application that loads in your browser. There is a standard DNS hosted version, which always has the latest features, and an IPFS version that is less frequently updated but is more decentralized. This is also often referred to as Polkadot-JS Apps, UI or the Apps UI. In the Wiki pages we will always refer to Polkadot-JS UI.</p> <p>Polkadot-JS Apps has many capabilities that go beyond basic wallet functions such as account creation and sending or receiving transactions. See the dedicated section for more information about the UI.</p>"},{"location":"general/polkadotjs/#polkadot-js-ui-desktop-app","title":"Polkadot-JS UI Desktop App","text":"<p>The Polkadot-JS UI also exists as a desktop application for Windows, Mac and Linux. The main advantage of using it is that by default it stores encrypted accounts on the filesystem instead of browser's local storage. Local storage is susceptible to attacks using XSS (Cross-Site Scripting). There's no such risk when with files stored on disk.</p> <p>The desktop app uses the Electron framework. It provides the same features as web app, the only difference being different account storage.</p> <p>Info</p> <p>The desktop application does not support Ledger accounts. If you need a cold storage solution you can try Parity Signer (aka Polkadot Vault).</p>"},{"location":"general/polkadotjs/#polkadot-js-extension","title":"Polkadot-JS Extension","text":"<p>The Polkadot-JS browser extension is not a wallet per se but an account management tool. It allows you to create accounts and also import accounts from Ledger devices or Parity Signer, allowing the signing of extrinsics using these accounts. It also allows you export existing accounts and restore accounts (given you have the required information to restore them).</p> <p>The extension is a robust key storage tool, i.e. even if you clear the cache of your browser your accounts will be retained. The extension will recognize any websites that have been flagged for malicious activity. For additional security, the extension will always ask if you want a specific website to access the account information on it.</p> <p>The extension does not let users interact directly with on-chain functions as one would find on a wallet app like Metamask, i.e. it does not allow you to transact or do anything else other than adding and managing accounts. However, it provides a simple interface for interacting with extension-compliant dApps such as the Polkadot-JS UI and the Polkadot Staking Dashboard. Check wallets and extensions page for wallets that are capable of transacting on-chain directly.</p> <p>Info</p> <p>The browser extension is a tool that interacts with the Polkadot network, but it is disconnected from it when it is not in use. It is important you always check for metadata updates before using the extension or other account management tools such as Parity Signer (aka Polkadot Vault).</p>"},{"location":"general/polkadotjs/#polkadot-js-phishing-list","title":"Polkadot-JS Phishing List","text":"<p>The Polkadot-JS phishing list website is a community-driven curation of malicious actors and operators. The Polkadot-JS extension uses this list to warn a user about suspicious URLs and addresses that are part of the list, and automatically blocks the account address.</p>"},{"location":"general/polkadotjs/#polkadot-js-api","title":"Polkadot-JS API","text":"<p>The Polkadot-JS API is a JavaScript API allowing for programs to interface with the functionalities of Polkadot.</p> <p>While interacting with the underlying @polkadot/api, most interfaces are generated automatically when connecting to an available node. This is quite a departure from many other API designs where the interfaces are commonly static.</p> <p>When the API connects to a node, it initially retrieves the metadata which is used to \"decorate\" the API based on its contents. The metadata provides data in the form of <code>api.&lt;type&gt;.&lt;module&gt;.&lt;section&gt;</code> where <code>type</code> fits into one of the following categories:</p> <ul> <li><code>consts</code> - runtime constants (these are not functions so the values are returned directly as they   are defined by the endpoint)</li> <li><code>query</code> - chain state values</li> <li><code>tx</code> - all extrinsics</li> </ul> <p>The metadata also provides information on events, which can be queried using the <code>api.query.system.events()</code> interface.</p> <p>None of the information contained within the <code>api.{consts, query, tx}.&lt;module&gt;.&lt;method&gt;</code> endpoints are hard-coded in the API. These values are defined by the decoration applied from the initial metadata response and are therefore completely dynamic. This suggests that when you connect to different parachains, the metadata and API decoration will change and provide varying interfaces based on the chain.</p> <p>A developer can use Polkadot-JS Apps to test code's functionality. Interacting with the Polkadot-JS comes down to either querying on-chain data or issuing an extrinsic.</p>"},{"location":"general/polkadotjs/#querying-on-chain-data","title":"Querying On-chain Data","text":"<p>To populate the Apps UI, the web app queries the Polkadot-JS API. The API then queries a node and uses JavaScript to return information that the UI will display on the screen. You can choose which node to connect to by changing it in the upper-left-hand corner of the screen.</p> <p>Let's see how we can query on-chain data with Polkadot-JS UI on the Polkadot network with an example. To find out the current value for existential deposit, navigate to Developer &gt; Chain state &gt; Constants and query the balances pallet for existential deposit as shown in the snapshot below. You need to click on the plus button to execute the query. The value displayed is in plancks</p> <p></p>"},{"location":"general/polkadotjs/#issuing-extrinsics","title":"Issuing Extrinsics","text":"<p>Extrinsics are pieces of information that come from outside the chain and are included in a block. Extrinsics can be one of three types: inherents, signed, and unsigned transactions.</p> <p>Most extrinsics displayed on Polkadot-JS Apps are signed transactions. Inherits are non-signed and non-gossiped pieces of information included in blocks by the block author, such as timestamps, which are \u201ctrue\u201d because a sufficient number of validators have agreed about validity.</p> <p>Unsigned transactions are information that does not require a signature but will require some sort of spam prevention, whereas signed transactions are issued by the originator account of a transaction which contains a signature of that account, which will be subject to a fee to include it on the chain.</p>"},{"location":"general/scams/","title":"How to Protect Yourself from Scams","text":"<p>Scams and hacks are an unfortunate reality of the crypto industry. It's important to stay alert and protect yourself and your non-refundable crypto assets from scammers and hackers. If you ever feel you have been the target of such an attempt or are currently targeted, please contact Polkadot Support.</p>"},{"location":"general/scams/#disclaimer-key-security","title":"DISCLAIMER: Key Security","text":"<p>One of the most attractive targets for malicious actors are your wallet secret seeds or the optionally exported backup JSON file. Keep them offline in a secure and private location. If you share these with anyone, they can access your account and execute any transaction.</p> <p> Stay Safe in Polkadot </p> <p>Info</p> <p>Visit this support article for more information about key security.</p>"},{"location":"general/scams/#essential-rules","title":"Essential Rules","text":"<ol> <li>Never ever share your seed phrase or backup JSON file with anyone. If you do that, you hand over    all your funds, so don\u2019t do it!</li> <li>Be careful with extensions/applications and typing in recovery seeds or importing backup JSON    files in there, they could be malicious or pretend to be a well-known wallet.</li> <li>Do not trust anyone online. Malicious actors often pretend to be someone else to gain your trust.</li> <li>If you are scammed, there is likely nothing that can be    done to recover your funds. If a scammer gets a hold of your seed phrase, they can transfer all    your funds to their account in seconds.</li> <li>If it sounds too good to be true, it probably is. People, especially celebrities, do not give    away crypto for free. Even if they wanted to, they could just ask for your address as opposed to    having you send them tokens.</li> <li>Scams are absolutely rife in this space. It is easy and cheap to set a scam up, and hard to shut    one down. Therefore, the user must be diligent to avoid such scams.</li> <li>If you can, always try to verify new information that you see through an official source, such as    Polkadot network's official blog or    Polkadot's Official Support. Often, scammers will fake a    websites or blog posts, but if you validate such information through a secondary source, you will    reduce the chances of being scammed.</li> </ol>"},{"location":"general/scams/#some-common-types-of-scams","title":"Some Common Types of Scams","text":"<ul> <li>Private messages sent to you over Telegram, X/Twitter, Discord, and other social media - admins or   employees will never contact you.</li> <li>\"Giveaways\" advertising that you \"send us some DOT/KSM, we'll send you double back\".</li> <li>Sites where you must enter your seed phrase to \"sync\" your account, claim tokens, unblock   transactions, etc.</li> <li>Emails asking for DOT/KSM private keys/seeds/etc., posing as a member of any of our teams.</li> <li>Scammers will take official videos and add \"giveaway\" text around them to look like Polkadot,   Kusama, Web3 Foundation, Parity, or another well-known entity supporting the giveaway.</li> <li>Many scammers will create nearly perfect imitations of sites - always triple-check the URL.</li> <li>People are offering to help you stake or get rewards.</li> <li>People responding to publicly asked questions in a private chat.</li> <li>Advertisements pointing to imitations of sites asking you to enter your seed words.</li> </ul> <p>These are just some of the types of scams. Scammers are inventing new ones all the time. In general, do not trust anyone messaging you that you did not message yourself, and be wary of anyone attempting to help you or offer you a \"deal\".</p> <p>Scammers will often imitate the usernames, profile pictures, etc., of well-known members of the community. Often the differences in these accounts will be minor, such as <code>joe_sm1th</code> or <code>jo_smith</code> instead of <code>joe_smith</code>. Sometimes, the display name will be identical if uniqueness is not enforced; check over a 2<sup>nd</sup> (ideally verifiable) communication channel to be sure you are talking to the right person.</p> <p>Scammers often make it seem like the \"deal\" is only available for a limited time. Do not be tricked by this, it is always better to confirm than to risk losing everything.</p>"},{"location":"general/scams/#admins-will-never-contact-you-directly","title":"Admins will never contact you directly","text":"<p>If you received a message from an admin over Telegram, ignore it. Our team members will never personally message you. Our social media accounts are posted on our website, and our team will announce any new ones. We will never offer to sell you DOT at a discount, air-drop \"rewards\", or message you privately to help with a problem you posted publicly. Our social media and community pages can be found here.</p>"},{"location":"general/scams/#keep-your-data-secure","title":"Keep your data secure","text":"<p>You should never share your seed phrase, passwords, private keys, or any other personal data with anyone. If you are concerned a wallet could be fake, please check out our list of well-known wallets.</p> <p>Some simple things that you can do to keep your assets and information secure from hackers:</p> <ul> <li>Keep your seed phrase only on paper, in a secret and secure location.</li> <li>DO NOT keep your seed phrase on any electronic medium connected to the internet, e.g., cloud   services, password managers, your daily computer, etc.</li> <li>Never enter your seed or mnemonic phrase directly into a website.</li> <li>Your seed phrase is a backup in case you lose access to your wallet. Use it only for that purpose   and only in wallets you've used before and trust.</li> <li>Your passwords should be strong and unique. It is recommended that you use a   password manager app   to create and store your passwords. Use fido2 (hardware dongles) for best security, not google   authenticator/OTP.</li> <li>Keep your computer free of malware. Although an antivirus can be of great help, it's not a   panacea. Safe browsing and downloading is the only way to be sure your computer is clean. Beware   of unvetted (not security-scanned) software, such as extensions, 3<sup>rd</sup> party software, and   registries/repositories that come in many forms and shapes.</li> <li>Store your assets in cold storage, like a hardware wallet or   Polkadot Vault.</li> </ul>"},{"location":"general/scams/#always-check-the-source","title":"Always check the source","text":"<p>For any potential scam, always do a background check on the source, i.e., look at any username, email, YouTube channel name, URL, etc. If something seems fishy, that's because it likely is. Never enter any personal data if you feel the source could be a scam. Feel free to check with Polkadot's official support.</p>"},{"location":"general/scams/#check-twice-before-sending-dotksm","title":"Check twice before sending DOT/KSM","text":"<p>A good practice to consider is to verify the address to which you are sending crypto. You shouldn't be sending your assets to an account you do not know or are not familiar with. Crypto is a decentralized space with no room for errors.</p>"},{"location":"general/scams/#install-the-polkadot-js-extension","title":"Install the Polkadot-JS extension","text":"<p>The extension uses crowd-sourced anti-phishing measures to automatically prevent your browser from displaying known phishing or scam sites. They will be blocked upon loading, helping to prevent you from visiting these sites and thus falling for them.</p>"},{"location":"general/scams/#our-official-sites","title":"Our official sites","text":"<p>You can use the following list of our official domains to make sure that you're visiting an official site:</p> <ul> <li>https://polkadot.com</li> <li>https://polkadot.io</li> <li>https://kusama.network</li> <li>https://web3.foundation</li> <li>https://parity.io</li> <li>https://docs.polkadot.com/</li> </ul> <p>Of course, many projects building on Polkadot and Kusama use similar names. If, however, a site poses as Polkadot, Kusama, Web3 Foundation, or Parity on a domain not listed above, then it's most likely a scam.</p> <p>Besides those, there are also <code>polkadot.js.org</code> and <code>dotapps.io</code> that host our web wallet and other tools.</p>"},{"location":"general/scams/#i-got-scammed-what-can-i-do","title":"I Got Scammed - What Can I Do?","text":"<p>In the unfortunate case of having fallen for a scam, nothing can likely be done to recover your funds. However, you can still receive help and support. The Polkadot Support Team stands ready to help you in this difficult situation. Please check this Support Article for steps you should take to prevent further loss and contact Polkadot Support from the same page.</p>"},{"location":"general/staking-apps/","title":"Polkadot Staking Apps","text":"<p>Community Page</p> <p>This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your protocol native, permissionless, non-custodial NPoS Staking app to this page.</p> <ul> <li>Polkadot Staking Dashboard</li> <li>Sub.ID</li> <li>NOMI</li> <li>SubWallet Earning</li> </ul>"},{"location":"general/staking-apps/#polkadot-staking-dashboard","title":"Polkadot Staking Dashboard","text":"<p>The Polkadot Staking Dashboard is a web3 application dedicated to native non-custodial staking on the relay chain. The dashboard allows to stake as a solo nominator or as a nomination pool member. Users can also create their nomination pools. The dashboard supports Ledger, Polkadot Vault, SubWallet, Talisman, WalletConnect, Fearless Wallet, PolkaGate, and Enkrypt. The dashboard also supports staking proxies.</p> <p>You can find more information about the Polkadot staking dashboard on the dedicated wiki page and support articles.</p> <p>Below a list of video tutorial about the Polkadot Staking Dashboard.</p> <p>Stake Your DOT</p> <p>Join a Nomination Pool</p> <p>Staking Dashboard Walkthrough</p> <p>After Staking</p> <p>Create, Manage &amp; Destroy Pools</p>"},{"location":"general/staking-apps/#subid","title":"Sub.ID","text":"<p>Sub.ID is a one-stop-shop for managing your Polkadot accounts, viewing your addresses and balances, and looking at other accounts. It features a Polkadot staking page, where you can easily start staking. Stakers can choose their preferred validators or stake with the recommended validator set.</p>"},{"location":"general/staking-apps/#nomi","title":"NOMI","text":"<p>NOMI is designed to actively involve nominators in native staking on the relay chain. It aims to offer a unique and enhanced nomination experience, using Multiple-Criteria Decision Analysis (MCDA) as a base for the analytical research. MCDA is an open and transparent approach for evaluating numerous conflicting traits in the decision-making process. For the analysis, validator data is collected at the last block of every session.</p> <p></p> <p>source: https://github.com/turboflakes/apps</p>"},{"location":"general/staking-apps/#subwallet-earning","title":"SubWallet Earning","text":"<p>SubWallet Web Dashboard is the all-in-one solution to manage assets and stake on multiple networks in the Polkadot, Kusama and Polkadot SDK (Substrate) ecosystems.</p> <p>The Web Dashboard features an Earning tab which allows users to stake DOT easily via native nomination pools, as well as in liquid staking and lending protocols, without having to manage multiple applications with different interfaces and experiences.</p>"},{"location":"general/start-building/","title":"Build on Polkadot","text":""},{"location":"general/start-building/#polkadot-sdk","title":"Polkadot SDK","text":"<p>The Polkadot SDK repository provides all the resources needed to start building on the Polkadot network, a multi-chain blockchain platform that enables different blockchains to interoperate and share information in a secure and scalable way. The Polkadot SDK comprises three main pieces of software:</p> <ul> <li>Polkadot Node</li> <li>Substrate Blockchain SDK</li> <li>Cumulus Tool Suite for Parachains</li> </ul> <p>The programming language used for development is Rust.</p> <p>Info</p> <p>For more information about building on Polkadot, see the Builder's Guide.</p>"},{"location":"general/start-building/#requests-for-comment-rfcs","title":"Requests for Comment (RFCs)","text":"<p>With the release of Polkadot runtime 1.0, Polkadot's codebase is in the hands of the community. Anyone can open a Request for Comment (RFC) to propose and discuss changes to the network protocol, runtime logic, public interfaces, and other technical matters.</p> <p>To submit an RFC, follow the instructions here.</p> <p>RFCs can only be approved and merged by III-Dan members of Polkadot Technical Fellowship via on-chain voting mechanism. Definitive approval or rejection is done by issuing the <code>RFC_APPROVE(xxxx, h)</code> or <code>RFC_REJECT(xxxx, h)</code> on-chain remark from the Fellowship origin on the Polkadot Collectives parachain, where <code>xxxx</code> is the RFC number and <code>h</code> is the hash of the raw proposal text.</p> <p>For example, the first RFC RFC-1 about Agile Coretime was proposed by Gavin Wood on the 30<sup>th</sup> of June 2023 and merged on the 12<sup>th</sup> of August 2023. Subsequently, the code for the Agile Coretime Broker pallet was added to the Substrate FRAME system.</p> <p>In general, the workflow from RFC write-up submission to its implementation follows the timeline below:</p> <ul> <li>RFC submitted by following the instructions.</li> <li>RFC review by the Technical Fellowship via GitHub</li> <li>Polkadot Technical Fellowship Referendum of the RFC submitted to the Track <code>3 / Fellows</code> by   members with a rank greater than or equal to 3.</li> <li>If the Referendum is approved through on-chain vote by the Technical Fellowship, changes discussed   in the RFC will be implemented.</li> <li>If the changes requested through the RFC require a broader consensus of DOT holders, an OpenGov   referendum may be created. For instance,   adding a new system collective   or making changes to network parameters like inflation rate, treasury inflow etc.</li> </ul> <p>Note</p> <p>Although the Technical Fellowship maintains the runtimes of Polkadot and Kusama, changes to the network protocol are not gated by the fellowship. Any DOT holder can submit a referendum on the Polkadot OpenGov Root track to set the runtime code with the proposed changes.</p> <p>For more information about the adoption of RFCs within the Polkadot ecosystem, see this Medium article and the original Polkadot Forum post.</p>"},{"location":"general/thousand-contributors/","title":"Thousand Contributors Program","text":"<p>The Thousand Contributors Program is an initiative maintained by Web3 Foundation's Technical Education and Support team to offer an off-chain contributor program to support and reward community contributions. The program focuses on rewarding contributors in the areas of technical education, community, and support that relate to the Polkadot and Kusama ecosystems.</p> <p>Note</p> <p>The pilot phase of Thousand Contributors Program has ended   You can still submit your intent to participate. The submissions will be reviewed and accepted on a case-by-case basis.</p>"},{"location":"general/thousand-contributors/#how-to-participate","title":"How to Participate","text":"<p>You can signal your intent to participate by:</p> <ol> <li>Choosing a task from this list of open tasks</li> <li>Then fill out this typeform</li> </ol>"},{"location":"general/thousand-contributors/#process","title":"Process","text":"<p>Once you have submitted your contribution proposal, the team will:</p> <ol> <li>Evaluate. Your evaluators will differ depending on which area you want to    contribute.</li> <li>Accept or deny. Once we review your proposal, we will get in touch with you about the status.</li> <li>Define your delivery. All tasks will have different delivery requirements; we will communicate    what your contribution needs to fulfill.</li> <li>Fund. Once both parties finalize the delivery of the task, the team will deposit your rewards to    the account shared with us.</li> </ol>"},{"location":"general/thousand-contributors/#submission-reviews","title":"Submission reviews","text":"<p>The review process follows the present pipeline in the 1KC public GitHub project.</p> <p>Learn more about the program and its components on the official 1KC repository</p>"},{"location":"general/transaction-attacks/","title":"Why Verify Transactions?","text":"<p>In general, an attacker would make you think you are signing a Transaction A when in reality you are signing a Transaction B. An Attack might come from:</p>"},{"location":"general/transaction-attacks/#clipboard-memory","title":"Clipboard Memory","text":"<p>Info</p> <p>For a more detailed read about clipboard memory attacks see this article.</p> <p>This is a common attack. The clipboard memory is that memory on your computer dedicated to copy-paste operations. There is malicious software that can be remotely installed on your computer and that can detect when a cryptocurrency address is copied. For example, you want to send funds to Address A (belonging to you) but after copying address A a malicious software swaps that address with Address B (belonging to an attacker). This attack can be prevented by checking the receiver address before signing. Failing to do so could result in loss of the funds.</p>"},{"location":"general/transaction-attacks/#malicious-websitedapp","title":"Malicious Website/dApp","text":"<p>This is a common attack that can happen if you are interacting with a malicious site (dApp). In this scenario you want to perform Transaction A on the website, but the dApp will send Transaction B to the extension for signing. In this case the extension will show Transaction B. If you are using a Ledger device you have a second layer of verification, as it will also display Transaction B.</p>"},{"location":"general/transaction-attacks/#malicious-browser-extension","title":"Malicious Browser Extension","text":"<p>This scenario can happen if you have downloaded a malicious browser extension or a trusted browser extension, from a non-trusted source. In this scenario the extension will display that you will sign for an Transaction A but in the background will execute Transaction B. If you are using a Ledger device this attack can be detected because you will be able to see Transaction B on the screen of your Ledger device.</p>"},{"location":"general/transaction-attacks/#corrupted-metadata","title":"Corrupted metadata","text":"<p>This attack is least common and might result in signing a non-intended transaction without the possibility of verifying it. Before authorizing the metadata update check who is requesting it. Metadata updates for browser extensions might be requested by dApps (for example DeFi apps of parachains). For the extensions, you should trust the app that requests the update. When updating the metadata for Parity Signer you should trust the issuer of the metadata (or generate the QR fountain yourself).</p>"},{"location":"general/transaction-attacks/#corrupted-qr-code-parity-signer","title":"Corrupted QR-code (Parity Signer)","text":"<p>This is a sub-case of the malicious dApp scenario. If your account is on Parity Signer the transaction will be displayed as a QR code, instead of the extension showing its details and you need to verify it on the device. The corrupted QR code will make you sign for an Transaction B when you want to sign for Transaction A. This will be showed in the Signer app and a careful user will notice it. If the metadata in the Signer is already incorrect (or the Signer is corrupted) there is the risk of signing a non-intended transaction without the possibility of verifying it.</p>"},{"location":"general/transaction-attacks/#replay-attack","title":"Replay Attack","text":"<p>A replay attack is where past transactions can be replayed (same balance, receiver account, etc.) without knowing private keys. It is an attack where publicly known data can be \"replayed\" as a new extrinsic. This could happen in the context of reaping accounts because the reaping process resets the nonce value. If all signed transactions until the nonce before the reaping event were immortal, all past transactions can be replayed once the account is refunded. There is no need for the attacker to know your private key, valid signatures for those past transactions and nonces already exist and are stored on-chain (meaning the private key was already used to generate those signatures).</p> <p>Making a transaction mortal with a relatively short mortality window will almost certainly ensure that replay attacks are not possible, with the only exception being if the account is reaped and then re-funded shortly after submitting a mortal transaction, and then an attacker replays that transaction within the mortality window (i.e., the specified block interval) and such transaction is valid (e.g. if you only have 10 DOT, and you try to issue an extrinsic sending 20 DOT, the transfer will fail).</p>"},{"location":"general/transaction-attacks/#defense-against-attacks","title":"Defense against Attacks","text":"<p>Warning</p> <p>If you can't verify the transaction or you suspect you are signing something different than what you intended, don't sign it!</p> <p>To avoid being victim of an attack:</p> <ul> <li>Use only trusted extensions, sites and software in general.</li> <li>Use cold storage options (Ledger, Signer) and verify them. Trust what these devices tell you over   what is shown in the app or the browser extension.</li> <li>Update Signer metadata only from trusted sources (or do it yourself).</li> <li>Accept metadata updates for the extension only from trusted apps.</li> </ul>"},{"location":"general/wallets-and-extensions/","title":"Wallets and Extensions","text":"<p>Caution</p> <p>Using your due diligence in researching and using the wallets listed below would be best. For any issues related to these wallet, reach out to their support teams directly.</p> <p>Info</p> <p>Explore Polkadot with a secure and user-friendly wallets listed on the Polkadot website.</p> <p>If you are new to blockchain technology, generally a typical blockchain network account is a public-private key pair. Access to a private key gives full access to all the allowed transactions on that blockchain account. It is essential to keep the private key secure.</p> <p>Typically, the account keys are either stored and accessed through a browser extension or a smartphone app (which are considered as a hot wallets as they are online), or an air-gapped device or a hardware wallet (which are considered as cold wallets as they are offline).</p> <p>Not your keys, not your tokens!</p> <p>With custodial wallets (like accounts in centralized exchanges), another party controls your private keys. Private keys are used to access funds in your account, so you trust the exchange that your key will always be given to you whenever you need it. With non-custodial wallets, only you can access your account's private key.</p> <p>To realize Polkadot's multichain vision, it is important to have non-custodial wallets that make it convenient to interact with multiple blockchains within the Polkadot ecosystem. Below there is a list of all non-custodial treasury-funded wallets developed by the community.</p>"},{"location":"general/wallets-and-extensions/#overview","title":"Overview","text":""},{"location":"general/wallets-and-extensions/#browser-extensions","title":"Browser Extensions","text":"<p>At a bare minimum, browser extension wallets act as key storage and management solution, allowing you to use your accounts with apps in the Web3 space. The wallets listed below offer functionality beyond that, allowing the featured actions to be performed directly through the extension. Some of them also allow interaction with air-gapped wallets and hardware devices.</p> Wallet Browsers Staking and Nomination Pools NFTs Crowdloans Ledger support Governance Other features Enkrypt Brave, Chrome, Edge, Firefox, Opera, Safari No, No Yes No Yes No Enkrypt Features PolkaGate Brave, Chrome, Firefox, Edge Yes, Yes Yes Yes Yes Yes PolkaGate features SubWallet Brave, Chrome, Edge, Firefox Yes, Yes Yes Yes Yes No SubWallet features Talisman Brave, Chrome, Edge, Firefox Yes, Yes Yes Yes Yes No Talisman features Fearless Wallet Brave, Chrome No, No Yes No No No Fearless Wallet Features <p>Ledger support only for chromium-based browsers</p> <p>Currently, all browser extensions support Ledger devices only on chromium-based browsers (i.e. Chrome, Brave, Edge, Opera).</p>"},{"location":"general/wallets-and-extensions/#mobile-wallets","title":"Mobile Wallets","text":"<p>Mobile wallets are fully packaged apps that allow all the featured actions, as well as the storage and management of your accounts, through the mobile app. Unlike browser extensions, mobile wallets usually can\u2019t connect to third-party web apps. Some mobile wallets provide support for hardware wallets through Bluetooth connectivity.</p> Wallet Platforms Staking and Nomination Pools NFTs Crowdloans Ledger support Governance Proxy Accounts Other features Fearless Wallet iOS, Android Yes, Yes No Yes No No No Fearless Wallet Features Nova Wallet* iOS, Android Yes, Yes Yes Yes Yes Yes Yes Nova Wallet features Polkawallet iOS, Android Yes, Yes No Yes No Yes No Polkawallet features SubWallet iOS, Android Yes, Yes Yes Yes No No No SubWallet features <p>Note about Nova wallet</p> <p>There's another Nova wallet that is unrelated to the Polkadot ecosystem. Users are advised to ensure that they use the correct Nova wallet by downloading the app from their official website. Before creating or restoring accounts, it is wise to double-check the wallet website URLs through official channels (most projects have it listed on their official social media handles).</p>"},{"location":"general/wallets-and-extensions/#web-wallets","title":"Web Wallets","text":"<p>Web Wallets are the all-in-one solution to accessing the Web3 space, allowing you to sign transactions on the web without having to download and install any browser extension and mobile app. With all of the features of mobile wallets, you can also connect to and interact with decentralized web apps.</p> Wallet Platforms Staking and Nomination Pools Liquid Staking NFTs Crowdloans Ledger support Governance Other features SubWallet Any web browsers Yes, Yes Yes Yes Yes Yes No SubWallet features"},{"location":"general/wallets-and-extensions/#telegram-wallets","title":"Telegram Wallets","text":"<p>Telegram Wallets are applications running ontop of the Telegram Messenger platform. These wallets typically provide a streamlined user experience and provide an easy way for new users to get started in the Polkadot ecosystem without having to download any new applications.</p> Wallet Platforms Self-Custodial Send Tokens to Telegram Username Send Tokens to any Address Notifications Other features Telenova Mobile, Desktop, Web Yes Yes Yes Yes Telenova Features"},{"location":"general/wallets-and-extensions/#enkrypt","title":"Enkrypt","text":"<p>A multichain crypto wallet - Bitcoin, Ethereum, Polkadot, Kusama and a few parachains. Non-custodial, private, hardware wallet support (Ledger and Trezor). Private and open source. Hold, send, and receive tokens and NFTs. Swap tokens and bridge assets between chains. Manage multiple accounts on multiple networks. Connect to web3 apps. Recipient of a development grant from Web3 Foundation.</p>"},{"location":"general/wallets-and-extensions/#fearless-wallet","title":"Fearless Wallet","text":"<p>The Fearless DeFi Wallet for the Future. Simply, intuitively, and fearlessly interact with Web3. Currently supports Staking, Crowdloans, Parachain Accounts, Nomination Pools Native Staking, dApp Signer on desktop through your mobile phone (experimental), Chromium-based browser extension. Safety features such as Scam Address Warning and Network Failure Warnings help fearlessly navigate web3. Formerly funded and supported by Kusama Treasury [1, 2, 3, 4, 5], and the SORA community [1], developed by SORAMITSU. Stay Fearless!</p>"},{"location":"general/wallets-and-extensions/#nova-wallet","title":"Nova Wallet","text":"<p>A user-friendly wallet for the Polkadot &amp; Kusama ecosystems, providing a smooth web3 experience on both iOS and Android. Nova Wallet supports Polkadot OpenGov (including agile delegations), Governance v1 (including support for parachain governance), Staking, NFT management, XCM Transfers, Parity Signer &amp; Ledger Support, DApp Support with Polkadot JS and Metamask/EVM Integration and crowdloans. Nova Wallet received funding from Kusama Treasury [1, 2], as well as funding from the Polkadot Treasury [1].</p>"},{"location":"general/wallets-and-extensions/#polkagate","title":"PolkaGate","text":"<p>The PolkaGate extension, funded by the Kusama Treasury [1, 2] is a feature-rich wallet for the Polkadot and Kusama ecosystems. It simplifies account management with export, import, derivation tools, Ledger integration, and watch-only accounts. Key features include governance participation, vote delegation, identity management, proxy management, pool staking, solo staking, crowdloans, and parachain account handling. Additional tools include NFT support, phishing detection, spam address warnings, light clients, and optimized remote node selection. PolkaGate also tracks balances in multiple currencies, manages transaction histories, and generates QR codes for addresses\u2014offering a seamless and secure blockchain experience.</p>"},{"location":"general/wallets-and-extensions/#polkawallet","title":"Polkawallet","text":"<p>Polkawallet provides cross-chain asset one-stop management, convenient staking, governance, and multiple DeFi services; the private key is self-owned. Polkawallet received funding from Kusama Treasury [1, 2].</p>"},{"location":"general/wallets-and-extensions/#subwallet","title":"SubWallet","text":"<p>A non-custodial Polkadot, Substrate &amp; Ethereum wallet. Track, send, receive, and monitor multi-chain assets on 150+ networks. Import account with seed phrase, private key, QR code, and JSON file. Import token &amp; NFT, attach read-only account. XCM Transfer, NFT Management, Parity Signer &amp; Ledger support, light clients support, EVM DApp support, MetaMask compatibility, custom endpoints, fiat on-ramp, phishing detection, transaction history. SubWallet received funding from Polkadot Treasury [1, 2, 3, 4].</p>"},{"location":"general/wallets-and-extensions/#talisman","title":"Talisman","text":"<p>A better way to explore Web3. Keep your assets safe, manage your portfolio and explore Polkadot and Ethereum apps with Talisman. Interact with Web3 apps, store your favourite crypto assets and manage your accounts on over 150+ Substrate and EVM networks. NFT Management, ledger Support, fiat On-ramp, portfolio tracking. Talisman received funding from Polkadot Treasury [1].</p>"},{"location":"general/wallets-and-extensions/#telenova","title":"Telenova","text":"<p>Telenova is a brand new self-custodial Polkadot wallet that runs directly in Telegram providing you with a simple and clean user interface to manage your DOT &amp; KSM tokens. Send crypto to anyone in Telegram, Buy/Sell DOT and KSM tokens, get notified about your balance changes, view your total balance in multiple fiat currencies, secured by your personal Telegram cloud and manual backups.</p> <p>Use Telenova on any of your devices \u2014 be it mobile or desktop \u2014 within the same Telegram account, and start exploring the Polkadot ecosystem today!</p>"},{"location":"general/web3-and-polkadot/","title":"Web3 and Polkadot","text":"<p>Back in the early 2000's the internet featured read-only, static, basic web pages. The online connected world at the time was only the beginning of virtual data, identities, and more. The internet during this time can be viewed as its first version (Web1).</p> <p>As social media platforms and online businesses began to emerge, the internet transformed into its next iteration - the Web2. This upgraded internet, which we use today, features dynamic, interactive web pages, where users can read and write information and publish their own for others to see. However, this version of the web comes with downsides, dealing with data control, privacy issues, and the consequences of trusting centralized entities to store our data on their servers. This is where Web3 comes into the picture.</p> <p>Web3 is transforming applications hosted on centralized infrastructure into decentralized applications (dApps) powered by trust-free blockchain protocols. The goal is to transform the internet into a decentralized web, where users control their data and identity in a trust-free environment. The Web3 movement aims to remove intermediaries and build trustless infrastructure. Web3 is an interactive and collaborative web where users can read, write, and own data.</p> <p>Note</p> <p>To learn more about the Web3 movement, check out this video from the Web3 Summit</p>"},{"location":"general/web3-and-polkadot/#data-ownership","title":"Data Ownership","text":"<p>In web3, ownership is achieved and validated through cryptography. Each user has a digital identity bound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the famous public and private key pair.</p> <p>Unlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3 just need to generate a key pair. The public key can be the identity that can be shared with anybody to send you messages or assets, while the private key is used to access your account, sign messages, transfer funds, edit identity details, etc. Keeping your private key secure is essential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main factors hindering web3 adoption. No legitimate person or entity will ever ask you to share your private key, and those who attempt to do so are likely trying to steal your digital identity and anything you own related to it.</p> <p>To mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody of your keys) there are account abstraction solutions that separate the key management from the user experience. To mitigate key hacks, there are cold wallet solutions where the private key is generated and stored on dedicated devices with secure elements that are not exposed to the internet (see Ledger), or dedicated applications that can be installed on air-gapped devices such as phones (see Polkadot Vault). For custodial accounts, you trust third parties to manage your keys and give you access whenever needed.</p> <p>To summarize, data ownership comes from the fact that any message you sign with your private key comes from your digital identity, and the signature proof can be cryptographically verified. Unless someone else stole your keys, you and only you are held accountable for signing the messages and are responsible for the information on your account. Transferring an NFT between two accounts is essentially a transfer of ownership.</p>"},{"location":"general/web3-and-polkadot/#trustless-environment","title":"Trustless Environment","text":"<p>Cryptography also brings the possibility of building a trustless environment where we do not have to trust third parties, or have any relationship between the sender and receiver of a message. We do not need to trust centralized entities since we can verify who wrote the message and who owns what just by using cryptography. Trust is embedded in the code. Well-audited and reviewed code ultimately provides a solid, trustless environment.</p>"},{"location":"general/web3-and-polkadot/#data-immutability","title":"Data Immutability","text":"<p>But what if the data we own can be easily modified or tampered with after they have been signed and stored?</p> <p>Here is where blockchain technology plays an important role. Blockchain networks comprise of distributed state machines where increments of data are stored within blocks that build on each other using hash functions. For example, the hash of block <code>N + 1</code> contains data of that block together with the hash of the previous block <code>N</code>. This creates the situation where if you modify the content of block <code>N</code> you will change the hash of block <code>N + 1</code>, <code>N + 2</code>, etc. essentially breaking the chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an invalid block (a block with invalid transactions) or to censor certain transactions. In decentralized proof-of-stake blockchains like Polkadot however, such attacks are financially expensive and attempting them can get you slashed.</p> <p>So, with blockchain as a means of storing data and transactions permanently without an option to modify them, we can ensure what we cryptographically sign with our digital identity is set in stone digitally.</p>"},{"location":"general/web3-and-polkadot/#data-retrievability","title":"Data Retrievability","text":"<p>But what if our data are stored in a blockchain, but that blockchain is run on a centralized server or by different computers belonging to the same operator?</p> <p>That server or those computers can be easily shut down, the blockchain can be stopped from running and its data wiped out. This can be achieved from the inside by the malicious network participants or from the outside by regulatory rules and other forces. Though blockchain offers immutability, there would be little sense in using a centralized blockchain to prove ownership as it can possibly cease to exist in the future.</p> <p>Data retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through elements such as decentralization, economic incentives, and on-chain governance to ensure the network can sustain on its own.</p> <p>!!!info Data Retrievability vs. Data Availability</p> <p>Data retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.</p> <p>Data availability assures full nodes can access and verify the full transactions associated with a specific block. It does not necessarily imply that the data is accessible forever. For more information about data availability on Polkadot, see the dedicated section on the parachain protocol page.</p>"},{"location":"general/web3-and-polkadot/#decentralization","title":"Decentralization","text":"<p>Having multiple nodes belonging to numerous independent identities increases network resiliency and thus data retrievability.</p> <p>Blockchain is a state machine, and consensus must be achieved on every single state transition by every node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node in the network produce a block, consensus is achieved probabilistically by building on the longest chain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like Polkadot enable deterministic consensus by allowing only a limited number of privileged nodes to produce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of network nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls more than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic consensus. Different blockchains have different levels of decentralization.</p> <p>Nowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is typically rented through service providers. Resiliency is also achieved by ensuring nodes run on as many different providers as possible and avoiding a significant share of the nodes being run under the same provider in the same geographic region. A legislation change or a natural disaster could impact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of decentralization can be explored through the Polkawatch app.</p> <p>The Decentralized Nodes program aims to incentivize the creation of new validator nodes to increase the level of node decentralization.</p>"},{"location":"general/web3-and-polkadot/#decentralized-storage","title":"Decentralized Storage","text":"<p>Blockspace is limited and valuable. Not all data we have can be stored on the blockchain. Large files like pictures, music, movies, etc., typically will never be held on the blockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient and decentralized storage solution.</p> <p>The most important thing is that the proof of ownership is stored on the blockchain through the hashes of data and metadata. The files are uploaded on decentralized storage networks hosting protocols like IPFS.</p>"},{"location":"general/web3-and-polkadot/#stake-allocation","title":"Stake Allocation","text":"<p>In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial security). In a decentralized network, you want to ensure that the difficulty level for a financial attack to happen is equally difficult across all nodes. Polkadot's election algorithm makes sure that the stake is maximized across all active validators, and the variance in stake across validators is minimized as much as possible.</p>"},{"location":"general/web3-and-polkadot/#economic-incentives","title":"Economic Incentives","text":"<p>Strong incentives are essential to incentivize network participants to run nodes and secure the network. Strong incentives are possible because blockchain is a trustless system where there are no intermediaries between who sends a message and who receives it. Such incentives, coupled with punishment for bad behavior, ensure that most of the participants make the interest of the network and work together to improve it.</p> <p>But from where are those incentives coming from? Polkadot's native token DOT is inflationary. Inflation is used to pay validators for running nodes and reward nominators for providing the necessary stake to secure the network.</p>"},{"location":"general/web3-and-polkadot/#governance-and-treasury","title":"Governance and Treasury","text":"<p>In Polkadot, an on-chain treasury together with an open governance model allow to access funds in a fully decentralized manner without any bank transaction whatsoever. This opens up the possibility to come to a decision through on-chain voting mechanism, promoting a sense of community and creating an independent socio-economical environment.</p>"},{"location":"general/web3-and-polkadot/#decentralized-access-points","title":"Decentralized Access Points","text":"<p>But what if we have data we own stored on a resilient blockchain, but the only way to access the blockchain is through an RPC server? Whoever is behind the server or an attacker could present us data that is not the truth. How can we trustlessly verify that the data is true?</p> <p>Here is where light clients play a key role. Light clients are clients that can sit on a web browser and can fetch data directly from blockchain. The figure below shows the architectural difference between web2 and web3 applications.</p> <p></p> <p>In web2 applications, data are stored on a centralized server, while in web3 applications, data (or better data proofs) are stored on the blockchain. With light clients, it is possible to access blockchain data through a full node and verify the validity of such data. They efficiently synchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of the latest chain state, and hence can trustlessly verify any response by full node against the commitment. In this way, we can always verify that the data we see is the truth, which is done automatically by the light client. Polkadot has a browser-embedded light client Substrate connect that uses the smoldot codebase. Most web3 applications today access blockchain data through a centralized RPC server.</p> <p>For more details about the inner workings of Smoldot, see this blog post and this video.</p>"},{"location":"general/web3-and-polkadot/#interoperability","title":"Interoperability","text":"<p>The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for interoperability. Blockchains compete and differentiate themselves based on decentralization, throughput, and specific use case focus. Some aim for a single high-performance base-layer blockchain, while others focus on decentralization through layer-2 networks. With such diverse approaches, it's crucial for distinct on-chain environments to interoperate, especially for developers building cross-chain applications and traditional systems interacting with multiple blockchains.</p> <p>Various cross-chain interactions are employed to achieve interoperability, including token swaps, token bridges, native payments, contract calls, and programmable token bridges. Each mechanism serves specific functions, such as facilitating the exchange of tokens between different blockchains or enabling smart contract interactions across chains. Other interoperability solutions validate the state of a source blockchain and relay transactions to the destination blockchain, which is essential for completing cross-chain interactions.</p> <p>Interoperability between chains having different consensus has been a challenging task. Most of hacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure interoperability through XCM and XCMP to all blockchains attached to it. For more information, see the Polkadot 1.0 page and the section about XCM and Accords in Polkadot Direction page.</p>"},{"location":"general/apps/","title":"Apps","text":"<p>Explore the different applications in the Polkadot and Kusama ecosystems.</p> <ul> <li>Polkadot Ecosystem Apps - Explore Polkadot ecosystem apps.</li> <li>DotAppStore - Access DotAppStore.</li> <li>Staking Apps - Information on staking apps.</li> <li>Governance Apps - Details on governance apps.</li> <li>Multisig Apps - Information on multisig apps.</li> <li>NFT Projects - Learn about NFT projects.</li> <li>Parachains Apps - Information on parachains apps.</li> </ul>"},{"location":"general/community/","title":"Community &amp; Contributors","text":"<ul> <li>Community - Information about the community.</li> <li>Contributing - How to contribute.</li> <li>Contributors - List of contributors.</li> </ul>"},{"location":"general/dashboards/","title":"Dashboards","text":"<ul> <li>Dune Analytics - Access Dune Analytics dashboards.</li> <li>Parity Data Dashboards - Parity data dashboards.</li> <li>Staking Dashboard - Staking dashboard.</li> <li>Fellowship Dashboard - Fellowship dashboard.</li> </ul>"},{"location":"general/dashboards/parity-data-dashboards/","title":"Parity Data Dashboards","text":""},{"location":"general/dashboards/parity-data-dashboards/#accessing-polkadot-ecosystem-dashboards","title":"Accessing Polkadot Ecosystem Dashboards","text":"<p>The Parity Data Team has made publicly available a website that displays a number of dashboards relating to Polkadot Ecosystem On-Chain data. The graphs provided are grouped into the following sections:</p> <ul> <li>Stablecoins - metrics around stablecoins   in Polkadot AssetHub.</li> <li>Treasury - metrics around treasuries in   the ecosystem.</li> <li>Staking - metrics pertaining to staking,   nomination pools and more.</li> <li>Ecosystem - high level activity metrics   for relay chains and Parachains.</li> <li>Monthly Report - an updated version of the   Polkadot in Numbers: Annual Report 2023.</li> </ul>"},{"location":"general/dashboards/parity-data-dashboards/#notes-on-how-to-use-the-interactive-charts","title":"Notes on How to Use the Interactive Charts","text":"<p>The Ecosystem Tab shows a number of universally applicable metrics (Active Accounts, Unique Accounts, Transactions, Events) across both Polkadot &amp; Kusama Relay/Parachains. Users can select whether they want to view:</p> <ul> <li>Polkadot or Kusama</li> <li>Daily or monthly figures</li> <li>Substrate Only, EVM Only or Substrate + EVM numbers.</li> </ul> <p>The default view is set to Polkadot,Monthly, Substrate + EVM.</p> <p></p> <p>Here is an example of selecting Polkadot, Daily, Substrate Only for Transactions.</p> <p></p> <p>Users can also specify which chains they would like to view metrics for. The default view is set to the entire Relay &amp; Parachain grouping. Below is an example of selecting data for only Polkadot Relay, Moonbeam and Nodle chains. Users can hit invert selection for convenience to de-select all options before selecting their desired chains.</p> <p></p> <p>Also, for all graphs on the website, in the top right users can toggle between chart types: choosing bar, line or stacked and a combination of those. See below for an example from the Stablecoins tab.</p> <p></p>"},{"location":"general/dashboards/parity-data-dashboards/#where-the-data-comes-from","title":"Where the Data Comes From","text":"<p>The data displayed on the website comes from DotLake, which is a scalable and cost-efficient data platform built on Google Cloud Platform (GCP) by the Data Team at Parity Technologies. It's designed to store all blocks, events, extrinsics, and more for all the chains in the Polkadot ecosystem. The platform uses a range of existing technologies, keeping the architecture simple with low operational overhead. This includes tools like Terraform, the Substrate Sidecar, Rust &amp; Python programming languages, and various GCP services like Cloud Storage, BigQuery, Cloud Run &amp; Jobs, and Workflows &amp; Functions.</p> <p>The approach allows the processing of data from block number N to M, storing the raw results as JSON in Google Cloud Storage. This method not only provides a convenient abstraction, but also avoids the pitfalls of custom block parsing strategies in the ever-evolving Substrate Framework. The key to the platform's efficiency is the Block Compressor, which optimizes and reduces the data size significantly, making it more manageable for analytical purposes.</p> <p>DotLake has evolved from it's origins as a data warehouse built to serve Parity's internal data needs. Since then, the scope has been broadened to share data intitiatives and learnings with the wider community. The plan is to progressively make datasets available to the public, alongside dashboards, metrics, code, and best practices employed to ingest and decode Substrate data.</p> <p>DotLake currently consists of 80+ Polkadot, Kusama, solo-chains and test-nets with their full history and is continuously expanding.</p> <p>DotLake Batch Architecture</p> <p></p> <p>Real-Time Architecture</p> <p></p>"},{"location":"general/dashboards/parity-data-dashboards/#support-data-requests-collaborations-parachain-onboarding-etc","title":"Support: Data Requests, Collaborations, Parachain Onboarding etc.","text":"<p>The Parity Data Team is very eager to collaborate with the Ecosystem. If you have any questions, data requests that you need help with, interest in partnerships or you are a Parachain team and want your chain onboarded to the platform - please get in contact with data-team@parity.io.</p>"},{"location":"general/dashboards/staking-dashboard/","title":"Polkadot Staking Dashboard","text":""},{"location":"general/dashboards/staking-dashboard/#preliminary-notes","title":"Preliminary Notes","text":"<p>The Polkadot Staking Dashboard supports proxy accounts and you can import your staking proxy (for nominators) or non-transfer proxy (for nomination pool admins and members).</p> <p>The dashboard also has native Ledger support, meaning that you do not need an extension or a wallet to use it; you just need your Ledger device. Metadata updates are thus not necessary, as you only need to keep your Ledger apps up-to-date.</p> <p>Before using the dashboard, make sure you have a wallet or extension with a funded account. Note that accounts on wallets or extensions can be imported from Ledger or Polkadot Vault.</p> <p>On top of the existential deposit, you need some free balance to pay for transaction fees and the minimum amount to place your nominations or join a nomination pool. For more information about staking visit the staking page and the advanced staking page.</p>"},{"location":"general/dashboards/staking-dashboard/#using-the-polkadot-staking-dashboard","title":"Using the Polkadot Staking Dashboard","text":"<p>The Polkadot Staking Dashboard is a tool only dedicated to staking on Polkadot, Kusama (Polkadot's canary network) and Westend (Polkadot's test network).</p> <p>The dashboard is not a wallet, meaning that you cannot transfer funds between accounts. To fund accounts, you can use wallets and extension. You can participate in staking by being a nominator or a member of a nomination pool. Once you have a funded account, you need to connect it to the dashboard (connect button on the top-right corner), this will allow you to interact with native staking.</p> <p>The dashboard is a Web3 dApp</p> <p>The dashboard is a decentralized application (dApp), and to login you do not need to sign up with an email and password but just need an account created on the supported non-custodial wallets. Any transaction to be submitted needs to be signed by you. Also, if you use light clients, which are resistant to censorship, you interact trustlessly with the network without intermediaries. Welcome to the world of true Web3!</p> <p>Note the pictures on this page refer to Kusama, but the same applies to Polkadot and Westend.</p> <p>The structure of this page follows the sidebar of the staking dashboard. Here you will learn about the main features of the dashboard. If you need more information, see the Walkthrough Tutorial.</p> <p>Walk-through Video Tutorials</p> <ul> <li>Nominating: Stake your tokens, choose your best validators, and start your staking journey.</li> <li>Becoming a Pool Member: Start becoming a part of the Polkadot movement, keep the network secure by staking minimum 1 DOT and receiving staking rewards.</li> <li>Dashboard Walkthrough: Become a Pro using the Staking Dashboard.</li> <li>After Staking: Nominating is not a set-and-forget action, learn what you can do with the dashboard after you started staking.</li> </ul>"},{"location":"general/dashboards/staking-dashboard/#overview","title":"Overview","text":"<p>Staking Dashboard Walk-through video tutorial</p> <p>This video tutorial shows you everything you can do with the Staking Dashboard.</p> <p></p> <p>This page of the dashboard has six main panels:</p> <ul> <li> <p>Section A: The Sidebar shows which page you are on (in this case, the Overview). It will also   show the role you currently have in staking (in this case, active in both Pools and   Nominate). You can also change the network (currently on Kusama).</p> </li> <li> <p>Section B: The Accounts Panel allows you to connect one account to the dashboard. Once   connected, the account will appear next to the <code>Accounts</code> button. You can see it here if you are   active as a nominator and/or a pool member. In this case, the account KSM Stash is a nominator and   a member of the pool Insight Finance. Proxy accounts are also shown here if applicable. Note that   the dashboard will automatically fetch the stash and the proxy.</p> </li> </ul> <p>Note that Sections A and B will always be visible while you use the dashboard.</p> <ul> <li> <p>Section C: The Stats Panel shows the general view of current staking metrics, including the historical reward rate (including after   inflation), the supply staked and time remaining   in the current era.</p> </li> <li> <p>Section D: The Summary Panel shows your current situation and gives you general tips about   staking. In this case, the KSM Stash account is a nominator and a pool member, and by clicking on   <code>Manage &gt;</code> you can go directly to the Nominate and Pools pages,   respectively. You can take actions such as changing staking preferences, bonding more funds, etc.</p> </li> <li> <p>Section E: The Balance Panel shows the bonded amount distinguishing between \"Nominating\", \"In   a Pool\", and \"Not Staking\". The amount that is not staking is further divided into \"Free\" (a   balance that can be transferred) and \"Reserve\" (a balance that is needed the keep the account   on-chain, see existential deposit).   In this case, 0.301 KSM are bonded for nominating, 0.3 KSM are bonded in a pool, and 0.145 KSM are   not used for staking. Of the non-staking balance, 0.144 KSM are free while   a small portion is reserved for the existential deposit.</p> </li> <li> <p>Section F: The Recent Payouts Panel shows a bar chart with the rewards paid out to you in the   past 15 days either as a nominator or a pool member (manually claimed). Note how the 4<sup>th</sup> of April   bar has the tip that is not filled with color. This is to show a pending payout (for nominators   only). Below the bar chart is a line chart showing the 10-day moving average.</p> </li> </ul> <p>Additional statistics can be found at the bottom of the overview page.</p> <p>Pool funds are in system accounts</p> <p>Remember that funds bonded in a pool are transferred to the pool's system account, which can only be accessed by the protocol, and not by any individual user. Some wallets might not display the balance bonded in pools, but the dashboard will always show it.</p>"},{"location":"general/dashboards/staking-dashboard/#stake","title":"Stake","text":"<p>In this category, you can access all functionalities allowing you to stake your tokens as a nominator, member of a nomination pool, or both. The payout section will enable you to inspect the most recently received rewards.</p>"},{"location":"general/dashboards/staking-dashboard/#pools","title":"Pools","text":"<p>Joining a Nomination Pool - Walk-through video tutorial</p> <p>This video tutorial shows you how to join a nomination pool with the Staking Dashboard. You can also read the dedicated support article about joining a pool.</p> <p></p> <p>This page of the dashboard has four main panels (Sidebar and Accounts Panels excluded):</p> <ul> <li>Section A: The Stats Panel shows the number of active pools and the minimum number of tokens   needed to join a pool and/or create one.</li> <li>Section B: The Balance Panel shows the number of tokens bonded in pools and those that are   free. In this case, we have 0.3 KSM bonded and 0.144 KSM free. In this panel, you can bond more   funds (<code>+</code> button) or unbond some funds (<code>-</code> button). Unbonding will withdraw unclaimed rewards   and funds will be locked for the unbonding period.   Once the unbonding period has passed, you can unlock the locked funds (button with a lock icon)   that will be available as a free balance.</li> </ul> <p>No fast unstake and pool swap for pool members</p> <p>Note that the option to fast unstake is only available to nominators. Also, to change pool, you cannot simply swap memberships. You will need to unbond and go through the whole unbonding period.</p> <ul> <li> <p>Section C: The Pool Panel shows the pool id where you have membership (in this case, Pool 82),   the pool name, and next to it, a <code>Manage</code> button that will allow to choose between different   options:</p> <ul> <li>Update Claim Permissions: you can allow other pool members to compound your rewards, withdraw your rewards as a free balance, or both. More details about nomination pools and updating claim permissions can be found on the dedicated wiki page.</li> </ul> <p></p> <p>Info</p> <p>For more information about how-to update your claim permissions with the staking dashboard see this support article.</p> <ul> <li>Leave the pool and unbond all the funds in the pool.</li> </ul> <p>If you are a pool admin you will be able to see the additional options:</p> <ul> <li>Claim Commission: you can claim pool commissions to an account specified under Manage Commission (below).</li> <li>Manage Commission: you can manage the pool commission rate, maximum commission, maximum change rate, and minimum time delay between commission updates. More details about nomination pools and managing pool commissions can be found on the dedicated wiki page.</li> </ul> <p></p> <p>Info</p> <p>For more information about how-to manage commission of your nomination pool with the staking dashboard see this support article.</p> <ul> <li>Rename Pool: you can change the pool's name.</li> <li>Lock Pool: you can lock the pool so that new members are not allowed.</li> <li>Destroy Pool: you can destroy the pool. See this wiki page and this support article for more information.</li> </ul> <p>You can see any unclaimed rewards in the middle of the panel. You can claim and bond the rewards (<code>+ Compound</code> button) or withdraw them as a free balance (<code>Withdraw</code> button). In this case, there are approximately 0.0012 KSM that can be claimed. You can see the Pool Status at the bottom of the panel, currently set to \"Nominating and Earning Rewards\".</p> <p>Note that if it is the first time you log in to the dashboard, you will see two buttons\u00a0<code>Create</code>\u00a0and\u00a0<code>Join</code>, instead of <code>Manage</code>. For more information about how to create a nomination pool, see this support article.</p> </li> <li> <p>Section D: The Pool Nominations Panel shows the nominations of the pool you are currently in,   highlighting the validator that is active and will pay rewards to the pool at the end of the era   (in this case <code>ParaNodes.io/11</code>).</p> </li> </ul> <p>If you scroll down the page, there are two additional panels:</p> <ul> <li>Roles showing the accounts of the pool's Depositor, Root, Nominator, and Bouncer. The same   account can cover all the roles.</li> <li>Pool Stats showing the Pool State (either Active, Closed, or Destroying), Pool Members (number   of members in the pool), and Total Bonded (total number of bonded tokens).</li> </ul> <p>The Pools page is divided into four parts: the Overview is basically what we talked about until now, the Members section will show all accounts of the pool members, the All Pools section will show all pools (you can filter Active, Locked, and Destroying pools), and the Favorites section shows all pools that you liked (you can like a pool in the All Pools section by clicking on the heart icons).</p>"},{"location":"general/dashboards/staking-dashboard/#nominate","title":"Nominate","text":"<p>Walk-through video tutorial of How to Nominate</p> <p>This video tutorial shows you how to become a nominator with the Staking Dashboard.</p> <p></p> <p>This page of the dashboard has four main panels (Sidebar and Accounts Panels excluded):</p> <ul> <li>Section A: The Stats Panel shows the number of active nominators,   the minimum number of tokens to nominate   and the minimum active bond. The system keeps 12500   nomination intents and puts them into the   bags list. The fact that active nominators are not   12500 is because there are nominators that have no active validator.</li> <li>Section B: The Balance Panel shows the number of tokens bonded in nominations and those that   are free. In this case, we have 0.301 KSM bonded and 0.144 KSM free. In this panel, you can bond   more funds (<code>+</code> button) or unbond some funds (<code>-</code> button). Unbonding will withdraw unclaimed   rewards and funds will be locked for the   unbonding period. Once the unbonding period has   passed, you can unlock the locked funds (button with a lock icon) that will be available as a free   balance.</li> </ul> <p>Fast unstake</p> <p>If your account did not receive rewards in the past 28 eras, you will be eligible for fast unstake. The dashboard will automatically check this for you and prompt a banner.</p> <ul> <li>Section C: The Nominator Panel shows the current status of the nominator, currently set to   \"Nominating and Earning Rewards\", and next to it, the <code>Unstake</code> button allows you to unstake the   whole bonded amount and stop nominating. In the middle of the panel, the payout destination is   currently set to \"Compounding\" (i.e. rewards are added to the bonded funds). The <code>Update</code> button   will allow you to change the destination to \"To Your Account\" (to the stash account as a free   balance), \"To Another Account\" (an account that is not the stash), or \"None\" (no payout   destination).</li> <li>Section D: The Nominations panel shows your nominations and allows you to stop all nomination   with the <code>Stop</code> button or to select specific validators (<code>Select</code> button) and stop nominating only   those.</li> </ul>"},{"location":"general/dashboards/staking-dashboard/#payouts","title":"Payouts","text":"<p>This page is an expanded version of Panel F on the Overview page. It also shows all validators and/or nomination pools that paid out rewards to your accounts in the past few months.</p>"},{"location":"general/dashboards/staking-dashboard/#after-staking","title":"After Staking","text":"<p>Walk-through video tutorial - What to do after Staking</p> <p>This video tutorial shows you how to what you can do after staking with the Staking Dashboard.</p>"},{"location":"general/dashboards/staking-dashboard/#validators","title":"Validators","text":"<p>This page of the dashboard has two main panels (Sidebar and Accounts Panels excluded):</p> <ul> <li>Panel A: The Stats Panel shows the total number of active validators, all validators currently   registered (active and inactive), and average commission across all validators.</li> <li>Panel B: The Validators Panel shows all validators. You can order them by low/high commission   or apply the following filters:</li> <li>Include only active validators</li> <li>Exclude validators that have 100% commission, blocked nominations, and have missing identity.</li> </ul>"},{"location":"general/dashboards/staking-dashboard/#support","title":"Support","text":"<p>Support for the Staking Dashboard is available at the official Polkadot support website.</p>"},{"location":"general/dashboards/staking-dashboard/#network","title":"Network","text":"<p>Under Network, you can connect to either Polkadot, Kusama, or Westend through public RPC nodes or light clients for a true Web3 experience. For more information about light clients, see this page.</p>"},{"location":"general/dashboards/dune-analytics/","title":"Dune Analytics","text":"<p>Dashboards in Dune Analytics created by Colorful Notion.</p> <ul> <li>Polkadot Ecosystem Overview \u2013 Overview of the Polkadot Ecosystem.</li> <li>Onboarding Status and Key Dashboards - Onboarding Status and Key Dashboards.</li> <li>Polkadot 2024 Review - Annual Review of Polkadot for 2024.</li> <li>Polkadot Dashboards Overview - Overview of Polkadot Dashboards.</li> <li>Governance - Governance Dashboards.</li> <li>Staking - Staking Dashboards.</li> <li>Network - Network Dashboards.</li> <li>Project Dashboards - Various Project Dashboards.</li> <li>DuneSQL Cheatsheet - Cheatsheet for DuneSQL.</li> </ul>"},{"location":"general/dashboards/dune-analytics/dunesql-cheatsheet/","title":"DuneSQL Cheatsheet","text":"<p>It is important to note that when querying on Dune Analytics, DuneSQL is employed. Although most functions and syntax are similar to standard SQL, there are still some differences compared to other versions of SQL. Below is a comparison table of common features between DuneSQL and Google BigQuery SQL.</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL documentation.</p> Problem Type BigQuery DuneSQL(V2) Description JSON Reading Method <code>JSON_EXTRACT_SCALAR(call_args, \"$.remark\")</code> <code>JSON_EXTRACT_SCALAR(JSON_PARSE(call_args), '$.remark')</code> In DuneSQL, <code>JSON_PARSE</code> is needed to split the JSON if it is initially not in JSON format but is transformed into a JSON string. JSON array to SQL array <code>JSON_EXTRACT_ARRAY(JSON_EXTRACT(pv, '$.others'))</code> <code>cast(json_extract(pv, '$.others') as array&lt;json&gt;)</code> BigQuery uses a function for this conversion, while DuneSQL utilizes casting and supports the JSON data type. HEX to UTF8 <code>SAFE_CONVERT_BYTES_TO_STRING(FROM_HEX(SUBSTR(hex_encode, 3)))</code> <code>FROM_UTF8(from_hex(SUBSTR(hex_encode, 3)))</code> In DuneSQL, the <code>SAFE_CONVERT_BYTES_TO_STRING</code> is not required. Time Series <code>TIMESTAMP_TRUNC(block_time, DAY) &gt;= TIMESTAMP(\"2023-12-01\")</code> <code>block_time &gt;= date('2023-12-01')</code> Time conversion in DuneSQL is simpler, involving direct usage of <code>variable operator date(value)</code>. Data Type Conversion (FLOAT64 to DOUBLE) <code>CAST(JSON_EXTRACT_SCALAR(nominationpools_rewardpools, '$.lastRecordedRewardCounter') AS FLOAT64)</code> <code>CAST(JSON_EXTRACT_SCALAR(nominationpools_rewardpools, '$.lastRecordedRewardCounter')</code> BigQuery refers to the data format as FLOAT64, while in DuneSQL, it is termed DOUBLE. Handling Null Values <code>IFNULL(prev_member_bonded, 0)</code> <code>COALESCE(prev_member_bonded, 0)</code> In DuneSQL, BigQuery's <code>IFNULL</code> is equivalent to <code>COALESCE</code>. Calculating Local Time and Subtracting Days <code>TIMESTAMP_TRUNC(ts, DAY) &gt;= TIMESTAMP(DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY))</code> <code>ts &gt;= date(current_date - interval '30' day)</code> In BigQuery, operations on dates require functions, but DuneSQL allows direct use of <code>+</code> and <code>-</code>. Using Hyperlinks in Tables <code>SELECT concat(concat(concat(\"&lt;a href='https://analytics.polkaholic.io/superset/dashboard/77/?account=\", address_ss58), \"'&gt;\"), if(address_name is null, concat(address_ss58, '&lt;/a&gt;'), concat(address_name, '&lt;/a&gt;')))</code> <code>CONCAT('&lt;a target=\"_new\" href=\"https://analytics.polkaholic.io/superset/dashboard/77/?account=', address_ss58, '\"&gt;', address_ss58 ,'&lt;/a&gt;') AS address_ss58</code> DuneSQL enables string concatenation using <code>CONCAT</code>, making it straightforward compared to the multiple <code>concat</code> functions required in BigQuery."},{"location":"general/dashboards/dune-analytics/onboarding-status-and-key-dashboards/","title":"Onboarding Status &amp; Key Dashboards","text":"<p>To date, over 40 publicly accessible parachains and more than 80 key dashboards have been created by Colorful Notion and the broader community to demonstrate the powerful Dune-Polkadot Integration.</p> <ul> <li>Sept 2024 - Dune: The Most Comprehensive Onchain Data Hub for Polkadot\u2019s 50+ Parachains</li> <li>Nov 2024 - From Polkadot RPC Byte to Pixels on Dashboard: The Magic ETL Pipeline (DuneCon 2024)</li> <li>2024 Polkadot Year In Review</li> </ul> <p>The data must flow. As dashboard catalysts, we are looking forward to seeing more impressive dashboards developed by the community in 2025, leveraging this rich comprehensive dataset to unlock new possibilities and insights.</p> <p>The table below displays the onboarding status of various parachains into Dune Analytics. </p>"},{"location":"general/dashboards/dune-analytics/project-dashboards/","title":"Project Dashboards","text":"<p>This page contains a list of dashboards about some of the interesting projects in the Polkadot ecosystem. The dashboards are created using Dune Analytics and DuneSQL.</p> <ul> <li>Polkadot and Kusama Decentralized Voices:   The Web3 Foundation has introduced the Decentralized Voices program for Polkadot and Kusama to   enhance involvement in OpenGov. By delegating 180,000 KSM and 42 million DOT in voting power, the   program aims to empower active voters in these ecosystems.</li> <li>JAM DUNA: The JAM DUNA aims to be decentralized   unincorporated non-profit association with a community originating in Kusama+Polkadot. The initial   goal is set up the JAM DUNA as a Wyoming DUNA in July 2024. Wyoming DUNAs provide significant   legal advantages over DAOs, requiring a minimum 100 members.</li> <li>DED: DED is a memecoin project originated in the DOT   community and developed by the DED Foundation</li> </ul>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/","title":"Polkadot's 2024 Review","text":"<p>Below are excerpts from the Polkadot 2024: Year In Review on Dune.</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#number-of-validators","title":"Number of Validators","text":"<p>The number of validators increased significantly this year:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#top-15-chains","title":"Top 15 Chains","text":"<p>There are over 50 parachains secured by Polkadot, here we show the top 15 by 3 metrics:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#by-active-accounts","title":"By Active Accounts","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#by-signed-extrinsics","title":"By Signed Extrinsics","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#by-transfer-count","title":"By Transfer Count","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#total-dot-staked-vs-liquid-dot-staked-2024","title":"Total DOT Staked VS Liquid DOT Staked (2024)","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#total-staked-dot-by-staking-type","title":"Total Staked DOT (By Staking Type)","text":"<p>The majority of DOT is Solo Staked, but nominated DOT increased steadily this year:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#liquid-staked-dot","title":"Liquid Staked DOT","text":"<p>Bifrost and Acala lead Liquid Staking:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#inflation","title":"Inflation","text":"<p>At the beginning of 2024, Polkadot's annual inflation rate was 10%. In November 2024, it was adjusted to the rate of 8%, with plans for a gradual decrease over time. This change was proposed, voted on, and executed on-chain by OpenGov Ref 1139.</p> <p>Upon implementation, 8% of the total issuance equated to approximately 120M DOT per year (roughly 10M DOT per month) in inflation, with 15% allocated to the Polkadot treasury and 85% distributed to stakers.</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#daily-dot-inflation-allocated-to-inflation","title":"Daily DOT Inflation Allocated to Inflation","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#opengov-voting-and-expenditures","title":"OpenGov Voting and Expenditures","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#monthly-proposals-by-outcome","title":"Monthly Proposals by Outcome","text":"<p>2024 saw nearly 1000 proposals:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#referendum-with-most-voting-power","title":"Referendum With Most Voting Power","text":"<p>These proposals brought out the most voting power:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#top-20-voters","title":"Top 20 Voters","text":"<p>Here are the top 20 voters of 2024:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#treasury-expenditures","title":"Treasury Expenditures","text":"<p>Expenditures were higher in the first half of the year than the second half of the year:</p> <p>Starting in Summer 2024, expenditures started in USDT+USDC from Polkadot Asset Hub:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#decentralized-voice-dv-program-cohorts","title":"Decentralized Voice (DV) Program Cohorts","text":"<p>The Web3 Foundation introduced the Decentralized Voice program in February 2024 to enable active voters be significantly involved in the OpenGov.Each cohort is delegated 42M DOT of voting power which is shared equally among each cohort's members. So far, there have been three Cohorts. The current cohort 3 began in Novemeber and will run through into 2025.</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#participation-rate","title":"Participation Rate","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#voting-times","title":"Voting Times","text":""},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#polkadot-gamingdefi-year-in-review","title":"Polkadot Gaming+Defi - Year In Review","text":"<p>Here we summarize some key chains that led Polkadot Defi in 2024:</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#mythos","title":"Mythos","text":"<p>After completing migration to Polkadot in Summer from Ethereum, Mythos saw robust MAUs in Fall 2024 with 100K+ MAUs:</p> <p>Over 450K DOT holders received Mythos in an airdrop via OpenGov Ref 643, see Mythos.</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#hydration","title":"Hydration","text":"<p>Helped by incentives from Polkadot, liquidity in the Omnipool started to grow massively in Summer 2024.</p> <p>The account analysis shows steady growth and good retention, with predictable bouts of churn after bursts of enthusiasm where prices jumped.</p> <p>See also Hydration</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#bifrost","title":"Bifrost","text":"<p>Bifrost's account analysis shows a peak of new customers in Spring 2024, with many not becoming regular active users. If people stake and forget, this may not be an issue.</p> <p>Value staked peaked in March 2024, lost all of its gain for the year in 2024, only to rebound strongly again in the last 6 weeks and again reach a peak of 90m at the height of the 100k BTC frenzy.</p> <p>GLMR staking moved elsewhere and MANTA was clearly #2 for 2024.</p> <p>See also Bifrost</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#centrifuge","title":"Centrifuge","text":"<p>For the two funds present on the Centrifuge chain, growth was steady:</p> <p>See also Centrifuge</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#stellaswap","title":"Stellaswap","text":"<p>Liquidity in the top pools on Stellaswap surged massively starting in September 2024, thanks to a large grant of DOT to incentivize liquidity providers (LPs)</p> <p>Volume surged in March 2024 and November 2024 in line with heightened activity everywhere. Just a handful of pairs dominate the volume.</p> <p>See also Stellaswap</p>"},{"location":"general/dashboards/dune-analytics/annual-reviews/polkadot-dashboards-2024-year-in-review/#supported-by-opengov","title":"Supported by OpenGov","text":"<p>The Polkadot-Dune integration has been led by Colorful Notion and supported by OpenGov throughout 2024. Colorful Notion thanks everyone for supporting our work in 2024.</p> <p>See something in 2024 that belongs here? Edit this page and share your Dune dashboard!</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/","title":"Acala Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/#overview","title":"Overview","text":"<p>Acala is a decentralized finance hub and stablecoin platform powering cross-blockchain liquidity and applications. It serves as a critical infrastructure layer for the Polkadot ecosystem.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Acala parachain:</p> <ul> <li>Acala on Polkadot: This dashboard provides a comprehensive   view of financial activities and token dynamics within the Acala network.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Acala parachain is organized into several key tables:</p> <ul> <li><code>acala.balances</code></li> <li><code>acala.blocks</code></li> <li><code>acala.calls</code></li> <li><code>acala.events</code></li> <li><code>acala.extrinsics</code></li> <li><code>acala.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Acala are provided:</p> Title Query Description Acala Asset Exchange Rate by Date query_3672976 Retrieves historical exchange rates for Acala assets, date-wise breakdown Acala Assets Most Frequently Subject to Swapping query_3673478 This query identifies which Acala assets are swapped the most frequently on the platform. <p>These descriptions aim to provide more context and details about what each query does and the insights they offer.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/acala-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Acala List of Assets\" showLineNumbers WITH     decimals_for_each_symbol AS (             SELECT                 symbol,                 MAX(decimals) AS decimals             FROM                 acala.transfers             WHERE                 symbol IS NOT NULL             GROUP BY                 symbol         ) SELECT     b.asset,     b.symbol,     d.decimals FROM     acala.balances b LEFT JOIN decimals_for_each_symbol d ON b.symbol = d.symbol GROUP BY     b.asset,     b.symbol,     d.decimals ORDER BY     SUM(b.free + b.reserved + b.misc_frozen + b.frozen) DESC</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/","title":"Asset Hub Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/#overview","title":"Overview","text":"<p>Asset Hub is a specialized parachain on Polkadot designed to facilitate the handling and management of digital assets across various applications. It supports asset tokenization, trading, and bridging services within the Polkadot ecosystem.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Asset Hub parachain:</p> <ul> <li>Asset Hub: Explore comprehensive analytics on digital asset   management and operations within the AssetHub parachain.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Asset Hub parachain is organized into several key tables:</p> <ul> <li><code>assethub.balances</code></li> <li><code>assethub.blocks</code></li> <li><code>assethub.calls</code></li> <li><code>assethub.events</code></li> <li><code>assethub.extrinsics</code></li> <li><code>assethub.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Asset Hub are provided:</p> Title Query Description Asset Hub Sum of Stablecoin on Each Chain by Time query_3526956(asset_id='[ASSET_ID]') Find the sum of stablecoin on each chain by time"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/assethub-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Sum of USDC in Polkadot Parachains\" showLineNumbers SELECT   * FROM   \"query_3526956(asset_id='1984')\" -- AssetHub Sum of Stablecoin on Each Chain by Time WHERE   not chain_name = ''</code></p> <p>Query result:</p> <p>Visualized result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/","title":"Astar Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/#overview","title":"Overview","text":"<p>Astar Network, previously known as Plasm, is a blockchain platform designed for Web3. It is compatible with both EVM (Ethereum Virtual Machine) and WebAssembly, enabling seamless interaction between the two environments. Developers can participate in the Build2Earn program to earn rewards by creating decentralized applications.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Astar parachain:</p> <ul> <li>Astar dApp Staking Overview: This dashboard is   designed to provide a quick overview of various aspects of Astar dApp Staking.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Astar parachain is organized into several key tables:</p> <ul> <li><code>astar.balances</code></li> <li><code>astar.blocks</code></li> <li><code>astar.calls</code></li> <li><code>astar.events</code></li> <li><code>astar.extrinsics</code></li> <li><code>astar.transfers</code></li> <li><code>astar.traces</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Astar are provided:</p> Title Query Description Astar dApp Info by Era query_3727264 This query provides comprehensive information on decentralized applications (dApps) within the Astar ecosystem, including details about the dApp name, staking statistics, tier levels, and developer profiles, facilitating deeper insights into dApp performance and engagement across different eras. Astar Reward Info by Era query_3727888 Explore comprehensive data on rewards distribution within the Astar network, broken down by era to identify trends and patterns. Astar Staker info by Era query_3728048 Access a detailed breakdown of staker activities and statistics on the Astar network, categorized by era for historical comparison."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/astar-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Astar, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Astar EVM Executed\" showLineNumbers SELECT     block_number, extrinsic_id, event_id, extrinsic_hash, section, method,     json_extract_scalar(data, '$[0]') as tx_from,     json_extract_scalar(data, '$[1]') as tx_to,     json_extract_scalar(data, '$[2]') as tx_hash,     json_extract(data, '$[3]') as tx_success FROM     astar.events WHERE     block_time &gt;= TIMESTAMP '2024-02-13 00:00:00' and (section = 'ethereum' and method = 'Executed') limit 10000;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/","title":"Bifrost Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/#overview","title":"Overview","text":"<p>Bifrost is a decentralized finance hub and liquid staking platform on the Polkadot network and other chains. Users obtain a liquid staking token, vToken, by staking their native tokens. The vToken can then be used in DeFi applications, such as lending, borrowing, and trading.</p> <p>On Polkadot, users can stake DOT, ASTR, FIL, GLMR, Manta at the moment.</p> <p>They can also trade their vTokens in a DEX (stableswap) operating on the Bifrost parachain.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Bifrost parachain:</p> <ul> <li>bifrost on Polkadot: This dashboard provides a comprehensive   view of staking, value locked, and trading on Bifrost parachain.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the bifrost parachain is organized into several key tables:</p> <ul> <li><code>bifrost.balances</code></li> <li><code>bifrost.blocks</code></li> <li><code>bifrost.calls</code></li> <li><code>bifrost.events</code></li> <li><code>bifrost.extrinsics</code></li> <li><code>bifrost.transfers</code></li> </ul> <p>The <code>bifrost.traces</code> table is created by a snapshot script utilizing Bifrost API calls to fetch accurate values which would be difficult to calculate from the blockchain events alone.</p> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Bifrost are provided:</p> Subject Area Query Description Liquid Staking query 3571958 Provides amount of vTokens and therefore tokens staked (1=1) Used HydraDX oracle for USD values. Bifrost Stableswap query 3532234 Provides price and volume for stableswap pairs, e.g. DOT \\&lt;-&gt; VDOT <p>Dune users are encouraged to study the source code of the queries, including parts of a query that may have been commented out for future use.</p> <p>Uncommenting these parts may accelerate your effort of adopting a query to a slightly different use case.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bifrost-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Bifrost, you are welcome to use the mentioned queries. You can also use the following DuneSQL queries as examples:</p> <p>```sql title=\"Bifrost Loan Market Data\" showLineNumbers WITH A AS (   SELECT     block_time,     event_id,     section,     method,     JSON_ARRAY_LENGTH(data) AS array_length,     JSON_VALUE(data, 'strict $[0]') AS account,     -- JSON_QUERY(data, 'strict $[1]') AS value_1,     -- JSON_VALUE(data, 'strict $[2]') AS some_amount,     JSON_QUERY(data, 'strict $[3]') AS token_in,     JSON_QUERY(data, 'strict $[4]') AS token_out,     CAST(JSON_VALUE(data, 'strict $[5]') AS UINT256) AS amount_in,     CAST(JSON_VALUE(data, 'strict $[9]') AS UINT256) AS amount_out     -- JSON_QUERY(data, 'strict $[7]') AS value_7,     -- JSON_QUERY(data, 'strict $[8]') AS value_8,     -- JSON_QUERY(data, 'strict $[9]') AS value_9   FROM     bifrost.events   WHERE     section = 'stableAsset'     AND method IN ('TokenSwapped')     AND block_time &gt; TIMESTAMP '2024-05-01' ) SELECT   date_trunc('hour', block_time) AS \"day\",   SUM(amount_in) / 1e10 AS dot_volume_swapped,   1.000 * SUM(amount_in) / SUM(amount_out) AS avg_price,   (1.000 * SUM(amount_in) / SUM(amount_out)) &lt; 1 AS price_low -- very low prices FROM   A WHERE   token_in = '{\"token2\":0}'   AND token_out = '{\"vToken2\":0}'   AND amount_out &gt; 0   AND block_time &gt; TIMESTAMP '2024-05-01' GROUP BY   1 ORDER BY   1 DESC;</p> <p>```</p> <p>The query is fairly typical for a parachain query on Dune. It parses events from the <code>bifrost.events</code> table, and calculates the aggregate values for each hour.</p> <p>The query uses Dune's native UINT256 type, which allows to deal with very large numbers and still maintain precision.</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/","title":"BridgeHub Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/#overview","title":"Overview","text":"<p>Polkadot BridgeHub is a system parachain within the Polkadot ecosystem, designed to enable trustless bridging between Polkadot and other blockchains such as Kusama and Ethereum. It ensures secure cross-chain communication through a combination of on-chain and off-chain components. This dashboard primarily analyzes the bridging information between Polkadot and Kusama.</p> <p>The Ethereum to Polkadot BridgeHub primarily utilizes Snowbridge. For more details, visit our Snowbridge Dashboard.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the BridgeHub parachain:</p> <ul> <li>BridgeHub: A comprehensive analysis of BridgeHub,   including: Kusama Related On Chain Data Analysis, Analysis of Messages with Kusama.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the BridgeHub parachain is organized into several key tables:</p> <ul> <li><code>bridgehub.balances</code></li> <li><code>bridgehub.blocks</code></li> <li><code>bridgehub.calls</code></li> <li><code>bridgehub.events</code></li> <li><code>bridgehub.extrinsics</code></li> <li><code>bridgehub.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Bridgehub are provided:</p> Title Query Description Bridgehub Messages with Kusama queries_3816910 Find all message records between Polkadot and Kusama"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/bridgehub-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Bridgehub and Kusama Message Trends\" showLineNumbers WITH   transactions AS (     SELECT       CASE         WHEN ROW_NUMBER() OVER (           PARTITION BY             \"from\",             \"to\",             \"send_time\"           ORDER BY             \"send_time\"         ) % 2 = 1 THEN \"from\"         ELSE \"to\"       END AS direction,       date_trunc('month', \"send_time\") as month     FROM       query_3816910   ),   polkadot_to_kusama AS (     SELECT       month,       COUNT(*) as count_polkadot_to_kusama     FROM       transactions     WHERE       direction = 'polkadot'     GROUP BY       month   ),   kusama_to_polkadot AS (     SELECT       month,       COUNT(*) as count_kusama_to_polkadot     FROM       transactions     WHERE       direction = 'kusama'     GROUP BY       month   ),   all_polkadot_to_kusama AS (     SELECT       'for_join' as \"for_join\",       COUNT(*) as total_count_polkadot_to_kusama     FROM       transactions     WHERE       direction = 'polkadot'   ),   all_kusama_to_polkadot AS (     SELECT       'for_join' as \"for_join\",       COUNT(*) as total_count_kusama_to_polkadot     FROM       transactions     WHERE       direction = 'kusama'   ),   monthly_result as (     SELECT       coalesce(         polkadot_to_kusama.month,         kusama_to_polkadot.month       ) as month,       coalesce(count_polkadot_to_kusama, 0) as count_polkadot_to_kusama,       coalesce(count_kusama_to_polkadot, 0) as count_kusama_to_polkadot,       'for_join' as \"for_join\"     FROM       polkadot_to_kusama       FULL OUTER JOIN kusama_to_polkadot ON polkadot_to_kusama.month = kusama_to_polkadot.month     ORDER BY       month   ) SELECT   monthly_result.month,   monthly_result.count_polkadot_to_kusama,   monthly_result.count_kusama_to_polkadot,   all_polkadot_to_kusama.total_count_polkadot_to_kusama,   all_kusama_to_polkadot.total_count_kusama_to_polkadot FROM   monthly_result   LEFT JOIN all_polkadot_to_kusama on monthly_result.for_join = all_polkadot_to_kusama.for_join   LEFT JOIN all_kusama_to_polkadot on monthly_result.for_join = all_kusama_to_polkadot.for_join</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/","title":"Centrifuge Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/#overview","title":"Overview","text":"<p>Centrifuge is a platform for real-world asset tokenization. Through Centrifuge, investors gain access to a diverse range of assets, improving transparency and achieving better insight into their portfolio. Asset managers tokenize their funds and streamline access to necessary service providers and investors, saving cost for fund operations and unlocking new sources of capital.</p> <p>Centrifuge provides both the infrastructure and ecosystem to tokenize, manage, and invest into a complete, diversified portfolio of real-world assets.</p> <p>Asset pools are fully collateralized, investors have legal recourse, and the protocol is asset-class agnostic with pools for assets spanning structured credit, real estate, US treasuries, carbon credits, consumer finance, and more.</p> <p>Centrifuge's ecosystem extends beyond its onchain financial infrastructure, incorporating a DAO (decentralized autonomous organization) supported by a diverse community of finance professionals and developers.</p> <p>By bringing the entire structured credit market onchain across securitization, tokenization, privacy, governance, and liquidity integrations, Centrifuge is building a more transparent, affordable, and limitless financial system.</p> <p>Some assets are managed on Ethereum, others are managed on Centrifuge.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you'll find a variety of dashboards that help visualize data from the Centrifuge parachain on Polkadot:</p> <ul> <li>centrifuge on Polkadot: This dashboard provides details   for</li> <li>assets pools on Centrifuge parachain. (As of June 2024: only one)</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the centrifuge parachain is organized into several key tables: <code>centrifuge.balances</code>,</p> <ul> <li><code>centrifuge.balances</code></li> <li><code>centrifuge.blocks</code></li> <li><code>centrifuge.calls</code></li> <li><code>centrifuge.events</code></li> <li><code>centrifuge.extrinsics</code></li> <li><code>centrifuge.transfers</code></li> </ul> <p>The <code>centrifuge.traces</code> table is created by a snapshot script utilizing Centrifuge API calls to fetch accurate values which would be difficult to calculate from the blockchain events alone.</p> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Centrifuge are provided:</p> Subject Area Query Description Portfolio query_3708897 Provides details about the assets in the pools Centrifuge Pool Data Anemoy query_3708939 Provides details for the Anemoy pool (first pool on Centrifuge) <p>Dune users are encouraged to study the source code of the queries, including parts of a query that may have been commented out for future use.</p> <p>Uncommenting these parts may accelerate your effort of adopting a query to a slightly different use case.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/centrifuge-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Centrifuge, you are welcome to use the mentioned queries. You can also use the following DuneSQL queries as examples:</p> <p>```sql title=\"Centrifuge Loan Market Data\" showLineNumbers WITH portfolio AS (   SELECT     ts,     CAST(JSON_VALUE(c.kv, 'strict $.asset_id.id') AS INT) AS asset_id,     CAST(JSON_VALUE(c.kv, 'strict $.asset_id.pool') AS BIGINT) AS pool_id,     FROM_UNIXTIME(CAST(JSON_VALUE(c.pv, 'strict $.maturity_date') AS BIGINT)) AS maturity_date,     CAST(JSON_VALUE(c.pv, 'strict $.outstanding_interest') AS UINT256) AS outstanding_interest,     CAST(JSON_VALUE(c.pv, 'strict $.outstanding_principal') AS UINT256) AS outstanding_principal,     CAST(JSON_VALUE(c.pv, 'strict $.present_value') AS UINT256) AS present_value,     CAST(JSON_VALUE(c.pv, 'strict $.total_borrowed') AS UINT256) AS total_borrowed,     CAST(JSON_VALUE(c.pv, 'strict $.total_repaid_interest') AS UINT256) AS total_repaid_interest,     CAST(JSON_VALUE(c.pv, 'strict $.total_repaid_principal') AS UINT256) AS total_repaid_principal,     CAST(JSON_VALUE(c.pv, 'strict $.total_repaid_unscheduled') AS UINT256) AS total_repaid_unscheduled,     CAST(JSON_VALUE(c.pv, 'strict $.pool_currency.symbol') AS VARCHAR) AS currency_symbol,     CAST(JSON_VALUE(c.pv, 'strict $.pool_currency.decimals') AS INT) AS decimals,     CAST(JSON_VALUE(c.pv, 'strict $.type') AS VARCHAR) AS type   FROM     centrifuge.traces c   WHERE     track = 'portfolio' ) SELECT   ts,   asset_id,   pool_id,   maturity_date,   outstanding_interest / POW(10, decimals) AS outstanding_interest,   outstanding_principal / POW(10, decimals) AS outstanding_principal,   present_value / POW(10, decimals) AS present_value,   total_borrowed / POW(10, decimals) AS total_borrowed,   total_repaid_interest / POW(10, decimals) AS total_repaid_interest,   total_repaid_principal / POW(10, decimals) AS total_repaid_principal,   total_repaid_unscheduled / POW(10, decimals) AS total_repaid_unscheduled,   currency_symbol FROM   portfolio WHERE   type = 'Other' ORDER BY   maturity_date DESC;</p> <p>```</p> <p>The query is fairly typical for a parachain query on Dune. It parses details from the <code>centrifuge.traces</code> table, and displays relevant values with suitable labels.</p> <p>The query uses Dune's native UINT256 type, which allows to deal with very large numbers and still maintain precision.</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/","title":"Collectives Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/#overview","title":"Overview","text":"<p>The Technical Fellowship is a self-governing body of experts and developers of Polkadot and Kusama networks protocols. It operates on-chain through the Polkadot Collectives system chain and off-chain through the Polkadot Fellows repository.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Collectives parachain:</p> <ul> <li>Collectives: This dashboard provides an overview of the   Collectives ecosystem. On this dashboard, you can see the entire landscape of activities within   the Collectives network, such as the distribution of Salaries, Member Ranks, and voting activities   on Referenda.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the manta parachain is organized into several key tables:</p> <ul> <li><code>collectives.balances</code></li> <li><code>collectives.blocks</code></li> <li><code>collectives.calls</code></li> <li><code>collectives.events</code></li> <li><code>collectives.extrinsics</code></li> <li><code>collectives.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Collectives are provided:</p> Title Query Description Collectives Core Member Events query_3799229 Provides details on events involving core members of Collectives. Collective Fellowship Referenda query_3776581 Offers comprehensive data on Collective fellowship referenda, covering vote counts (Ayes, BareAyes, Nays), current status, and type of referendum."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/collectives-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Collectives, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Collectives Referenda Types\" showLineNumbers WITH types AS (   SELECT     block_time,     JSON_EXTRACT_SCALAR(params, '$.proposal.lookup.hash') AS lookup,     JSON_EXTRACT_SCALAR(params, '$.proposal_origin.fellowshipOrigins') AS fellowshipOrigins   FROM     collectives.extrinsics   WHERE     section = 'fellowshipReferenda'     AND method = 'submit'     AND JSON_EXTRACT_SCALAR(params, '$.proposal.lookup.hash') IS NOT NULL ) SELECT   JSON_EXTRACT_SCALAR(data, '$[0]') AS r_id,   JSON_EXTRACT_SCALAR(data, '$[2].lookup.hash') AS lookup,   COALESCE(types.fellowshipOrigins, 'Fellows') AS types FROM   collectives.events LEFT JOIN types ON JSON_EXTRACT_SCALAR(data, '$[2].lookup.hash') = types.lookup WHERE   method = 'Submitted'   AND JSON_EXTRACT_SCALAR(data, '$[2].lookup.hash') IS NOT NULL;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/","title":"Coretime Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/#overview","title":"Overview","text":"<p>Coretime is a parachain on Polkadot that focuses on time-stamping and data certification, providing a decentralized and secure mechanism for verifying data integrity.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Coretime parachain:</p> <ul> <li>Coretime Dashboard: Explore comprehensive data   visualizations related to time-stamping services on Coretime.</li> <li>Kusama Coretime Sales History:   Detailed historical data and trends of sales activities on the Kusama network.</li> </ul> <p>Please also visit our dashboards for Coretime on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Coretime parachain is organized into several key tables:</p> <ul> <li><code>coretime.balances</code></li> <li><code>coretime.blocks</code></li> <li><code>coretime.calls</code></li> <li><code>coretime.events</code></li> <li><code>coretime.extrinsics</code></li> <li><code>coretime.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Coretime are provided:</p> Title Query Description Kusama Coretime Core Statistics query_3765036 This query provides detailed statistics on Coretime sales activities on the Kusama network, including sale start time, lead-in length, start and regular prices, region details, cores sold, and more."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/coretime-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Kusama Coretime Core Statistics\" showLineNumbers WITH   core_sta as (     SELECT       block_time,       get_href (         'https://nodle.subscan.io/extrinsic/' || cast(extrinsic_id as VARCHAR),         extrinsic_id       ) as extrinsics_url,       extrinsic_id,       CAST(JSON_EXTRACT_SCALAR(data, '$[0]') AS BIGINT) as sale_start,       CAST(JSON_EXTRACT_SCALAR(data, '$[1]') AS BIGINT) as leadin_length,       CAST(JSON_EXTRACT_SCALAR(data, '$[2]') AS BIGINT) / pow(10, 12) as start_price,       CAST(JSON_EXTRACT_SCALAR(data, '$[3]') AS BIGINT) / pow(10, 12) as regular_price,       CAST(JSON_EXTRACT_SCALAR(data, '$[4]') AS BIGINT) as region_begin,       CAST(JSON_EXTRACT_SCALAR(data, '$[5]') AS BIGINT) as region_end,       CAST(JSON_EXTRACT_SCALAR(data, '$[6]') AS BIGINT) as ideal_cores_sold,       CAST(JSON_EXTRACT_SCALAR(data, '$[7]') AS BIGINT) as cores_offered,       CAST(         ROW_NUMBER() OVER (           ORDER BY             block_time ASC         ) AS BIGINT       ) AS sale_round     FROM       coretime_kusama.events     WHERE       section = 'broker'       AND method = 'SaleInitialized'   ) SELECT   *,   get_href (     'https://dune.com/substrate/kusama-coretime-sales-history?sale_round=' || cast(sale_round as VARCHAR),     cast(sale_round as VARCHAR)   ) as sale_round_url FROM   core_sta ORDER BY   block_time DESC</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/","title":"EnergyWebX Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/#overview","title":"Overview","text":"<p>EnergyWebX is a parachain focused on integrating blockchain technology within the energy sector, aiming to enhance energy efficiency and promote renewable energy sources across the Polkadot ecosystem.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the EnergyWebX parachain:</p> <ul> <li>EnergyWebX: This dashboard provides a comprehensive view   of the blockchain activities and energy transactions within the EnergyWebX network.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the EnergyWebX parachain is organized into several key tables:</p> <ul> <li><code>energywebx.balances</code></li> <li><code>energywebx.blocks</code></li> <li><code>energywebx.calls</code></li> <li><code>energywebx.events</code></li> <li><code>energywebx.extrinsics</code></li> <li><code>energywebx.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for EnergyWebX are provided:</p> Title Query Description EnergyWebX Solutions and Groups query_3810095 Provides a list of solutions and groups created within the EnergyWebX network. EnergyWebX Operators and Worker query_3813780 Displays a list of operators and workers connected to the EnergyWebX network."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/energywebx-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Snowbridge, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p>```sql title=\"EnergyWebX Token Lifted &amp; Lowered\" showLineNumbers WITH   lift AS (     SELECT       date_trunc('day', block_time) AS day,       SUM(         CAST(json_extract_scalar(data, '\\([1]') AS double) / POWER(10, 18)       ) AS amount,       'AVTLifted' AS method     FROM       energywebx.events     WHERE       method = 'AVTLifted'     GROUP BY       date_trunc('day', block_time)   ),   lower AS (     SELECT       date_trunc('day', block_time) AS day,       SUM(         CAST(json_extract_scalar(data, '\\)[2]') AS double) / POWER(10, 18)       ) AS amount,       'AVTLowered' AS method     FROM       energywebx.events     WHERE       method = 'AvtLowered'     GROUP BY       date_trunc('day', block_time)   ) SELECT   * FROM   lift UNION ALL SELECT   * FROM   lower;</p> <p>```</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/","title":"Frequency Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/#overview","title":"Overview","text":"<p>Frequency is a parachain on Polkadot focusing on decentralized communication solutions. It allows the creation and management of decentralized networks for various applications, enhancing data privacy and security.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Frequency parachain:</p> <ul> <li>Frequency Dashboard: A comprehensive view of the   activities within the Frequency parachain.</li> </ul> <p>Please also visit our dashboards for Frequency on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Frequency parachain is organized into several key tables:</p> <ul> <li><code>frequency.balances</code></li> <li><code>frequency.blocks</code></li> <li><code>frequency.calls</code></li> <li><code>frequency.events</code></li> <li><code>frequency.extrinsics</code></li> <li><code>frequency.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Frequency are provided:</p> <p>Frequency Schema List (Off-chain Payload) Frequency Schema List Frequency MSA Count</p> Title Query Description Frequency Schema List (Off-chain Payload) query_3781175 Provides a list of schemas used in the off-chain payload of Frequency. Frequency Schema List query_3760992 Lists the schemas used in Frequency. Frequency MSA Count query_3820268 Displays the count of Message Source Accounts (MSAs) extrinsics in Frequency."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/frequency-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Frequency Extrinsics by Day\" showLineNumbers SELECT     DATE_TRUNC('day', block_time) AS day,     section || '_' || method AS section_method,     COUNT(*) AS cnt FROM     frequency.extrinsics WHERE     section || '_' || method IN (         SELECT section_method         FROM unnest(SPLIT('{{ section_method }}', ',')) AS c(section_method)     ) GROUP BY     DATE_TRUNC('day', block_time),     section || '_' || method;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/","title":"Hydration Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/#overview","title":"Overview","text":"<p>Hydration, formerly known as HydraDX, is a decentralized finance hub on Polkadot. It offers several types of DEX pools:</p> <ul> <li>Omnipool: a single liquidity pool for assets that have been vetted by governance. Typically, these   would be currencies that have existed for a while and are expected to generate a high volume of   trades.</li> <li>Stable pools: pools where all coins in the same pool are expected to trade almost at the same   price, e.g. USDC/USDT.</li> <li>xyk-pools: pools where the price of the assets is determined by the x * y = k formula, also known   as the constant product formula.</li> </ul> <p>Users can swap from any asset to any other asset using an automated router that will calculate the most efficient path.</p> <p>Liquidity providers can earn fees from the trades in the pools they provide liquidity to.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Hydration parachain:</p> <ul> <li>hydration on Polkadot: This dashboard provides a   comprehensive view of DEX volumes and liquidity on the Hydration parachain.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the hydration parachain is organized into several key tables:</p> <ul> <li><code>hydradx.balances</code></li> <li><code>hydradx.blocks</code></li> <li><code>hydradx.calls</code></li> <li><code>hydradx.events</code></li> <li><code>hydradx.extrinsics</code></li> <li><code>hydradx.transfers</code></li> </ul> <p>The <code>hydradx.traces</code> table is created by a snapshot script utilizing Hydration API calls to fetch accurate values which would be difficult to calculate from the blockchain events alone.</p> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Hydration are made available as materialized views.</p> Subject Area Query Materialized View Description Oracle query_3459562 <code>dune.substrate.result_hydradx_oracle</code> Provides hourly oracle values for all currencies present in the omnipool. Uses LRNA. Oracle (Alt.) query_3573146 <code>dune.substrate.result_hydra_dx_oracle_new</code> Provides hourly oracle values for all currencies present in the omnipool. Uses DOT. Oracle (Alt. Daily) query_3445402 <code>dune.substrate.result_hydra_dx_oracle_new_daily</code> Same, but aggregated daily. Oracle Pairs query_3483707 <code>dune.substrate.result_hydra_dx_oracle_pairs</code> Provides volume and transaction counts for all pairwise trades in the omnipool. Omnipool Liquidity query_3507194 <code>dune.substrate.result_hydradx_liquidity_master</code> Provides liquidity in the Omnipool on a per-account basis. Assets query_3482301 N/A Provides asset_id, symbol, and decimals for all assets in the Hydration parachain. <p>The first Oracle query is the recommended one to use for any oracle use cases that are not historical in nature. This is because it relies on the most reliable mechanism for determining the actual price, using the intermediate LRNA token price. This level of detail is only available from Jan. 2024 onwards.</p> <p>For historical price analysis, the alternative oracle query uses DOT as the intermediate currency. It may be slightly less accurate and take a bit longer to calculate.</p> <p>Liquidity in the Omnipool is calculated on a per-account basis, using the NFT positions that represent shares in the Omnipool.</p> <p>Dune users are encouraged to study the source code of the queries, including parts of a query that may have been commented out for future use.</p> <p>Uncommenting these parts may accelerate your effort of adopting a query to a slightly different use case.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/hydration-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Hydration, you are welcome to use the mentioned materialized queries. You can also use the following DuneSQL queries as examples:</p> <p>```sql title=\"Hydration Omnipool Asset (Latest)\" showLineNumbers WITH MaxTimestamps AS (   SELECT     CAST(JSON_VALUE(kv, 'strict $.id') AS INT) AS asset_id,     MAX(ts) AS max_ts   FROM hydradx.traces   WHERE track = 'omniasset'   GROUP BY 1 ), A AS (   SELECT     m.asset_id,     A1.ticker,     A1.decimals,     m.max_ts AS ts,     CAST(JSON_VALUE(t.pv, 'strict $.cap') AS UINT256) AS cap,     CAST(JSON_VALUE(t.pv, 'strict $.hubReserve') AS UINT256) AS hubReserve,     CAST(JSON_VALUE(t.pv, 'strict $.protocolShares') AS UINT256) AS protocolShares,     CAST(JSON_VALUE(t.pv, 'strict $.shares') AS UINT256) AS shares,     JSON_VALUE(t.pv, 'strict $.tradable.bits') AS tradeable   FROM MaxTimestamps m   INNER JOIN hydradx.traces t     ON m.asset_id = CAST(JSON_VALUE(t.kv, 'strict $.id') AS INT)     AND m.max_ts = t.ts   JOIN query_3482301 A1     ON A1.asset_id = m.asset_id   WHERE t.track = 'omniasset' ) SELECT   asset_id,   ticker,   ROUND(100.0 * hubReserve / (SUM(hubReserve) OVER (ORDER BY 1)), 1) AS percentage_of_pool,   cap / POW(10, 18) AS cap,   ROUND(hubReserve / POW(10, 12)) AS hubReserve,   ROUND(protocolShares / POW(10, decimals)) AS protocolShares,   ROUND(shares / POW(10, decimals)) AS shares,   ts AS last_update -- when this data was collected FROM A WHERE tradeable = '15' -- all bits set to \"on\" ORDER BY 3 DESC;</p> <p>```</p> <p>The query is fairly typical for a parachain query on Dune. It calculates the last available values from the snapshot table <code>hydradx.traces</code>.</p> <p>The query uses Dune's native UINT256 type extensively, which allows to deal with very large numbers and still maintain precision.</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/","title":"Interlay Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/#overview","title":"Overview","text":"<p>Interlay is a decentralized finance hub on Polkadot. It started as a native Bitcoin bridge, allowing users to mint and redeem iBTC on the Polkadot network. iBTC is a trustless, decentralized, and interoperable token redeemable one-for-one with native Bitcoin.</p> <p>In the summer of 2023, Interlay also launched a DEX and a lending protocol. While the DEX has seen liquidity disappear after rewards were stopped, the lending protocol has seen continued usage.</p> <p>Vaults play a crucial role for iBTC, as they guarantee the value of the minted iBTC through vault collateral. Currently, vault collateral can be DOT, VDOT, USDC, USDT, and lend tokens (qDOT, qUSDT, etc.) from the lending protocol. When using lend tokens, vault operators are double dipping: earning interest on the currency lent, and earning vault rewards.</p> <p>New currencies can be added to the Interlay protocol via governance proposals. The governance token, INTR, is used to vote on these proposals. Only staked INTR can vote, and the staked INTR is locked for a period of time.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Interlay parachain:</p> <ul> <li>interlay on Polkadot: This dashboard provides a   comprehensive view of iBTC minting, redeeming, lending, borrowing, and vault rewards.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the interlay parachain is organized into several key tables:</p> <ul> <li><code>interlay.balances</code></li> <li><code>interlay.blocks</code></li> <li><code>interlay.calls</code></li> <li><code>interlay.events</code></li> <li><code>interlay.extrinsics</code></li> <li><code>interlay.transfers</code></li> </ul> <p>The <code>interlay.traces</code> table is created by a snapshot script utilizing Interlay API calls to fetch accurate values which would be difficult to calculate from the blockchain events alone.</p> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Interlay are made available as materialized views.</p> Subject Area Query Materialized View Description Vault Collateral query_3437565 <code>dune.substrate.result_interlay_vault_creation</code> Provides vaults and their collateral. Interlay Oracle query_3445402 <code>dune.substrate.result_interlay_oracle</code> Provides hourly oracle values for all currencies present on the parachain. <p>Dune users are encouraged to study the source code of the queries, including parts of a query that may have been commented out for future use.</p> <p>Uncommenting these parts may accelerate your effort of adopting a query to a slightly different use case.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/interlay-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Interlay, you are welcome to use the mentioned materialized queries. You can also use the following DuneSQL queries as examples:</p> <p>```sql title=\"Interlay Loan Market Data\" showLineNumbers WITH ASSETS AS (   SELECT symbol, decimals   FROM (VALUES     ('DOT', 10),     ('INTR', 10),     ('IBTC', 8)   ) AS t(symbol, decimals) ), LOANDATA AS (   SELECT     E.block_time,     E.method,     event_id,     COALESCE(CAST(JSON_VALUE(data, 'strict $[0].token') AS VARCHAR), FA.symbol) AS token,     -- json_array_length(data) as len,     -- COALESCE(ASSETS.decimals, FA.decimals) as token_decimals,     CAST(JSON_VALUE(data, 'strict $[1]') AS UINT256) / POW(10, COALESCE(ASSETS.decimals, FA.decimals)) AS total_borrows,     CAST(JSON_VALUE(data, 'strict $[2]') AS UINT256) / POW(10, COALESCE(ASSETS.decimals, FA.decimals)) AS total_reserves,     CAST(JSON_VALUE(data, 'strict $[3]') AS UINT256) / 1e18 AS borrow_index,     CAST(JSON_VALUE(data, 'strict $[4]') AS UINT256) / 1e6 AS utilization,     CAST(JSON_VALUE(data, 'strict $[5]') AS UINT256) / 1e18 AS borrow_rate,     CAST(JSON_VALUE(data, 'strict $[6]') AS UINT256) / 1e18 AS supply_rate,     CAST(JSON_VALUE(data, 'strict $[7]') AS UINT256) / 1e18 AS exchange_rate   FROM interlay.events E   LEFT JOIN query_3564454 FA ON FA.foreign_asset = CAST(JSON_VALUE(data, 'strict $[0].foreignAsset') AS INT)   LEFT JOIN ASSETS ON ASSETS.symbol = JSON_VALUE(data, 'strict $[0].token')   WHERE E.section = 'loans' AND E.method = 'InterestAccrued' ) SELECT   date_trunc('hour', block_time) AS hour_period,   token,   AVG(total_borrows) AS total_borrows,   AVG(total_reserves) AS total_reserves,   AVG(borrow_index) AS borrow_index,   AVG(utilization) AS utilization,   AVG(borrow_rate) AS borrow_rate,   AVG(supply_rate) AS supply_rate,   AVG(exchange_rate) AS exchange_rate FROM LOANDATA GROUP BY 1, 2 ORDER BY 1 DESC;</p> <p>```</p> <p>The query is fairly typical for a parachain query on Dune. It parses events from the <code>interlay.events</code> table, and calculates the average values for each hour.</p> <p>It also joins the <code>interlay.events</code> table with another query, <code>query_3564454</code>, which provides the foreign assets used in the loan market.</p> <p>Finally, it uses the <code>ASSETS</code> CTE to provide the decimals for each native token in the loan market. The native assets are not available on chain, so they are hardcoded in the <code>ASSETS</code> CTE. However, they are unlikely to change over time, so this is safe.</p> <p>The query uses Dune's native UINT256 type extensively, which allows to deal with very large numbers and still maintain precision.</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/","title":"Invarch Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/#overview","title":"Overview","text":"<p>The InvArch Network is a Multichain Account abstraction hub, optimized for decentralized operations &amp; financial management spanning across every blockchain.</p> <p>InvArch provides individuals, organizations &amp; DAOs with a single account that can be used to manage all of their assets &amp; execute transactions across any network.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Acala parachain:</p> <ul> <li>InvArch: This dashboard provides a comprehensive view of   InvArch chain-state and information about DAO Staking.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the InvArch parachain is organized into several key tables:</p> <ul> <li><code>invarch.balances</code></li> <li><code>invarch.blocks</code></li> <li><code>invarch.calls</code></li> <li><code>invarch.events</code></li> <li><code>invarch.extrinsics</code></li> <li><code>invarch.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for InvArch are provided:</p> Title Query Description InvArch DAO Staking All events query_3753984 This query provides a comprehensive overview of all events related to DAO staking on the InvArch network, including details about the staking amount, staker address, and event type. InvArch DAO staking info by DAO and Era query_3755288 Access detailed information on DAO staking activities within the InvArch network, categorized by DAO and era for historical comparison."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/invarch-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"InvArch Cumulative Activated Acounts by Day\" showLineNumbers WITH accounts_first_active AS (   SELECT     address_ss58,     MIN(date_trunc('day', ts)) AS first_active_date   FROM     invarch.balances   WHERE     (free + reserved + misc_frozen + frozen) &gt; 0   GROUP BY     address_ss58 ) SELECT   first_active_date AS date,   SUM(COUNT(DISTINCT address_ss58)) OVER (     ORDER BY       DATE(first_active_date)   ) AS cumulative_accounts FROM   accounts_first_active GROUP BY   first_active_date ORDER BY   first_active_date DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/","title":"Litentry Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/#overview","title":"Overview","text":"<p>Litentry is a decentralized identity aggregator that links user identities while ensuring privacy protection, thus enabling various social and economic innovations. It features a three-layer structure, comprising source data, address analysis, and identity aggregation layers, all secured with Trusted Execution Environment (TEE) technology to enhance security and privacy. Litentry's applications include airdrop whitelisting, credit scoring, and cross-platform reputation building.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Litentry parachain:</p> <ul> <li>Litentry: A comprehensive analysis of Litentry, including:   Token Sent To Ethereum, Staking, Asset Analysis.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Litentry parachain is organized into several key tables:</p> <ul> <li><code>litentry.balances</code></li> <li><code>litentry.blocks</code></li> <li><code>litentry.calls</code></li> <li><code>litentry.events</code></li> <li><code>litentry.extrinsics</code></li> <li><code>litentry.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Litentry are provided:</p> Title Query Description Litentry Latest Collator Info query_3827164 Find the latest collator information on Litentry Litentry LIT Token Sent To Ethereum query_3825036 Find all records of LIT tokens sent to Ethereum"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/litentry-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Litentry LIT Token Sent To Ethereum\" showLineNumbers SELECT DISTINCT   block_time,   extrinsic_id,   get_href(     'https://litentry.statescan.io/#/extrinsics/' || extrinsic_id,     extrinsic_id   ) AS extrinsic_id_url,   JSON_VALUE(data, 'strict $[0]') AS dest_id,   JSON_VALUE(data, 'strict $[1]') AS nonce,   JSON_VALUE(data, 'strict $[2]') AS source_id,   IF(     JSON_VALUE(data, 'strict $[3]') LIKE '0x%',     bytearray_to_int256(JSON_VALUE(data, 'strict $[3]')) / POW(10, 12),     CAST(JSON_VALUE(data, 'strict $[3]') AS int256) / POW(10, 12)   ) AS amount,   JSON_VALUE(data, 'strict $[4]') AS recipient,   get_href(     'https://etherscan.io/address/' || JSON_VALUE(data, 'strict $[4]'),     CONCAT(       SUBSTR(JSON_VALUE(data, 'strict $[4]'), 1, 4),       '...',       SUBSTR(         JSON_VALUE(data, 'strict $[4]'),         LENGTH(JSON_VALUE(data, 'strict $[4]')) - 3       )     )   ) AS recipient_url FROM   litentry.events WHERE   section = 'chainBridge'   AND method = 'FungibleTransfer' ORDER BY   block_time DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/","title":"Manta Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/#overview","title":"Overview","text":"<p>Manta Atlantic is a fast and decentralized ZK Layer 1 supporting modular on-chain compliance identities. Its suite of core products and technologies, including zkNFTs, staking, and ecosystem projects, offers user-friendly access to powerful ZK-enabled use cases.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Manta parachain:</p> <ul> <li>Manta Parachain Staking Dashboard: This dashboard provides   various information on Manta Parachain Staking.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the manta parachain is organized into several key tables:</p> <ul> <li><code>manta.balances</code></li> <li><code>manta.blocks</code></li> <li><code>manta.calls</code></li> <li><code>manta.events</code></li> <li><code>manta.extrinsics</code></li> <li><code>manta.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Manta Delegator All events</p> <p>Some useful queries for Manta are provided:</p> Title Query Description Manta Delegator All events query_3722522 This query provides a comprehensive overview of all events related to Delegator activities on the Manta network, including collator, delegator, amount, and event type."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/manta-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Manta to Moonbeam XTokens Transfer\" showLineNumbers SELECT   DATE_TRUNC('day', block_time) AS day,   SUM(     CAST(json_extract_scalar(params, '$.amount') AS DOUBLE) / POWER(10, 18)   ) AS amount,   'Manta to Moonbeam' AS section FROM   manta.extrinsics WHERE   section = 'xTokens'   AND method = 'transfer'   AND json_extract_scalar(params, '$.dest.v3.interior.x2[0].parachain') = '2004' GROUP BY   DATE_TRUNC('day', block_time) ORDER BY   day DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/","title":"Moonbeam Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/#overview","title":"Overview","text":"<p>Moonbeam is a fully Ethereum-compatible parachain on the Polkadot network, enabling developers to deploy existing Solidity smart contracts and DApp frontends with minimal changes. It is designed to provide interoperability and compatibility, bridging the gap between Ethereum and Polkadot.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Moonbeam parachain:</p> <ul> <li>Moonbeam DEX: Explore decentralized exchange activities   and token swaps within the Moonbeam ecosystem.</li> <li>Moonbeam Governance: Detailed insights into   governance proposals, voting, and outcomes within the Moonbeam community.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Moonbeam parachain is organized into several key tables:</p> <ul> <li><code>moonbeam.balances</code></li> <li><code>moonbeam.blocks</code></li> <li><code>moonbeam.calls</code></li> <li><code>moonbeam.events</code></li> <li><code>moonbeam.extrinsics</code></li> <li><code>moonbeam.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Moonbeam are provided:</p> Title Query Description Moonbeam Referenda Result query_3679042 Provides details on the results of Moonbeam referenda, including the total aye and nay votes, support, and the result of the referendum. Moonbeam All Voting Types query_3642417 Offers a comprehensive overview of all voting types on Moonbeam, including standard, split, and split abstain votes, voting conviction, and voting tokens."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/moonbeam-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Moonbeam Referenda Result\" showLineNumbers SELECT DISTINCT   CAST(JSON_EXTRACT_SCALAR(data, '$[0]') AS INTEGER) AS referenda_id,   get_href(     'https://moonbeam.subscan.io/referenda_v2/' || CAST(JSON_EXTRACT_SCALAR(data, '$[0]') AS VARCHAR),     CAST(JSON_EXTRACT_SCALAR(data, '$[0]') AS VARCHAR)   ) AS referenda_id_url,   varbinary_to_uint256(     from_hex(SUBSTR(JSON_EXTRACT_SCALAR(data, '$[1].ayes'), 3))   ) / POW(10, 18) AS aye_total,   varbinary_to_uint256(     from_hex(SUBSTR(JSON_EXTRACT_SCALAR(data, '$[1].nays'), 3))   ) / POW(10, 18) AS nay_total,   varbinary_to_uint256(     from_hex(SUBSTR(JSON_EXTRACT_SCALAR(data, '$[1].support'), 3))   ) / POW(10, 18) AS support,   method AS result FROM   moonbeam.events WHERE   section = 'referenda'   AND (     method = 'Confirmed'     OR method = 'Rejected'     OR method = 'Cancelled'     OR method = 'TimedOut'   ) ORDER BY   referenda_id DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/","title":"Neuroweb Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/#overview","title":"Overview","text":"<p>NeuroWeb is a decentralized AI blockchain that rewards knowledge creation and sharing. Its NEURO token supports the AI economy by incentivizing contributions to the OriginTrail Decentralized Knowledge Graph (DKG). NeuroWeb builds upon the groundwork established by its predecessor, the OriginTrail Parachain (OTP). This transformation into NeuroWeb was facilitated through a community governance vote on OTP in December 2023.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Neuroweb parachain:</p> <ul> <li>Neuroweb: A comprehensive analysis of NeuroWeb, including:   DKG, knowledge asset, asset, and XCM analysis.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the NeuroWeb parachain is organized into several key tables:</p> <ul> <li><code>neuroweb.balances</code></li> <li><code>neuroweb.blocks</code></li> <li><code>neuroweb.calls</code></li> <li><code>neuroweb.events</code></li> <li><code>neuroweb.extrinsics</code></li> <li><code>neuroweb.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Neuroweb are provided:</p> Title Query Description Neuroweb Knowledge Asset query_3695045 Find all transfer records of knowledge assets on Neuroweb"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/neuroweb-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Neuroweb Knowledge Asset Distribution\" showLineNumbers SELECT DISTINCT   get_href(     'https://dkg.origintrail.io/profile?wallet=' || CAST(To AS VARCHAR),     CONCAT(       SUBSTR(To, 1, 4),       '...',       SUBSTR(To, LENGTH(To) - 3)     )   ) AS Holder_URL,   CONCAT(     SUBSTR(To, 1, 4),     '...',     SUBSTR(To, LENGTH(To) - 3)   ) AS Holder,   COUNT(\"Token ID\") AS \"# of Tokens\" FROM   query_3695045 GROUP BY   To ORDER BY   \"# of Tokens\" DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/","title":"Nodle Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/#overview","title":"Overview","text":"<p>Nodle is a parachain on Polkadot focused on providing connectivity and data liquidity for the Internet of Things (IoT). It enables devices to securely connect, interact, and transact with efficiency.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Nodle parachain:</p> <ul> <li>Nodle Dashboard: A comprehensive view of IoT connectivity and   transactions within the Nodle ecosystem.</li> </ul> <p>Please also visit our dashboards for Nodle on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Nodle parachain is organized into several key tables:</p> <ul> <li><code>nodle.balances</code></li> <li><code>nodle.blocks</code></li> <li><code>nodle.calls</code></li> <li><code>nodle.events</code></li> <li><code>nodle.extrinsics</code></li> <li><code>nodle.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Nodle are provided:</p> Title Query Description Nodle Mint Uniques query_3753531 This query retrieves data on Unique NFTs minted within the Nodle ecosystem."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/nodle-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Nodle Mint Uniques\" showLineNumbers SELECT DISTINCT   block_time,   JSON_EXTRACT_SCALAR(call_args, '$.owner.id') AS owner,   JSON_EXTRACT(call_args, '$.collection') AS collection,   JSON_EXTRACT(call_args, '$.item') AS item FROM   nodle.calls WHERE   (call_section = 'nodleUniques' OR call_section = 'uniques')   AND call_method = 'mint'   AND extrinsic_id NOT IN (     SELECT       extrinsic_id     FROM       nodle.events     WHERE       method = 'ExtrinsicFailed'   );</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/","title":"Pendulum Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/#overview","title":"Overview","text":"<p>Pendulum is a parachain on Polkadot that focuses on bridging fiat currencies and decentralized finance (DeFi). It aims to create a fully functional fiat-optimized blockchain that facilitates open financial applications and connects them with the traditional financial sector.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Pendulum parachain:</p> <ul> <li>Pendulum on Polkadot: Explore comprehensive data   visualizations tracking the integration of fiat and DeFi on the Pendulum parachain.</li> </ul> <p>Please also visit our dashboards for Pendulum on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Pendulum parachain is organized into several key tables:</p> <ul> <li><code>pendulum.balances</code></li> <li><code>pendulum.blocks</code></li> <li><code>pendulum.calls</code></li> <li><code>pendulum.events</code></li> <li><code>pendulum.extrinsics</code></li> <li><code>pendulum.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Pendulum are provided:</p> Title Query Description Pendulum Spacewalk Transactions query_3821151 Find all Spacewalk transactions on the Pendulum parachain"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/pendulum-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Pendulum Spacewalk Transactions by Month\" showLineNumbers SELECT   DATE_TRUNC('month', block_time) AS month,   SUM(amount) AS amount,   COUNT(*) AS count,   token_name FROM   query_3821151 -- Pendulum Spacewalk Transactions GROUP BY   DATE_TRUNC('month', block_time),   token_name;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/","title":"People Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/#overview","title":"Overview","text":"<p>People's Chain focuses on decentralized identity and social interactions, enabling users to manage their digital identity and engage in community governance.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the People parachain:</p> <ul> <li>People Dashboard: A comprehensive view of identity management   and social interaction activities within the People ecosystem.</li> </ul> <p>Please also visit our dashboards for People on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the People parachain is organized into several key tables:</p> <ul> <li><code>people.balances</code></li> <li><code>people.blocks</code></li> <li><code>people.calls</code></li> <li><code>people.events</code></li> <li><code>people.extrinsics</code></li> <li><code>people.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for People are provided:</p> Title Query Description Kusama People Chain - Identity History query_3836167 Find all identity history records on the Kusama People Chain"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/people-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Kusama People Chain - Identity History Sample\" showLineNumbers SELECT   block_time,   extrinsic_id,   signer_ss58,   signer_pub_key,   CAST(     from_utf8(       from_hex(JSON_EXTRACT_SCALAR(call_args, '$.info.display.raw'))     ) AS VARCHAR   ) AS name,   CAST(     from_utf8(       from_hex(JSON_EXTRACT_SCALAR(call_args, '$.info.email.raw'))     ) AS VARCHAR   ) AS email FROM   people_kusama.calls WHERE   call_section = 'identity'   AND call_method = 'setIdentity';</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/","title":"Phala Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/#overview","title":"Overview","text":"<p>Phala is a parachain on Polkadot that provides a privacy-preserving computation and data protection framework. It allows for the processing of sensitive data with guaranteed privacy.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Phala parachain:</p> <ul> <li>Phala Dashboard: A comprehensive view of activities within the   Phala ecosystem.</li> </ul> <p>Please also visit our dashboards for Phala on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Phala parachain is organized into several key tables:</p> <ul> <li><code>phala.balances</code></li> <li><code>phala.blocks</code></li> <li><code>phala.calls</code></li> <li><code>phala.events</code></li> <li><code>phala.extrinsics</code></li> <li><code>phala.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p> <p>Additional curated dataset from Phala team can be found at <code>dune.phala_network.*</code></p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Phala are provided:</p> Title Query Description Phala Computation query_3619434 This query provides an overview of the Phala network's computation, including circulation, bridge, reward, issuance, supply, value, worker count, rewards, APR, budget, and delegator count. Phala Recent AI Agent Contracts query_3743294 This query lists the recent AI agent contracts deployed on the Phala network, including deployer, instantiation time, code hash, stake, and staker."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/phala-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Phala Computation\" showLineNumbers SELECT   chain,   circulation,   sygma_bridge,   reward,   COALESCE(total_issuance, total_supply) AS total_issuance,   total_value,   idle_worker_count,   daily_rewards,   average_apr,   budget_per_share,   delegator_count FROM   dune.phala_network.dataset_phala_computation;</code></p> <p>Query result:</p> <p>Visualizations using the query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/","title":"Polimec Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/#overview","title":"Overview","text":"<p>Polimec offers a decentralized, transparent, and compliant method for fundraising, ensuring that stakeholder incentives are aligned both during and after the fundraising process.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Polimec parachain:</p> <ul> <li>Polimec: A comprehensive analysis of Polimec, including:   Staking, Funding, Asset Analysis.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the polimec parachain is organized into several key tables:</p> <ul> <li><code>polimec.balances</code></li> <li><code>polimec.blocks</code></li> <li><code>polimec.calls</code></li> <li><code>polimec.events</code></li> <li><code>polimec.extrinsics</code></li> <li><code>polimec.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Polimec are provided:</p> Title Query Description Polimec Latest Collator Info query_3776548 Find the latest collator information on Polimec Plimec All Evaluations query_3802921 Get all evaluation information for all projects on Polimec Polimec All Funding Participations query_3850228 Get all funding participation information for all projects on Polimec"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polimec-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Polimec Latest Reward Distribution\" showLineNumbers WITH latest_round AS (   SELECT     MAX(CAST(JSON_EXTRACT_SCALAR(data, '$[0]') AS BIGINT)) AS start_block   FROM     polimec.events   WHERE     section = 'parachainStaking'     AND method = 'NewRound' ), summed AS (   SELECT     MAX(block_time) AS latest_time,     JSON_EXTRACT_SCALAR(JSON_PARSE(data), '$[0]') AS delegator,     SUM(       CAST(JSON_EXTRACT_SCALAR(data, '$[1]') AS BIGINT) / POW(10, 10)     ) AS reward   FROM     polimec.events   WHERE     section = 'parachainStaking'     AND method = 'Rewarded'     AND CAST(block_number AS BIGINT) &gt;= (       SELECT         start_block       FROM         latest_round     )   GROUP BY     JSON_EXTRACT_SCALAR(JSON_PARSE(data), '$[0]') ) SELECT   latest_time,   delegator,   get_href(     'https://explorer.polimec.org/polimec/account/' || delegator,     CONCAT(       SUBSTR(delegator, 1, 4),       '...',       SUBSTR(delegator, LENGTH(delegator) - 3)     )   ) AS delegator_url,   reward FROM   summed ORDER BY   reward DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/","title":"Polkadex Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/#overview","title":"Overview","text":"<p>Polkadex is a decentralized exchange parachain on Polkadot that combines the benefits of centralized and decentralized exchanges, offering a high-performance trading experience with trustless custody. It aims to provide a seamless trading environment while ensuring the security of a decentralized platform.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Polkadex parachain:</p> <ul> <li>Polkadex: This dashboard provides a comprehensive view of   trading activities and token dynamics within the Polkadex network.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Polkadex parachain is organized into several key tables:</p> <ul> <li><code>polkadex.balances</code></li> <li><code>polkadex.blocks</code></li> <li><code>polkadex.calls</code></li> <li><code>polkadex.events</code></li> <li><code>polkadex.extrinsics</code></li> <li><code>polkadex.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Polkadex are provided:</p> Title Query Description Polkadex MultiAssets Transfers query_3830615 Daily count of 'TransferredMultiAssets' observed on Polkadex parachain Polkadex \\&lt;-&gt; AssetHub Table query_3824637 This query provides a comprehensive overview of the assets transferred between Polkadex parachain and AssetHub, including the amount, symbol, and section."},{"location":"general/dashboards/dune-analytics/parachain-dashboards/polkadex-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Snowbridge, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Polkadot BridgeHub Outbound Msg Sent To Ethereum\" showLineNumbers SELECT   DATE_TRUNC('day', block_time) AS day,   COUNT(method) AS cnt FROM   polkadex.events WHERE   method = 'TransferredMultiAssets' GROUP BY   DATE_TRUNC('day', block_time);</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/","title":"Snowbridge Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/#overview","title":"Overview","text":"<p>Snowbridge is a general-purpose, trustless, and decentralized bridge that connects Polkadot and Ethereum. This bridge facilitates communication between any Polkadot parachain and Ethereum using Polkadot's XCMP messaging protocol. Parachains can send XCM instructions to BridgeHub, leveraging Snowbridge for cross-chain interactions.</p> <p>For more details on bridging with Kusama, please refer to our BridgeHub Dashboard.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Snowbridge protocol:</p> <ul> <li>Snowbridge: A comprehensive analysis of Snowbridge,   including: Ethereum Related On Chain Data Analysis, Analysis of Messages with Ethereum.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Snowbridge protocol is organized into several key tables:</p> <ul> <li><code>bridgehub.balances</code></li> <li><code>bridgehub.blocks</code></li> <li><code>bridgehub.calls</code></li> <li><code>bridgehub.events</code></li> <li><code>bridgehub.extrinsics</code></li> <li><code>bridgehub.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Snowbridge are provided:</p> Title Query Description Snowbridge Tokensent query_3828274 Monitoring Tokensent from Snowbridge's gateway contract on Ethereum to Polkadot BridgeHub Polkadot AssetHub ForeignAsset Mint &amp; Burn query_3828126 Monitoring ForeignAsset Mint &amp; Burn"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/snowbridge-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Snowbridge, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Polkadot BridgeHub Outbound Msg Sent To Ethereum\" showLineNumbers SELECT DISTINCT   block_time,   block_number,   block_hash,   extrinsic_id,   extrinsic_hash,   event_id,   section,   method,   CAST(JSON_VALUE(data, 'strict $[0]') AS VARCHAR) AS message_id,   CAST(JSON_VALUE(data, 'strict $[1]') AS uint256) AS nonce FROM   bridgehub.events WHERE   section = 'ethereumOutboundQueue'   AND method = 'MessageAccepted';</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/","title":"Stellaswap Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/#overview","title":"Overview","text":"<p>Stellaswap is the leading DEX on Moonbeam, no matter whether you measure by volume, number of pools, or accounts using it. It also offers liquid staking for DOT.</p> <p>Users can swap from any asset to any other asset using an automated router that will calculate the most efficient path.</p> <p>Liquidity providers can earn fees from the trades in the pools they provide liquidity to.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from StellaSwap:</p> <ul> <li>stellaswap on Polkadot: This dashboard provides a   comprehensive view of DEX volumes and liquidity on StellaSwap.</li> </ul>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the stellaswap DEX is sourced directly from substrate moonbeam tables: <code>moonbeam.events</code></p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Hydration are made available as materialized views.</p> Subject Area Query Materialized View Description Stellaswap V3 Trades query_3661633 <code>dune.substrate.result_stellaswap_v_3_trades</code> Trades in V3 pools, similar to dex.trades format. Stellaswap V3 Trades (alt) query_3646057 <code>dune.substrate.result_stellaswap_v3_trades</code> Trades in V3 pools, suitable for volume and price analysis V3 Trades Enriched query_3656957 <code>dune.substrate.result_stellaswap_trades_enriched</code> Trades in V3 pools, with USD equivalent prices. Stellaswap V3 Pools query_3639606 <code>dune.substrate.dataset_stella_pools</code> (dataset) Master data for the pools <p>The three queries presented are all very similar, but they are optimized for different use cases.</p> <p>Each trade will provide a token0 and token1, which are the two tokens traded. The order depends on the order in the pool definition (see V3 pools query). Example: for the pool WGLMR-xcDOT, WGLMR is token0 and xcDOT is token1. Whether someone was buying or selling GLMR can be seen by the sign of amount0. Positive means \"selling\", negative means \"buying\". Only one of the first of the three queries above sorts the tokens into the right order.</p> <p>The other queries keep token0 and token1 in the order in which they appear in the raw data, which also makes it easier to aggregate for the price and volume.</p> <p>Pool master data is currently provided as a dataset directly, rather than parsed from events or from a snapshot. This means the latest pools added may not be included in the dataset. (Remains a work in progress.)</p> <p>Dune users are encouraged to study the source code of the queries, including parts of a query that may have been commented out for future use.</p> <p>Uncommenting these parts may accelerate your effort of adopting a query to a slightly different use case.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/stellaswap-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Stellaswap, you are welcome to use the mentioned materialized queries. You can also use the following DuneSQL queries as examples:</p> <p>```sql title=\"Stellaswap Volume Last Day\" showLineNumbers WITH maxts AS (   SELECT     MAX(DATE_TRUNC('day', block_time)) AS maxts   FROM     dune.substrate.result_stellaswap_trades_enriched T ) SELECT   DATE_TRUNC('day', block_time) AS date,   T.token_pair,   project_contract_address,   current_timestamp - MAX(block_time) AS last_seen_ago,   ROUND(SUM(ABS(amount_usd))) AS volume_usd,   T.subquery FROM   dune.substrate.result_stellaswap_trades_enriched T WHERE   DATE_TRUNC('day', block_time) = (SELECT maxts FROM maxts) GROUP BY   1, 2, 3, 6 ORDER BY   1 DESC, 5 DESC;</p> <p>```</p> <p>The query calculates the last available day's volume for each token pair. It also shows which pair was used to calculate the USD value of the tokens involved. For example, if you trade a pair which contains USDC or USDT, the dollar value of the trade is just the amount of USDC or USDT traded. For other pairs, the USD value is calculated using another currency as an intermediate, i.e. DOT or GLMR. Any pair which does not at least have one of these currencies will not have a USD value calculated.</p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/","title":"Unique Dashboards","text":""},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/#overview","title":"Overview","text":"<p>Unique is a leading parachain on Polkadot dedicated to enabling NFTs and their collections. It provides a robust framework for users and developers to engage with non-fungible tokens across different applications.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you will find a variety of dashboards that help visualize data from the Unique parachain:</p> <ul> <li>Unique NFT Dashboard: A comprehensive view of   NFT activities within the Unique parachain.</li> <li>Unique Collection Details Dashboard:   Detailed insights into specific NFT collections.</li> </ul> <p>Please also visit our dashboards for Unique on Dune Analytics.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/#key-tables","title":"Key Tables","text":"<p>Data from the Unique parachain is organized into several key tables:</p> <ul> <li><code>unique.balances</code></li> <li><code>unique.blocks</code></li> <li><code>unique.calls</code></li> <li><code>unique.events</code></li> <li><code>unique.extrinsics</code></li> <li><code>unique.transfers</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/#useful-queries","title":"Useful Queries","text":"<p>Some useful queries for Unique are provided:</p> Title Query Description Unique ss58 and pubkey Maping Table query_3632470 Find all Unique ss58 and pubkey mappings Unique NFT Info query_3630265 Find all Unique NFT information Unique Collection Info query_3628043 Find all Unique collection information Unique NFT Transaction Info query_3631785 Find all Unique NFT transaction information"},{"location":"general/dashboards/dune-analytics/parachain-dashboards/unique-dashboards/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Unique Top Collections by Total Sales Amount\" showLineNumbers SELECT   collection_id_with_dashboard_url,   token_prefix,   SUM(for_price) AS total_amount FROM   dune.substrate.result_unique_nft_transaction_info GROUP BY   collection_id_with_dashboard_url,   token_prefix ORDER BY   SUM(for_price) DESC;</code></p> <p>Query result:</p> <p>DuneSQL Reference</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/","title":"Polkadot Dashboards Governance","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#overview","title":"Overview","text":"<p>This document demonstrated various Polkadot governance dashboards, offering insights into treasury management, referendum outcomes, voting patterns, and OpenGov referenda. These dashboards aim to enhance community engagement by simplifying access to governance information and fostering a transparent decision-making environment.</p> <p>Authored by @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#polkadot-governance-dashboard","title":"Polkadot Governance Dashboard","text":"<p>View On Dune: Polkadot Governance Dashboard</p> <p>The Polkadot Governance Dashboard provides a clear and concise representation of the network's governance activities.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#polkadot-treasury-flow","title":"Polkadot Treasury Flow","text":"<p>Visualizes the monthly financial movements within the Polkadot treasury.</p> <ul> <li>Treasury Netflow: Treasury Inflows - Treasury Outflows</li> <li>Treasury Inflows: Inflation + Fees + Txn Tips + Slash</li> <li>Treasury Outflows: Opengov Proposals (Spender + Tipper Track) + Bounties + Burnt</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#number-of-votes-by-duration-of-lock","title":"Number of Votes by Duration of Lock","text":"<p>Visualizes Polkadot governance voting commitments.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#monthly-governance-metrics","title":"Monthly Governance Metrics","text":"<p>These charts offer insights into monthly Polkadot governance engagement.</p> <ul> <li>Number of Monthly Voters / Monthly Capital by Type / Monthly Voting Power by Type </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#conviction-voting-power","title":"Conviction Voting Power","text":"<ul> <li>None (0.1x) - No lock</li> <li>Locked1x - 7 Days</li> <li>Locked2x - 14 Days</li> <li>Locked3x - 28 Days</li> <li>Locked4x - 56 Days</li> <li>Locked5x - 112 Days</li> <li>Locked6x - 224 Days</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#referenda-metrics","title":"Referenda Metrics","text":"<ul> <li> <p>Number of Referenda by Outcome (OpenGov) </p> </li> <li> <p>Number of Referenda by Origin </p> </li> <li> <p>Monthly Tokens Voted by Direction / Monthly Voting Power by Direction </p> </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#delegation-and-voting-dynamics","title":"Delegation and Voting Dynamics","text":"<ul> <li> <p>Recent Major Delegation Changes </p> </li> <li> <p>Recent Major Swing Votes </p> </li> <li> <p>Whale Voters </p> </li> <li> <p>Awakened Whale Voters </p> </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#polkadot-opengov-referenda-home","title":"Polkadot OpenGov Referenda - Home","text":"<p>View On Dune: Polkadot OpenGov Referenda - Home</p> <p>Designed for voters to quickly understand the current trend in Polkadot OpenGov and proceed to vote on Polkassembly.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#referenda-basic-information","title":"Referenda Basic Information","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#controversial-referenda","title":"Controversial Referenda","text":"<p>Referenda with approval ratings ranging from 0.2 to 0.8 are considered controversial.</p> <p></p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#polkadot-opengov-referendum-voting-analysis","title":"Polkadot Opengov - Referendum Voting Analysis","text":"<p>View On Dune: Polkadot Opengov - Referendum Voting Analysis</p> <p>Tip</p> <p>Default parameters are applied to all parameterized charts on this Wiki page as a demonstration. Visit our dashboard on Dune to use the <code>referendum_id</code> parameter for more in-depth analysis. For more information, please visit theDune documentation on parameters.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#voting-power-analysis","title":"Voting Power Analysis","text":"<ul> <li> <p>Voting Power Daily Accumulation </p> </li> <li> <p>Aye vs Nay </p> </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#vote-analysis","title":"Vote Analysis","text":"<ul> <li>Aye Votes Analysis </li> </ul> <ul> <li>Nay Votes Analysis </li> </ul> <ul> <li>Abstain Votes Analysis </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-governance/#voter-insights","title":"Voter Insights","text":"<ul> <li> <p>First Time Voter Analysis </p> </li> <li> <p>Voter Conviction Adjustment </p> </li> </ul> <ul> <li>Awakened Voters </li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/","title":"Polkadot Dashboards Network","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/#overview","title":"Overview","text":"<p>This document demonstrated various Polkadot network dashboards, offering insights into shared security, staking rates, validator dynamics, and staking pools. These dashboards aim to provide a comprehensive understanding of the Polkadot ecosystem's economic and consensus mechanisms, emphasizing network participation, security, and decentralization.</p> <p>Authored by @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/#polkadot-shared-security-of-the-network","title":"Polkadot Shared Security of the Network","text":"<p>View On Dune: Polkadot Shared Security of the Network</p> <p>The Polkadot - Shared Security of the Network dashboard showcases the staking and validator dynamics within the Polkadot network. It emphasizes various aspects of network security, such as staking rates, validator nomination pools, and the minimum and maximum stakes required for validators. This dashboard visualizes data trends over time, reflecting the network's stake distribution and the participation of validators and nominators. It serves as an essential indicator of network participation, security, and decentralization.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/#polkadot-network-staking-rate-chart","title":"Polkadot - Network Staking Rate Chart","text":"<p>This chart analyzes the Polkadot network's staking rate over time, focusing on the ratio of total staked tokens to total issued tokens. It shows the portion of the network's capital used for securing the blockchain, a key metric for assessing network engagement and security.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/#polkadot-nominators-validators-pools-chart","title":"Polkadot - Nominators &amp; Validators &amp; Pools Chart","text":"<p>The chart tracks the number of active validators, nominators, and staking pools. This data helps visualize the network's decentralization and stakeholder participation, crucial for understanding the robustness of Polkadot's staking ecosystem.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-network/#polkadot-minimum-and-maximum-validator-stakes","title":"Polkadot Minimum and Maximum Validator Stakes","text":"<p>This chart represents the stake distribution among validators in the Polkadot network on a monthly basis. It illustrates the minimum, average, and maximum stakes held by validators, providing a clear visualization of the variance and spread within the validator pool. Additionally, it highlights the stake concentration by showing the difference between the highest and lowest stakes as a percentage of the total stake, offering insights into the network's staking dynamics and the level of decentralization.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/","title":"Polkadot Dashboards Overview","text":"<p>Polkadot is a flagship project by Web3 Foundation, designed to enable a completely decentralized web where users are in control. It is a sharded multichain network, meaning it can process many transactions on several chains in parallel, improving scalability.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#featured-dashboards-on-dune","title":"Featured Dashboards on Dune","text":"<p>Here you'll find a variety of dashboards that help visualize data from the Polkadot network:</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#governance","title":"Governance","text":"<p>Explore Polkadot's governance through dashboards detailing proposal submissions, referenda outcomes, and voting behaviors. These tools highlight the decentralized decision-making process and its efficacy.</p> <ul> <li>Polkadot Governance Dashboard: The Polkadot Governance   Dashboard provides a clear and concise representation of the   network's governance activities. It   serves as a useful tool for community members to observe   treasury management,   referendum outcomes, and   voting patterns. This dashboard aims to enhance community engagement by simplifying access to   governance information and fostering a transparent decision-making environment.</li> <li>Polkadot OpenGov Referenda - Home:   This dashboard is designed for those who wish to vote, allowing them to quickly understand the   current trend in Polkadot OpenGov and proceed to vote on   Polkassembly. If you want to see more details of each   referendum, please check   Polkadot Opengov - Referendum Voting Analysis.</li> <li>Polkadot Opengov - Referendum Voting Analysis:   Detailed insights into the referendum voting process and outcomes.</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#staking","title":"Staking","text":"<p>Dive into the staking ecosystem with dashboards that analyze validator performance, nominator contributions, and staking distributions. For a deeper understanding of Polkadot's staking mechanism and to optimize your staking strategies, visit the official staking mechanism documentation and the staking web app documentation.</p> <ul> <li>Polkadot Staking Dashboard: Overview of staking   dynamics and distribution across the network.</li> <li>Polkadot Staking Dashboard (Validators) \ud83d\udcb0:   Analyze validator performance and statistics.</li> <li>Polkadot Staking Dashboard (Nominators) \ud83d\udcb0:   Insights into nominator contributions and rewards.</li> <li>Polkadot Staking Dashboard (Pool Member) \ud83d\udcb0:   Data on staking pools and individual member activity.</li> <li>Polkadot Staking Dashboard (Nomination Pool) \ud83d\udcb0:   Detailed view of nomination pools and their performance.</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#miscellaneous","title":"Miscellaneous","text":"<p>Discover diverse aspects of Polkadot through Miscellaneous dashboards, which provide insights into DOT ordinals and other unique network activities. Ideal for uncovering trends in the broader ecosystem.</p> <ul> <li>DOT Ordinals: Examination of DOT ordinal metrics and   trends.</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#key-tables","title":"Key Tables","text":"<p>Data from the Polkadot network is organized into several key tables:</p> <ul> <li><code>polkadot.balances</code></li> <li><code>polkadot.blocks</code></li> <li><code>polkadot.calls</code></li> <li><code>polkadot.events</code></li> <li><code>polkadot.extrinsics</code></li> <li><code>polkadot.transfers</code></li> <li><code>polkadot.traces</code></li> <li><code>polkadot.stakings</code></li> </ul> <p>Start building your own queries using granular data on Dune here.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#useful-queries","title":"Useful Queries","text":"<p>Here are materialized queries for Polkadot that may be useful to build your own charts:</p> <ul> <li>Polkadot Referenda Total Voting Power   (<code>dune.substrate.result_polkadot_referenda_total_voting_power</code>)</li> <li>Polkadot Staking Nomination Total   (<code>dune.substrate.result_polkadot_staking_nomination_total</code>)</li> <li>Polkadot OpenGov Delegation   (<code>dune.substrate.result_polkadot_open_gov_delegation</code>)</li> <li>Polkadot Vote Record   (<code>dune.substrate.result_polkadot_vote_record</code>)</li> <li>Polkadot Proposals proposed   (<code>dune.substrate.result_polkadot_proposals_proposed</code>)</li> <li>Polkadot Referenda Direct Vote   (<code>dune.substrate.result_polkadot_referenda_direct_vote</code>)</li> <li>Polkadot Each Vote Record(<code>dune.substrate.result_polkadot_each_vote_record</code>)</li> <li>Polkdaot Referenda Origin Map(<code>dune.substrate.result_polkdaot_referenda_origin_map</code>)</li> <li>Polkadot Failed calls in batch(<code>dune.substrate.result_polkadot_failed_calls_in_batch</code>)</li> <li>polkadot_validator   (<code>dune.substrate.result_polkadot_validators</code>)</li> <li>polkadot_nominationpools   (<code>dune.substrate.result_polkadot_nominationpools</code>)</li> <li>polkadot_nominators   (<code>dune.substrate.result_polkadot_nominators</code>)</li> <li>polkadot_poolmembers   (<code>dune.substrate.result_polkadot_poolmembers</code>)</li> <li>polkadot_identity (<code>dune.substrate.result_polkadot_identity</code>)</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-overview/#getting-started-with-queries","title":"Getting Started with Queries","text":"<p>To get started with querying data from Unique, you are welcome to use the mentioned materialized queries. You can use the following DuneSQL queries as examples:</p> <p><code>sql title=\"Polkadot Staking APR (Normalized)\" showLineNumbers SELECT   AVG(validator_normalized_staking_apr) AS staking_apr,   era,   DATE_FORMAT(ts, '%Y-%m-%d') AS era_ts FROM   dune.substrate.result_polkadot_validators WHERE   validator_is_active = TRUE   AND validator_commission &lt;&gt; 1 GROUP BY   era,   ts HAVING   AVG(validator_normalized_staking_apr) &gt; 0 ORDER BY   era DESC;</code></p> <p>Query result:</p> <p>Visualized result:</p> <p>Info</p> <p>For more information on DuneSQL, please refer to the DuneSQL Cheatsheet and DuneSQL Official Documentation.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/","title":"Polkadot Dashboards Staking","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#overview","title":"Overview","text":"<p>This document demonstrated various Polkadot staking dashboards, offering insights into staking rewards, validator and nominator metrics, nomination pools, and pool member activities. These dashboards aim to provide a comprehensive view of staking dynamics within the Polkadot network.</p> <p>Authored by @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-dashboard","title":"Polkadot Staking Dashboard","text":"<p>View On Dune: Polkadot Staking Dashboard</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#completed-era","title":"Completed Era","text":"<p>Completed eras can have at most a 2-day delay before the staking rewards &amp; APY computation becomes available. The Staking Home Page shows the most recently completed era.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#reward-rate-math","title":"Reward Rate Math","text":"<ul> <li>Reward Rate: (validator_erasRewardPoints / erasRewardPoints_total) * ErasValidatorReward /   validator_total_stake.</li> <li>Effective Reward Rate: (1 - validator_commission) * Reward Rate.</li> <li>Normalized Reward Rate: total_era_rewards / number_of_validators * (1 - commission) /   validator_total_stake.</li> </ul> <p>Source Table: polkadot.stakings, MaterializedView: dune.substrate.result_polkadot_validators, dune.substrate.result_polkadot_nominators, dune.substrate.result_polkadot_nominationpools, dune.substrate.result_polkadot_poolmembers, dune.substrate.result_polkadot_identity</p> <p>Github repo: substrate-etl</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#staking-analytics","title":"Staking Analytics","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-dashboard-validators","title":"Polkadot Staking Dashboard (Validators)","text":"<p>View On Dune: Polkadot Staking Dashboard (Validators)</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-rewards","title":"Polkadot Staking Rewards","text":"<ul> <li>Reward Rate: (validator_erasRewardPoints / erasRewardPoints_total) * ErasValidatorReward /   validator_total_stake.</li> <li>Effective Reward Rate: (1 - validator_commission) * Reward Rate.</li> <li>Normalized Reward Rate: total_era_rewards / number_of_validators * (1 - commission) /   validator_total_stake.</li> </ul> <p>Source Table: polkadot.stakings, MaterializedView: dune.substrate.result_polkadot_validators</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-dashboard-nominators","title":"Polkadot Staking Dashboard (Nominators)","text":"<p>View On Dune: Polkadot Staking Dashboard (Nominators)</p> <p>For a specific nominator, this dashboard shows:</p> <ul> <li>Nominator Staking Rewards</li> <li>Nominator Shares</li> <li>Delegated Amount</li> <li>Nominator Staking Rewards Raw Data</li> </ul> <p>Source Table: polkadot.stakings, MaterializedView: dune.substrate.result_polkadot_nominators</p> <p>Tip</p> <p>Default parameters are applied to all parameterized charts on this Wiki page as a demonstration. Visit our dashboard on Dune to use the <code>nominator_ss58</code> parameter for more in-depth analysis. For more information, please visit the Dune documentation on parameters.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-dashboard-nomination-pool","title":"Polkadot Staking Dashboard (Nomination Pool)","text":"<p>View On Dune: Polkadot Staking Dashboard (Nomination Pool)</p> <p>For a specific nomination pool ID, this dashboard shows:</p> <ul> <li>Pool Members</li> <li>Historical APY, Daily Pool Rewards &amp; Fees</li> </ul> <p>Raw data is presented at the bottom.</p> <p>Source Table: polkadot.stakings, MaterializedView: dune.substrate.result_polkadot_nominationpools</p> <p>Tip</p> <p>Default parameters are applied to all parameterized charts on this Wiki page as a demonstration. Visit our dashboard on Dune to use the <code>pool_id</code> parameter for more in-depth analysis. For more information, please visit the Dune documentation on parameters.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/polkadot-dashboards-staking/#polkadot-staking-dashboard-pool-member","title":"Polkadot Staking Dashboard (Pool Member)","text":"<p>View On Dune: Polkadot Staking Dashboard (Pool Member)</p> <p>For a specific nomination pool member, this dashboard shows raw data of member activity within the pool.</p> <p>Member Pool Fee: 365 * member_staking_rewards / member_bonded</p> <p>Source Table: polkadot.stakings, MaterializedView: dune.substrate.result_polkadot_poolmembers</p> <p>Tip</p> <p>Default parameters are applied to all parameterized charts on this Wiki page as a demonstration. Visit our dashboard on Dune to use the <code>user_ss58</code> parameter for more in-depth analysis. For more information, please visit the Dune documentation on parameters.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-dot-ordinals/","title":"DOT Ordinals","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-dot-ordinals/#view-on-dune-dot-ordinals","title":"View On Dune: DOT Ordinals","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-ecosystem-overview/","title":"Polkadot Ecosystem Overview","text":"<p>The Polkadot ecosystem is a dynamic and evolving network that aims to enable different parachains to transfer messages and value in a trust-free fashion; sharing their unique features while pooling their security.</p> <p>In this overview, we provide insights to the vibrancy and growth of the Polkadot ecosystem. Specifically, we highlight data on active accounts, extrinsics, events, and XCMs.</p> <p>View On Dune: Polkadot &amp; Parachains Ecosystem Metrics</p> <p>Info</p> <p>This page only shows a high-level overview of the ecosystem metics. For an in-depth analysis, please visit Polkadot Dashboards and Parachain Dashboards categories.</p> <p>For example, following are some of topics you might be interested in:</p> <ul> <li>For stablecoins, visit   Asset Hub Dashboards</li> <li>For Polkadot relay chain treasury, visit   Polkadot Dashboards Governance</li> <li>For Polkadot staking, visit   Polkadot Dashboards Staking</li> <li>For NFTs, visit Unique Dashboards</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-ecosystem-overview/#activities-metrics","title":"Activities Metrics","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-ecosystem-overview/#polkadot-treasury-flow","title":"Polkadot Treasury Flow","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-ecosystem-overview/#polkadot-network-security","title":"Polkadot Network &amp; Security","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-ecosystem-overview/#xcm-metrics","title":"XCM Metrics","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/","title":"Polkadot Governance Dashboard","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#view-on-dune-polkadot-governance-dashboard","title":"View On Dune: Polkadot Governance Dashboard","text":"<p>The Polkadot Governance Dashboard provides a clear and concise representation of the network's governance activities. It serves as a useful tool for community members to observe treasury management, referendum outcomes, and voting patterns. This dashboard aims to enhance community engagement by simplifying access to governance information and fostering a transparent decision-making environment.</p> <p>Authored by Stanley, Jerry, and William @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#polkadot-treasury-flow","title":"Polkadot Treasury Flow","text":"<p>The Polkadot Treasury Flow chart visualizes the monthly financial movements within the Polkadot treasury, delineating inflows from inflation and outflows from proposals, bounties, and burnt funds, to present a clear picture of the treasury's net flow. For more details, see the Polkadot Treasury section on the Polkadot Wiki.</p> <ul> <li>Treasury Netflow: Treasury Inflows - Treasury Outflows</li> <li>Treasury Inflows: Inflation + Fees + Txn Tips + Slash</li> <li>Treasury Outflows: Opengov Proposals(Spender + Tipper Track) + Bounties + Burnt</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#number-of-votes-by-duration-of-lock","title":"Number of Votes by Duration of Lock","text":"<p>The Number of Votes by Duration of Lock chart visualizes Polkadot governance voting commitments, categorizing votes by token lock duration to reflect conviction levels. It highlights community engagement from short-term to long-term network commitments, showcasing voter participation strength and stability. For more on voting and locking, see Voluntary Locking and Adaptive Quorum Biasing on Polkadot Wiki.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#number-of-monthly-voters-monthly-capital-by-type-monthly-voting-power-by-type","title":"Number of Monthly Voters / Monthly Capital by Type / Monthly Voting Power by Type","text":"<p>These charts offer insights into monthly Polkadot governance engagement, tracking participant numbers, represented capital, and voting conviction. They highlight the community's dynamic involvement in network direction. For governance details, visit Polkadot Governance and Introduction to Polkadot OpenGov.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#conviction-voting-power-tokens-conviction_multiplier","title":"Conviction Voting Power: tokens * conviction_multiplier","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#current-lock-durations","title":"Current Lock Durations","text":"<ul> <li>None(0.1x) - No lock</li> <li>Locked1x - 7 Days</li> <li>Locked2x - 14 Days</li> <li>Locked3x - 28 Days</li> <li>Locked4x - 56 Days</li> <li>Locked5x - 112 Days</li> <li>Locked6x - 224 Days</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#polkadot-number-of-referenda-by-outcome-opengov","title":"Polkadot Number of Referenda by Outcome (OpenGov)","text":"<p>The Polkadot Number of Referenda by Outcome (OpenGov) chart provides a categorical breakdown of referenda results within the Polkadot ecosystem, categorized into <code>Confirmed</code>, <code>Rejected</code>, <code>Timed Out</code>, and <code>Cancelled</code>. The data is curated to reflect the outcomes of governance decisions up to a specified date.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#polkadot-number-of-referenda-by-origin","title":"Polkadot Number of Referenda by Origin","text":"<p>The Polkadot Number of Referenda by Origin chart delineates the sources of governance proposals within the Polkadot network. It quantifies the initiatives by their points of inception, offering a clear distribution of referenda across different origins. In the context of Polkadot, Origin refers to the track through which the proposal has been introduced. This can include public proposals submitted by the token holders, council motions, or treasury proposals. Each track has its own procedural requirements and reflects a different aspect of the network\u2019s governance model.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#monthly-tokens-voted-by-direction-monthly-voting-power-by-direction","title":"Monthly Tokens Voted by Direction / Monthly Voting Power by Direction","text":"<p>The Monthly Tokens Voted by Direction and Monthly Voting Power by Direction charts provide a dynamic view of the Polkadot community's voting behavior over time, breaking down the distribution of tokens and voting power across various voting options. These charts reveal the community's sentiment trends, showcasing the balance between support ('Aye'), opposition ('Nay'), and nuanced positions ('Split' and 'SplitAbstain'), both in terms of token quantity and the weighted influence of votes. By tracking these metrics, stakeholders can gauge the evolving priorities and concerns within the Polkadot ecosystem.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#opengov-vote-types","title":"Opengov Vote Types","text":"<ul> <li>Standard Aye - Available with 0.1-6x conviction</li> <li>Standard Nay - Available with 0.1-6x conviction</li> <li>Split - Allocate votes between (Aye, Nay) with 0.1x conviction</li> <li>splitAbstain: Allocate votes between (Aye, Nay, Abstain) with 0.1x conviction</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#recent-major-delegation-changes","title":"Recent Major Delegation Changes","text":"<p>The Recent Major Delegation Changes chart visualizes significant delegation transactions within a specified timeframe. It highlights two primary types of delegations: 'First Time', where a delegator is delegating to a validator for the first time, and 'Switching', where a delegator changes their delegation from one validator to another</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#recent-major-swing-votes","title":"Recent Major Swing Votes","text":"<p>The Recent Major Swing Votes chart presents a crucial analysis of voting dynamics within the Polkadot network, focusing on the instances where voters have changed their stance on specific referenda. This shift, known as a 'swing vote', is particularly significant when the voter wields a substantial number of tokens, with the potential to sway the outcome of a referendum. The chart meticulously records these pivotal moments, detailing the voter's identity, the magnitude of their tokens, and the direction of their swing\u2014whether towards <code>Aye</code>, <code>Nay</code>, or `Abstain.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#whale-voters","title":"Whale Voters","text":"<p>The Whale Voters chart illuminates the participation of prominent token holders in Polkadot's governance decisions. It showcases the influential votes cast by individuals or entities with significant token stakes, their voting preferences, and the corresponding voting power. This chart elucidates the sway of large stakeholders in shaping the outcome of governance referenda, highlighting the distribution of their voting power in recent decisions.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-governance-dashboard/#awakened-whale-voters","title":"Awakened Whale Voters","text":"<p>The Awakened Whale Voters chart visualizes the activity of influential participants in the Polkadot governance system, commonly known as \"whales\". These are voters who have not participated in the voting process for at least 90 days and have now cast a vote with a significant amount of tokens. The chart displays their voting behavior, the referenda they are involved in, and their voting conviction, using interactive elements that link to external references for detailed blockchain data. This allows for an in-depth look at the re-emergence of major stakeholders in the decision-making process.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referenda-home/","title":"Polkadot OpenGov Referenda - Home","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referenda-home/#view-on-dune-polkadot-opengov-referenda-home","title":"View On Dune: Polkadot OpenGov Referenda - Home","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referenda-home/#polkadot-opengov-referenda-home_1","title":"Polkadot OpenGov Referenda Home","text":"<p>This dashboard is designed for those who wish to vote, allowing them to quickly understand the current trend in Polkadot OpenGov and proceed to vote on Polkassembly.</p> <p>If you want to see more details of each referendum, please check Polkadot Opengov - Referendum Voting Analysis.</p> <p>Authored by @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referenda-home/#controversial-referenda","title":"Controversial Referenda","text":"<p>Select those referenda with approval ratings ranging from 0.2 to 0.8, and consider them as controversial referenda.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/","title":"Polkadot Opengov - Referendum Voting Analysis","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#view-on-dune-polkadot-opengov-referendum-voting-analysis","title":"View On Dune: Polkadot Opengov - Referendum Voting Analysis","text":"<p>We're using default parameters for all of the following parameterized charts. Visit our dashboard on Dune to use the referendum_id parameter and analyze a specific referendum.</p> <p>Source table: polkadot.events, polkadot.calls</p> <p>Authored by @ colorfulnotion</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#voting-power-daily-accumulation","title":"Voting Power Daily Accumulation","text":"<ul> <li>Daily cumulative \"Aye\" and \"Nay\" voting powers, along with approval and support rates for a   specific referendum.</li> <li>Approval Rate - (Conviction _ Aye token) / ((Conviction _ Aye token) + (Conviction * Nay   token))</li> <li>Support Rate - (Aye token + Abstain token) / Total Issuance</li> <li>Learn more about   Opengov Support &amp; Approval</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#aye-vs-nay","title":"Aye vs Nay","text":"<p>\"Aye Power\" (Conviction _ Aye Token) vs \"Nay Power\" (Conviction _ Nay Token)</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#aye-votes-analysis","title":"Aye votes analysis","text":"<p>All voters who voted AYE for the referendum, sorted by \"Voting Power\" (Conviction * Token), including split Aye</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#nay-votes-analysis","title":"Nay votes analysis","text":"<p>All voters who voted NAY for the referendum, sorted by \"Voting Power\" (Conviction * Token), including Split NAY</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#abstain-votes-analysis","title":"Abstain votes analysis","text":"<p>All voters who Abstain themselves for the referendum, sorted by \"Voting Power\" (0.1X * Token)</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#first-time-voter-analysis","title":"First time voter analysis","text":"<p>A Referendum is considered hot or controversital if it has high turnout or high First-time Voting Rate</p> <ul> <li>First-time voters who voted \u201cAye\u201d or \u201cNay\u201d in a specific referendum.</li> <li>First-time Voting Rate: first-time voters / total voters</li> </ul>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#voter-conviction-adjustment","title":"Voter conviction adjustment","text":"<p>Analyze the change in voter's voting conviction for a specific referendum which offers insights into how voter convictions shift across referenda.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#methodology","title":"Methodology","text":"<p>Calculates each voter's previous average conviction, compares it to their current conviction in the referendum, and categorizes the change as Increase \ud83d\udd3c, Maintain \ud83d\udd01, or Decrease \ud83d\udd3d. Finally, it provides counts and percentages for each category</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-opengov-referendum-voting-analysis/#awakened-voters","title":"Awakened Voters","text":"<p>Enumerate the \"Aye\" and \"Nay\" voters who have not voted in the last 90 days</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-nomination-pool/","title":"Polkadot Staking Dashboard (Nomination Pool)","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-nomination-pool/#view-on-dune-polkadot-staking-dashboard","title":"View On Dune: Polkadot Staking Dashboard","text":"<p>We're using default parameters for all of the following parameterized charts. Visit our dashboard on Dune to use the pool_id parameter and analyze a specific referendum.</p> <p>For a _specific nomination pool id, this dashbaord shows:</p> <ul> <li>Pool Members</li> <li>Historical APY, Daily Pool Rewards &amp; Fees</li> </ul> <p>Raw data is presented at the bottom.</p> <p>Source Table: polkadot.stakings , MaterializedView: dune.substrate.result_polkadot_nominationpools</p> <p>Go back to Polkadot Staking Home</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-nominators/","title":"Polkadot Staking Dashboard (Nominators)","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-nominators/#view-on-dune-polkadot-staking-dashboard","title":"View On Dune: Polkadot Staking Dashboard","text":"<p>We're using default parameters for all of the following parameterized charts. Visit our dashboard on Dune to use the nominator_ss58 parameter and analyze a specific referendum.</p> <p>For a specific nominator, this dashboard shows:</p> <ul> <li>Nominator Staking Rewards</li> <li>Nominator Shares</li> <li>Delegated Amount</li> <li>Nominator Staking Rewards Raw Data</li> </ul> <p>Source Table: polkadot.stakings , MaterializedView: dune.substrate.result_polkadot_nominators</p> <p>Go back to Polkadot Staking Home</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-pool-member/","title":"Polkadot Staking Dashboard (Pool Member)","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-pool-member/#view-on-dune-polkadot-staking-dashboard","title":"View On Dune: Polkadot Staking Dashboard","text":"<p>We're using default parameters for all of the following parameterized charts. Visit our dashboard on Dune to use the user_ss58 parameter and analyze a specific referendum.</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-pool-member/#for-a-specific-nomination-pool-member","title":"For a specific nomination pool member","text":"<p>This dashboard shows raw data of member activity within the pool</p> <p>Member Pool Fee: 365 * member_staking_rewards / member_bonded</p> <p>Source Table: polkadot.stakings , MaterializedView: dune.substrate.result_polkadot_poolmembers</p> <p>Go back to Polkadot Staking Home</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-validators/","title":"Polkadot Staking Dashboard (Validators)","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-validators/#view-on-dune-polkadot-staking-dashboard","title":"View On Dune: Polkadot Staking Dashboard","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard-validators/#polkadot-staking-rewards","title":"Polkadot Staking Rewards","text":"<p>Reward Rate - computed as (validator_erasRewardPoints/erasRewardPoints_total) * ErasValidatorReward / validator_total_stake.</p> <p>Effective Reward Rate - computed as (1-validator*commision) * (validator*erasRewardPoints/erasRewardPoints_total) * ErasValidatorReward / validator_total_stake - In other words, (1-validator_commision) *Reward Rate, after considering validator_commision</p> <p>Normalized Reward Rate - computed as total_era_rewards / number_of_validators * (1 - commission) / validator_total_stake. This metric nomoralized the reward rate across active validator sets</p> <p>Source Table: polkadot.stakings , MaterializedView: dune.substrate.result_polkadot_validators</p> <p>Go back to Polkadot Staking Home</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard/","title":"Polkadot Staking Dashboard","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard/#view-on-dune-polkadot-staking-dashboard","title":"View On Dune: Polkadot Staking Dashboard","text":""},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard/#polkadot-staking-dashboard_1","title":"Polkadot Staking Dashboard","text":"<p>Completed Era - completed era can have at most 2 days delay before the staking rewards &amp; apy computation becomes available. The Staking Home Page is showing the most recently completed era</p> <p>Please note that Reward Rate and Effective Reward Rate can be volatile as erapoint varies based on network condition and total delegation amount are subject to phragmen algo</p> <p>Authored by Stanley, Jerry, and William @ colorfulnotion (QA'ed: MK)</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard/#rewards-rate-math","title":"Rewards Rate Math","text":"<p>Reward Rate - computed as (validator_erasRewardPoints/erasRewardPoints_total) * ErasValidatorReward / validator_total_stake.</p> <p>Effective Reward Rate - computed as (1-validator*commision) * (validator*erasRewardPoints/erasRewardPoints_total) * ErasValidatorReward / validator_total_stake - In other words, (1-validator_commision) *Reward Rate, after considering validator_commision</p> <p>Normalized Reward Rate - computed as total_era_rewards / number_of_validators * (1 - commission) / validator_total_stake. This metric nomoralized the reward rate across active validator sets</p>"},{"location":"general/dashboards/dune-analytics/polkadot-dashboards/legacy/polkadot-staking-dashboard/#sources","title":"Sources","text":"<p>Raw staking data can be found at polkadot.stakings table. To demonstrate how to compute and generate validators, nominators, pools, poolmembers granular metrics, the following queries have been provided:</p> <ul> <li>Validators - dune.substrate.result_polkadot_validators   (MetVeiw)</li> <li>Nominators - dune.substrate.result_polkadot_nominators   (MetVeiw)</li> <li>Nomination Pools -   dune.substrate.result_polkadot_nominationpools (MetVeiw)</li> <li>Pool Members -   dune.substrate.result_polkadot_poolmembers (MetVeiw)</li> <li>On-Chain Identities -   dune.substrate.result_polkadot_identity (MetVeiw)</li> </ul> <p>Github repo: substrate-etl</p>"},{"location":"general/funding/","title":"Funding","text":"<ul> <li>Grants - Information on grants.</li> <li>Decentralized Futures - Details on decentralized futures.</li> <li>Polkadot OpenGov Treasury - Information on Polkadot OpenGov Treasury.</li> <li>Polkadot Community Foundation - Polkadot Community Foundation details.</li> <li>Ecosystem Funds - Information on ecosystem funds.</li> </ul>"},{"location":"general/polkadot-vision/","title":"Polkadot Vision","text":"<ul> <li>Polkadot V1 - Information on Polkadot V1.</li> <li>Polkadot Direction - Details on Polkadot direction.</li> </ul>"},{"location":"general/programs/","title":"Programs Index","text":""},{"location":"general/programs/#programs","title":"Programs","text":"<ul> <li>Decentralized Voices - Information on Decentralized Voices.</li> <li>Bug Bounty - Details on the bug bounty program.</li> <li>Ambassadors - Information on the ambassadors program.</li> <li>Alpha Program - Details on the Alpha Program.</li> <li>Decentralized Nodes - Information on decentralized nodes.</li> <li>Thousand Contributors - Details on the Thousand Contributors program.</li> <li>Dev Heroes - Information on Dev Heroes.</li> </ul>"},{"location":"general/stay-safe/","title":"Stay Safe","text":"<ul> <li>How to DYOR - Guide on how to do your own research.</li> <li>Scams - Information on scams.</li> <li>Transaction Attacks - Details on transaction attacks.</li> </ul>"},{"location":"general/wallets/","title":"Wallets","text":"<ul> <li>Polkadot Ecosystem Wallets - Explore Polkadot ecosystem wallets.</li> <li>Wallets and Extensions - Information on wallets and extensions.</li> <li>Ledger - Details on Ledger.</li> <li>Polkadot Vault - Information on Polkadot Vault.</li> </ul>"},{"location":"kusama/kusama-adverserial-cheatsheet/","title":"Adversarial Cheatsheet","text":"<p>Expect things to break on Kusama. To help you break some things, take a look at the following threat model.</p> Hacker wants to \u2026 Security promise that should prevent the hack Hacking Incentive Hacking Damage Hacking value details Double spend tokens via getting the clients to accept a different chain Integrity (System-wide) High High If attackers are able to double spend tokens, they are able to get services without paying for them. This gives them a high monetary incentive to execute the attack. Cause system to mint tokens to his own account Integrity (System-wide) \u00a0Medium Low - Medium If an attacker is able to craft transactions that mint tokens to their account, then this provides a high monetary incentive to execute this attack. Validate malicious blocks to double spend tokens Availability (System-wide) \u00a0High Medium If an attacker is able to double spend tokens, they are able to get services without paying for them. This gives them a high monetary incentive to execute the attack. Undermine consensus mechanism to split chain Integrity (System-wide) High High \"If an attacker is able to double spend tokens, they are able to get services without paying for them. This gives them a high monetary incentive to execute the attack. Betting on decrease in value of the cryptocurrency or competitors want to damage the reputation, so that the value of their blockchain increases. Tamper/manipulate blockchain history to invalidate transactions (e.g. a voting result) Integrity (System-wide) Medium Medium - High Attacker can rollback undesired transactions by intentionally invalidating the block where transaction has happened. Attacker can force a governance decision (or even an on-chain update) that favors them. Undermine blockchain or consensus mechanism to damage the ecosystem's reputation Availability (System-wide) High High Betting on decrease in value of the cryptocurrency or competitors want to damage the reputation, so that the value of their blockchain increases Censorship Availability (System-wide) Medium High Hackers are able to block undesirable types of transactions (e.g. industry competitor transactions or referendum votes). This could be achieved by colluding with other stakeholders or by otherwise obtaining more voting power. Deanonymize users Confidentiality (Node) Medium Medium Parties that want to de-anonymize users can use the information to oppress the opposition (e.g. political activists). Steal token from node Integrity (Node) High High Attackers that are able to steal tokens from nodes can claim assets for themselves, which gives them a high monetary incentive to execute the attack. Steal token from node by leaking credentials Confidentiality (Node) High High Attackers that are able to steal tokens from nodes can claim assets for themselves, which gives them a high monetary incentive to execute the attack. Prevent node from accessing the Polkadot network Availability (Node) Low Low - Medium Run a targeted denial-of-service attack out of revenge, monetary interests (in case of a competing coin exchange, etc.). Defraud other participants Integrity (Node) Medium Low - Medium Attacker can abuse other participants\u2019 misunderstanding of Polkadot's security guarantees to defraud them. Also, if the reward for calling out bad behavior can be set up so that it is higher than the according punishment, a set of self-handled nodes can be set up to generate a source cycle. Other participants are not needed for this attack. Defraud other participants Integrity (System-wide) High High An attacker could abuse bugs in Polkadot's economic system to defraud other participants. For example, an attacker could exploit a logic bug to not pay transaction fees."},{"location":"kusama/kusama-bug-bounty/","title":"Bug Bounty","text":"<p>Program Scope</p> <p>The bug bounty program does not cover bugs on code bases that are external to or, written on top of Kusama, or that use Kusama. To be eligible for the bug bounty program the bug has to be a part of the Kusama codebase, this includes protocols that Polkadot uses such as AnV, XCM, GRANDPA, etc.</p> <p>We call on our community and all bug bounty hunters to help identify bugs in Kusama.</p> <p>If you discover a bug, we appreciate your cooperation in responsibly investigating and reporting it as per instructions on Web3 Foundation website. Disclosure to any third parties disqualifies bug bounty eligibility.</p>"},{"location":"kusama/kusama-bug-bounty/#eligibility","title":"Eligibility","text":"<p>Generally speaking, any bug that poses a significant vulnerability, either to the soundness of protocols and protocol/implementation compliance to network security, to classical client security, as well as security of cryptographic primitives, could be eligible for a reward. Please note that it's entirely our discretion to decide whether a bug is significant enough to qualify for a reward.</p> <p>Examples include: An attack that could disrupt the entire network and harm the validity to the network would be considered a critical threat. An attack that would disrupt service to others would be regarded as a high threat.</p> <p>Please note: The submission quality will be a significant factor in the level of considered compensation. A high-quality submission includes explaining how the bug can be reproduced, how it was discovered, and otherwise critical details. Please disclose responsibly; disclosure to any third parties disqualifies bug bounty eligibility.</p> <p>Responsible investigation and reporting Responsible investigation and reporting include, but isn't limited to, the following:</p> <ul> <li>Don't violate the privacy of other users, destroy data, etc.</li> <li>Don't defraud or harm Kusama network or its users during your research; you should make a good   faith effort not to interrupt or degrade our services.</li> <li>Don't target the validators' physical security measures, or attempt to use social engineering,   spam, distributed denial of service (DDoS) attacks, etc.</li> <li>Initially, report the bug only to us and not to anyone else.</li> <li>Give us a reasonable amount of time to fix the bug before disclosing it to anyone else, and give   us adequate written warning before disclosing it to anyone else.</li> <li>In general, please investigate and report bugs in a way that makes a reasonable, good-faith effort   not to be disruptive or harmful to our users or us. Otherwise, your actions might be interpreted   as an attack rather than an effort to be helpful.</li> </ul>"},{"location":"kusama/kusama-bug-bounty/#how-to-report-a-bug","title":"How to report a bug","text":"<p>Please follow the instructions at web3.foundation/security-report/.</p>"},{"location":"kusama/kusama-coc/","title":"Kusama Code of Conduct","text":"<p>While Kusama has been its own network and has had its own ecosystem for a while now, it is still one big experiment, and we need your participation for it to continue being a great success.</p>"},{"location":"kusama/kusama-coc/#community","title":"Community","text":"<p>We want to foster a sense of collaboration amongst ourselves and the open-source community. Kusama participants exist to encourage the open exchange of ideas and expression and require an environment that recognizes the inherent worth of every person and group. We are here to collaborate, discuss, and even disagree. The key is doing this in a manner that comes from a place of respect and professionalism. Participants in the Kusama network may consist of an online forum, on-chain governance participants, parachain deployment teams, validators, enthusiasts, and ecosystem tool builders. We expect for there to be participation from all backgrounds but like to set some social boundaries on how you may be treated and treat others.</p> <p>Kusama community members come from across the globe and are not bordered by race, gender, or background. Community participants have read through the requisite resources and obtained sufficient knowledge about Kusama and all related content. This knowledge equips the community with the requisite information needed to dispense of their duties as a participant.</p> <p>Examples of Unacceptable Behavior</p> <p>These are just a few examples, and you can always consult a team member if you have any questions.</p> <ul> <li>Obnoxious, aggressive comments towards individuals or other projects on any medium of   communication.</li> <li>Knowingly distributing false information about Kusama or other projects.</li> <li>Harassing other individuals or projects.</li> </ul> <p>That said, please note that Kusama is an edgy and meme-friendly network, and community member actions shouldn't be taken too seriously - try to assume jest before malice.</p> <p>What To Do If You Witness or Are Subject To Unacceptable Behavior</p> <p>If you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact the administrator of the channel you\u2019re in.</p> <p>This Code of Conduct may be revised at any time. We are always willing to revise this document based on feedback from the Kusama participants and/or the Polkadot community.</p>"},{"location":"kusama/kusama-coc/#bugs","title":"Bugs","text":"<p>Please understand that this network is, despite its success, an experiment with potential flaws, so it\u2019s appreciated that community members help report any sort of exploits directly to the team before sharing publicly. Please see the bug bounty program.</p>"},{"location":"kusama/kusama-getting-started/","title":"Interact with Kusama","text":""},{"location":"kusama/kusama-getting-started/#polkadots-canary-network","title":"Polkadot's Canary Network","text":"<p>Kusama is a canary network for Polkadot; an earlier release of the code that is available first and holds real economic value. For developers, Kusama is a proving ground for runtime upgrades, on-chain governance, and parachains.</p> <p>No Promises</p> <p>Kusama is owned by those who hold the Kusama tokens (KSM). There's no central kill switch and all changes are made through the protocol's on-chain governance.</p> <p>The network is a permissionless and anyone can come along and start using it. Those who participated in the Polkadot sale can claim a proportional amount of KSM through the Kusama Claims process.</p> <p>Kusama is experimental. Expect Chaos.</p> <p>As a KSM holder</p> <p>You can interact with all the features of the Kusama network such as staking (i.e. validating or nominating), governance, basic transfers and everything else.</p> <ul> <li>Timeline \u2013 Stay up-to-date with the latest action on Kusama.</li> <li>Code of Conduct - Kusama's Code of Conduct to sustain chaos.</li> <li>Bug Bounty - An Overview of how you can help catch bugs.</li> <li>Account Recovery - Steps on how to perform account recovery on Kusama.</li> <li>Adversarial Cheatsheet - A Cheatsheet to help you create chaos.</li> <li>Kappa Sigma Mu - Learn about the Kappa Sigma Mu Society and Join as a Member.</li> <li>KSM Inflation - Explanation of KSM's Inflation Model.</li> </ul>"},{"location":"kusama/kusama-getting-started/#what-can-i-do-with-my-ksm","title":"What can I do with my KSM?","text":"<p>KSM is the native token of the Kusama Network. KSM can be used for transaction fees, staking, governance, purchase of coretime, and for enabling several key functionalities on Kusama. See more information on the Chain State Values page.</p> <p>KSM has utility in Kusama's OpenGov where you can vote, delegate your voting power, and place deposits for your referenda or referenda proposed by others. KSM can also enable you to participate in programs like the Decentralized Nodes program.</p>"},{"location":"kusama/kusama-getting-started/#kusama-gifts","title":"Kusama Gifts","text":"<p>Kusama Gifts provide an easy way to:</p> <ul> <li>Onboard friends or family who are curious about blockchain but haven\u2019t made the leap yet.</li> <li>Share your love of Kusama and send any amount of KSM.</li> <li>Say \u2018thank you\u2019 or send someone tokens when you don\u2019t know their address.</li> <li>Get friends and family set up to participate in crowdloans.</li> </ul> <p>Learn more about how you can create and send Kusama Gifts here.</p> <p>While Kusama does not support smart contracts natively, building apps on it is possible (e.g. RMRK.app).</p>"},{"location":"kusama/kusama-inflation/","title":"Kusama Inflation Model","text":"<p>        Learn about Polkadot's native token DOT inflation.      </p> \u2716 <p>KSM is an inflationary token. Inflation is set to be 10% annually. Depending on the supply staked and the ideal staking rate (more about this below), part of the inflation is distributed to the stakers and part to the treasury.</p> <p>!!!info The current KSM token supply can be seen here.</p> <p>It is essential to understand that the primary objective of inflation is to incentivize network participants through Nominated Proof of Stake (NPoS) and to grow the network through funding the on-chain treasury. There is an opportunity cost of keeping the number of tokens idle with the current inflation model as the tokens get diluted over time. Economics and game theory suggest that setting an ideal inflation rate is essential for incentivizing the network participants as well as the growth of the network, and any deviation from it can have adverse effects. Reducing the inflation rate could limit growth, while increasing the inflation rate could break the incentive model of the token. Hence, token inflation rate is not a forever fixed value, and inflation can be updated in the future through on-chain governance based on thorough tokenomics research.</p>"},{"location":"kusama/kusama-inflation/#kusama-inflation-model","title":"Kusama Inflation Model","text":"<p>The chart below shows the inflation model of the network. Depending on the number of staked tokens, the distribution of the inflation to validators and nominators versus the treasury will change dynamically to provide incentives to participate (or not participate) in staking.</p> <p>There is a dynamic ideal staking rate (in the figure set to 0.6 or 60%) that the network tries to maintain. The inflation model will incentivize network participants to stake when the current staking rate &lt; ideal staking rate and disincentivize staking when current staking rate &gt; ideal staking rate. The goal is to have the staking rate meet the ideal staking rate. The current staking rate would be the total amount staked in the current era over the total token supply, where the total amount staked is the stake of all validators and nominators on the network. The ideal staking rate accounts for having sufficient backing of tokens to prevent the possible compromise of security while keeping the native token liquid.</p> <p></p> <p>More information here.</p> <ul> <li>x-axis: Proportion of staked tokens</li> <li>y-axis: Annualized percentage (inflation and staking rewards, see below)</li> <li>Blue line: Annual inflation rate diverted to NPoS, i.e., the total amount of tokens minted to pay validators and nominators. For instance, 0.1 corresponds to 10% of token inflation diverted to stakers. Since annual token inflation is 10%, all inflation is used to pay validators and nominators, and 0% of token inflation is diverted to the treasury.</li> <li>Green line: Annual rewards rate for stakers. For instance, 0.2 corresponds to 20% of annual returns on the staked tokens. You can determine the current annual staking rewards rate by looking at the top bar of the staking overview on the Polkadot Staking Dashboard.</li> </ul> <p>Assuming that the ideal staking rate is 60%, all of the inflation would go to the validators and nominators if 60% of all tokens are staked. Any deviation from the 60% - positive or negative - sends the proportional remainder to the treasury. Deviations from the ideal staking rate are referred to as staking inefficiencies. Thus, the treasury does not receive an inflow of funds from inflation when the system staking rate equals the ideal staking rate. See this page for more information about treasury inflow sources.</p> <p>For those who are interested in knowing more about the design of the inflation model for the network, please see here.</p>"},{"location":"kusama/kusama-inflation/#ideal-staking-rate","title":"Ideal Staking Rate","text":"<p>The ideal staking rate can vary between 45% to 75% based on the number of parachains that occupied a core (this excludes the system parachains), based on the implementation here.</p> <p>Briefly, the ideal staking rate can be calculated as follows:</p> <p><code>0.75 - auction_proportion</code></p> <p>where <code>auction_proportion</code> is obtained by computing <code>min(auctioned_slots, 60) / 300</code>. The <code>auctioned_slots</code> are all the auctioned slots (or cores) without the cores for system parachains.</p> <p>Assuming there are 50 filled cores, of which five are dedicated to system parachains, there are 45 auctioned cores. The <code>auction_proportion</code> is thus <code>45 / 300 = 0.15</code>. The ideal staking rate is <code>0.75 - 0.15 = 0.6</code>.</p> <p>If the amount of tokens staked goes below 60%, then staking rewards for nominators increase, incentivizing them to stake more tokens on the network. On the contrary, staking rewards drop if staked tokens exceed the ideal staking rate. This results from the change in the percentage of staking rewards that go to the Treasury.</p>"},{"location":"kusama/kusama-social-recovery/","title":"Social Recovery","text":"<p>Managing an account is not an easy task. Many people have lost their private keys due to improper key management over the past few years. Kusama provides a method that allows users to recover their accounts by setting up a social recovery. It is an M-of-N recovery tool based on the multi-signature wallet to get back access to your lost account.</p> <p>caution There is no way to get back your private key by using this method</p> <p>This is just a way of performing transactions on behalf of the lost account, so you can think of it as a proxy instead. s In this guide, you will learn how to create a recoverable account, how to recover it, and what you need to be aware of when using it.</p>"},{"location":"kusama/kusama-social-recovery/#create-a-recoverable-account","title":"Create a Recoverable Account","text":"<p>You will use your existing account to call <code>createRecovery</code> to select a list of accounts you trust to help you recover the account when you lose the private key. To create a recoverable account, you will be required to set a <code>threshold</code> that is the number of your friends who need to approve the recovery process to recover your account.</p> <p></p> <p>Account Recovery</p> <p>If you are recovering an account, ensure that your network is set to Kusama. You can do this by selecting the network from the top right corner in the Polkadot-JS UI.</p> <p>First, see the Accounts page on Polkadot-JS Apps that shows all available accounts on your browser's local storage and Polkadot-JS extension. To create a recoverable account, make sure you have some KSM to pay the transaction fees. You You will also need some for the reserve required by the account recovery setup.</p> <p></p> <p>Then, click the menu beside the \"send\" button, and choose \"Make recoverable\".</p> <p></p> <p>Now you need to provide the following information:</p> <p><code>trusted social recovery helpers</code> - A list of accounts that you trust. These can help you if you lose the private key. Since setting up a recoverable account requires you to lock up KSM, ensure your account has enough transferable balance to cover it. As you select additional recovery helpers, more KSM will be required.</p> <p><code>recovery threshold</code> - The number of friends required to submit a <code>vouchRecovery</code> transaction in order to recover the account.</p> <p>Info</p> <p>1 is the minimum, but it is not recommended to set a small number. If you set 1, that means any of your recovery helpers would be able to recover your account.</p> <p><code>recovery block delay</code> - Once the threshold is reached, you will need to wait until the block delay has passed until you can claim the recovery. This is a protection mechanism to allow the account owner to have enough time to check and react in case someone pretends to be you and initiates a recovery process.</p> <p>Info</p> <p>Setting the block delay to be a little longer would be better since even if an attacker acquired enough signatures to recover your account, they would still have to wait until the block delay is passed to control your account.</p> <p></p>"},{"location":"kusama/kusama-social-recovery/#recover-your-account","title":"Recover your Account","text":"<p>This section would be showing you how to initiate a recovery process and get back the balance that held in the lost account to the new account.</p> <p></p> <p>The above diagram shows the whole process of recovering an account.</p> <p>Info</p> <p>Ensure that your new account has enough KSM to pay for the transaction fees and the amount that is used for reserve when making a recovery.</p> <p>Navigate to the menu beside the send button in the row of your new account and click the \"Initiate recover for another\" option.</p> <p></p> <p>Then input the address you would like to recover in the \"recover this account\" field and click \"Start recovery\".</p> <p></p> <p>Once the transaction went through, some KSM will be locked to prevent malicious behavior.</p> <p></p> <p>Now call your friends that you have set in the first section, but heading over to \"Developer\" &gt; \"Extrinsics\" and using the recovery pallet. They are required to submit a <code>vouchRecovery</code> transaction.</p> <p></p> <p>Once the threshold is reached and the block delay is passed, use the new account to submit a <code>claimRecovery</code> transaction that would set a proxy on behalf of your lost account. It means that you can still indirectly use the lost account to interact with the network.</p> <p></p> <p>To see the proxy information, use your new account by calling the \"recovery-&gt;proxy(Accountid)\" function at the Chain state page. It should point to your lost account.</p> <p></p> <p>Next, in order to call the \"closeRecovery\" transaction, you can make use of the \"asRecovered\" function as your lost account to get the locked KSM.</p> <p></p> <p>Once the transaction goes through, the reserved KSM from the \"NEW-ACC\" will have been moved to the lost account. This is a way of preventing someone from recovering other accounts maliciously. Imagine if someone tried to initiate recovery on your account; you can do this to slash their locked KSM.</p> <p></p> <p>Moving on, we use the <code>asRecovered</code> function to submit the <code>removeRecovery</code> transaction on behalf of the lost account to release the reserved KSM from your lost account.</p> <p></p> <p>Now your account balance should be transferable.</p> <p></p> <p>Finally, transfer all of your available balance from the lost account to the new account.</p> <p></p> <p>The recovery process is now complete and successful.</p> <p></p> <p>Using <code>Root</code> origin</p> <p>There is still one possible way to recover the account without going through the recovery process. That is by using the <code>Root</code> origin. However, in order to use root permissions, you will need to either go through governance.</p>"},{"location":"kusama/kusama-social-recovery/#further-reading","title":"Further Reading","text":"<ul> <li>Substrate's Recovery Pallet -   The Rust implementation of the recovery pallet.</li> </ul>"},{"location":"kusama/kusama-society/","title":"Kappa Sigma Mu","text":"<p>Kappa Sigma Mu is a membership club using the Substrate Society pallet. It is an economic game to incentivize users to join a society that coordinates around whatever the rules are decided to be. The members of the society are incentivized to participate in the society via the rewards paid by the treasury. Currently, there is only one society on Kusama but it is possible to have multiple societies in the future through a runtime upgrade.</p> <p> </p> <p>Before joining the society, let's take a brief look at the Society UI on Polkadot-JS apps and read through all the rules to become a member.</p>"},{"location":"kusama/kusama-society/#ui-overview","title":"UI Overview","text":"<ul> <li><code>Members</code>: The number of members in the society. Currently, the maximum number of members is set   to <code>150</code>. It can be changed by using governance to increase the number.</li> <li><code>Rotation</code>: The time period for membership rotations.</li> <li><code>Challenge</code>: The time period to randomly select one of the members to defend his membership in the   society.</li> <li><code>Pot</code>: Resource balance that is used to support members of the society.</li> <li><code>Bids</code>: A list of users who submitted a bid to join the society.</li> </ul>"},{"location":"kusama/kusama-society/#user-types","title":"User Types","text":"<p>Below are the various types of users at different stages.</p> <ul> <li><code>Bidder</code> - A token holder who intends to join the society by placing a bid.</li> <li><code>Candidate</code> - The selected bidders that will be voted on by members of the society.</li> <li><code>Suspended Candidate</code> - The candidates that failed to join the society.</li> <li><code>Member</code> - Member of the society.</li> <li><code>Suspender Member</code> - A member of the society who has accumulated too many strikes or failed their   membership challenge.</li> <li><code>Head</code> - One winning candidate will be randomly chosen as head of the members, weighted by the   number of approvals the winning candidates accumulated.</li> <li><code>Defender</code> - In every challenge period, one of the members will be randomly selected to defend   their membership in the society. The rules for defending the membership are documented   in the rules.</li> </ul>"},{"location":"kusama/kusama-society/#procedure","title":"Procedure","text":"<p>Remember to take a look at the rules first. And since those rules are not enforced entirely on-chain, it is recommended to join the Kappa Sigma Mu Lounge to ask any questions if anything is unclear.</p>"},{"location":"kusama/kusama-society/#1-bid-phase","title":"1. Bid Phase","text":"<p>To submit a bid, click the Submit Bid button on the Society page.</p> <p>Anyone can submit a bid to join the society by reserving a deposit or finding an existing member to create a bid on their behalf by vouching for them. At every rotation period, as many bids as the society pot can support will be selected. The selected bids will be moved to the candidate phase, whereas bids that were not selected will stay in the bidder pool until they are selected or a user chooses to unbid.</p> <p>Anyone who wants to join the society is required to deposit 1.6 KSM for reserve on Kusama and declare the bid amount (1 KSM in this case) that they will receive for joining the society.</p> <p></p> <p>Once you have submitted the transaction, your bid will be shown on the Society page under the bids section. You can cancel the bidding if you changed your mind about joining the society by calling <code>unbid</code> on the same page.</p> <p>You can find an existing member to place a bid on your behalf if you do not have KSM and you are willing to give them a tip. An existing member can submit a <code>vouch</code> transaction through the Extrinsics page.</p> <p>vouch(who,value,tip)</p> <ul> <li>who: The user you are vouching for</li> </ul> <ul> <li>value: The value that the user would like to get when joining the society</li> <li>tip: Fees you get</li> </ul> <p>The final value that the candidate will get = (value - tip)</p> <p></p>"},{"location":"kusama/kusama-society/#2-candidate-phase","title":"2. Candidate Phase","text":"<p>Bids selected in this phase will be voted on by the existing members to decide whether or not you will be approved to join the society. Members will vote for all the candidates and the final outcome will be randomly selected by one of the votes. Let's take a look the example shown below:</p> <p>Info</p> <p>If the randomly selected member does not vote, it will be treated as a rejection. For each rotation period, the maximum number of members that can be accepted is set as 10.</p> <p>A - Accept, R - Reject, S - Skeptic</p> Member 1 2 3 4 5 Vote A A A R S Selected X <p>In this example, a candidate will be approved to join the society since member 3 was selected as a final voting outcome. A number of members will also be randomly chosen as \"skeptics\" to vote for the candidates during the rotation period.</p> <p>Since member 5 was chosen as a skeptic, they are required to participate in the voting process. If they do not participate in voting, they will be punished with one strike per missing vote. If one accumulates too many strikes, one's membership is suspended which means they may need to re-apply and their unclaimed payouts will be slashed. Moreover, each member who voted opposite to the randomly selected vote will have their unclaimed payouts slashed and strikes increased. In this case, member 4 will be punished.</p> <p>!!!info The maximum number of strikes you can have is on Kusama is 10.</p> <p>The slashed funds (2 KSM currently) will be given to a random member who voted the same as the selected vote as a reward for participating in the vote. The reward is escrowed for some period of time - see below.</p>"},{"location":"kusama/kusama-society/#lock-up-time","title":"Lock-up Time","text":"<p>It would take the number of members of the society as the variable to determine how many blocks you have to wait in order to get the payout. The longest lockup time is close to 3 years. The formula is defined in the society pallet if you would like to have a look.</p> <p>Example:</p> <pre><code>Let's assume we have 5 members in the society\n\nlock_duration = 100 - 50_000 / (5 + 500)\nlock_duration * MAX_LOCK_DURATION_IN_BLOCKS\n\nResult = 1% * 15_552_000 ~ 11 days\n</code></pre> <p>Based on the above calculation, it is required to wait close to 11 days to get the slashed funds.</p> <p>If the candidate wins the vote, they receive their bid reward as a future payout. If the bid was placed by a voucher, they will get back the reward that was set during vouching with the remainder given to the candidate - both escrowed for some time.</p> <p>If the candidate loses the vote, they are suspended and it is up to the founder of the society (the <code>Suspension Judgement Origin</code>) to determine if the candidate should go through the bidding process again, should be accepted into the membership society, or rejected and their deposit slashed.</p>"},{"location":"kusama/kusama-society/#3-member-phase","title":"3. Member Phase","text":"<p>Once you become a member of the society, you will get back the deposit that you have reserved during the bidding. A few things you need to be aware of. First, you should vote on candidates who applied for the membership in every rotation period.</p> <p>Second, you will need to claim your payout manually by calling <code>payout</code> after the lockup time. It is the same as the above mentioned lockup formula.</p> <p></p> <p>Third, there will be a membership challenge every seven days on Kusama. So one of the members will be randomly selected as a defender. Then, other members can vote whether this defender should stay in the society or not. A simple majority wins the vote. You can take a look here and search for \"Existing Members (Challenges)\". Besides that, you can earn extra KSM by helping a user apply for the membership and requesting a tip. This is useful when a user does not have enough balance to reserve a deposit. The tip will be given when a user successfully joins the society.</p> <p>Info</p> <p>Each member can only vouch for one user at a time. A member is not required to reserve the deposit when vouching for a user.</p> <p>If a member accumulates too many strikes or fails their membership challenge, they will become suspended. While a member is suspended, they are unable to claim matured payouts. It is up to the suspension judgment origin to determine if the member should re-enter society or be removed from society with all their future payouts slashed.</p>"},{"location":"kusama/kusama-society/#useful-links","title":"Useful links","text":"<p>Convention of Approval of Membership - Rules about joining the Kusama society</p> <p>The rules are encoded on-chain in UTF-8 format. This is displayed in most block explorers as a hexadecimal string. In order to see the rules in human-readable format, you can convert it. In the extrinsic's parameters go to Element 1 (\"proposal\") -&gt; \"value\" -&gt; \"params\" -&gt; Element 2 (\"rules\") and copy the value corresponding to the key \"value\". You can use a hex-to-UTF8 converter to then display the text. Note that the text is formatted with Markdown.</p>"},{"location":"kusama/kusama-timeline/","title":"Kusama Timeline","text":"<p>Kusama network started as a Proof-of-Authority network and was transitioned to Proof-of-Stake on October 28, 2019 at approximately 16:43 UTC. The first successful validator set rotation took place at 20:45 UTC.</p> <p>Currently, Kusama is a healthy Proof-of-Stake network with over 900 validators and over eight million blocks produced. If you are curious about the history of the Kusama network, you will find more information in the sections below.</p>"},{"location":"kusama/kusama-timeline/#rollout-plan","title":"Rollout plan","text":"<p>The rollout of full functionality of Kusama was staggered to allow for a safe transition. The first PoS phase began with 20 validators. Of the 20, Web3 Foundation ran nine and Parity Technologies ran six. Five were ran by highly staked community members as voted in by the Phragm\u00e9n election.</p> <p>When the initial transition was successful, additional validator spots were opened 10 at a time in order to allow for more validators to enter the active set.</p> <p>When the first transition to PoS took place, the full functionality of Kusama was not fully available. Notably, the Sudo key still existed and was used to initiate further upgrades. Balance transfers were still disabled for a short while.</p> <p>Kusama now has its full functionality enabled.</p>"},{"location":"kusama/kusama-timeline/#kusamas-first-adventure","title":"Kusama's First Adventure","text":"<p>Source</p> <p>On January 4, 2020, the Polkadot mainnet runtime, which at that time still wasn't live, was uploaded to the Kusama chain during a runtime upgrade. The mishap was due to a recent split of the Kusama logic from the Polkadot logic and that runtime was not correctly named. This led to a halt of block production on the Kusama chain and bricked the chain entirely.</p> <p>The solution to the issue involved a rollback of the chain history before the problematic runtime upgrade. However, due to intricacies of the block production mechanism, it was also necessary to encapsulate the validators of the chain into a time bubble to trick them into believing that they were producing blocks in the past. Furthermore, in order for the chain to catch up to the present moment it was necessary to make time flow in the bubble at a speed of six times greater than the speed of time in the real world. Therefore, the session of Kusama which would normally last one hour would last only 10 minutes until the validators caught up to the present moment.</p> <p>The above plan was executed successfully on January 7, 2020. Due to the time warp, the number of missed blocks in the sessions directly following block #516558 was significantly higher. This is partly what contributes to the much higher ratio of missed blocks on Kusama versus Polkadot today.</p>"},{"location":"kusama/kusama-timeline/#auctions","title":"Auctions","text":"<p>Kusama promised chaos, and it delivered on that promise. On June 15<sup>th</sup>, 2021, the roll out of the first public parachain slot auction commenced, marking the beginning of the end to deliver on the last piece of core functionality outlined in the Polkadot whitepaper: purpose-built, interoperable parachains.</p> <p>Teams and projects looking to become an official parachain on the Kusama network have been working hard to bring their technologies to life, many of whom started a crowdloan campaign in order to participate in the auctions.</p> <p>Kusama has made history with the permissionless launch of several independent parachains, and continues to do so with ongoing auction. As parachains become operational, the community will determine which additional features and network upgrades should be added over time.</p> <p>While Kusama\u2019s current parachains are taking advantage of the built-in features of the network and forkless upgradability provided by Substrate, chaos continues, and in the spirit of chaos, more teams are eager to deploy on Kusama. The path of Kusama deployment has paved the way to Polkadot's parachains as the technology became proven.</p>"},{"location":"learn/","title":"Learn about Polkadot","text":"<p>Learn about the technology behind the Polkadot ecosystem, and the tools you can use to become a participant of Web3.</p> <ul> <li>General - General information about Polkadot.</li> <li>Basics - Basic information about Polkadot.</li> <li>Advanced - Advanced information about Polkadot.</li> <li>Comparisons - Comparisons with other networks.</li> <li>Video Tutorials - Video tutorials on Polkadot.</li> <li>Future Implementations - Future implementations in Polkadot.</li> <li>Archive - Archived information about Polkadot.</li> </ul>"},{"location":"learn/learn-DOT-KSM-bridge/","title":"Polkadot <> Kusama Bridge","text":"<p>Both Polkadot and Kusama blockchain networks achieve finality through GRANDPA consensus, which enables trustless bridging of both the networks through their respective Bridge Hubs. Polkadot Bridge Hub runs a light client of Kusama network and Kusama Bridge Hub runs a light client of Polkadot network, which were both enabled through their respective OpenGov referenda. This trustless bridge allows Polkadot Asset Hub to bridge in wrapped KSM tokens and Kusama Asset Hub to bridge in wrapped DOT tokens, thus making DOT available to all Kusama parachains and KSM to all Polkadot parachains.</p> <p>Transferring Assets between Polkadot and Kusama</p> <p>The user guides for transferring assets between Polkadot and Kusama are available here.</p>"},{"location":"learn/learn-DOT-KSM-bridge/#polkadot-and-kusama-bridge-relayers","title":"Polkadot and Kusama Bridge Relayers","text":"<p>The job of the relayers is to relay Kusama/Polkadot GRANDPA justifications to the bridge hubs on one side to the other. They also relay finalized Kusama Bridge Hub and Polkadot Bridge Hub block headers. They operate only when messages are queued at the bridge hubs. When there are no messages queued, the relayers stay idle.</p>"},{"location":"learn/learn-DOT-KSM-bridge/#run-a-polkadot-and-kusama-bridge-relayer","title":"Run a Polkadot and Kusama Bridge Relayer","text":"<p>Anyone can start running a relayer for the Polkadot &lt; &gt; Kusama Bridge. For instructions, check the relayer docs on Polkadot-SDK repository. Of course, running relayer has costs involved. Apart from paying for the CPU and network, the relayer pays for transactions at both sides of the bridge.</p>"},{"location":"learn/learn-DOT-KSM-bridge/#relayer-rewards","title":"Relayer Rewards","text":"<p>Relayer Incentive Mechanism - Work in Progress</p> <p>The initial bridge design supports any number of relayers, but there's no guaranteed reward for each and every relayer submitting valid bridge transactions. Also, these rewards are distributed from the accounts controlled by the respective relay chain's governance. Hence, any delays in replenishing the funds on these accounts will result in not receiving any rewards.</p> <p>Rewards paid to relayer has two parts - static and dynamic. The static part of the reward is set through the on-chain governance. It requires the relayer to deliver a preset number of valid messages to earn a preset number of DOT or KSM. The other reward part is dynamic, which involves delivering an XCM message from one BridgeHub to another. The relayer needs to submit transactions on both the bridge hubs, where each transaction has its cost, which can be:</p> <ul> <li>dynamic, because message size can change and/or fee factor of the target chain may change.</li> <li>significant, because the bridge transactions can be of arbitrary size.</li> </ul> <p>The relayers are compensated for the cost of submitting valid, minimal and useful bridge-related transactions. Valid here means that the transaction doesn't fail. Minimal means that all data within transaction call is actually required for the transaction to succeed. Useful means that all supplied data in transaction is new and yet unknown to the target chain.</p> <p>It is always the sending chain that will be paying for rewards for the relayers. The sending chain will be paying at both ends of the bridge from its sovereign accounts on each Bridge Hub. For example Polkadot Asset Hub (PAH) \u2192 Kusama Asset Hub (KAH) transfer will involve relayers getting some rewards from PAH's sovereign account on Polkadot Bridge Hub (PBH) and some rewards from PAH's sovereign account on Kusama Bridge Hub (KBH). It is the responsibility of Polkadot OpenGov to replenish the funds of PAH's sovereign account on both the bridge hubs (PBH and KBH). Similarly, KAH \u2192 PAH transfer is rewarded by KAH's sovereign accounts on PBH and KBH, which have to be replenished through Kusama OpenGov.</p> <p>For more information on relayer rewards, check the relayers compensation scheme section on the relayer docs on the Polkadot-SDK repository.</p>"},{"location":"learn/learn-DOT/","title":"DOT","text":""},{"location":"learn/learn-DOT/#what-is-dot","title":"What is DOT?","text":"<p>DOT is the native token of the Polkadot network in a similar way that BTC is the native token of Bitcoin or Ether is the native token of the Ethereum blockchain.</p>"},{"location":"learn/learn-DOT/#the-planck-unit","title":"The Planck Unit","text":"<p>The smallest unit for the account balance on Substrate based blockchains (Polkadot, Kusama, etc.) is Planck (a reference to Planck Length, the smallest possible distance in the physical Universe). You can compare DOT's Planck to BTC's Satoshi or ETH's Wei. Polkadot's native token DOT equals to 10<sup>10</sup> Planck and Kusama's native token KSM equals to 10<sup>12</sup> Planck.</p>"},{"location":"learn/learn-DOT/#polkadot","title":"Polkadot","text":"Unit Decimal Places Conversion to Planck Conversion to DOT Planck 0 1 Planck 0.0000000001 DOT Microdot (uDOT) 4 10<sup>4</sup> Planck 0.0000010000 DOT Millidot (mDOT) 7 10<sup>7</sup> Planck 0.0010000000 DOT Dot (DOT) 10 10<sup>10</sup> Planck 1.0000000000 DOT Million (MDOT) 16 10<sup>16</sup> Planck 1,000,000.00 DOT <p>DOT was redenominated at block #1_248_328</p> <p>DOT was originally equal to 10<sup>12</sup> Planck just like Kusama (which is referred to as \"DOT (old)\"), but went through a process of redenomination which increased DOT's supply by 100x. As a consequence, 1 DOT now equals to 10<sup>10</sup> Planck.</p>"},{"location":"learn/learn-DOT/#kusama","title":"Kusama","text":"Unit Decimal Places Conversion to Planck Conversion to KSM Planck 0 1 Planck 0.000000000001 KSM Point 3 10<sup>3</sup> Planck 0.000000001000 KSM MicroKSM (uKSM) 6 10<sup>6</sup> Planck 0.000001000000 KSM MilliKSM (mKSM) 9 10<sup>9</sup> Planck 0.001000000000 KSM KSM 12 10<sup>12</sup> Planck 1.000000000000 KSM"},{"location":"learn/learn-DOT/#what-are-the-uses-of-dot","title":"What are the uses of DOT?","text":"<p>DOT serves three key functions in Polkadot:</p> <ul> <li>to be used for governance of the network,</li> <li>to be staked for the operation of the network,</li> <li>to be bonded to connect a chain to Polkadot as a parachain.</li> </ul> <p>DOT can also serve ancillary functions by being a transferrable token. For example, DOT stored in the Treasury can be sent to teams working on relevant projects for the Polkadot network.</p> <p>Explainer video on token utility</p> <p>These concepts have been further explained in the video Usage of DOT and KSM on Polkadot and Kusama.</p>"},{"location":"learn/learn-DOT/#dot-for-governance","title":"DOT for Governance","text":"<p>The first function of DOT is to entitle holders to control the governance of the platform. Some functions that are included under the governance mechanism include determining the fees of the network, the addition or removal of parachains, and exceptional events such as upgrades and fixes to the Polkadot platform.</p> <p>Polkadot will enable any holder of DOT to participate in governance. For details on how holders can participate in governance, as well as their rights and responsibilities, see the governance page.</p>"},{"location":"learn/learn-DOT/#dot-for-consensus","title":"DOT for Consensus","text":"<p>DOT will be used to facilitate the consensus mechanism that underpins Polkadot. For the platform to function and allow for valid transactions to be carried out across parachains, Polkadot will rely on holders of DOT to play active roles. Participants will put their DOT at risk (via staking) to perform these functions. The staking of DOT acts as a disincentive for malicious participants who will be punished by the network by getting their DOT slashed. The DOT required to participate in the network will vary depending on the activity that is being performed, the duration the DOT will be staked for, and the total number of DOT staked. For more information about staking on Polkadot visit the dedicated staking page.</p>"},{"location":"learn/learn-DOT/#dot-to-access-cores-on-the-relay-chain","title":"DOT to Access Cores on the Relay Chain","text":"<p>DOT can be used to purchase coretime in-bulk or on-demand and access the relay chain to benefit from Polkadot's security and interoperability.</p>"},{"location":"learn/learn-DOT/#token-issuance","title":"Token Issuance","text":""},{"location":"learn/learn-DOT/#total-issuance","title":"Total Issuance","text":"<p>The total issuance is the total number of token units in existence on the network.</p>"},{"location":"learn/learn-DOT/#inactive-issuance","title":"Inactive Issuance","text":"<p>The inactive issuance is the total units of outstanding deactivated balance on the network that cannot be used for participation in governance. This comprises tokens locked away in crowdloans and nomination pools.</p>"},{"location":"learn/learn-DOT/#active-issuance","title":"Active Issuance","text":"<p>Active issuance = Total issuance - Inactive issuance</p> <p>All the tokens under active issuance are can be used to participate in the governance on-chain.</p>"},{"location":"learn/learn-DOT/#obtaining-testnet-tokens","title":"Obtaining Testnet Tokens","text":"<p>DOT are required to make transactions on the Polkadot network. Tokens on Polkadot's Testnets do not have any value besides allowing you to experiment with the features on the network.</p> <p>Tokens for each testnet described below can be obtained here.</p>"},{"location":"learn/learn-DOT/#getting-tokens-on-the-paseo-testnet","title":"Getting Tokens on the Paseo Testnet","text":"<p>The Paseo testnet mirrors the Polkadot runtime and it is maintained by the community. The PAS tokens can be obtained here and have the same Planck conversion as Polkadot's native token DOT.</p> Unit Decimal Places Conversion to Planck Conversion to PAS Planck 0 1 Planck 0.0000000001 PAS Microdot (uPAS) 4 10<sup>4</sup> Planck 0.0000010000 PAS Millidot (mPAS) 7 10<sup>7</sup> Planck 0.0010000000 PAS Dot (PAS) 10 10<sup>10</sup> Planck 1.0000000000 PAS Million (MPAS) 16 10<sup>16</sup> Planck 1,000,000.00 PAS <p>Users can also obtain PAS by posting <code>!drip &lt;PASEO_ADDRESS&gt;</code> in the Matrix chatroom #paseo_faucet:matrix.org.</p>"},{"location":"learn/learn-DOT/#getting-tokens-on-the-westend-testnet","title":"Getting Tokens on the Westend Testnet","text":"<p>Polkadot's testnet is called Westend. Besides the official faucet, you can obtain its native WND tokens by posting <code>!drip &lt;WESTEND_ADDRESS&gt;</code> in the Matrix chatroom #westend_faucet:matrix.org. Your account will be credited with 1 WND by default. You can also specify to get more tokens by <code>!drip &lt;WESTEND_ADDRESS&gt; X</code>, where X is the number of tokens.</p> <p>On the Westend network, you can also earn WNDs as rewards by becoming a validator. Watch the video below on how to get started on Westend.</p> <p> Testing Polkadot features on Westend </p> Unit Decimal Places Conversion to Planck Conversion to WND Planck 0 1 Planck 0.000000000001 WND Point 3 10<sup>3</sup> Planck 0.000000001000 WND MicroWND (uWND) 6 10<sup>6</sup> Planck 0.000001000000 WND MilliWND (mWND) 9 10<sup>9</sup> Planck 0.001000000000 WND WND 12 10<sup>12</sup> Planck 1.000000000000 WND"},{"location":"learn/learn-DOT/#faucets-support","title":"Faucets support","text":"<p>If you require help with using faucets, or wish to report an issue, there is a support chat #faucets-support:matrix.org, or you can create an issue directly in the faucets repo</p>"},{"location":"learn/learn-DOT/#kusama-tokens","title":"Kusama Tokens","text":"<p>Unlike testnet DOT, Kusama tokens are not freely given away. Kusama tokens are available via the claims process (if you had DOT at the time of Kusama genesis) or through the Treasury. Alternatively, they can be obtained on the open market.</p>"},{"location":"learn/learn-DOT/#polkadot-mainnet-dot","title":"Polkadot Mainnet DOT","text":"<p>Polkadot Mainnet DOT are not freely given away. If you purchased DOT in the original 2017 offering, you may claim them via the Polkadot claims process. Alternatively, they are available on the open market.</p>"},{"location":"learn/learn-account-abstraction/","title":"Polkadot's Account Abstraction","text":""},{"location":"learn/learn-account-abstraction/#your-keys-your-responsibility","title":"Your Keys, Your Responsibility","text":"<p>Account abstraction addresses the challenges of managing cryptographic keys representing accounts on blockchains. Accounts on blockchains represent entities, from an individual's identity to an institution. In Web3, you digitally sign any transaction or, more generally, any message using your private key. Data is recorded on a public ledger (usually blockchain-based) whose multiple copies of it are stored in computers participating in a P2P network.</p> <p>While the account\u2019s private keys grant users control and ownership, losing them results in losing access to digital assets and fragmentation of your digital identity since you will need to create a new account with a new set of keys. This poses a hurdle for both users and developers regarding security and adoption.</p>"},{"location":"learn/learn-account-abstraction/#definition-of-account-abstraction","title":"Definition of Account Abstraction","text":"<p>The concept of account abstraction was first mentioned via Ethereum's EIP-4337 focused on allowing users to flexibly program more security and better user experiences into their accounts. The idea also aims to separate the user experience from the private key, enabling a piece of code to dictate account behavior. This allows for increased flexibility of accounts that originally were not engineered to be flexible and decreased chances of key mismanagement.</p> <p>Users are still responsible for their keys, but through account abstraction, they can take precautions to ensure they do not end up losing their accounts.</p> <p>Account abstraction introduces a layer of on-chain logic that controls an account, typically in the form of a smart contract, that completely avoids the need for consensus-layer protocol changes. Without a smart contract, abstracting accounts would require changes in the core architecture of the protocol.</p> <p>Polkadot's generic codebase makes the concept of an account natively flexible and abstract without the direct need for smart contracts.</p>"},{"location":"learn/learn-account-abstraction/#origin-abstraction-in-polkadot","title":"Origin Abstraction in Polkadot","text":"<p>Adopting a generic design is crucial in scaling Web3 technologies. Abstraction and generalization of protocols are essential to improving user experience and security in blockchain adoption.</p> <p>When users interact with a blockchain they call dispatchable functions to do something. Because those functions are called from the outside of the blockchain interface, in Polkadot's terms any action that involves a dispatchable function is an extrinsic. Extrinsics are calls coming from the outside of the blockchain interface that (if successfully executed) invoke some changes in the inside of the blockchain's state. An extrinsic is always directed to a specific function within a particular pallet.</p> <p>For example, the <code>balances.transferKeepAlive</code> extrinsic is directed to the <code>transferKeepAlive</code> function within the <code>balances</code> pallet. If successful, the execution of that function will transfer funds between two accounts, changing the balances of those accounts and thus the chain state (as accounts hold some state within the blockchain).</p> <p>In Substrate's FRAME, functions are not necessarily called by accounts. Functions can be called by any origin, where origins are caller-personas associated with privilege levels. For example, the Polkadot OpenGov has different origins with different privileges, such as allocating treasury funds, cancelling a referendum, etc. Neither of those origins is subservient to the concept of an account or assume anything about state or associated data. Custom origins can be created while designing your chain using the Substrate (which is part of the Polkadot SDK).</p> <p>The figure below shows Polkadot's origin abstraction. Accounts happen to be just one variant (or corner case) of Substrate's FRAME possible origins, the <code>frame_system::RawOrigin::Signed</code>. OpenGov origins function in a way that, if conditions (approval and support) are met and a proposal passes, the appropriate origin is then associated with the scheduled call. Those origins are caller-personas that do not have any entity behind them, and do not hold any state on chain.</p> <p></p> <p>In Substrate, the concept of account is completely deprioritized. Substrate itself remains indifferent to an account's balance and nonce. While FRAME can support their presence, it fundamentally does not need to rely on them.</p> <p>The Cross-Consensus Messaging (XCM) format can take advantage of origin abstraction for cross-consensus communications by specifying the context for a particular message. Origins in this case imply the authority under which a message is being sent (and thereby, executed).</p> <p>On a lower level, the XCM format also provides a much powerful origin abstraction that allows calling personas that are so abstract to not necessarily have direct representation on the local chain within its FRAME system origin.</p>"},{"location":"learn/learn-account-abstraction/#protocol-level-account-abstraction","title":"Protocol-level Account Abstraction","text":"<p>While the Substrate FRAME system does not have a single pallet (module) for complete account abstraction, it incorporates various pallets that collectively achieve similar functionalities. Polkadot's native account abstraction functionalities include:</p> <ul> <li>Multi-signature accounts to control an account using different ones</li> <li>Proxy accounts for role-based representation, and ownership representation   through pure proxies</li> <li>Derivative accounts for using the same parent   private key on multiple children accounts</li> <li>Account recovery mechanisms such as social recovery to help regain access to your key using   trusted third-party accounts</li> <li>Batching functionality to   submit multiple calls in one single transaction</li> <li>Payments with non-native tokens</li> </ul> <p>All the above can be used together, meaning that, for example, you can create a multi-signature account of pure proxies to keep the same multi-signature account when signatories change. A more complex combination to build a hot wallet can be found in this blog post.</p> <p>Additionally, developers have the flexibility to design their own rules for abstraction.</p> <p>In the Substrate FRAME system, accounts are represented by Accounts IDs. Such unique identifiers can be any 32-byte number and are not limited to just a public key (with a corresponding private key). For example, multi-signature accounts do not have a private key, and their Account ID is built with hashed information from signatories\u2019 public keys and the multisig threshold.</p>"},{"location":"learn/learn-account-abstraction/#smart-contract-level-account-abstraction","title":"Smart-contract Level Account Abstraction","text":"<p>Account abstraction can be implemented in parachains also with traditional smart-contracts for example using the ink! smart contract language.</p>"},{"location":"learn/learn-account-abstraction/#further-readings","title":"Further Readings","text":"<ul> <li>Hackernoon Article by   Bader Youssef - \"Abstracting Away Account Abstraction   on Polkadot\"</li> <li>Parity Blog Post by   Joe Petrowski - \"Building a Hot Wallet with Substrate Primitives\"</li> <li>FRAME Origin - Polkadot-SDK Docs</li> </ul>"},{"location":"learn/learn-account-advanced/","title":"Polkadot Accounts In-Depth","text":""},{"location":"learn/learn-account-advanced/#address-format","title":"Address Format","text":"<p>The address format used in Substrate-based chains is SS58. SS58 is a modification of Base-58-check from Bitcoin with some minor changes. Notably, the format contains an address type prefix that identifies an address belonging to a specific network.</p> <p>For example:</p> <ul> <li>Polkadot addresses always start with the number 1.</li> <li>Kusama addresses always start with a capital letter, such as C, D, E, F, G, H, J.</li> <li>Generic Substrate addresses always start with the number 5.</li> </ul> <p>These prefixes, including how to validate addresses, are embedded in the Substrate SS58 format. Never use regular expressions for address validation.</p> <p>It's important to understand that different network formats are merely other representations of the same public key in a private-public keypair generated by an address generation tool. As a result, the addresses across Substrate-based chains are compatible if the format is converted correctly.</p> <p>As of Runtime 28, the default address format is the <code>MultiAddress</code> type.</p> <p>This <code>enum</code> is a multi-format address wrapper for on-chain accounts and allows us to describe Polkadot's default address format to represent many different address types. This includes 20 byte, 32 byte, and arbitrary raw byte variants. It also enhances the original <code>indices</code> lookup.</p> <p>Info</p> <p>Many wallets allow you to convert between formats. Stand-alone tools exist as well; you can find them in the address conversion tools section.</p>"},{"location":"learn/learn-account-advanced/#for-the-curious-how-prefixes-work","title":"For the Curious: How Prefixes Work","text":"<p>The SS58 registry states that:</p> <ul> <li>Polkadot has an address type of <code>00000000b</code> (<code>0</code> in decimal).</li> <li>Kusama (Polkadot Canary) has an address type of <code>00000010b</code> (<code>2</code> in decimal).</li> <li>Generic Substrate has <code>00101010b</code> as the address type (<code>42</code> in decimal).</li> </ul> <p>Because the <code>Base58-check</code> alphabet has no number 0, the lowest value is indeed 1. So <code>00000000b</code> is 1 in Base58-check. If we try to decode a Polkadot address like <code>1FRMM8PEiWXYax7rpS6X4XZX1aAAxSWx1CrKTyrVYhV24fg</code>, the result is <code>000aff6865635ae11013a83835c019d44ec3f865145943f487ae82a8e7bed3a66b29d7</code>. The first byte is <code>00</code>, which is indeed <code>00000000</code> in binary and <code>0</code> in decimal and thus matches the address type of Polkadot.</p> <p>Let's take a look at Substrate addresses. If we decode <code>5CK8D1sKNwF473wbuBP6NuhQfPaWUetNsWUNAAzVwTfxqjfr</code>, we get <code>2a0aff6865635ae11013a83835c019d44ec3f865145943f487ae82a8e7bed3a66b77e5</code>. The first byte is <code>2a</code> which when converted from hex to decimal is 42. 42 is <code>00101010</code> in binary, just as the SS58 document states.</p> <p>Finally, let's look at Kusama addresses. Decoding <code>CpjsLDC1JFyrhm3ftC9Gs4QoyrkHKhZKtK7YqGTRFtTafgp</code> gives us <code>020aff6865635ae11013a83835c019d44ec3f865145943f487ae82a8e7bed3a66b0985</code> with the first byte being <code>02</code>, just as specified. If we try a Kusama address that starts with a completely different letter, like <code>J4iggBtsWsb61RemU2TDWDXTNHqHNfBSAkGvVZBtn1AJV1a</code>, we still get <code>02</code> as the first byte: <code>02f2d606a67f58fa0b3ad2b556195a0ef905676efd4e3ec62f8fa1b8461355f1142509</code>. It seems counterintuitive that some addresses always have the same prefix and others like Kusama can vary wildly, but it's just a quirk of Base58-check encoding.</p>"},{"location":"learn/learn-account-advanced/#address-conversion-tools","title":"Address Conversion Tools","text":"<p>You can use the tools below to convert any SS58 address for any network for use on different networks</p> <ul> <li>handy subscan tool</li> <li>simple address converter</li> </ul>"},{"location":"learn/learn-account-advanced/#how-to-verify-a-public-keys-associated-address","title":"How to Verify a Public Key's Associated Address","text":"<p>You can verify your public key's associated address through a series of inspection steps, where the key is a base-16 (hexadecimal) address.</p>"},{"location":"learn/learn-account-advanced/#using-subkey-to-retrieve-public-key-from-ss58-address","title":"Using Subkey to Retrieve Public Key from SS58 Address","text":"<p>This is to showcase that the SS58 address is based on the public key (aka \"Account ID\")</p> <p>The Subkey Tool's The Inspecting Keys section explains how to use the <code>inspect</code> command to recalculate your key pair's public key and address.</p> <p>Start by inspecting your account's Polkadot address by running the inspect command against your account's address:</p> <pre><code>$ subkey inspect 1a1LcBX6hGPKg5aQ6DXZpAHCCzWjckhea4sz3P1PvL3oc4F\n\nPublic Key URI `1a1LcBX6hGPKg5aQ6DXZpAHCCzWjckhea4sz3P1PvL3oc4F` is account:\n  Network ID/version: polkadot\n  Public key (hex):   0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  Account ID:         0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  SS58 Address:       1a1LcBX6hGPKg5aQ6DXZpAHCCzWjckhea4sz3P1PvL3oc4F\n</code></pre> <p>Take note of the hexadecimal string for \"Public key (hex)\". This is your account's public key.</p> <p>Running the <code>inspect</code> command on your public key along with the <code>--public</code> parameter the SS58 address for the default network (substrate) is returned.</p> <pre><code>$ subkey inspect --public 0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n\nNetwork ID/version: substrate\n  Public key (hex):   0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  Account ID:         0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  Public key (SS58):  5CdiCGvTEuzut954STAXRfL8Lazs3KCZa5LPpkPeqqJXdTHp\n  SS58 Address:       5CdiCGvTEuzut954STAXRfL8Lazs3KCZa5LPpkPeqqJXdTHp\n</code></pre> <p>Using the <code>--network</code> flag, you can define the network that you would like to inspect, where the SS58 address will be based on that network. Now, running the <code>inspect</code> command with <code>--network polkadot</code> return your original Polkadot address, thus verifying the public key.</p> <pre><code>$ subkey inspect --network polkadot 5CdiCGvTEuzut954STAXRfL8Lazs3KCZa5LPpkPeqqJXdTHp\n\nPublic Key URI `5CdiCGvTEuzut954STAXRfL8Lazs3KCZa5LPpkPeqqJXdTHp` is account:\n  Network ID/version: polkadot\n  Public key (hex):   0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  Account ID:         0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce\n  Public key (SS58):  1a1LcBX6hGPKg5aQ6DXZpAHCCzWjckhea4sz3P1PvL3oc4F\n  SS58 Address:       1a1LcBX6hGPKg5aQ6DXZpAHCCzWjckhea4sz3P1PvL3oc4F\n</code></pre> <p>You will notice that the Subkey Tool recognizes the correct address network and returns the associated public key. The public key is returned as a hexadecimal string (i.e. prefixed with \"0x\"). For both SS58 addresses, the same public key is returned.</p>"},{"location":"learn/learn-account-advanced/#address-verification","title":"Address Verification","text":""},{"location":"learn/learn-account-advanced/#consider-the-following-example","title":"Consider the following example:","text":"<p>If you are comfortable enough to distinguish between each account parameter, you can prefix the public-key string with \"0x\" on your own:</p> <p>From: <code>Pay DOTs to the Polkadot account:192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce</code>, we prefix the address by \"0x\" -&gt; <code>0x192c3c7e5789b461fbf1c7f614ba5eed0b22efc507cda60a5e7fda8e046bcdce</code>.</p> <p>Using the handy subscan tool, you can verify both address associations to your public key. Copy your public key into the \"Input Account or Public Key\" textbox and click \"Transform\" at the bottom. On the right-hand side, the addresses for Polkadot and Substrate that are returned based on your public key should match the ones you inspected.</p> <p></p> <p>Note</p> <p>You may have to scroll down to the bottom of the menu to find the Substrate address based on the menu listings. You will notice that many networks that also use the same Substrate address.</p> <p>You can verify your public key verification by recalling that Polkadot addresses start with a '1', whereas Substrate addresses generally start with a '5' (Kusama addresses start with a capital letter). See Addresses for more details.</p> <p>Furthermore, the Utility Scripts can be referenced for how the verification is performed: pubkeyToAddress.js demonstrates how a single public key interprets a Polkadot, Substrate, or Kusama address.</p>"},{"location":"learn/learn-account-advanced/#portability","title":"Portability","text":"<p>Portability is the ability to use a mnemonic phrase or seed across multiple wallets.</p> <p>Most wallets generate a mnemonic phrase for users to back up their wallets and generate a private key from the mnemonic. Not all wallets use the same algorithm to convert from mnemonic phrase to private key, which affects the ability to use the same mnemonic phrase in multiple wallets. Wallets that use different measures will arrive at a different set of addresses from the exact mnemonic phrase.</p> <p>Not all wallets use the same algorithm to convert from mnemonic phrase to private key</p> <p>Subkey and Polkadot-JS based wallets use the BIP39 dictionary for mnemonic generation, but use the entropy byte array to generate the private key, while full BIP39 wallets (like Ledger) use 2048 rounds of PBKDF2 on the mnemonic. The same mnemonic may generate different private keys on other wallets due to the various cryptographic algorithms used. See Substrate BIP39 Repo for more information.</p> <p>Portability depends on several factors:</p> <ul> <li>Derivation path</li> <li>Mnemonic format</li> <li>Seed derivation</li> <li>Signature scheme</li> </ul> <p>To use the exact mnemonic across multiple wallets, ensure they follow compatible methods for generating keys and signing messages. If you are still looking for understandable documentation, contact the project maintainers.</p> Mnemonic Format Derivation Path Seed Derivation Signature Support Polkadot-JS Extension Standard User-Defined BIP32 sr25519 Polkadot-JS Apps Standard* User-Defined BIP32 sr25519, ed25519, secp256k Ledger BIP39 BIP44\u2020 BIP32\u2021 ed25519\u00a7 Subkey Standard* User-Defined BIP32 sr25519, ed25519, secp256k1 <p>* Ed25519 keys have limited compatibility with BIP39.</p> <p>\u2020 BIP44 Registry</p> <p>\u2021 Ed25519 and BIP32 based on Khovratovich</p> <p>\u00a7 Sr25519 planned</p>"},{"location":"learn/learn-account-advanced/#derivation-paths","title":"Derivation Paths","text":"<p>If you want to create and manage several accounts on the network using the same seed, you can use derivation paths. We can think of the derived accounts as child accounts of the root account created using the original mnemonic seed phrase.</p>"},{"location":"learn/learn-account-advanced/#soft-and-hard-derivation","title":"Soft and Hard Derivation","text":"<p>A soft derivation allows someone to potentially \"go backward\u201d to figure out the initial account's private key if they know the derived account's private key. It is also possible to determine that different accounts generated from the same seed are linked to that seed. A hard derivation path does not allow either of these - even if you know a derived private key, it's not feasible to figure out the private key of the root address, and it's impossible to prove that the first account is linked with the second. These derivation methods have their use cases, given that the private keys for all the derived accounts are fully secure. Unless you have a specific need for a soft derivation, it is recommended to generate the account using a hard derivation path.</p> <p>Many Polkadot key generation tools support hard and soft derivation. For instance, if you intend to create an account to be used on the relay chain, you can derive a hard key child account using // after the mnemonic phrase.</p> <pre><code>'caution juice atom organ advance problem want pledge someone senior holiday very//0'\n</code></pre> <p>and a soft key child account using / after the mnemonic phrase</p> <pre><code>'caution juice atom organ advance problem want pledge someone senior holiday very/0'\n</code></pre> <p>If you want to create another account using the Polkadot chain using the same seed, you can change the number at the end of the string above. For example, <code>/1</code>, <code>/2</code>, and <code>/3</code> will create different derived accounts.</p> <p>You can use any letters or numbers in the derivation path as long as they make sense to you; they do not have to follow any specific pattern. You may combine multiple derivations in your path, as well. For instance, <code>//bill//account//1</code> and <code>//john/polkadot/initial</code> are both valid. To recreate a derived account, you must know both the seed and the derivation path, so you should either use a well-defined sequence (e.g. //0, //1, //2...) or be sure to write down any derivation paths you use.</p> <p>See the Subkey documentation for details and examples of derivation path formats. The Polkadot-JS Apps and Extension and Parity Signer support custom derivation paths using the same syntax as Subkey.</p> <p>Some wallets will automatically add derivation paths to the end of the generated mnemonic phrase. This will generate separate seeds for different paths, allowing separate signing keys with the same mnemonic, e.g. <code>&lt;mnemonic phrase&gt;//polkadot</code> and <code>&lt;mnemonic phrase&gt;//kusama</code>. Although you may correctly save the mnemonic phrase, using it in another wallet will generate the same addresses only if both wallets use the same derivation paths.</p> <p>Polkadot and Kusama both have paths registered in the BIP44 registry.</p> <p>Warning</p> <p>You must have the parent private key and the derivation path to arrive at the key for an address. Only use custom derivation paths if you are comfortable with your knowledge of this topic.</p>"},{"location":"learn/learn-account-advanced/#password-derivation","title":"Password Derivation","text":"<p>There is an additional type of derivation called password derivation. On Polkadot you can derive a password key account using /// after the mnemonic phrase</p> <pre><code>'caution juice atom organ advance problem want pledge someone senior holiday very///0'\n</code></pre> <p>In this type of derivation, if the mnemonic phrase leaks, accounts cannot be derived without the initial password. In fact, for soft- and hard-derived accounts, if someone knows the mnemonic phrase and the derivation path, they will have access to your account. For password-derived accounts, the password is applied on the derivation path. You can know the mnemonic phrase and the derivation path, but without the password, it is impossible to access the account. In mathematical terms, if we have a <code>written derivation path</code> and a <code>password</code>, we can calculate the <code>real derivation path</code> as <code>f(written derivation path, password)</code>, where <code>f</code> is a function. We can then calculate the <code>account key pair</code> using <code>f(seed, real derivation path)</code>. Unlike hard and soft derivations that can be mixed, only a single password should be specified per derivation.</p> <p>Info</p> <p>Password-derived account are as secure as the chosen password.</p>"},{"location":"learn/learn-account-advanced/#account-derivation-on-ledger-live","title":"Account Derivation on Ledger Live","text":"<p>Ledger Live will only show the main account with BIP44 path 44'/354'/0'/0'/0'. This means that if you created a derived account with a derivation path 44'/354'/0'/0'/1' on a wallet or extension, it will not be displayed on the Ledger Live App. Consequently, it is not possible to transact with derived accounts using the Ledger Live App, but it is possible to do so using Polkadot-JS. Check the accounts page for more information about derived accounts and derivation paths.</p> <p>Note that you cannot import Kusama Ledger accounts in Ledger Live. To see Kusama account balances, you must import your ledger account into a wallet.</p>"},{"location":"learn/learn-account-advanced/#account-derivation-on-subkey-and-polkadot-vault","title":"Account Derivation on Subkey and Polkadot Vault","text":"<p>The Subkey tool and Polkadot Vault App use the following Polkadot Standard Hard Derivation scheme:</p> <ul> <li><code>//network</code> as the primary account for <code>network</code>, named according to <code>network</code>'s named chain   specification</li> <li><code>//network//0</code>, <code>//network//1</code>, ... as the secondary high-security accounts for <code>network</code></li> </ul> <p>For example, the Vault app will generate a new account from a <code>SEED PHRASE</code>, and for each network will create a derived child account from that seed. For the default networks Polkadot, Kusama and Westend the derivation path will be:</p> <ul> <li><code>SEED PHRASE//polkadot</code> for Polkadot, with <code>SEED PHRASE//polkadot//0</code> as the first secondary   high-security account</li> <li><code>SEED PHRASE//kusama</code> for Kusama, with <code>SEED PHRASE//kusama//0</code> as the first secondary   high-security account</li> <li><code>SEED PHRASE//westend</code> for Westend, with <code>SEED PHRASE//westend//0</code> as the first secondary   high-security account</li> </ul> <p>Additionally, although it is not strictly necessary, users can adopt the following good practice scheme:</p> <ul> <li><code>//network//pub</code> as the primary high-security public account for <code>network</code> (the one the user is   happy to be associated with their \"real\" ID)</li> <li><code>//network//pub//0</code>, <code>//network//pub//0</code>, ... as the secondary high-security public accounts for     <code>network</code></li> <li><code>//network//hot</code> as the primary low-security account for <code>network</code> (the one whose secret key the   user exports from the Vault app to carry on an internet-connected device)</li> <li><code>//network//hot//0</code>, <code>//network//hot//1</code>, ... as the secondary low-security accounts for     <code>network</code></li> </ul> <p>Info</p> <p>For more information about account derivation best practices, see this post on the Polkadot Forum.</p>"},{"location":"learn/learn-account-advanced/#system-accounts","title":"System Accounts","text":"<p>As the word suggests, system accounts are used by the system. They are used, for example, for the treasury, crowdloans, and nomination pools. From the point of view of the runtime, these accounts are like any other account on-chain. These special system accounts are just public keys, with the private key being unknown (and unattainable). So, that means that only the pallet itself can interact with this account. These accounts can never issue a signed extrinsic since they do not have a private key.</p> <p>Explore the main system accounts below.</p> PolkadotKusama <p>Treasury account address - <code>13UVJyLnbVp9RBZYFwFGyDvVd1y27Tt8tkntv6Q7JVPhFsTB</code></p> <p>Treasury account address - <code>F3opxRbN5ZbjJNU511Kj2TLuzFcDq9BGduA9TgiECafpg29</code></p> <p>You can view the existing system accounts on Subscan.</p> <p>Let us take a look at how system accounts are generated under the hood. For instance, to generate the treasury account, the raw bytes of the strings \"modl\" and \"py/trsry\" are combined to create the <code>AccountID</code>. For more information, check the post on Substrate StackExchange on Treasury accounts. Similarly, to generate the crowdloan account, the raw bytes of the strings \"modl\" and \"py/cfund\" along with the fund index are combined to create the <code>AccountID</code>. Similar logic applies to nomination pool and parachain accounts as well.</p>"},{"location":"learn/learn-account-advanced/#indices","title":"Indices","text":"<p>Polkadot addresses can have indices. An index is like a short and easy-to-remember version of an address. Claiming an index requires a deposit released when the index is cleared. Any index can be claimed if it is not taken by someone else.</p> <p>But what if an account gets reaped, as explained above? In that case, the index is emptied. In other words, the slot frees up again, making it available for anyone to claim. It is possible to freeze an index and permanently assign it to an address. This action consumes a deposit, and the index will be permanently bound to the address with no option to release it.</p> <p>Lookup Account Index on-chain</p> <p>When someone shares their account index, their actual account address on-chain can be looked up through Polkadot-JS Apps UI &gt; Developer &gt; Chain state &gt; Storage and selecting state query on indices pallet for the account corresponding to the index.</p> <p>Here is an example snapshot that shows how to lookup the corresponding account address of the account index 1988 on Westend network (Polkadot Test Network), using Polkadot-JS Apps UI. The output shows the account address, deposit amount, and a boolean flag indicating whether this is claimed permanently.</p> <p></p> <p>Submit a <code>claim</code> extrinsic to the <code>indices</code> pallet to register an index. The easiest way to do this is via Polkadot-JS UI through the Developer -&gt; Extrinsics menu:</p> <p></p> <p>To find available indices to claim on Polkadot or Kusama, this helper tool may come in handy.</p> <p>For keeping the index permanently, you can follow up with a <code>freeze</code> extrinsic as mentioned above.</p>"},{"location":"learn/learn-account-advanced/#creating-accounts-with-subkey","title":"Creating Accounts with Subkey","text":"<p>Subkey is recommended for technically advanced users comfortable with the command line and compiling Rust code. Subkey lets you generate keys on any device that can compile the code. Subkey may also be useful for automated account generation using an air-gapped device. It is not recommended for general users. Follow the instructions in the Subkey documentation.</p> <p>Info</p> <p>For guidelines about how to create an account using Subkey, see this video tutorial and visit this support article.</p>"},{"location":"learn/learn-account-advanced/#using-ens-with-dotksm-accounts","title":"Using ENS with DOT/KSM accounts","text":"<p>ENS (Ethereum Name Service) is a distributed and open system of smart contracts on the Ethereum blockchain which allows users to claim domain names like <code>bruno.eth</code>.</p> <p>The ENS is equivalent to a DNS (Domain Name System) domain. Instead, it offers a decentralized and secure way to translate text via smart contracts. Supporting wallets can then allow senders to input ENS domains instead of long and unwieldy addresses. This prevents phishing, fraud, and typos and adds a layer of usability to the regular wallet user experience.</p> <p>Note</p> <p>You will need an ENS name and an Ethereum account with some ether to follow along with this guide. To register an ENS name, visit the ENS App or any number of subdomain registrars like Nameth. Note that if you're using an older ENS name, you should make sure you're using the new resolver. Visiting the ENS App will warn you about this. You will also need some way to use your Ethereum address - following this guide on a personal computer is recommended. Wallets like Frame and Metamask are safe and will make interacting with the Ethereum blockchain through your browser very easy.</p> <p>Despite living on the Ethereum blockchain, the ENS system has multi-chain support. In this guide, you'll go through the process of adding a KSM and DOT address to ENS. We cover both KSM and DOT to show two different approaches.</p> <p>Note</p> <p>DOT can currently only be added using the Resolver method. KSM can be added through both methods are described below.</p> <p>This guide is also available in video format on YouTube.</p>"},{"location":"learn/learn-account-advanced/#adding-via-the-ui","title":"Adding via the UI","text":"<p>The ENS App allows an ENS domain owner to inspect all records bound to the domain, and to add new ones.</p> <p></p> <p>In the example above, the domain <code>bruno.eth</code> has an Ethereum and a Bitcoin address attached. Let's attach a KSM account. First, click the <code>[+]</code> icon in the Records tab.</p> <p></p> <p>Then, pick \"Other Addresses\", \"KSM\", and input the Kusama address:</p> <p></p> <p>After clicking Save, your Ethereum wallet will ask you to confirm a transaction. Once processed, the record will show up on the domain's page:</p> <p></p> <p>The exact process applies to adding your DOT address.</p> <p>Once the transaction is confirmed, your address will be bound to your ENS domain.</p>"},{"location":"learn/learn-account-advanced/#wallet-support","title":"Wallet Support","text":"<p>There is no wallet support for ENS names for either KSM or DOT at this time, but the crypto accounting and portfolio application Rotki does support KSM ENS resolution.</p>"},{"location":"learn/learn-account-advanced/#relevant-links","title":"Relevant links","text":"<ul> <li>ENS docs</li> <li>ENS Multi-chain announcement</li> <li>Address encoder</li> <li>Namehash calculator</li> <li>Address to pubkey converter</li> </ul>"},{"location":"learn/learn-account-advanced/#transferring-polkadot-js-apps-accountsaddresses-from-one-computer-to-another","title":"Transferring Polkadot-JS Apps Accounts/Addresses From One Computer to Another","text":"<p>Caution</p> <p>This will overwrite existing accounts with the same pubkey on your new computer. This generally should not make a difference (since it can still access the same account), but it might if you have e.g. an account that was stored externally in the extension on the old computer but was created directly in the browser on the new one.</p> <p>This has been tested on Brave and Chrome, but not other browsers.</p> <ol> <li>Go to Polkadot-JS Apps</li> <li>Go to JavaScript console on the browser (Available in Developer Tools)</li> <li>Type in the command:</li> </ol> <pre><code>JSON.stringify(localStorage)\n</code></pre> <ol> <li>Copy and paste the returned string to a text editor and save the file.</li> <li>Check that the string you pasted begins and ends with a tick mark ('). If not, add one to the    beginning and end.</li> <li>Save and send that file with the copied string to the new computer.</li> <li>On the new computer, go to Polkadot-JS Apps</li> <li>Open the Javascript console on the browser (Available in Developer Tools)</li> <li>Set a variable raw equal to the string from the text file</li> </ol> <pre><code>raw = ... copy-pasted json from original computer ...\n</code></pre> <ol> <li>Run the following code on the console:</li> </ol> <pre><code>accounts = JSON.parse(raw);\nfor (var key in accounts) {\n    if (accounts.hasOwnProperty(key)) {\n        val = JSON.stringify(accounts[key]).replace(/\\\\/g,'').slice(1,-1);\n        console.log(key + \" -&gt; \" + val);\n        localStorage.setItem(key, val);\n    }\n}\n</code></pre> <ol> <li>Refresh Polkadot-JS App browser and check the Accounts and Addresses pages. All of your accounts     and addresses should now be available.</li> </ol>"},{"location":"learn/learn-account-balances/","title":"Account Balances","text":"<p>In the Polkadot ecosystem, there are different types of balances depending on the account activity. Different balance types dictate whether your balance can be used for transfers, to pay fees, or must remain frozen and unused due to an on-chain requirement.</p> <p>A more efficient distribution of account balance types</p> <p>Soon, pallets on Polkadot SDK will be implementing the fungible trait (see the tracking issue for more info). This new logic will allow for more efficient use of your account balance. Specifically, the fungible trait will allow using the <code>free</code> balance for on-chain activity like setting proxies and identities.</p> <p>There are 5 types of account balances:</p> <ul> <li>Free is the balance that can be used for on-chain activity like staking, participating in   governance etc. but is not necessarily spendable (or transferrable)</li> <li>Frozen is the free balance locked for staking,   governance, and vesting   (also called locked balance)</li> <li>On hold is used for identities, proxies,   OpenGov preimages and deposits,   and it is no longer free (also called reserved balance)</li> <li>Spendable is the free balance that can be spent</li> <li>Untouchable is the portion of the free balance that cannot be moved (i.e., not spendable) but   can still be used for on-chain activity</li> </ul> <p>The spendable balance is calculated as follows:</p> <pre><code>spendable = free - max(frozen - on_hold, ED)\n</code></pre> <p>where <code>free</code>, <code>frozen</code> and <code>on_hold</code> are defined above. The <code>ED</code> is the the existential deposit.</p> <p>Wallet providers might show you the spendable, locked, and reserved balance.</p>"},{"location":"learn/learn-account-balances/#example-of-account-balance-types","title":"Example of Account Balance Types","text":"<p>Below is an in-depth example of how an account balance composition changes depending on user actions once the fungible trait is used for account balances. Let\u2019s take, for example, an account with 100 DOT.</p> <pre><code>Free: 100 DOT\nFrozen: 0 DOT\nOn hold: 0 DOT\nSpendable: 99 DOT\nUntouchable: 1 DOT (ED)\n</code></pre> <p></p> <p>In this case, the existential deposit of 1 DOT is untouchable (meaning you can\u2019t touch it if the account can\u2019t or shouldn\u2019t get reaped). If 80 DOT from the account is staked, we get the following balance structure:</p> <pre><code>Free: 100 DOT\nFrozen : 80 DOT\nOnhold: 0 DOT\nSpendable: 20 DOT\nUntouchable: 80 DOT\n</code></pre> <p></p> <p>The spendable balance would be 20 DOT (which would also include fees for future transactions from this account).</p> <p>Note how the account cannot be reaped from the state while it has a frozen balance, or in general any consumer and provider reference. Those references determine if an account can be reaped, usually because other accounts depend on the existence of such an account). For example, the existential deposit adds a provider reference simply because the account exists, while a proxy account adds a consumer reference (the proxy existence depends on the proxied account; the proxy is the consumer). Because the existential deposit is part of the untouchable balance, the user can use all the spendable balance (there is no need to keep 1 DOT as spendable).</p> <p>Info</p> <p>The use of the free balance as shown in the following figures will be possible once the fungible trait is implemented for account balances.</p> <p>If the account creates a proxy, it will use the <code>free</code> balance as shown below.</p> <pre><code>Free: 80 DOT\nFrozen : 80 DOT\nOnhold: 20 DOT\nSpendable: 20 DOT\nUntouchable: 60 DOT\n</code></pre> <p></p> <p>Note how, through the fungible trait, the system uses the <code>balance</code> that is frozen instead of the <code>free</code> balance that is spendable (present configuration on-chain). In other words, holds are subtracted from free balance but overlap with the frozen balance. The free portion shrinks from 100 to 80 DOT, and the <code>on_hold</code> portion increases from 0 to 20 DOT. The creation of an identity will grow the <code>on_hold</code> portion to 40 DOT, and shrink further the <code>free</code> from 80 to 60 DOT. Note how the spendable balance stays the same in the process.</p> <pre><code>Free: 60 DOT\nFrozen: 80 DOT\nOnhold: 40 DOT\nSpendable: 20 DOT\nUntouchable: 40 DOT\n</code></pre> <p></p> <p>This update using the fungible trait allows the use of the frozen balance for on-chain activity like setting up proxies and identities. Note that holds are slashable, and the pallet migrations need to take that into account. This means that freezes should account for hold being slashed (for example, your stash account balance getting reduced because your governance deposit for a proposal was slashed).</p>"},{"location":"learn/learn-account-balances/#locks","title":"Locks","text":"<p>Locks are abstractions over an account's free balance, preventing it from being spent. Several locks can overlap on the same account balance instead of being stacked on top of one another. Locks are automatically added onto accounts when the account participates in activities on-chain (staking, voting, etc.), but these are not customizable.</p> <p>Locks are accounted for within the <code>frozen</code> balance of the account. This is the balance that can be <code>free</code> but not transferrable, and locked in staking, governance and vesting.</p> <p>Locks overlap (in both amount and duration), and the general rule is that:</p> <ul> <li>If you have multiple locks of different amounts of tokens, the biggest lock decides the total   amount of locked tokens</li> <li>If you have multiple locks of the same amount of tokens, the lock with the longest duration   decides when those tokens can be unlocked</li> </ul> <p>Let's take, for example, 80 DOT as a <code>frozen</code> balance. These 80 DOT are currently used in staking and governance as follows:</p> <ul> <li>80 DOT Staking (just unbonded) -&gt; lock 28 days</li> <li>24 DOT OpenGov 1x conviction (referendum just ended, winning side) -&gt; lock 7 days</li> <li>4 DOT OpenGov 6x conviction (referendum just ended, winning side) -&gt; lock 224 days</li> </ul> <p></p> <p>The 1 DOT ED is the existential deposit. The locked amount is 80 DOT (not 108 DOT). But those 80 DOT will be available for unlock at different times. You will first need to remove the governance lock on the 24 DOT after 7 days, then remove the staking lock for the 80 DOT after 28 days, and finally, after 224 days, you will be able to remove the second governance lock.</p> <p></p> <p>After 224 days, all 80 DOT (- ED) will be free and transferrable.</p>"},{"location":"learn/learn-account-balances/#edge-case-for-locks","title":"Edge Case for Locks","text":"<p>The longest period and the largest amount are considered if you use different convictions while you have ongoing locks.</p> <p>Following the previous example, if you:</p> <ul> <li>undelegate a 1x conviction delegation of 24 DOT, you will get a 7-day lock on 24 DOT</li> <li>delegate 4 DOT with 6x conviction</li> <li>undelegate again before the 1x conviction lock is removed</li> </ul> <p>You will get a 6x conviction for 24 DOT! See here for more information.</p>"},{"location":"learn/learn-account-balances/#balance-types-on-polkadot-js","title":"Balance Types on Polkadot-JS","text":"<p>Below is an example that displays different balance types on the Polkadot-JS UI (wallet) of a Kusama account (note that the balance types are the same for a Polkadot account).</p> <p></p> <ul> <li>The total balance indicates the total number of tokens in the account. Note that this number   does not necessarily correspond to the tokens you can transfer. In the example, the total number   of tokens is 0.6274 KSM. The transferrable balance indicates the number of free tokens to be   transferred. This is calculated by subtracting the number of locked and reserved tokens from   the total number of tokens. Locked funds correspond to tokens used in staking, governance, and   vested transfers (see below). In the example, the transferrable balance is 0.0106 KSM.</li> <li>The vested balance indicates tokens sent to the account and released with a specific time   schedule. The account owns the tokens, but they are locked and become available for transfer   after a specific number of blocks. In the example, the vested balance is 0.25 KSM.</li> <li>The bonded balance indicates the number of tokens that are locked for on-chain participation   to staking. In the example, the bonded balance is 0.4 KSM.</li> <li>The democracy balance indicates the number of tokens that are locked for on-chain   participation in democracy (i.e., voting for referenda and council). In the example, the democracy   balance is 0.4 KSM.</li> <li>The redeemable balance indicates the number of tokens ready to be unlocked to become   transferrable again. Those tokens already went through the unbonding period. In this case, the   redeemable balance is 0.1 KSM.</li> <li>The locked balance indicates the number of frozen tokens for on-chain participation to staking   and democracy or for vested transfers. Locks do not stack, which means that if you have   different locks, the total locked balance is not the addition of the individual locks. Instead,   the biggest lock decides the total locked balance. In the example, the locked balance is 0.55   KSM because the biggest lock is on democracy (0.55 KSM).</li> <li>The reserved balance indicates the number of frozen tokens for on-chain activity other than   staking, governance, and vested transfers. Such activity can be setting an identity or a proxy.   Reserved funds are held due to on-chain requirements and can usually be freed by taking some   on-chain action. For example, the \"Identity\" pallet reserves funds while an on-chain identity is   registered, but by clearing the identity, you can unreserve the funds and make them free again.   The same applies to proxies. The idea is that those actions require some network memory usage that   is not given for free. In the example, we created a governance proxy, and the reserved funds for   this are 0.0668 KSM.</li> </ul>"},{"location":"learn/learn-account-multisig/","title":"Multi-Signature Accounts","text":"<p>Multisig Apps</p> <p>See the multisig apps page for more information about user-friendly tools about multi-signature accounts.</p> <p>It is possible to create multi-signature accounts (multisig) in Substrate-based chains. A multisig is composed of one or more addresses and a threshold. The threshold defines how many signatories (participating addresses) need to agree on submitting an extrinsic for the call to be successful.</p> <p>For example, Alice, Bob, and Charlie set up a multisig with a threshold of 2. This means Alice and Bob can execute any call even if Charlie disagrees with it. Likewise, Charlie and Bob can execute any call without Alice. A threshold is typically a number smaller than the total number of members but can also be equal to it, which means they all have to agree.</p> <p>Multi-signature accounts have several uses:</p> <ul> <li>securing your stash: use additional signatories as a 2FA mechanism to secure your funds. One   signer can be on one computer, and another can be on another or in cold storage. This slows down   your interactions with the chain but is orders of magnitude more secure.</li> <li>board decisions: legal entities such as businesses and foundations use multisigs to govern over   the entity's treasury collectively.</li> <li>group participation in governance: a multisig account can do everything a regular account can. A   multisig account could be a referendum proposer or a recipient of funds (recommended) in   governance.</li> </ul> <p>Multi-signature accounts cannot be modified after being created. Changing the set of members or altering the threshold is not possible and instead requires the dissolution of the current multisig and creation of a new one. As such, multisig account addresses are deterministic, i.e. you can always calculate the address of a multisig by knowing the members and the threshold, without the account existing yet. This means one can send tokens to an address that does not exist yet, and if the entities designated as the recipients come together in a new multisig under a matching threshold, they will immediately have access to these tokens.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about multi-signature accounts.</p>"},{"location":"learn/learn-accounts/","title":"Polkadot Accounts","text":"<p>User friendly wallets</p> <p>Create your Polkadot accounts with any of the secure and user-friendly wallets listed on the Polkadot website.</p> <p>See the Wallets section for more information about different wallet options available, and specifically the wallets and extensions page, which lists the user friendly wallet projects funded by the Polkadot/Kusama Treasuries or by the Web3 Foundation Grants Program.</p> <p>This document covers the basics of accounts in the Polkadot ecosystem. See the Advanced Account page for more information about accounts such as account derivation and indices. For a more in-depth explanation of the cryptography behind accounts, please see the cryptography page.</p>"},{"location":"learn/learn-accounts/#account-address","title":"Account Address","text":"<p>An address is the public part of an account. The private part is the key used to access this address. The public and private parts together make up an account. You can think of the public address of your account, like your mailbox and the private key like the key to open that mailbox. Anybody can send mail to your mailbox, but only you can access it as only you have access to its key. In the context of accounts, anybody can send tokens to your public address, but only you can transact with them using your private key. That is why you should keep your private key secret.</p>"},{"location":"learn/learn-accounts/#mnemonic-seed-phrase","title":"Mnemonic Seed Phrase","text":"<p>A user's account requires a private key that can sign on to one of the supported curves and signature schemes. Without a private key, an account cannot sign anything. In Polkadot, there are some exceptions of accounts that do not have known private keys (i.e. keyless accounts). Such accounts are multi-signature accounts, pure proxies, and system accounts that are not discussed here and are meant for an advanced audience.</p> <p>A typical 12-word mnemonic seed phrase is shown below.</p> <pre><code>'caution juice atom organ advance problem want pledge someone senior holiday very'\n</code></pre> <p>Its corresponding private/public keypair is also shown.</p> <pre><code>Secret seed (Private key): 0x056a6a4e203766ffbea3146967ef25e9daf677b14dc6f6ed8919b1983c9bebbc\nPublic key (SS58): 5F3sa2TJAWMqDhXG6jhV4N8ko9SxwGy8TpaNS1repo5EYjQX\n</code></pre> <p>Polkadot default address format is the <code>MultiAddress</code> type. This means the same mnemonic phrase will generate public keys for different parachains. For more information, see the Address Format section on the Advanced Account page.</p>"},{"location":"learn/learn-accounts/#account-generation","title":"Account Generation","text":"<p>Usually, there are two ways of generating a mnemonic seed:</p> <ul> <li>On a \"hot\" device, i.e. a device that is connected to the internet</li> <li>On a \"cold\" device, i.e. a device that is not (and ideally will never be) connected to the   internet</li> </ul> <p>Hot wallets are susceptible to a wide range of attacks, so it is recommended to use cold wallets when dealing with non-trivial amounts of funds.</p> <p>Generating a mnemonic seed on a browser extension or a mobile application will create a hot key or hot wallet. Create your Polkadot accounts with a secure and user-friendly wallet listed on the Polkadot website. See also the Wallets section for more information about wallets and the wallets and extensions page for wallets and browser extensions funded by the Polkadot/Kusama Treasuries or by the Web3 Foundation Grants Program.</p> <p>Cold keys are generated on special devices such as those provided by Ledger. Additionally, you can generate your account using the Polkadot Vault mobile app (you need a dedicated air-gapped Android or iOS-compatible smartphone that you are comfortable using only for Polkadot Vault), or a dedicated hardware implementation of Polkadot Vault such as the Kampela Signer.</p> <p>Usually, browser extensions and mobile devices have options to securely import accounts from cold wallets. Note that the private keys of those accounts will remain on the cold wallet, meaning that you will always need the device to sign any transaction. Exceptions exist where you can generate hot wallet based proxy accounts and sign on behalf of a cold wallet account without connecting the cold device. This is practical, especially for transactions made frequently.</p>"},{"location":"learn/learn-accounts/#backing-up-accounts","title":"Backing Up Accounts","text":"<p>Depending on what software you use to access your account, there are various ways to back up and restore your account. It is a good idea to back your information up and keep it secure. In general, as long as you know how you created your account and have the mnemonic seed phrase or the JSON backup file (and password) stored securely, you can restore your account.</p>"},{"location":"learn/learn-accounts/#existential-deposit-and-reaping","title":"Existential Deposit and Reaping","text":"<p>Info</p> <p>Visit this support page for more information about existential deposit.</p> <p>When you generate an account (address), you only generate a key that lets you access it. The account does not exist yet on-chain. For that, it needs the existential deposit.</p> <p>Having an account go below the existential deposit causes that account to be reaped. The account will be wiped from the blockchain's state to conserve space, along with any funds in that address. You do not lose access to the reaped address - as long as you have your private key or recovery phrase, you can still use the address - but it needs a top-up of another existential deposit to be able to interact with the chain.</p> <p>Transaction fees cannot cause an account to be reaped. Since fees are deducted from the account before any other transaction logic, accounts with balances equal to the existential deposit cannot construct a valid transaction. Additional funds will need to be added to cover the transaction fees.</p> <p>The existential deposit can be different on parachains</p> <p>Having an Existential Deposit (ED) on the relay chain account does not guarantee the liveness of the same account on its system chains or parachains. Parachains typically define ED for an account in their native tokens but can also configure it with tokens that are deemed sufficient. For example, the Existential Deposit on Polkadot Asset Hub can be in DOT or sufficient assets like USDC or USDT.</p> <p>Here's another way to think about existential deposits. Ever notice those <code>Thumbs.db</code> files on Windows or <code>.DS_Store</code> files on Mac? Those are junk; they serve no specific purpose other than making previews a bit faster. If a folder is empty saved for such a file, you can remove the folder to clear the junk off your hard drive. That does not mean you will lose access to this folder forever - you can always recreate it. You have the key, after all - you're the computer's owner. It just means you want to keep your computer clean until you maybe need this folder again and recreate it. Your address is like this folder - it gets removed from the chain when nothing is in it but gets put back when it has the existential deposit.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about accounts.</p>"},{"location":"learn/learn-agile-coretime/","title":"Scheduling","text":"<p>Scheduling is the process of assigning tasks or jobs to resources (like CPU cores) at specific times or under certain conditions. Effective scheduling ensures that resources are used efficiently and that tasks are completed in a timely manner.</p> <p>Polkadot introduces scheduling with Agile Coretime, enabling efficient utilization of Polkadot network resources and provides economic flexibility for builders, generalizing Polkadot beyond what was initially proposed and envisioned in its whitepaper. The introduction of coretime enables multi-threading.</p> <p>Multi-threading is a programming model where multiple threads (smaller sequences of programmed instructions) are created within a single process to perform multiple tasks at once. Multi-threading is commonly used to improve the performance of applications by executing different parts of a program concurrently. Concurrency does not imply parallel execution; rather, it enables a system to manage multiple processes by quickly switching among them.</p> <p>Polkadot achieves multi-threading by splitting and interlacing Coretime.</p>"},{"location":"learn/learn-agile-coretime/#introduction-to-agile-coretime","title":"Introduction to Agile Coretime","text":"<p>In Polkadot 1.0, the only way for a parachain to be secured by Polkadot was to rent a lease through an auction, which guaranteed parachain block validation for up-to two years. This involved locking significant amount of DOT, leading to a high barrier of entry for small and medium scale blockchain projects. The parachains produced blocks at a regular interval of 12 seconds, irrespective of the network activity. This led to inefficient resource allocation and misplaced economic incentives while producing almost empty blocks under lighter traffic and being unable to accommodate heavier traffic when it exceeded block limits. Agile Coretime resolves all of these drawbacks.</p> <p>The figure below shows the core usage for Polkadot 1.0, where the horizontal axis is time, and each row represents a core. Colors show different parachains, each using one core (i.e., one parachain, one core).</p> <p></p> <p>Agile Coretime allows for the purchase of coretime in \u201cbulk\u201d with an allocation for one month. Heavy duty parachains which need to author a block every 12 seconds (or every 6s through Asynchronous Backing), can seamlessly \u201crenew\u201d the core each month. Coretime renewal orders take precedence over new orders and provide protection against price fluctuations, allowing parachains to plan their project budget and costs more effectively.</p> <p>The purchased coretime can also be split up and sold in parts, down to a single block per month, allowing for secondary markets to thrive and improve the allocation efficiency of coretime. Furthermore, Agile Coretime offers on-demand coretime functionality that enables the authoring of a parachain block on-demand.</p> <p></p>"},{"location":"learn/learn-agile-coretime/#agile-coretime-terminology","title":"Agile Coretime Terminology","text":""},{"location":"learn/learn-agile-coretime/#core","title":"Core","text":"<p>The term \"Core\" captures the virtual abstraction of computational resources provided by the relay chain to secure the blocks of a parachain, which involves a randomized set of the relay chain validators.</p>"},{"location":"learn/learn-agile-coretime/#coretime","title":"Coretime","text":"<p>The time allocated for utilizing a core, measured in relay chain blocks.</p>"},{"location":"learn/learn-agile-coretime/#bulk-coretime","title":"Bulk Coretime","text":"<p>A fixed duration of continuous coretime represented by an NFT that can be split, shared, or resold. Currently, the duration of bulk coretime is set to 28 days.</p>"},{"location":"learn/learn-agile-coretime/#region","title":"Region","text":"<p>The NFT representing a single unit of bulk coretime.</p>"},{"location":"learn/learn-agile-coretime/#on-demand-coretime","title":"On-demand Coretime","text":"<p>Previously known as instantaneous coretime, the on-demand coretime refers to coretime acquired through bidding in near real-time for the validation of a single parachain block on one of the cores reserved specifically for on-demand orders.</p> <p>Parathreads are renamed to on-demand parachains</p> <p>On-demand parachains (previously called parathreads) are parachains that buy on-demand coretime and use it to access the relay chain through the on-demand coretime pool.</p>"},{"location":"learn/learn-agile-coretime/#on-demand-coretime-pool","title":"On-demand Coretime Pool","text":"<p>Set of cores that are available on-demand. Cores reserved through bulk coretime could also be made available in the on-demand coretime pool, in parts or in entirety.</p>"},{"location":"learn/learn-agile-coretime/#coretime-chain","title":"Coretime Chain","text":"<p>A system parachain that is responsible for the sale, manipulation of bulk coretime and eventually the purchase of on-demand coretime credits. It is also responsible for scheduling the respective cores on the relay chain to the parachains.</p>"},{"location":"learn/learn-agile-coretime/#timeslice","title":"Timeslice","text":"<p>A timeslice represents the granularity the Coretime Chain schedules cores on the relay chain. The Coretime Chain announces a schedule for each core, comprising the next 80 relay chain blocks in advance. 5,040 timeslices corresponds to the region length of 28 days (which is the initial configuration set for bulk coretime).</p>"},{"location":"learn/learn-agile-coretime/#task","title":"Task","text":"<p>The term \"Task\" captures the abstraction of utility of the core. Tasks on the cores are not just limited to securing parachains.</p>"},{"location":"learn/learn-agile-coretime/#agile-coretime-implementation","title":"Agile Coretime Implementation","text":"<p>Coretime is managed through the broker pallet which is deployed on the Coretime Chain. In theory, the Polkadot relay chain can support around a hundred cores seamlessly and can support over a few hundred cores through optimizations. Preliminary tests ran successfully with 80 cores with 12-second block times. Coretime revenue sales are burned.</p>"},{"location":"learn/learn-agile-coretime/#coretime-sales","title":"Coretime Sales","text":"<p>Sales on the Coretime Chain are of <code>timeslice</code> length. These sales are divided into two main periods: the Renewal period and the Sale period.</p> <p></p> <ul> <li>Renewal periods are of <code>interlude_length</code> blocks long, and it\u2019s where bulk coretime can be   renewed.</li> <li>Sale periods are as well divided into two periods: a Price Discovery period and a Fixed Price   period. After the Renewal period, a new <code>start_price</code> will be set by the Coretime Chain and a   dutch auction of <code>leadin_length</code> blocks will start, putting downward pressure on price to find   the right equilibrium. This process will set the <code>regular_price</code> which will be the one offered at   the Fixed Price period.</li> </ul> <p>This discussion on initial coretime pricing can be viewed here</p>"},{"location":"learn/learn-agile-coretime/#splitting-and-interlacing","title":"Splitting and Interlacing","text":"<p>Splitting and interlacing are actions that can be performed within a region. Performing either of these actions makes you lose the right to a price-capped renewal.</p> <ul> <li>Splitting: the action of dividing a region into several regions with different start and end   timeslices.</li> <li>Interlacing: the action of dividing a region into the execution of different tasks for each   block of a timeslice. The result regions will have the same start and end timeslice as the parent   region, but different tasks will be executed at different blocks.</li> </ul>"},{"location":"learn/learn-agile-coretime/#elastic-scaling","title":"Elastic Scaling","text":"<p>With elastic scaling (still under development) projects can scale seamlessly and without being limited to previously allocated resources. Elastic scaling is the process of getting multiple cores for one task. This allows parachains to include more blocks per unit time (relay chain-side), and produce more blocks per unit time (async backing on the parachain side). Elastic scaling can be paired with on-demand coretime to increase your bandwidth seamlessly.</p>"},{"location":"learn/learn-agile-coretime/#agile-coretime-faq","title":"Agile Coretime FAQ","text":""},{"location":"learn/learn-agile-coretime/#roadmap","title":"Roadmap","text":""},{"location":"learn/learn-agile-coretime/#where-can-we-track-agile-coretime-progress","title":"Where can we track Agile Coretime Progress","text":"<p>Agile Coretime project logistics can be tracked on the Parachains Team GitHub Dashboard</p>"},{"location":"learn/learn-agile-coretime/#is-all-of-rfc-1-coming-at-once-or-in-parts","title":"Is all of RFC-1 coming at once or in parts?","text":"<p>No, with the initial Kusama launch, the following features mentioned in RFC-1 are rolled out:</p> <ul> <li>The purchase of bulk coretime and placement of on-demand orders</li> <li>Renewing leases</li> <li>Splitting and interlacing regions</li> </ul> <p>These features are still under development and will be rolled out in later releases:</p> <ul> <li>Getting rewards for adding your region to the on-demand pool</li> <li>Credits for on-demand coretime (currently you are able to buy with native tokens of relay chain)</li> </ul>"},{"location":"learn/learn-agile-coretime/#what-is-currently-being-developed-in-the-ecosystem-to-support-agile-coretime","title":"What is currently being developed in the ecosystem to support Agile Coretime?","text":"<p>There are several ecosystem projects in the making, such as the secondary markets for coretime, Lastic, and\u00a0RegionX.</p> <p>Always do your own research. If you feel your project should be listed on the Wiki, please follow the contributor's guide.</p>"},{"location":"learn/learn-agile-coretime/#will-all-the-current-leaseholder-parachains-migrate-and-when","title":"Will all the current leaseholder parachains migrate and when?","text":"<p>They will migrate when the runtime upgrade with Agile Coretime is performed on the relay chain. Any parachains with existing lease periods will be automatically credited bulk coretime for the remainder of their lease period.</p>"},{"location":"learn/learn-agile-coretime/#product","title":"Product","text":""},{"location":"learn/learn-agile-coretime/#where-will-coretime-be-maintained","title":"Where will coretime be maintained?","text":"<p>Coretime will be managed by the broker pallet which is deployed on the Coretime Chain.</p>"},{"location":"learn/learn-agile-coretime/#is-the-broker-chain-the-same-as-the-coretime-chain","title":"Is the Broker Chain the same as the Coretime Chain?","text":"<p>Yes, the broker pallet runs on the Coretime Chain.</p>"},{"location":"learn/learn-agile-coretime/#can-cores-be-shared-at-the-same-time","title":"Can cores be shared at the same time?","text":"<p>Currently not. Cores can be shared, but only in time. For example, you get a core at block X, another one gets it at block Y. This may change in future.</p>"},{"location":"learn/learn-agile-coretime/#what-limits-are-there-to-the-number-of-cores","title":"What limits are there to the number of cores?","text":"<p>Successful tests were made with around 80 cores and 12-second block times for parachains. A single test validator set is able to validate 80 blockchains simultaneously. In theory a single relay chain should be able to support a few hundred cores. Optimizations to get closer to this theoretical limit will be developed and deployed continuously.</p> <p>Once that theoretical limit is reached, ideas for further scaling are already on the table. The goal is not to scale by lowering security guarantees (similarly to optimistic rollups) but to optimize and improve allocation efficiency (by making better use of the existing cores).</p>"},{"location":"learn/learn-agile-coretime/#is-there-a-ui-for-the-coretime-chain","title":"Is there a UI for the Coretime Chain?","text":"<p>Teams in the ecosystem are working on a UI. RegionX has released an app for testing on Paseo:\u00a0https://app.regionx.tech/. Without the UI, this would be automated from the parachains\u2019 runtimes or manually with Coretime Chain extrinsics via Polkadot-JS.</p>"},{"location":"learn/learn-agile-coretime/#coretime-pricing-and-purchasing","title":"Coretime Pricing and Purchasing","text":""},{"location":"learn/learn-agile-coretime/#how-is-the-price-for-bulk-coretime-calculated","title":"How is the price for bulk coretime calculated?","text":"<p>The pricing for bulk coretime depends on factors from several sources:</p> <ol> <li>The first source is the implementation directly in the pallet, which is not exposed as a    configuration</li> <li>The second source is configurable in the runtime of the Coretime Chain</li> <li>Configurable parameters, such as the starting sales price, ideal bulk ration and the number of    cores offered per sale, which are set through governance</li> <li>Market forces, such as the demand and perceived true market price of a core - the impact of which    can be increased or decreased through the configuration set by governance</li> </ol> <p>A more detailed description of the elements that have an influence on the bulk coretime price can be found here.</p> <p>After a thorough analysis it was decided to open a governance proposal for an initial price ~5 KSM. The price will be set with the \u201cstart sales\u201d call, which will go through governance after runtime upgrade. Keep an eye on the post to be informed and decide with us upon the initial price for Agile Coretime on KSM. The price for Polkadot is still under discussion.</p>"},{"location":"learn/learn-agile-coretime/#how-do-sale-periods-work-on-the-coretime-chain","title":"How do sale periods work on the Coretime Chain?","text":"<p>Sales on the Coretime Chain are of region length. These sales are divided into two main periods: the Renewal period and the Sale period.</p> <ul> <li>Renewal periods are of the length of the interlude, which is defined as a number of blocks in the   broker pallet configuration, and it\u2019s where bulk coretime can be renewed.</li> <li>Sale periods are as well divided into two periods: a Price Discovery period and a Fixed Price   period. After the Renewal period, a new start price will be set by the Coretime Chain and a dutch   auction of lead-in length blocks will start, putting downward pressure on price to find the right   equilibrium. This process will set the base price which will be the one offered at the Fixed Price   period.</li> </ul>"},{"location":"learn/learn-agile-coretime/#how-does-the-pricing-mechanism-for-on-demand-coretime-work","title":"How does the pricing mechanism for on-demand coretime work?","text":"<p>There will be a minimum price configured, the rest is based on demand via a price function: the longer the queue, the higher the price.</p>"},{"location":"learn/learn-agile-coretime/#do-i-need-to-pay-a-deposit-to-register-for-coretime","title":"Do I need to pay a deposit to register for coretime?","text":"<p>All newly registered parachains must place a deposit equivalent to the cost of registering the maximum size of runtime (business logic) code. After a successful registration, parachains are allowed to be assigned to regions. The runtime of these parachains can then be upgraded without any additional costs. The maximum size is pre-defined and equal to everyone on the network. This way, every registration will cost the same independent of the size of the registered runtime code (Wasm blob).</p> <p>RFC-44 is proposing a new rent-based registration price model, which will become an alternative (if it gets approved).</p>"},{"location":"learn/learn-agile-coretime/#how-does-the-price-change-over-time","title":"How does the price change over time?","text":"<p>On-demand coretime will always be subject to market conditions. The price of bulk coretime changes based on the outcome of the previous sale. Factors such as the number of cores sold, the target (from the ideal bulk ratio) and the number of cores offered in the sale are used in combination with the price for which the last core was sold. Bulk renewals are capped within a percentage of the previous purchase price. The algorithm that is used is implemented in each runtime and can differ between chains.</p> <p>The bulk price in Kusama might vary between a 50% decrease in case no cores were sold in the previous sales and can increase by 5x depending on the number of cores sold and when they sell. These numbers represent extreme cases though.</p>"},{"location":"learn/learn-agile-coretime/#can-the-renewal-price-be-different-per-taskid-parachain-or-will-each-sale-cycle-have-a-fix-renewal-price","title":"Can the renewal price be different per taskID (Parachain)? Or will each sale cycle have a fix renewal price?","text":"<p>It is in general different per task if they hit their caps.</p> <p>With the current configuration on Kusama, if the price is going up, every renewal pays a maximum of 3% more than they paid for the sale before. That keeps going back to the sale cycle they first bought their coretime (or the sale cycle they renewed their lease). And because people buy in different sale cycles, or even at different times in each sale cycle, their prices can be wildly different from one another. There\u2019s a special case for leaseholders at the end of their lease. They pay the base price in the sale in which they expire.</p> <p>The story is different if the prices are decreasing, since the caps are irrelevant. If it drops far enough it could mean that all parachains renew at the same price.</p>"},{"location":"learn/learn-agile-coretime/#if-purchased-in-bulk-do-you-then-have-one-core-or-one-bucket-of-coretime-that-you-can-use-in-your-own-time-or-is-there-a-specific-slot","title":"If purchased in bulk, do you then have \u201cone core\u201d or \u201cone bucket of coretime\u201d that you can use in your own time? Or is there a specific slot?","text":"<p>You have a specific core for the duration of four weeks, and have the ability to split the region up. Splitting or interlacing the region makes you lose the right to a price-capped renewal.</p>"},{"location":"learn/learn-agile-coretime/#what-happens-to-purchased-coretime-if-i-dont-use-it","title":"What happens to purchased coretime if I don't use it?","text":"<p>Unused coretime can't be carried over. If the coretime within the time allocation (timeslice) is not used, then it is lost. If previously purchased coretime is no longer needed, it be sold on secondary markets.</p>"},{"location":"learn/learn-agile-coretime/#can-i-buy-coretime-in-advance-and-start-using-it-when-im-ready","title":"Can I buy coretime in advance and start using it when I'm ready?","text":"<p>Coretime can be purchased up to 28 days in advance. Later, \u201cfutures\u201d markets to hedge against price fluctuations could be a possible solution to increase predictability further.</p>"},{"location":"learn/learn-agile-coretime/#concepts","title":"Concepts","text":""},{"location":"learn/learn-agile-coretime/#is-it-on-demand-coretime-or-instantaneous-coretime","title":"Is it \u201con-demand coretime\u201d or \u201cInstantaneous coretime\u201d?","text":"<p>It was decided to stick with the term \"on-demand\".</p>"},{"location":"learn/learn-agile-coretime/#whats-the-correct-spelling-and-its-usage","title":"What's the correct spelling and its usage?","text":"<p>Other than Agile Coretime and the Coretime Chain, do not capitalize coretime or blockspace.</p>"},{"location":"learn/learn-agile-coretime/#whats-the-connection-between-blockspace-and-coretime","title":"What\u2019s the connection between blockspace and coretime?","text":"<p>(Secure) blockspace is the resource Polkadot provides, which is measured in and allocated through coretime.</p>"},{"location":"learn/learn-agile-coretime/#value-proposition","title":"Value Proposition","text":""},{"location":"learn/learn-agile-coretime/#what-are-the-benefits-of-agile-coretime-and-how-do-the-on-demand-and-bulk-models-suit-different-customers","title":"What are the benefits of Agile Coretime, and how do the on-demand and bulk models suit different customers?","text":"<ul> <li>On a high level, Agile Coretime brings a new era of scaling to Web3 with optimal resource   allocation across the entire network.</li> <li>The on-demand model democratizes blockchain access by opening the door to everyone building a   custom, sovereign Web3 application; the bulk model brings a new level of cost-predictability for   teams and projects.</li> </ul> <p>Specific benefits for decision makers and developers:</p> <ul> <li>Agile Coretime brings efficient utilization of resources, enabling scale and agility for better   UX, without compromising security or decentralisation.</li> <li>More flexible economic models for every stage of growth enable builders to innovate without   boundaries.</li> <li>Developers benefit from streamlined development through simplified resource management, as well as   from a consistent development environment through flexible and predictable cost modelling over   time.</li> <li>On-demand coretime removes barriers to entry: spin up your proof of concept quickly with full   access to Polkadot\u2019s entire ecosystem.</li> <li>Cost effectiveness: Remove inefficiencies by buying coretime on-demand only, or sell access to   coretime on secondary marketplaces.</li> <li>With elastic scaling (not supported yet) projects can scale seamlessly and without being limited   to previously allocated resources. Elastic scaling is the process of getting multiple cores for   one task. This allows parachains to include more blocks per unit time (relay chain-side), and   produce more blocks per unit time (async backing on the parachain side). With elastic scaling, add   on-demand coretime to increase your bandwidth seamlessly.</li> <li>Bulk coretime enables strategic resource planning: secure bulk coretime at a fixed price to   prevent spiking fees during high demand. This helps you future-proof your projects. Bulk coretime   provides a solid foundation for your long-term business plans, allowing for sustainable growth.</li> </ul>"},{"location":"learn/learn-agile-coretime/#what-makes-the-coretime-model-on-polkadot-competitive","title":"What makes the coretime model on Polkadot competitive?","text":"<p>The on-demand option removes barriers to entry and enables builders to start and innovate quickly. Combined with the bulk model, builders also mitigate risks of spiking fees during times of high demand.</p> <p>However, as compared to running on an L1 or a scaling solution, builders still have the benefits of running on a purpose-made parachain, which is more efficient and thus cheaper than running a smart contract on a generic L1. In addition, you are connected to and secured by the entire Polkadot network.</p> <p>Polkadot thus offers all the benefits of building high-performing, purpose-made, and composable appchains, combined with the most flexible economics.</p>"},{"location":"learn/learn-agile-coretime/#how-close-do-we-get-to-web2-scale-for-web3","title":"How close do we get to Web2 scale for Web3?","text":"<p>Agile Coretime mainly improves allocation efficiency. With elastic scaling, we take a big step towards enabling Web2 scale in Web3 by reducing parachain block production below 6 seconds. Theoretically, parachains will be able to produce blocks very fast and the limitations will lie on the relay chain side\u2019s cores and how many cores a parachain uses.</p>"},{"location":"learn/learn-agile-coretime/#implementation","title":"Implementation","text":"<p>Unable to use multiple cores!</p> <p>The coretime chain does not prohibit ordering multiple cores and assigning them to the same parachain. However, elastic scaling is still in the works so don't do this, you will not be able to use those cores.</p>"},{"location":"learn/learn-agile-coretime/#what-do-i-need-to-do-for-my-parachain-to-continue-working-in-the-switch-to-coretime","title":"What do I need to do for my parachain to continue working in the switch to coretime?","text":"<p>Current parachain slots will be converted to legacy leases automatically in the runtime upgrade through a migration, with no intervention needed. The lease will grant your parachain a core until the end of the region in which its slot would have expired.</p>"},{"location":"learn/learn-agile-coretime/#when-does-the-last-auction-take-place","title":"When does the last auction take place?","text":"<p>Auctions took place until the launch of Agile Coretime with Polkadot runtime upgrade on the 19<sup>th</sup> of September 2024. Ongoing auctions were canceled and existing active leases of previous auctions were migrated to Agile Coretime. In case you had a lease secured, you automatically got corresponding coretime, with renewal right.</p> <p>Note: if your team secured a lease with a new paraID, please read the question about swapping.</p>"},{"location":"learn/learn-agile-coretime/#when-and-how-can-i-renew-my-legacy-lease","title":"When and how can I renew my legacy lease?","text":"<p>The <code>slots.leases</code> are migrated to <code>leases</code> in the broker pallet with an expiry <code>timeslice</code> that corresponds to your original expiry block. When the lease expires, the parachain has a core until the end of the sales period that it expired in. After that, the <code>interlude</code> period starts. In that sale period you can renew your bulk coretime by calling\u00a0<code>renew</code>\u00a0on the lease's core. The price will be charged and will be equal to the market price of a bulk core in that sale.</p> <p>For more details, check out our technical guide.</p>"},{"location":"learn/learn-agile-coretime/#will-all-leases-be-migrated-to-agile-coretime","title":"Will all leases be migrated to Agile Coretime?","text":"<p>If your team has a lease secured by the time Agile Coretime launches, they will also have a lease on Agile Coretime and the right for renewal when the lease expires. If the lease of your project would only start after Agile Coretime launch (not yet active at launch time), the lease will be cancelled and your locked KSM refunded. You will need to purchase and assign coretime.</p> <p>Note: Your lease will also be canceled and refunded, in case it is not continuous, as leases with \u201choles\u201d are not supported by Agile Coretime.</p>"},{"location":"learn/learn-agile-coretime/#will-i-be-able-to-still-swap-my-lease-with-another-project","title":"Will I be able to still swap my lease with another project?","text":"<p>Unfortunately you won\u2019t be able for the current Kusama release, and it\u2019s advisable to avoid doing it on Polkadot too, as swapping is not something that will exist with Agile Coretime. Yet to ensure a smooth migration, we\u2019re implementing a solution for Polkadot. Once we release Agile Coretime on Polkadot, you should be able to call the swap extrinsic to swap your lease with another project and the change will be reflected on Agile Coretime as well.</p>"},{"location":"learn/learn-agile-coretime/#my-lease-is-about-to-end-what-do-i-need-to-do","title":"My lease is about to end, what do I need to do?","text":"<p>If your lease is about to expire, your core is added to the allowed renewals and you are able to renew your core for a fixed percentage increase before the rest of the market is able to bid on it. Please, make sure to renew your lease within the period defined by the broker chain to avoid downtime for your chain and potentially losing your fixed renewal cost.</p>"},{"location":"learn/learn-agile-coretime/#can-any-account-renew-coretime-on-behalf-of-a-parachain-or-does-this-need-to-be-from-the-parachain-sovereign-account","title":"Can any account renew coretime on behalf of a parachain or does this need to be from the parachain sovereign account?","text":"<p>Yes, any account with enough funds can renew it for any given parachain on a core which qualifies for renewal.</p>"},{"location":"learn/learn-agile-coretime/#how-is-the-coretime-price-determined-in-practice","title":"How is the coretime price determined in practice?","text":"<p>The starting price is initially configured by a referendum. In subsequent sales, it depends on the number of cores which were sold vs those which were for sale. If the ideal ratio was sold (the ratio is configured by referendum, too) then the price remains the same. If fewer cores than the ideal were sold, then the price decreases. If more cores are sold than ideal, then the price increases. In this way the price is sensitive to market conditions, the initial configuration, and the number of cores offered in the sales.</p>"},{"location":"learn/learn-agile-coretime/#how-is-coretime-measured-and-allocated-technically","title":"How is coretime measured and allocated technically?","text":"<p>The Coretime Chain is a proposed new system parachain within the Polkadot network that is responsible for the management of coretime. It is designed to handle the allocation of bulk coretime and track ownership of coretime as non-fungible assets (NFTs). The Coretime Chain provides information to the relay chain regarding the number of cores available, the tasks running on each core, and accounting information for on-demand coretime credit. Additionally, it processes renewals and allows for various manipulations of bulk coretime, such as transfers, partitioning, interlacing, assignment to tasks, and pooling for on-demand coretime.</p>"},{"location":"learn/learn-agile-coretime/#why-are-sales-of-on-demand-coretime-happening-on-the-relay-chain","title":"Why are sales of on-demand coretime happening on the relay chain?","text":"<p>In the beginning, sales are executed on the relay chain, but they could move to the Coretime Chain. Latency is the only drawback: at low demand, the buyer would receive the coretime instantly when via the relay chain, but there\u2019ll be a delay when executed on the Coretime Chain. At times of high demand, there will be a queue anyway and this delay matters less.</p>"},{"location":"learn/learn-agile-coretime/#whats-the-best-way-for-on-demand-tasks-previously-known-as-on-demand-parachains-to-regularly-send-extrinsics-to-the-relay-chain-for-allowing-a-block-to-be-validate","title":"What's the best way for on-demand tasks (previously known as on-demand parachains) to regularly send extrinsics to the relay chain for allowing a block to be validate?","text":"<p>A ready-to-use automated and decentralized method for ordering on-demand coretime is currently\u00a0being implemented. Some teams already implemented a simplified\u00a0variant. What works in any case is ordering on-demand coretime \"by hand\", by sending the\u00a0<code>placeOrderKeepAlive</code>\u00a0extrinsic of the\u00a0<code>onDemandAssignmentProvider</code>, via polkadot js for example. You can find an easy step-by-step guide here.</p>"},{"location":"learn/learn-agile-coretime/#how-many-cores-will-be-configured-for-on-demand-coretime","title":"How many cores will be configured for on-demand coretime?","text":"<p>We will certainly start with one core on Kusama and one on Polkadot, and then see if this is sufficient initially.</p>"},{"location":"learn/learn-agile-coretime/#what-happens-if-my-chain-runs-out-of-coretime","title":"What happens if my chain runs out of coretime?","text":"<p>Your chain won\u2019t be able to validate further blocks and will halt.</p>"},{"location":"learn/learn-agile-coretime/#what-does-splitting-and-interlacing-mean","title":"What does splitting and interlacing mean?","text":"<p>Splitting and interlacing are actions anyone can make within its own region. Performing any of these will result in a new region with new characteristics, and will make the owner of the original region unable to renew it.</p> <ul> <li>Splitting: the action of dividing a region into several regions with different start and end   timeslices.</li> <li>Interlacing: the action of dividing a region into the execution of different tasks for each   block of a timeslice. The result regions will have the same start and end timeslice as the parent   region, but different tasks will be executed at different blocks.</li> </ul>"},{"location":"learn/learn-architecture/","title":"Architecture","text":"<p>Polkadot is a heterogeneous multichain with shared security and interoperability.</p>"},{"location":"learn/learn-architecture/#relay-chain","title":"Relay Chain","text":"<p>The relay chain is the central chain of Polkadot. All validators of are staked on the relay chain in DOT and validate for the relay chain. The relay chain is composed of a relatively small number of transaction types that include ways to interact with the governance mechanism, and participating in NPoS. The relay chain has deliberately minimal functionality - for instance, smart contracts are not supported. The main responsibility is to coordinate the system as a whole, including parachains. Other specific work is delegated to the parachains, which have different implementations and features.</p>"},{"location":"learn/learn-architecture/#parachain-slots","title":"Parachain Slots","text":"<p>The relay chain can support a number of execution cores, like cores on a computer's processor (a modern laptop's processor may have eight cores, for example). Each one of these cores can run one process at a time. The relay chain allows these cores using two subscription models: parachains and on-demand parachains. Parachains have a dedicated core for their chain and are like a process that runs constantly. On-demand parachains share (not simultaneously) cores amongst a group, and are thus more like processes that need to be woken up and run less frequently (similarly to concurrency in modern computers).</p> <p>Most of the computation that happens across the network as a whole will be delegated to specific parachain implementations that handle various use cases. The relay chain places no constraints over what parachains can do besides that they must be able to generate a proof that can be validated by the validators assigned to the parachain. This proof verifies the state transition of the parachain. Some parachains may be specific to a particular application, others may focus on specific features like smart contracts, privacy, or scalability \u2014 still, others might be experimental architectures that are not necessarily blockchain in nature.</p> <p>The relay chain provides many ways to secure a core for a parachain for a particular length of time. On-demand parachains share cores (not simultaneously) with other parachains. Both regular and on-demand parachains have the same API and need to buy time on a core with DOT via coretime. Parachains can switch between being on-demand and permanent.</p>"},{"location":"learn/learn-architecture/#shared-security","title":"Shared Security","text":"<p>Parachains connected to the relay chain all share in the security of the relay chain. Polkadot has a shared state between the relay chain and all of the connected parachains. If the relay chain must revert for any reason, then all of the parachains would also revert. This is to ensure that the validity of the entire system can persist and no individual part is corruptible.</p> <p>The shared state ensures that the trust assumptions when using parachains are only those of the relay chain validator set and no other. Since the validator set on the relay chain is expected to be secure with a large amount of stake put up to back it, parachains should benefit from this security.</p>"},{"location":"learn/learn-architecture/#interoperability","title":"Interoperability","text":""},{"location":"learn/learn-architecture/#xcm","title":"XCM","text":"<p>XCM, short for cross-consensus message, is a format and not a protocol. The format does not assume anything about the receiver or senders consensus mechanism, it only cares about the format in which the messages must be structured in. The XCM format is how parachains will be able to communicate with one another. Different from XCMP, which is short for cross-chain messaging protocol, XCM is what gets delivered, and XCMP is the delivery mechanism. The best way to learn more about XCM is by reading the specification.</p>"},{"location":"learn/learn-architecture/#bridges","title":"Bridges","text":"<p>A blockchain bridge is a connection that allows for arbitrary data to transfer from one network to another. These chains are interoperable through the bridge but can exist as standalone chains with different protocols, rules, and governance models. In Polkadot, bridges connect to the relay chain and are secured through the consensus mechanism, maintained by collators.</p> <p>Polkadot uses bridges to bridge the future of Web 3.0, as bridges are fundamental to Polkadot's interoperable architecture by acting as a secure and robust communication channel for chains in isolation.</p>"},{"location":"learn/learn-architecture/#main-actors","title":"Main Actors","text":""},{"location":"learn/learn-architecture/#validators","title":"Validators","text":"<p>Validators, if elected to the validator set, produce blocks on the relay chain. They also accept proofs of valid state transition from collators and receive staking rewards in return.</p> <p>Validators are required to keep enough parachain blocks available for later use in their local storage. Those blocks are retrievable by peers who lack that information, so that they can reliably confirm the issued validity statements about parachain blocks. The Availability &amp; Validity (AnV) protocol consists of multiple steps for successfully upholding those responsibilities.</p>"},{"location":"learn/learn-architecture/#nominators","title":"Nominators","text":"<p>Nominators bond their stake to particular validators in order to help them get into the active validator set and thus produce blocks for the chain. In return, nominators are generally rewarded with a portion of the staking rewards from that validator.</p>"},{"location":"learn/learn-architecture/#collators","title":"Collators","text":"<p>Collators are full nodes on both a parachain and the relay chain. They collect parachain transactions and produce state transition proofs for the validators on the relay chain. They can also send and receive messages from other parachains using XCMP.</p> <p>Parachain blocks themselves are produced by collators, whereas the relay chain validators only verify their validity (and later, their availability).</p>"},{"location":"learn/learn-archive/","title":"Archived Learn Resources","text":"<p>import DocCardList from '@theme/DocCardList';</p> <p></p>"},{"location":"learn/learn-asset-conversion-assethub/","title":"Asset Conversion on AssetHub","text":"<p>Asset conversion is a simple AMM (Automated Market Maker) based on Uniswap V2 logic, deployed as a pallet on Polkadot AssetHub. In the AMM model the prices of tokens are determined by a mathematical formula based on the ratio of tokens in a liquidity pool, unlike traditional exchanges that use an order book. This will be a \u201ctrustless\u201d DEX, controlled through Polkadot OpenGov.</p> <p>Note</p> <p>The asset pairs of the liquidity pools of AssetHub will always contain the relay chain's native token as one of the assets. Provision of liquidity for pools with arbitrary asset pairs is not allowed.</p> <p>Asset Conversion on Asset Hub enables fee payment in any asset, given it has a liquidity pool, such that the fee handler (in this case, a Collator) only receives the native asset.</p> <p>Asset Conversion pallet allows you to:</p> <ul> <li>Create a liquidity pool   with the relay chain's native token and an asset</li> <li>Provide the liquidity   and receive back an LP token</li> <li>Exchange the LP token back to assets</li> <li>Swap assets if there is a pool created</li> <li>Query for an exchange price   via a runtime call endpoint</li> <li>Query the size of a liquidity pool.</li> </ul> <p>Asset Conversion Tutorials</p> <p>The Asset Conversion user guide and tutorials are available here</p>"},{"location":"learn/learn-asset-conversion-assethub/#fee-payment-in-any-asset-wallets","title":"Fee Payment in Any Asset - Wallets","text":"<p>Without Asset Conversion pallet, only DOT and sufficient assets can be used for paying transaction fees. With the Asset Conversion pallet deployed, Wallets can enable users to pay transaction fees through any arbitrary asset made available in pools with either DOT or sufficient assets. More specifically, this functionality is enabled through Asset Conversion Transaction Payment Pallet, allowing runtimes that include it to pay for transactions in assets other than the native token of the chain.</p> <p>Handling Pools with Low Liquidity</p> <p>The wallets and UIs should ensure that the user is prompted with the necessary warnings, such that they do not accidentally spend all of their funds to perform a swap on a pool with no or low liquidity.</p>"},{"location":"learn/learn-asset-conversion-assethub/#fee-payment-in-any-asset-parachains","title":"Fee Payment in Any Asset - Parachains","text":"<p>Parachains can pay for their XCM execution fees in any asset with a liquidity pool on AssetHub.</p>"},{"location":"learn/learn-asset-conversion-assethub/#creation-of-pools-with-foreign-assets-parachains","title":"Creation of Pools with Foreign Assets - Parachains","text":"<p>Assets pallet uses XCM MultiLocations to represent assets, and their corresponding origins to control them.</p> <p>One of the pain points of integrating parachain tokens natively on wallets and exchanges is that they require running individual parachain infrastructure like full nodes to process deposits, and require additional code to handle withdrawals because they need to be able to construct and broadcast transactions on each parachain. These parachains could use different balances pallets or order them differently. When Polkadot hosts hundreds of parachains (and possibly thousands of threads), this becomes a huge burden in terms of network support. This is in contrast to adding support for an additional ERC20 token; the marginal effort is very small since an Ethereum node already serves all the data they need.</p> <p>With support for these assets on Asset Hub, exchanges/custodians could monitor one chain for deposits (applications and UIs would need to give the option to transfer to Asset Hub). For withdrawals, users could choose to withdraw to their address on Asset Hub. There are two user experience bonuses here:</p> <ul> <li>The exchange/custodian only needs to transact on one parachain and can access every other without   any infrastructure lift.</li> <li>For the user, they never actually need to \u201csee\u201d AssetHub. It\u2019s entirely abstracted away behind   either the parachain wallet/application or the exchange/custodian.</li> </ul>"},{"location":"learn/learn-assets/","title":"Asset Hub","text":"<p>Assets in the Polkadot ecosystem can be represented on several chains. They can take many forms, from a parachain's native token to on-chain representations of off-chain reserves. This page focuses on the latter, namely assets issued by a creator (e.g. rights to audited, off-chain reserves held by the creator, or art issued as an NFT).</p> <p>The Asset Hub system parachain hosts data structures and logic that specialize in the creation, management, and use of assets in the network. Although other parachains can host applications dealing with assets on the Asset Hub, the hub can be thought of as a trusted \"home base\" of assets in the network.</p> <p>The Asset Hub uses the relay chain's native token. The chain yields its governance to its parent relay chain and has no inflation or era-based rewards for collators (although collators receive a portion of transaction fees). As a system parachain, the Asset Hub has a trusted relationship with the relay chain, and as such, can teleport the relay chain's native token between itself and the relay chain. That is, the native token on the relay chain is just as good on Asset Hub.</p> <p>The Asset Hub does not support smart contracts. See the Advanced section at the bottom for a discussion on using proxy and multisig accounts to replicate oft-used contract logic.</p>"},{"location":"learn/learn-assets/#sufficient-assets","title":"Sufficient Assets","text":"<p>A sufficient asset on Asset Hub can allow for an account to exist on-chain even though it does not have any account balance in the native asset. Any registered asset on the Asset Hub can be made sufficient through governance on the relay chain. A balance of a non-sufficient asset can only exist on accounts that are on-chain (i.e., accounts having the existential deposit of a sufficient asset). That is, a user could not keep an account on-chain by transferring a non-sufficient asset to it; the account must already be on-chain by having more than the existential deposit in native asset (or a sufficient asset).</p> <p>Assets deemed sufficient can instantiate accounts on the Asset Hub and pay for transaction fees without the need for the native token (DOT or KSM). An example would be USDT on the Polkadot Asset Hub. If an account holds 0.7 USDT, it would exist on the Polkadot Asset Hub system parachain without the need to hold DOT.</p> <p>Transfers of Non-sufficient assets</p> <p>Before transferring a non-sufficient asset, ensure the receiver account has enough funds to cover the existential deposit and transaction fees for future transfers. Please do so to ensure the asset transfer is successful.</p>"},{"location":"learn/learn-assets/#asset-conversion","title":"Asset Conversion","text":"<p>An asset conversion pallet is deployed on AssetHub with Uniswap V2-style functionality. It implements a simple AMM (automated market maker), which employs a mathematical formula to determine the price of a token based on its ratio within the liquidity pool.</p> <p>This pallet enables fees to be paid in any asset that has corresponding liquidity (in DOT/KSM) on AssetHub. Learn more about asset conversion on AssetHub, including guides on how to use it here.</p>"},{"location":"learn/learn-assets/#create-and-manage-assets","title":"Create and Manage Assets","text":"<p>Walk-through video tutorial about creating assets</p> <p>See this technical explainer video to learn how to create fungible assets on the Asset Hub.</p> <p>Anyone on the network can create assets on the Asset Hub as long as they can reserve the required deposits. The network reserves the deposit on creation. The creator also must specify a unique <code>AssetId</code>, an integer of type <code>u32</code>, to identify the asset. The <code>AssetId</code> should be the canonical identifier for an asset, as the chain does not enforce the uniqueness of metadata like \"name\" and \"symbol\". The creator must also specify a minimum balance, preventing accounts from having dust balances.</p> <p>Advanced How-to Guides</p> <p>See this page to learn more about creating assets using the Asset Hub.</p> <p>Asset classes and instances can have associated metadata. The metadata is an array of data that the class owner can add on-chain, for example, a link to an IPFS hash or other off-chain hosting service. The Uniques pallet also supports setting key/value pairs as attributes to a class or instance.</p> <p>An asset class has several privileged roles. The asset creator automatically takes on all privileged roles but can reassign them after creation. These roles are:</p> <ul> <li>The owner can set the accounts responsible for the other three roles and set asset metadata   (e.g. name, symbol, decimals).</li> <li>The issuer can mint and burn tokens to/from their chosen addresses.</li> <li>The admin can make force transfers as well as unfreeze accounts of the asset class.</li> <li>The freezer can freeze assets on target addresses or the entire asset class.</li> </ul> <p>Always refer to the reference documentation for certainty on privileged roles.</p> <p>An asset's details contain one field not accessible to its owner or admin team, asset sufficiency.</p> <p>Transaction Fees on Polkadot-JS UI</p> <p>Polkadot-JS UI doesn't support the functionality to pay with a sufficient asset yet. When using Polkadot-JS UI, transaction fee needs to be paid using the native asset (DOT or KSM).</p>"},{"location":"learn/learn-assets/#fungible-assets","title":"Fungible Assets","text":"<p>Fungible assets are interchangeable, i.e. one unit is equivalent to any other unit to claim the underlying item. The Asset Hub represents fungible assets in the Assets pallet. This pallet presents a similar interface for those familiar with the ERC20 standard. However, the logic is encoded directly in the chain's runtime. As such, operations are not gas-metered but benchmarked upon every release, leading to efficient execution and stable transaction fees.</p>"},{"location":"learn/learn-assets/#transferring-asset-balances","title":"Transferring Asset Balances","text":"<p>Walk-through video tutorial about transferring assets</p> <p>See this technical explainer video to learn how to transfer assets on the Asset Hub.</p> <p>For Ledger users see this video tutorial to learn how to use the Statemine Ledger app and what its current limitations are.</p> <p>Users have a simple interface, namely the ability to transfer asset balances to other accounts on-chain. As mentioned before, if the asset is not sufficient, then the destination account must already exist for the transfer to succeed.</p> <p>The chain also contains a <code>transfer_keep_alive</code> function, similar to that of the Balances pallet, that will fail if execution kills the sending account.</p> <p>The Asset Hub also sweeps dust balances into transfers. For example, if an asset has a minimum balance of 10 and an account has a balance of 25, then an attempt to transfer 20 units would transfer all 25.</p> <p>Info</p> <p>See this support article to learn more about transferring assets using the Asset Hub.</p>"},{"location":"learn/learn-assets/#destroying-an-asset","title":"Destroying an Asset","text":"<p>Walk-through video tutorial about destroying assets</p> <p>See this technical explainer video to learn how to destroy assets on the Asset Hub.</p> <p>To destroy an asset, go to the Polkadot-JS UI on the Asset Hub &gt; Developer &gt; Extrinsics. If you created an asset without minting any unit, you could call <code>assets.startDestroy</code> and then the <code>assets.finishDestroy</code> extrinsics specifying the asset id you want to destroy. If you created an asset and minted some units, follow the steps below:</p> <ul> <li><code>assets.freezeAsset</code> will freeze all assets on all accounts holding that asset id. Those accounts   will no longer be able to transfer that asset.</li> <li><code>assets.startDestroy</code> will start the destroying process.</li> <li><code>assets.destroyApprovals</code> will destroy all approvals related to that asset id (if there are any   approvals).</li> <li><code>assets.destroyAccounts</code> will destroy all accounts related to that asset id. All asset units will   be removed from those accounts.</li> <li><code>assets.finishDestroy</code> will finish the destroying process. The asset id will be removed and   available for another fungible token.</li> </ul>"},{"location":"learn/learn-assets/#application-development","title":"Application Development","text":"<p>The Asset Hub provides an <code>approve_transfer</code>, <code>transfer_approved</code>, and <code>cancel_approval</code> interface. Application developers can use this interface so that users can authorize the application to effectuate transfers up to a given amount on behalf of an account.</p>"},{"location":"learn/learn-assets/#cross-chain-accounting","title":"Cross-Chain Accounting","text":"<p>The Asset Hub uses a reserve-backed system to manage asset transfers to other parachains. It tracks how much of each asset has gone to each parachain and will not accept more from a particular parachain.</p> <p>As a result of this, asset owners can use the Asset Hub to track information like the total issuance of their asset in the entire network, as parachain balances would be included in the reserve-backed table. Likewise, for the minting and burning of tokens, an asset's team can perform all operations on the Asset Hub and propagate any minted tokens to other parachains in the network.</p> <p>Parachains that want to send assets to other parachains should do so via instructions to the Asset Hub so that the reserve-backed table stays up to date. For more info, see the \"Moving Assets between Chains in XCM\" section of the article on the XCM format.</p>"},{"location":"learn/learn-assets/#non-fungible-assets","title":"Non-Fungible Assets","text":"<p>Unlike fungible assets, the particular instance of a non-fungible asset (NFT) has a separate meaning from another instance of the same class. The Asset Hub represents NFTs in the Uniques and NFTs pallets.</p> <p>Similar to the Assets pallet, this functionality is encoded into the chain. Operations are benchmarked before each release instead of any runtime metering, ensuring efficient execution and stable transaction fees.</p>"},{"location":"learn/learn-assets/#transferring-nfts","title":"Transferring NFTs","text":"<p>Users can transfer their NFTs to other accounts. The chain also provides an <code>approve_transfer</code>, <code>transfer_approved</code> and <code>cancel_approval</code> interfaces that application developers can use to allow users to authorize an application to transfer an instance on their behalf.</p>"},{"location":"learn/learn-assets/#advanced-techniques","title":"Advanced Techniques","text":"<p>Many asset creators on other networks use smart contracts to control privileged functions like minting and burning. Although the Asset Hub does not have a smart contract interface, it contains the Multisig, Proxy, and Utility pallets, which will meet most account management needs.</p> <p>For example, if a team wants sign-off from two groups to perform a privileged operation, it could create a 2-of-2 multisig from two pure proxies, and then set members from each group as proxies to those two accounts.</p>"},{"location":"learn/learn-async-backing/","title":"Pipelining","text":"<p>     To fully follow the material on this page, it is recommended to be familiar with the primary stages of the             Parachain Protocol.          For upgrading a parachain for Asynchronous Backing compatibility, follow the instructions on             this Wiki document.      </p> \u2716 <p>Pipelining is a technique for processing multiple stages of a task simultaneously by breaking it into smaller steps. This allows the next step to start before the previous one is completely finished. This is often used in processors and computer architectures to increase throughput.</p> <p>Polkadot introduces pipelining to the parachain block generation, backing, and inclusion via asynchronous backing. It is analogous to the logical pipelining of processor instruction in traditional architectures, where some instructions may be executed before others are complete.</p> <p>Bundles of state transitions represented as blocks may be processed similarly. In the context of Polkadot, pipelining aims to increase the throughput of the entire network by completing the backing and inclusion steps for different blocks simultaneously. Asynchronous backing does not just allow for pipelining within a single pipe (or core). It lays the foundation for a large number of pipes (or cores) to run for the same parachain at the same time.</p> <p>In Polkadot, parablocks are generated by collators on the parachain side and sent to validators on the relay chain side for backing.</p> <p>What is backing?</p> <p>Backing refers to the process in which parablocks are verified by a subset of validators or backing groups. It is an important step in the validation process for parablocks, as it is the first line of defense in ensuring censorship resistance. Parablocks only need to be backed by one validator, and as a consequence, backing does not ensure parablock validity.</p> <p>Backed parablocks are sent to other validators for inclusion into the relay chain. Parablocks are included when validators have attested to having received erasure coded chunks of the parablock data. Note candidate receipts and not the parablocks themselves are included in relay blocks (but for simplicity, we refer to parablocks as being included). When generated, parablocks must be anchored to a relay chain block called relay parent. The relay parent is an input to parablock candidate generation. It provides the necessary context to build the next parablock. Note that the relay parent of a parablock and the relay block including that parablock are always different.</p>"},{"location":"learn/learn-async-backing/#synchronous-backing","title":"Synchronous Backing","text":"<p>Before diving into asynchronous backing, it is important to understand what synchronous backing is and its main limitations. In synchronous backing, parablock generation is tightly coupled to the relay chain's progression:</p> <ol> <li>A new parablock can be produced after including the previous one (i.e., every 12 seconds).</li> <li>Context to build the next parablock is drawn from the latest included parablock ancestor</li> <li>The relay parent must be the latest relay chain block.</li> </ol> <p>Because of (1) parablocks can be generated every other relay chain block (i.e., every 12 seconds). Because of (2) generation of parablock <code>P</code> can only start when <code>P - 1</code> is included (there is no pipelining). Because of (3) execution time can take maximum 0.5 seconds as parablock <code>P</code> is rushing to be backed in the next 5.5 seconds (2 seconds needed for backing and the rest for gossiping). Every parablock is backed in 6 seconds (one relay chain block) and included in the next 6 seconds (next relay chain block). The time from generation to inclusion is 12 seconds. This limits the amount of data a collator can add to each parablock.</p> <p>Parablock generation will choose the most recently received relay block as a relay parent, although with an imperfect network that may differ from the true most recent relay block. So, in general, if relay block <code>R</code> is the relay parent of parablock <code>P</code>, then <code>P</code> could be backed in <code>R + 1</code> and included in <code>R + 2</code>.</p> <p></p> <p>From left to right, parablock P1 is anchored to the relay parent R0 (showed with an <code>x</code>), backed into the relay chain block R1, and included in R2. After including P1, collators can start generating P2 that must be anchored to the relay parent R2. Note that R2 will be the relay parent of P2 if R2 is included on the relay chain and gossiped to the collator producing P2.</p> <p>Every collator also runs an attached relay chain full node</p> <p>The attached relay node receives relay blocks via gossip. Then, the relay node talks to the parachain node through the <code>CollationGeneration</code> subsystem. R2 is gossiped to the relay full node attached to the collator producing P2. Then, <code>CollationGeneration</code> passes information about R2 to the collator node. Finally, relay parent information from R2 informs the generation of candidate P2.</p> <p>Because P2 is rushing to be backed in 6 seconds into R3, validators have only 0.5 seconds for execution. Backing groups will take approximately 2 seconds to back it and some extra time for gossiping it (the whole process from collation to backing lasts 6 seconds). P2 is included in R4, which could be used as a relay parent for P3 (not shown). After 24 seconds P1 and P2 are included in the relay chain. Note how collators can start new parablocks every 12 seconds but only have 0.5 seconds for execution.</p>"},{"location":"learn/learn-async-backing/#asynchronous-backing","title":"Asynchronous Backing","text":"<p>Disclaimer: Performance Measurements</p> <p>Due to asynchronous backing not being fully implemented in a running production network, each performance metric is not thoroughly tested nor guaranteed until proper benchmarking has occurred.</p> <p></p> <p>In asynchronous backing, parablocks (P) are included every 6 seconds, and backing (B) and inclusion (I) can happen within the same relay chain block (R).</p>"},{"location":"learn/learn-async-backing/#synchronous-vs-asynchronous-backing","title":"Synchronous vs. Asynchronous Backing","text":"<p>Below is a table showing the main differences between synchronous and asynchronous backing.</p> Sync Backing Async Backing Async Backing Advantage Parablocks included every 12 seconds 6 seconds 2x more throughput or 2x less latency Parablock's maximum execution time 0.5 seconds 2 seconds 4x more data in a parablock Relay parent Is the latest relay chain block Is not necessarily the latest relay chain block Collators can submit parablocks to backing groups in advance Collators can build on The most recent ancestor included in the latest relay chain block An ancestor included in a relay chain block (not necessarily the latest), with augmented information from the latest ancestor in the unincluded segment Collators can start building parablocks in advance Number of unincluded parablocks Only one One, or more than one (depends on configuration parameters) More efficiency and scalability Unincluded parablocks Cannot be re-proposed Can be re-proposed if not successfully included in the first attempt Decrease wastage of unused blockspace Parablock's Backing-to-inclusion time 12 seconds 12 seconds No change Parablock's Inclusion-to-finality time 30 seconds 30 seconds No change <p>In synchronous backing, collators generate parablocks using context entirely pulled from the relay chain. While in asynchronous backing, collators use additional context from the unincluded segment. Parablocks are included every 6 seconds because backing of parablock <code>N + 1</code> and inclusion of parablock <code>N</code> can happen on the same relay chain bock (pipelining). However, as for synchronous backing, a parablock takes 12 seconds to get backed and included, and from inclusion to finality there is an additional 30-second time window.</p> <p>Because the throughput is increased by 2x and parachains have 4x more execution time, asynchronous backing is expected to deliver 8x more blockspace to parachains.</p>"},{"location":"learn/learn-async-backing/#sync-backing-as-a-special-case-of-async-backing","title":"Sync Backing as a special case of Async Backing","text":"<p>Two parameters of asynchronous backing can be controlled by Governance:</p> <ul> <li> <p><code>max_candidate_depth</code>:   the number of parachain blocks a collator can produce that are not yet included in the relay   chain.</p> </li> <li> <p><code>allowed_ancestry_len</code>:   the oldest relay chain parent a parachain block can be built on top of.</p> </li> </ul> <p>Values of zero for both correspond to synchronous backing: <code>max_candidate_depth = 0</code> means there can be only one unincluded parablock at all times, and <code>allowed_ancestry_len = 0</code> means a parablock can be built only on the latest relay parent for that parachain. Initial values will be set to 3 (4 unincluded parablocks at all times) and 2 (relay parent can be the third last).</p>"},{"location":"learn/learn-async-backing/#async-backing-diagram","title":"Async Backing Diagram","text":"<p>The diagram assumes:</p> <ul> <li><code>max_candidate_depth = 2</code>, meaning that there can be a maximum of three unincluded parablocks at   all times</li> <li><code>allowed_ancestry_len = 1</code>, meaning parablocks can be anchored to the last or second-last relay   parent (i.e., collators can start preparing parablocks 6 seconds in advance)</li> </ul> <p>From left to right, parablock P1 is backed into the relay chain block R1 and included in R2. While P1 undergoes backing, collators can already generate P2, which will have R0 as a relay parent (showed with an <code>x</code>). Note how R0 can also be relay parent for P1 as long as in the unincluded segment there is a maximum of three unincluded parablocks. Parablock P2 can be backed in R2 (the same relay block where P1 is included) and included in R3. Collators can now use up to two seconds for execution. And so on, P3 can be generated while backing groups check P2, and P4 can be built while P3 undergoing backing. In 24 seconds, P1 to P3 are included in the relay chain.</p> <p>Note how there are always three unincluded parablocks at all times, i.e. compared to synchronous backing there can be multiple unincluded parablocks (i.e. pipelining). For example, when P1 is undergoing inclusion, P2 and P3 are undergoing backing. Collators were able to generate multiple unincluded parablocks because on their end they have the unincluded segment, a local storage of not-included parablock ancestors that they can use to fetch information to build new parablocks. On the relay chain side, perspective parachains repeats the work each unincluded segment does in tracking candidates (as validators cannot trust the record kept on parachains).</p> <p>The 6-second relay chain block delay includes a backing execution timeout (2 seconds) and some time for network latency (the time it takes to gossip messages across the entire network). The limit collators have to generate parablocks is how long it takes to back it (i.e., 2 seconds). Collation generation conservatively always gives itself the same time limits. If there is extra time for collation generation and backing (i.e., more than 2s + 6s), then all that extra time is allocated to backing (see figure). This could result in backable blocks waiting their turn at the end of the backing step for a few extra seconds until a core frees up to back that block as of the next relay block or some later relay block. Note a core is occupied after backing and before inclusion.</p> <p>The 2-second execution time is thus a limiter, not a system limitation. If parablock generation takes &gt;2 seconds, the unincluded segment will shrink (less unincluded parablocks), while if it takes &lt; 2 seconds, the segment will grow (more unincluded parablocks that will need to be backed and included). Such flexibility from the parachain side will be possible when, on the relay chain side, there will be elastic scaling (i.e., agile core usage and coretime allocation).</p>"},{"location":"learn/learn-async-backing/#terminology","title":"Terminology","text":""},{"location":"learn/learn-async-backing/#candidate-receipt","title":"Candidate Receipt","text":"<p>Saying that a parablock has been included in a relay chain parent does not mean the entire parablock is in the relay chain block. Instead, candidate receipt consisting of the hash of the parablock, state roots, and ID info is placed on the parent block on the relay chain. The relay chain does not access the entire state of a parachain but only the values that changed during that block and the merkelized hashes of the unchanged values.</p>"},{"location":"learn/learn-async-backing/#unincluded-segments","title":"Unincluded Segments","text":"<p>Unincluded segments are chains of candidate parablocks that have yet to be included in the relay chain, i.e. they can contain parablocks at any stage pre-inclusion. An unincluded segment may thus include candidates that are seconded, backable, or backed. Every parablock candidate recorded in the unincluded segment is immediately advertised to validators to begin the backing process.</p> <p>The backing process occurs on the relay chain, whereas unincluded segments live in the runtimes of parachain collators. The core functionality that asynchronous backing brings is the ability to build on these unincluded segments of block ancestors rather than building only on ancestors included in the relay chain state.</p> <p>The purpose of each unincluded segment is twofold:</p> <ul> <li>Make each parachain aware of when and at what depth it can build blocks that won't be rejected by   the relay chain</li> <li>Provide critical context necessary to build parablocks with parent blocks that have yet to be   included. The unincluded segment is all about building parablocks.</li> </ul>"},{"location":"learn/learn-async-backing/#prospective-parachains","title":"Prospective Parachains","text":"<p>The purpose of prospective parachains is twofold:</p> <ul> <li> <p>Keep track of parablocks that have been submitted to backers but have yet to be included. This   includes tracking the full unincluded ancestry of each parablock, without which it wouldn't be   possible to verify their legitimacy.</p> </li> <li> <p>Look up and provide candidates which are children of the most recently included parablock for each   parachain. These are taken as inputs to the availability process. Prospective parachains is all   about tracking, storing, and providing candidates to the availability/inclusion step.</p> </li> </ul> <p>Prospective parachains essentially repeats the work each unincluded segment does in tracking candidates. Validators cannot simply trust the availability or validity of records kept on parachains. Prospective parachains is the relay chain's record of all parablock candidates undergoing the backing and inclusion process. It is the authoritative gatekeeper for parablock validity. Whereas the unincluded segment is a local record that allows parachains to produce blocks that comply with the rules prospective parachains later enforces.</p> <p>The unincluded segment lives in the parachain runtime, so it doesn't know or care about forks/other parachains. Prospective parachains lives in the relay chain client. So it has to simultaneously keep track of candidates from all forks of all parachains. It is as if you folded the unincluded segments from every fork of every parachain into one giant data structure. When you fold unincluded segments representing different chain forks together, they create a tree structure. Hence the term fragment tree.</p> <p>A single unincluded segment tells a collator whether it can build on top of one fork of one parachain. Prospective parachains tells a validator whether it should accept blocks built on top of any fork from any parachain.</p> <p>A parablock stops being a prospective parablock when it is included on chain. At that point prospective parachains does not have to care about it anymore. Alternatively, a parablock's relay parent can get too old before that parablock is included, in which case prospective parachains can throw away the candidate.</p>"},{"location":"learn/learn-async-backing/#learn-more","title":"Learn More","text":"<p>The information provided here is subject to change; keep up to date using the following resources:</p> <ul> <li>Polkadot Roadmap Roundup - Article by   Rob Habermeier, Polkadot founder, details the plans for Polkadot for 2023.</li> <li>Asynchronous Backing Spec &amp; Tracking Issue -   The implementation tracking issue for asynchronous backing</li> <li>Prospective Parachains Subsystem - The Polkadot Parachain Host Implementers' Guide</li> <li>Chapter 6.11. from Polkadot Blockchain Academy (PBA) lecture material:   Asynchronous Backing (Shallow)</li> <li>Chapter 6.15. from PBA lecture material:   Asynchronous Backing (Deep)</li> <li>Polkadot Blog Post -   Asynchronous Backing: Elevating Polkadot's Performance and Scale</li> <li>Blog posts by Filippo Franchini on   Synchronous   and   Asynchronous Backing</li> </ul>"},{"location":"learn/learn-bridges/","title":"Bridges","text":"<p>Bridges are vital infrastructure, enabling cross-chain communication between technically diverse networks like Polkadot and Ethereum. Bridges allow these chains to acknowledge and trust each other\u2019s finalized states, paving the way for many applications like asset swaps and chain migrations.</p> <p>Current bridge architectures rely on centralized intermediaries, such as multi-signature relayers, to validate information passed between chains. This approach introduces additional trust assumptions and creates a single point of failure, opening up attack vectors like censorship. Recent history has shown how risky this can be \u2014 centralized entities can be compromised or act maliciously. According to Chainalysis report, failures in centralized bridges account for over 60% of all crypto hacks, resulting in losses exceeding $2 billion. Four of the top five incidents on the rekt leaderboard are bridge-related hacks. A system\u2019s security is only as strong as its weakest link, and bridges have proven to be a critical vulnerability.</p> <p>Purpose of bridging</p> <p>Bridges enable Polkadot to communicate with external blockchains such as Bitcoin and Ethereum. Within Polkadot, chains already benefit from secure interoperability. For more information about the native interoperability technology that allows parachains to communicate trustlessly, please see the dedicated cross consensus page on the Wiki.</p> <p>Thus, Bridge designs come in various flavors ranging from centralized and trusted to more decentralized and trustless. Polkadot favors the latter bridge designs for its ecosystem.</p>"},{"location":"learn/learn-bridges/#trustless-bridges","title":"Trustless Bridges","text":"<p>A two-way trustless bridge between chains A and B can be viewed as two one-way bridges (A \u2192 B and B \u2192 A). Hence, the design of a two-way bridge can be explained in terms of a one-way bridge with a source and a target chain. Any trustless bridge will have on-chain and off-chain components.</p> <p>Trustlessness means that users do not need to trust particular individuals or organizations; they only need to trust mathematics, code, cryptography, and protocol. An example of a system which implies a high level of trust would be that of a bridge which is controlled via a multi-signature scheme, wherein you must trust the cosignatories.</p> <p>Basic assumptions are always needed in principle when defining a trustless system as a completely trustless setup cannot always be guaranteed.</p>"},{"location":"learn/learn-bridges/#on-chain-bridge-components","title":"On-chain Bridge Components","text":"<p>Building a trustless bridge can be done through the implementation of the following on-chain components (ordered by suggested methodology):</p> <ul> <li>Bridge pallets - For Substrate-native chains, use a bridge pallet (e.g.   Kusama <code>&lt;-&gt;</code> Polkadot bridge, since both networks' parachains use   Substrate).</li> <li>Smart contracts - If the chain is not on Substrate, you should have smart contracts on the   non-Substrate chain to bridge (e.g. Snowbridge, Ethereum mainnet has a   bridge smart contract that initiates Eth transactions based on incoming XCMP messages).</li> <li>Higher-order protocols - If your chain does not support smart contracts (e.g. Bitcoin), you   should use XClaim or similar protocols to bridge.</li> </ul> <p>On-chain bridge components are modules (usually pallets or smart contracts) deployed on the chain's runtime. Modules that track the finality of the source chain are required to be deployed on the target chain, while the modules that deal with cross-chain messaging need to be deployed on both source and target chains.</p> <p>There are also on-chain components responsible for queuing messages at the source chain and receiving the message proofs at the target chain. The messages are sent through a particular lane, where they are guaranteed to be received in the same order they are sent. On Bridge Hub, the messages are in XCM format, and an XCM executor is used to dispatch them.</p>"},{"location":"learn/learn-bridges/#via-bridge-pallets","title":"via Bridge Pallets","text":"<p>Operating a bridge between chains that finalize through GRANDPA consensus is straightforward. A GRANDPA light client of the source chain built into the target chain's runtime provides a \"source of truth\" about the source chain's finality. For instance, Bridge Hub runs an on-chain light client of Kusama which uses GRANDPA consensus and infers the finality of all the transactions on Kusama and its parachains.</p> <p>Receiving messages on Polkadot from an external, non-parachain blockchain is possible through a Substrate pallet. The Substrate instance can then be deployed to Polkadot either as a system-level parachain (native extension to the core Polkadot software) or as a community-operated parachain.</p> <p>An example of a bridge that would strictly use bridge pallets would be the Kusama <code>&lt;-&gt;</code> Polkadot bridge, since both use parachains based on Substrate.</p> <p>For the standalone chains that will not have a parachain bridging module (non-Substrate), it will be necessary to deploy bridge contracts.</p>"},{"location":"learn/learn-bridges/#via-smart-contracts","title":"via Smart Contracts","text":"<p>Given the generality of blockchain platforms with Turing-complete smart contract languages, it is possible to bridge Polkadot and any other smart-contract-capable blockchain. For instance, Snowbridge uses the Polkadot Bridge Hub to run an on-chain light client of Ethereum to infer the finality of transactions on the Ethereum chain. Running a GRANDPA light client through smart contracts on Ethereum is possible but expensive. Hence, BEEFY consensus layer sitting on top of GRANDPA enables a cost-effective solution for operating a trustless bridge with Ethereum and other protocols. Trustless bridges to chains like Cosmos, Avalanche, NEAR, etc., would require custom pallets to be deployed on Bridge Hub.</p> <p>Note</p> <p>To learn more on how Bitcoin and Ethereum can cooperate and collaborate through Polkadot, check out this explainer video here</p>"},{"location":"learn/learn-bridges/#via-higher-order-protocols","title":"via Higher-Order Protocols","text":"<p>Higher-order protocols (like XCLAIM) can be used to bridge but should only be used when other options are not available. XCLAIM, in particular, requires any swappable asset to be backed by a collateral of higher value than the swappable assets, which adds additional overhead.</p> <p>An example of a network that would be well-suited for higher-order protocols would be Bitcoin, since it does not support smart contracts, and it's not based on Substrate.</p>"},{"location":"learn/learn-bridges/#bitcoin-bridge-xclaim-substrate-polkadot","title":"Bitcoin Bridge (XCLAIM \\&lt;-&gt; Substrate \\&lt;-&gt; Polkadot)","text":"<p>The Interlay team has written a specification on a Bitcoin bridge that is based on the XCLAIM design paper. The protocol enables a two-way bridge between Polkadot and Bitcoin. It allows holders of BTC to issue iBTC in Polkadot and holders of iBTC to redeem BTC on the Bitcoin chain.</p> <p>The Bitcoin bridge, as documented in the specification, is composed of two logically different components:</p> <ul> <li>The XCLAIM component maintains all accounts that own iBTC.</li> <li>The BTC-Relay verifies the Bitcoin state when a new transaction is submitted.</li> </ul> <p>For full details on how it works, please refer to the specification.</p> <p>There is now a working implementation and mainnet bridge available.</p>"},{"location":"learn/learn-bridges/#offchain-bridge-components","title":"Offchain Bridge Components","text":"<p>Offchain bridge components are separate processes called relayers. Relayers are connected both to the source chain and target chain nodes. For instance, the task of relayer between chains that run on GRANDPA consensus is to submit source chain GRANDPA justifications and their corresponding headers to the Bridge GRANDPA Finality Pallet deployed at the target chain. For that, the relayer subscribes to the source chain GRANDPA justifications stream and submits every new justification to the target chain GRANDPA light client.</p> <p>Messages between chains are relayed through the relayers, which involve messages delivery relay and delivery confirmation relay. For more information on relayers and the Bridge Hub design, read through the High-level bridge documentation on the Polkadot-SDK repository.</p>"},{"location":"learn/learn-bridges/#bridge-comparison","title":"Bridge Comparison","text":"<p>Snowbridge and Hyperbridge are two trustless bridges that connect Polkadot with other ecosystems. Here below is a main technical comparison between the two.</p> <p>Tokens sent through different bridges are different</p> <p>Unless specific logic is implemented, WETH sent through Snowbridge cannot be sent back using Hyperbridge, and vice versa. Sending tokens using different bridges might lead to loss of funds.</p> Snowbridge Hyperbridge Ethereum only<sup>1</sup>. Multichain. Ethereum light client on Bridge Hub System Chain<sup>2</sup> and Polkadot light client on Ethereum smart contract. Own parachain. DOT token. Hyperbridge native token. Random-sampling BEEFY for prover. Zero-knowledge Proofs. Simple codebase but complex analysis by the verifier. Complex codebase, but simple analysis by the verifier. Low-spec hardware for prover, permissionless. High-spec hardware for prover, permissionless but somewhat permissioned due to the ZK-based nature. Possible high-level decentralization for the prover. Prover decentralization possible but probably by removing dependency on ZK circuits through BLS (Boneh\u2013Lynn\u2013Shacham) version of BEEFY and BLS precompiles on Ethereum. Ethereum &gt; Polkadot: In the range of 10-20 minutes. Polkadot &gt; Ethereum: High latency (half an hour) as two epochs are needed on Ethereum to achieve unpredictable randomness to update the Polkadot's state. Ethereum &gt; Polkadot: In the range of 10-20 minutes (to Polkadot, both bridges have the same latency). Polkadot &gt; Ethereum: Low latency, 5-7 minutes on reference hardware. Dependency on external library for BLS signature verification (Milagro BLS, used by Lighthouse, the Rust Ethereum consensus client). Dependency on external libraries due to ZK-based nature. Such libraries include PLONK. XCM as a cross-chain message format. ISMP as a bridge integration protocol. Live. Live. <p><sup>1</sup> WETH sent through different bridges are different. Unless specific logic is implemented, WETH sent through Snowbridge cannot be sent back using Hyperbridge.</p> <p><sup>2</sup> Because Snowbridge is deployed on a system chain, Snowbridge WETH can be considered as the \"official\" WETH on Polkadot (although this must not be interpreted as a positive sign for Snowbridge and negative sign for Hyperbridge).</p>"},{"location":"learn/learn-bridges/#resources","title":"Resources","text":"<ul> <li>Snowbridge - a trustless, decentralized bridge between Polkadot and Ethereum</li> <li>Parity Bridges Common Resources</li> <li>Substrate/Ethereum Bridge - ChainSafe and Centrifuge   were awarded a grant in W3F Grants   Wave 5   to build a Substrate to Ethereum two-way bridge.</li> <li>iBTC (Bitcoin \\&lt;-&gt; Polkadot Bridge)</li> <li>EOS Bridge - The Bifrost team was awarded a grant in   W3F Grants   Wave 5   to build a bridge to EOS.</li> <li>Tendermint Bridge - ChorusOne was awarded   a grant in   Wave 5   to build a GRANDPA light client in Tendermint.</li> <li>Interlay BTC Bridge - The Interlay team was awarded a   grant in W3F grants   Wave 5   to build a trust-minimized BTC bridge.</li> <li>ChainX BTC Bridge -   ChainX has implemented a BTC to Substrate bridge for their parachain.</li> <li>POA Network</li> <li>Case study of POA   Network's implementation of Parity's bridge chain solution.</li> <li>Edgeth Bridge - a bridge from Ethereum to   Edgeware chain (a Substrate-based chain) is now defunct and not maintained, but it is a good   example.</li> <li>XCLAIM - XCLAIM is a framework for achieving trustless and   efficient cross-chain exchanges using cryptocurrency-backed assets.</li> <li>Celer cBridge - a bridge to transfer assets   from Ethereum &amp; Binance Smart Chain to the Astar Polkadot EVM.</li> </ul>"},{"location":"learn/learn-collator/","title":"Collator","text":"<p>Info</p> <p>This page provides a general overview of the role of collators' in the Polkadot ecosystem. For more detailed information you can read the Parachain Protocol Overview.</p>"},{"location":"learn/learn-collator/#collators-role","title":"Collators' Role","text":"<p>Collators maintain parachains by collecting parachain transactions from users and producing state transition proofs for relay chain validators. In other words, collators maintain parachains by aggregating parachain transactions into parachain block candidates and producing state transition proofs (Proof-of-Validity, PoV) for validators.</p> <p>Collators maintain a full node for the relay chain and a full node for their particular parachain; meaning they retain all necessary information to be able to author new blocks and execute transactions in much the same way as miners do on PoW blockchains. Under normal circumstances, they will collate and execute transactions to create an unsealed block and provide it, together with a PoV, to one or more validators responsible for proposing a parachain block.</p> <p>Collators are similar to validators on any other blockchain but they do not need to provide security guarantees because the relay chain provides those. If a parachain block is invalid, it will get rejected by validators. The validators are required to check the validity of submitted candidates, followed by issuing and collecting statements about the validity of candidates to other validators. This process is known as candidate backing. Validators receive an arbitrary number of parachain candidates with associated PoV from untrusted collators. A candidate is considered backable when at least \u2154 of all assigned validators have issued a valid statement about that candidate.</p> <p>The validator must successfully verify the following conditions in the following order:</p> <ol> <li> <p>The candidate does not exceed any parameters in the persisted validation data.</p> </li> <li> <p>The signature of the collator is valid.</p> </li> <li> <p>Validate the candidate by executing the parachain Runtime.</p> </li> </ol> <p>Once a candidate meets a specified criteria for inclusion, the selected relay chain block author then chooses any of the backable candidates for each parachain and includes those into the relay chain block. We say the candidate blocks are backed.</p> <p>The assumption that having more collators is better or more secure is not correct. On the contrary, too many collators may slow down the network. The only nefarious power collators have is transaction censorship. To prevent censorship, a parachain only needs to ensure that there are some neutral collators - but not necessarily a majority. Theoretically, the censorship problem is solved by having just one honest collator.</p>"},{"location":"learn/learn-collator/#xcm","title":"XCM","text":"<p>Collators are a key element of the XCM (Cross-Consensus Message Passing Format). By being full nodes of the relay chain, they are all aware of each other as peers. This makes it possible for them to send messages from parachain A to parachain B.</p>"},{"location":"learn/learn-collator/#taking-the-case-for-one-parachain","title":"Taking the Case for One Parachain","text":"<p>A start of a new block candidate is initiated with a block creation time. The collator aggregates all new transactions at the end of the process. When doing so, the collator signs the parachain block candidate and produces state transition proofs (Proof-of-Validity, PoV), which are a summary of the final account balances caused by the transactions in the candidate block. The collator sends the candidate block and PoV to the parachain validators, so-called para-validators. The para-validators verify the transactions within the parachain block candidate. Upon verification, and if all is well, the candidate becomes backable and a para-validator shares the candidate block with the relay chain.</p> <p></p> <p>The validators on the relay chain will try to reach a consensus on the block candidate. Upon reaching consensus, the now validated block candidate is shared with the validators and collators, and the process repeats for new transactions. A collator cannot continue building blocks on a parachain until the block candidate they proposed to the relay chain validators have been validated. A block is produced every 6 seconds.</p>"},{"location":"learn/learn-collator/#collators-in-the-wild","title":"Collators in the Wild","text":"<p>Blockchains that are built using Substrate are unable to hook onto the relay chain on their own. The Parity team built the Cumulus library to address this. Collators are being used on the Paseo testnet, and you can learn more about how they are used with Cumulus via the Cumulus Rust documentation. More information can be found under the Cumulus section on the build parachain page.</p>"},{"location":"learn/learn-collator/#guides-and-tools","title":"Guides and Tools","text":"<ul> <li>Tutorial covering Cumulus and Collators</li> <li>Paseo testnet guide</li> <li>polkadot-launch - a tool to quickly spin up a   local Polkadot testnet based on some parameters like number of parachains, collator setup, etc.</li> </ul>"},{"location":"learn/learn-comparison-ethereum/","title":"Polkadot vs. Ethereum","text":"<p>Both protocols are blockchains at their core but serve fundamentally different roles in how they are utilized:</p> <ul> <li>Ethereum is a general-purpose blockchain that hosts the Ethereum Virtual Machine, an environment   for executing smart contracts. Ethereum is homogenous but can utilize rollups and layer two   solutions to scale its usage.</li> <li>Polkadot is a heterogeneous, multi-chain protocol (a \"layer 0\" or metaprotocol) that hosts   multiple layer one blockchains and allows them to partake in shared security. Polkadot acts as a   meta-protocol allowing multiple protocols to coexist and work together.</li> </ul> <p>Sharding</p> <p>In the context of blockchains, the term \"shards\" or \"sharded protocol\" is typically used to refer to sub-protocols or as a general term to refer to a form of horizontal scaling.</p>"},{"location":"learn/learn-comparison-ethereum/#high-level-comparison","title":"High-Level Comparison","text":"<p>Both protocols have fundamentally different goals:</p> <ul> <li> <p>Ethereum is a general-purpose blockchain based on the Ethereum Virtual Machine (EVM). Ethereum is   not specialized nor optimized for any particular application. Instead, its primary focus is the   Ethereum Virtual Machine for executing smart contracts. Ethereum achieves scalability via   rollups are secondary protocols that utilize Ethereum   as a settlement layer.</p> </li> <li> <p>Polkadot is a multi-chain protocol that provides shared security and secure interoperability for   each of its parachains. Each parachain (also called an \"appchain\" in this context) is   specialized towards a specific focus and optimized towards that goal. Parachains must abide by the   Parachains Protocol.</p> </li> </ul> <p>Polkadot does not directly run a virtual machine for smart contracts, as Polkadot's primary purpose is to validate the protocols that operate under it.</p> <p>However, several parachains provide smart contract functionality. Parachains on Polkadot can even run an EVM for executing smart contracts written in Solidity using Frontier, an Ethereum compatibility layer for Substrate.</p> <p>As a general summary, one could also say that Polkadot coordinates and validates sub-protocols that follow the Parachains Protocol (which are akin to an optimistic-style rollup). In contrast, Ethereum coordinates inputs and outputs for the EVM. On Polkadot, any sub-protocol can have its own logic so long as it compiles to WebAssembly.</p>"},{"location":"learn/learn-comparison-ethereum/#scalability-approaches","title":"Scalability Approaches","text":"<p>Ethereum favors a rollup-centric approach for scaling transaction throughput. Danksharding is how Ethereum plans to better accommodate and facilitate rollup activity by providing better utilities, such as data availability via Proto-Danksharding, for rollups to record state to Ethereum.</p> <p>Danksharding will allow for much more space to be utilized per block on Ethereum, where blobs of data will be verifiable for an amount of time before being pruned from the network. This approach will enable data availability at layer one and further enable layer two protocols on Ethereum to flourish more readily.</p> <p>In contrast, the relay chain requires parachains to register themselves in accordance with the Parachains Protocol. Once registered, the relay chain validates the state transitions of each parachain as per their parachain validation function (PVF). Data availability is an integral part of validating the parachain state. This approach enables parallelized interactions between parachains. They can trust that each sub-protocol's respective state is valid, as Polkadot collectively validated them.</p>"},{"location":"learn/learn-comparison-ethereum/#rollups-vs-parachain-creation","title":"Rollups vs. Parachain Creation","text":"<p>Ethereum primarily focuses on optimizing itself for rollups; Polkadot's parachains protocol allows validation to occur on the protocol level without needing a layer two solution.</p> <p>Rollup vs. Parachain Comparison</p> <p>For a more in-depth comparison of parachains versus rollups, take a look at the rollup comparison page.</p> <p>Each parachain hosts its own core logic, called a runtime (sometimes called a state transition function). Polkadot uses WebAssembly (Wasm) as a \"meta-protocol\".</p> <p>Parachains have the option of using cross-consensus messaging (XCM) to communicate with one another and facilitate inter-chain reactions. It is also possible to utilize XCM on Ethereum as it is merely a format for describing state transitions on a particular network.</p>"},{"location":"learn/learn-comparison-ethereum/#architectural-differences-polkadot-and-ethereum","title":"Architectural Differences: Polkadot and Ethereum","text":"<p>As previously mentioned, Ethereum is a general-purpose virtual machine that can run sandboxed programs are written in Solidity, whereas Polkadot is a meta-protocol for other parachains to connect and interact with each other.</p> <p>Ethereum operates as a single, homogeneous chain. Each Ethereum node is divided into two layers: the consensus and execution layers. Each layer handles the block validation information, peer discovery, and Proof-of-Stake of the Ethereum client.</p> <p>Polkadot's primary component is the relay chain, which hosts heterogeneous parachains. The relay chain aggregates information from each parachain, where validators agree upon consensus and finality. One can see Polkadot as a series of runtimes, which are state transition functions used to describe parachains and Polkadot itself.</p>"},{"location":"learn/learn-comparison-ethereum/#forks-upgrades-and-governance","title":"Forks, Upgrades, and Governance","text":"<p>Ethereum's governance is done off-chain, where various stakeholders come to a consensus through some medium other than the protocol itself. Upgrades on Ethereum will follow the standard hard fork procedure, coordinating the community and validators to upgrade their nodes to implement protocol changes.</p> <p>Polkadot uses on-chain governance, called OpenGov, to facilitate runtime upgrades. The stakeholders of Polkadot vote on these upgrades, and if successful, the upgrade is enacted automatically in the blocks to come. Polkadot validator operators only upgrade their nodes when the client itself gets updated.</p> <p>Because of this mechanism, the relay chain can enact upgrades using the Wasm meta-protocol without a hard fork. As the WebAssembly runtime for Polkadot (and all of its subsequent parachains) are stored on-chain, this involves simply replacing the runtime with a new WebAssembly blob once governance allowed the upgrade to be enacted.</p> <p>Anything within the state transition function, the transaction queue, or off-chain workers can be upgraded without forking the chain, as these are all part of the WebAssembly runtime.</p>"},{"location":"learn/learn-comparison-ethereum/#block-production-finalization","title":"Block Production &amp; Finalization","text":"<p>Both Ethereum and Polkadot use hybrid consensus models where block production and finality are decoupled.</p> <p>For finalization, Ethereum utilizes Casper FFG, which works with LMD-GHOST as the fork choice rule for finalization.</p> <p>Polkadot utilizes GRANDPA for finalization. Rather than decide on a block-by-block basis, GRANDPA can finalize chains of blocks. Both finalization mechanisms are both GHOST-based and can both finalize batches of blocks in one round.</p> <p>For block production, both protocols use slot-based protocols that randomly assign validators to a slot and provide a fork choice rule for unfinalized blocks. Polkadot uses BABE for block production. BABE includes two mechanisms for selecting block producers, one of which is a fallback in case the first fails, which allows for chain liveness. BABE produces unfinalized blocks on top of the chain already finalized by GRANDPA.</p> <p>There are two main differences between Ethereum and Polkadot consensus:</p> <ol> <li> <p>Polkadot finality protocol, GRANDPA, finalizes batches of blocks based on     availability and validity checks     that happen as the proposed chain grows. The time to finality varies with the number of checks     that need to be performed (and invalidity reports, which cause extra checks). The expected time     to finality is 30 seconds.</p> </li> <li> <p>Ethereum typically has many validators per round (called an     epoch on Ethereum) to provide strong validity     guarantees while Polkadot can provide stronger guarantees with fewer validators per round.     Polkadot achieves this by making validators distribute an     erasure coding to all validators in the system,     such that anyone - not only the round's validators - can reconstruct a parachain's block and     test its validity. This data availability is a core part of Polkadot - ensuring state is valid     for its state transitions. The random parachain-validator assignments and secondary checks are     performed by randomly selected validators, making it less likely for the small set of validators     on each parachain to collude.</p> </li> </ol>"},{"location":"learn/learn-comparison-ethereum/#staking-mechanics-ethereum-pos-vs-polkadot-npos","title":"Staking Mechanics: Ethereum PoS vs. Polkadot NPoS","text":"<p>Polkadot uses Nominated Proof of Stake (NPoS) to select validators from a smaller set, letting smaller holders nominate validators to run the network while claiming the system's rewards without running a node. Polkadot needs about five validators for each parachain in the network. For more information, see the staking page.</p> <p>Ethereum is a Proof of Stake (PoS) network that requires 32 ETH to stake for each validator instance. Validators run a primary Beacon Chain node and multiple validator clients - one for each 32 ETH. These validators get assigned to \"committees,\" randomly selected groups to validate blocks in the network.</p>"},{"location":"learn/learn-comparison-ethereum/#interoperability-and-message-passing","title":"Interoperability and Message Passing","text":"<p>Polkadot uses Cross-Consensus Messaging (XCM) for parachains to send arbitrary messages to each other. Parachains open connections with each other and can send messages via their established channels. Given that collators communicate directly to the relay chain, they will be connected and can relay messages from parachain A to parachain B if needed through these message passing channels (see: HRMP, VMP, and other message passing mechanisms for XCM).</p> <p>Messages do not pass through the relay chain. Only validity proofs and channel operations do (open, close, etc.). This enhances scalability by keeping data on the edges of the system.</p> <p>Currently, Ethereum rollups can communicate using shared sequencers, which provides a common ground of interoperability between layer two solutions.</p> <p>Polkadot plans to have the concept of Accords are opt-in treaties for different protocols to partake in. Accords ensure that logic about interoperability is kept consistent and cannot be changed and undermined by participating protocols. This helps ensure that any XCM message can be properly interpreted and executed as needed on the target protocol in a fully trustless environment.</p> <p>SPREE (Shared Protected Runtime Execution Enclaves) is the mechanism that provides shared logic for cross-consensus messages, and will be used to construct Accords.</p>"},{"location":"learn/learn-comparison-ethereum/#dapp-support-and-development","title":"DApp Support and Development","text":"<p>Ethereum supports smart contract development using Solidity. These contracts are immutable, and cannot be changed once published on-chain.</p> <p>Polkadot supports smart contracts through parachains, usually using the ink! smart contract language, but also Solidity through Frontier-enabled parachains. On Ethereum, smart contracts can call each other; however, they are fixed on-chain to the domain of Ethereum. On Polkadot, smart contracts can call each other in the same parachain and across parachains.</p> <p>On Polkadot, developers have the option of either using smart contracts, calling extrinsics from pallets that modify the chain's state in some particular way or merely use Polkadot's RPC to directly retrieve and act on-chain information. DApps on Polkadot are often composed of these multiple components working together to modify, retrieve, and watch state changes live as they happen.</p> <p>For a more comprehensive list of how to build on Polkadot, be sure to check the Build Section.</p>"},{"location":"learn/learn-comparison-ethereum/#conclusion","title":"Conclusion","text":"<p>Ethereum and Polkadot both use a sharded model. Danksharding plans to utilize a rollup-centric approach by focusing on data availability. The Polkadot ecosystem is secured by a main chain, called the \"relay chain,\" which in turn manages cores and allows tasks, such as parachains, to be run on top of those cores and messages to be sent between them.</p> <p>The primary differences between the two protocols are:</p> <ul> <li>Ethereum processes EVM-compatible state transitions, whether through rollups or on the mainnet   itself, while Polkadot allows its parachains to have an abstract state transition function   implementation.</li> <li>Governance processes in Ethereum are planned to be off-chain and thus require coordination for a   hard fork to enact governance decisions. In contrast, in Polkadot the decisions are on-chain and   enacted autonomously via forkless upgrades.</li> <li>Validator selection mechanisms differ as Polkadot can provide strong availability and validity   guarantees with fewer validators per protocol.</li> </ul>"},{"location":"learn/learn-comparisons-avalanche/","title":"Polkadot vs. Avalanche","text":"<p>Info</p> <p>To keep the content on this page factually correct and up-to-date, contributions are welcome.</p> <p>Polkadot and Avalanche both have an architecture that allows for application-specific blockchains to be designed and connected to a primary network. In Polkadot, the primary network is the relay chain and Avalanche does this with 3 main chains - the P-chain, X-chain, and C-chain. Similar to how Polkadot has its Parachains that connect to the relay chain, Avalanche has what\u2019s called subnets. Similar to Polkadot, Avalanche also uses a PoS mechanism for achieving consensus. The validators stake their AVAX tokens in order to participate in the PoS system and secure the network.</p>"},{"location":"learn/learn-comparisons-avalanche/#architecture","title":"Architecture","text":"<p>Avalanche's architecture separates the responsibility of a layer-1 smart contract platform into three chains. This allows for a separation of concern over validators and consensus, transactions, and smart contract execution. Avalanche uses a DAG (Directed Acyclic Graph) structure for one of its chains which is non-linear. Polkadot uses the linear chain structure similar to Bitcoin and Ethereum. Smart contracts in Polkadot are implemented on parachains. Polkadot being a layer-0 blockchain, is not a smart contract platform and does not have plans to support them natively.</p> <p></p> <p>Image source: Avalanche docs.</p>"},{"location":"learn/learn-comparisons-avalanche/#p-chain-platform","title":"P-chain (Platform)","text":"<p>The P-chain is responsible for maintaining the validator set and securing the network. AVAX token holders can spin up their own nodes and become validators by staking their tokens. Similar to the NPoS system that Polkadot uses, Avalanche uses a Delegated PoS which allows token holders to also delegate their token stake to existing validators instead of running their own nodes.</p>"},{"location":"learn/learn-comparisons-avalanche/#x-chain-exchange","title":"X-chain (Exchange)","text":"<p>The X-chain is responsible for the transaction layer of the Avalanche blockchain. It uses a UTXO model like Bitcoin whereas Polkadot uses an account model like Ethereum. This is the only chain that implements the DAG (Directed Acyclic Graph) model for its blockchain, making this the fastest chain on the Avalanche network. This chain does not support smart contract execution.</p>"},{"location":"learn/learn-comparisons-avalanche/#c-chain-contracts","title":"C-chain (Contracts)","text":"<p>The C-chain is where the most activity will happen on the Avalanche network. It allows for different virtual machines to execute smart contract code. Out of the box, it has support for EVM and AVM (Avalanche VM). C-Chain runs a fork of go-ethereum called coreth that has the networking and consensus portions replaced with Avalanche equivalents.</p> <p>As Polkadot does not have a smart contract layer out of the box, the EVM and WASM smart contract abilities lie in the Parachain layers. This is a major difference between Polkadot and Avalanche. The smart-contract abilities of Avalanche are baked into its three-chain model.</p>"},{"location":"learn/learn-comparisons-avalanche/#subnets-or-sub-networks","title":"Subnets or sub-networks","text":"<p>Avalanche defines a subnet as a dynamic set of validators that achieve consensus on a set of blockchains. In Polkadot's terminology, Subnets can be viewed as public or private blockchain runtimes that can be built on top of the primary network and allow a subset of the validators to validate these runtimes. Similar to the Parachains on Polkadot, Subnets provide the freedom to choose the transaction fee model, tokenomics, and custom compile rules. One or many validators can start validating a subnet runtime, effectively becoming a subset of the overall validator set of the Primary Network.</p>"},{"location":"learn/learn-comparisons-avalanche/#consensus","title":"Consensus","text":"<p>Image source: gyuho.dev.</p> <p>Avalanche consensus uses a family of protocols to achieve security, liveness, and finality. These are known as the Snow* protocols. This group of protocols composed together uses both classical and Nakamoto consensus as well as a Delegated Proof-of-Stake system for its block creators.</p> <p>The Snow family is a hierarchical collection of systems used to reach finality on Avalanche:</p> <ul> <li>Slush</li> <li>Snowflake</li> <li>Snowball</li> <li>Avalanche</li> <li>Snowman</li> <li>Slushie</li> </ul> <p>Compared to Polkadot, Avalanche uses an asynchronous hybrid system that is based on a classical and Nakomoto approach. Polkadot uses a synchronous hybrid model that combines BABE and GRANDPA, where BABE is the algorithm used to build blocks in a probabilistic way, and GRANDPA is a finality mechanism that uses a deterministic approach to adding blocks to the longest chain. In the end, validators agree to whole chains, rather than single new blocks.</p>"},{"location":"learn/learn-comparisons-avalanche/#snowball","title":"Snowball","text":"<p>The snowball protocol is an algorithm that nodes use to come to a consensus. Each node continuously queries x number of validators and takes the majority consensus and adopts it as its own. This method, in normal circumstances, will lead to the network reaching a consensus. The scalability of Snowball is promising, as the number of participants in the network grows, the number of consensus messages being passed around remains the same. Nodes will query no more than 20 nodes at a given time.</p>"},{"location":"learn/learn-comparisons-avalanche/#dagdirected-acyclic-graph","title":"DAG(Directed Acyclic Graph)","text":"<p>DAGs are graphs consisting of vertices and edges. In Avalanche they are used for partial ordering of decisions, such as transactions. Vertices point to each other using edges, and when ordered topologically vertices and edges create a sequence. Edges in the case of Avalanche can be conflicting, and nodes will use the snowball algorithm to make decisions about which edges to keep and which to not.</p>"},{"location":"learn/learn-comparisons-avalanche/#staking-mechanics","title":"Staking Mechanics","text":"<p>Avalanche uses a Delegated Proof-of-Stake mechanism without any slashing. The barrier to entry for staking as a full node validator is 2500 AVAX, and 25 AVAX to become a delegator. With a minimum stake period being two weeks and a maximum period being a year, for both validators and delegators. It is not clear from the Avalanche documentation what happens after a year, it is likely that validators will have to re-stake and start a new period. Validators acquire points for uptime and correctness of their work, and the remuneration of rewards depends on that.</p> <p>In Polkadot the minimum stake needed to be a validator is variable, same for being a nominator. The true minimum need to be competitive enough to be included in the active set for validators, or successfully being chosen as a nominator depends on the minimum staked amounts on the network at a given time. Read more about this in the staking page.</p>"},{"location":"learn/learn-comparisons-avalanche/#message-passing","title":"Message Passing","text":"<p>Avalanche does not have a native trustless message-passing mechanism. Instead, it relies on bridges. Though, because it is an EVM-compatible protocol, it's able to interoperate at a token level. However, subnets do not have a messaging layer out of the box. Polkadot, with its XCM and XCMP messaging protocols, allows for a native and trustless messaging scheme, thus supporting the composability of chains and enabling the development of powerful cross-chain applications.</p>"},{"location":"learn/learn-comparisons-avalanche/#governance","title":"Governance","text":"<p>According to its whitepaper, Avalanche plans to have an on-chain governance mechanism. It currently does not have an on-chain or off-chain system in production. Its governance system will limited to updating only a few key protocol parameters which include:</p> <ul> <li>Staking amount: This value defines the minimal stake required to be placed as bond before   participating in the system.</li> <li>Minimum staking time for a node: The minimal amount of time required for a node to stake into   the system.</li> <li>Maximum staking time for a node: The maximal amount of time a node can stake.</li> <li>Minting rate: Reward rate function, also referred to as minting rate, determines the reward a   participant can claim as a function of their staking amount given some number of x publicly   disclosed nodes under its ownership, over a period of t consecutive minimal staking time   timeframes, such that t*minimal staking time* \u2264 maximum staking time.</li> <li>Transaction fee amount: The fee structure, which is a set of governable fees parameters that   specify costs to various transactions.</li> </ul> <p>Limiting the governance functionality is a design choice to increase predictability and safety.</p> <p>Polkadot's governance mechanism has been in production from the very beginning and was used to slowly release functionality and decentralize the initial network. It is also not limited to a few parameters and in fact, the whole runtime is subject to change via protocol making Polkadot a meta-protocol.</p>"},{"location":"learn/learn-comparisons-avalanche/#upgrades","title":"Upgrades","text":"<p>The upgrades to Avalanche are administered by the protocol developers at Ava Labs. On Polkadot, the forkless upgrades are administered and deployed through the on-chain governance. When performing upgrades, every single validator on the Subnet will need to perform the identical upgrade. This requires a co-ordination effort among the Validators of the Subnet. On Polkadot, upgrades to Parachains can be deployed automatically without any coordination with the Validators on the relaychain.</p>"},{"location":"learn/learn-comparisons-avalanche/#conclusion","title":"Conclusion","text":"<p>Avalanche has made some design decisions that allow for an improved smart-contract development environment in which protocol engineers can have the freedom to create their own blockchains and include them in the Avalanche ecosystem via subnets. The trade-offs are that the autonomy of design is limited and blockchains have to buy into the design decisions of Avalanche's main chains. Unlike parachains on Polkadot, Subnets are not able to share the security of the main chains. In addition to utilizing block finality and security of the relay chain, parachains on Polkadot use XCM to pass native trustless messages, instead of having to rely on multiple bridging solutions. However, Subnets are easy to launch when compared to parachains, given that they only need a recommended minimum of 5 validators, which make the costs of launch predictable. Avalanche has plans to implement shared security, interoperability, composability and on-chain governance features which are already offered by Polkadot.</p>"},{"location":"learn/learn-comparisons-avalanche/#references","title":"References","text":"<ol> <li>The Avalanche Platform Whitepaper</li> <li>The Avalanche Consensus Whitepaper</li> <li>The AVAX Token Dynamics Paper</li> <li>Nakomoto vs Snow consensus</li> </ol>"},{"location":"learn/learn-comparisons-cosmos/","title":"Polkadot vs. Cosmos","text":"<p>Polkadot and Cosmos are both protocols that provide an interface for different state machines to communicate with each other. Both protocols are predicated on the thesis that the future will have multiple blockchains that need to interoperate with each other rather than individual blockchains existing in isolation.</p>"},{"location":"learn/learn-comparisons-cosmos/#model","title":"Model","text":"<p>Polkadot uses a sharded model where each shard in the protocol has an abstract state transition function (STF). Polkadot uses WebAssembly (Wasm) as a \"meta-protocol\". A shard's STF can be abstract as long as the validators on Polkadot can execute it within a Wasm environment.</p> <p>The shards of Polkadot are called \"parachains\". Every time a parachain wants to make a state transition, it submits a block (batch of state transitions) along with a state proof that Polkadot validators can independently verify. These blocks are finalized for the parachains when they are finalized by Polkadot's relay chain, the main chain of the system. As such, all parachains share state with the entire system, meaning that a chain re-organization of a single parachain would require a re-organization of all parachains and the relay chain.</p> <p>Cosmos employs horizontal scalability using app-chains. The Cosmos Network consists of 100+ IBC connected chains, including the Cosmos Hub, Osmosis, Celestia, dYdX v4 chain, Injective, etc. Each chain is responsible for securing the chain with a sufficiently staked and decentralized validator set. But chains also have the option to leverage shared security from the Cosmos Hub. Cosmos chains send cross-chain messages using the Inter-Blockchain Communication protocol. As chains do not share state, a re-organization of one chain would not re-organize other chains, meaning each message is trust-bound by the recipient's trust in the security of the sender.</p>"},{"location":"learn/learn-comparisons-cosmos/#architecture","title":"Architecture","text":""},{"location":"learn/learn-comparisons-cosmos/#polkadot","title":"Polkadot","text":"<p>Polkadot has a relay chain acting as the main chain of the system. All validators in Polkadot are on the relay chain. Parachains have collators who construct and propose parachain blocks to validators. Collators do not have any security responsibilities and, thus, do not require a robust incentive system. Collators can submit a single parachain block for every relay chain block every 6 seconds. Once a parachain submits a block, validators perform a series of availability and validity checks before committing it to the final chain.</p> <p>Parachains can access the relay chain through cores. Relay chain cores are limited, but parachain can decide to purchase coretime in-bulk (and reserve an entire core) or on-demand (and interlace a core with another chain) and executing on a pay-as-you-go basis, only paying to execute a block when they need to.</p> <p>To interact with chains that want to use their finalization process (e.g., Bitcoin), Polkadot has bridges that offer two-way compatibility.</p>"},{"location":"learn/learn-comparisons-cosmos/#cosmos","title":"Cosmos","text":"<p>Cosmos is a network of blockchains built using CometBFT as the consensus engine, Cosmos SDK as the VM, and IBC which allows chains to interoperate with one another.</p> <p>IBC leverages light clients that can keep track of the consensus of a counterparty chain. For example, when chains A and B want to talk to one another, chain A uses its light client of B to verify messages sent from chain B, and vice versa. IBC is currently live on Polkadot and Kusama. Work is ongoing to implement IBC to Ethereum and it's layer 2s.</p>"},{"location":"learn/learn-comparisons-cosmos/#consensus","title":"Consensus","text":"<p>Polkadot uses a hybrid consensus protocol with two sub-protocols: BABE and GRANDPA. BABE (Blind Assignment for Blockchain Extension) uses a verifiable random function (VRF) to assign slots to validators and a fallback round-robin pattern to guarantee that each slot has an author. GRANDPA (GHOST-based Recursive Ancestor Deriving Prefix Agreement) votes on chains, rather than individual blocks. Together, BABE can author candidate blocks to extend the finalized chain and GRANDPA can finalize them in batches (up to millions of blocks at a time).</p> <p>This isolation of tasks provides several benefits. First, it represents a reduction in transport complexity for both block production and finalization. BABE has linear complexity, making it easy to scale to thousands of block producers with low networking overhead. GRANDPA has quadratic complexity, but has an advantage in terms of the latency. It is capable of finalizing multiple blocks in one batch.</p> <p>Second, having the capacity to extend the chain with unfinalized blocks allows for liveness of the network and the validators to perform extensive availability and validity checks to ensure that no invalid state transitions make their way into the final chain.</p> <p>Cosmos chains use Tendermint consensus, a round-robin protocol that provides instant finality. Block production and finalization are on the same path of the algorithm, meaning it produces and finalizes one block at a time. Because it is a PBFT-based algorithm (like GRANDPA), it has quadratic complexity, designed to finalize one block at a time.</p>"},{"location":"learn/learn-comparisons-cosmos/#staking-mechanics","title":"Staking Mechanics","text":"<p>Polkadot uses Nominated Proof of Stake (NPoS) to select validators using the sequential Phragm\u00e9n algorithm. The validator set size is set by governance (1_000 validators planned) and stakers who do not want to run validator infrastructure can nominate up to 16 validators. Phragm\u00e9n's algorithm selects the optimal allocation of stake, where optimal is based on having the most evenly staked set.</p> <p>All validators in Polkadot have the same weight in the consensus protocols. That is, to reach greater than \u2154 of support for a chain, more than \u2154 of the validators must commit to it, rather than \u2154 of the stake. Likewise, validator rewards are tied to their activity, primarily block production and finality justifications, not their amount of stake. This creates an incentive to nominate validators with lower stakes, as they will earn higher returns on their staked tokens.</p> <p>The Cosmos Hub uses Bonded Proof of Stake (a variant of Delegated PoS) to elect validators. Stakers must bond funds and submit a delegate transaction for each validator they would like to delegate to with the number of tokens to delegate. The Cosmos Hub plans to support up to 300 validators.</p> <p>Consensus voting and rewards are both stake-based in Cosmos. In the case of consensus voting, more than \u2154 of the stake must commit, rather than \u2154 of the validators. Likewise, a validator with 10% of the total stake will earn 10% of the rewards.</p> <p>Finally, in Cosmos, if a staker does not vote in a governance referendum, the validators assume their voting power. Because of this, many validators in Cosmos have zero commission in order to acquire more control over the protocol. In Polkadot, governance and staking are completely disjoint; nominating a validator does not assign any governance voting rights to the validator.</p>"},{"location":"learn/learn-comparisons-cosmos/#message-passing","title":"Message Passing","text":"<p>Polkadot uses Cross-Consensus Message Passing Format (XCM) for parachains to send arbitrary messages to each other. Parachains open connections with each other and can send messages via their established channels. Collators are full nodes of parachains and full nodes of the relay chain, so collator nodes are a key component of message passing. Messages do not pass through the relay chain, only proofs of post and channel operations (open, close, etc.) go into the relay chain. This enhances scalability by keeping data on the edges of the system.</p> <p>In the case of a chain re-organization, messages can be rolled back to the point of the re-organization based on the proofs of post in the relay chain. The shared state amongst parachains means that messages are free from trust bounds; they all operate in the same context.</p> <p>Polkadot has an additional protocol called SPREE that provides shared logic for cross-chain messages. Messages sent with SPREE carry additional guarantees about provenance and interpretation by the receiving chain.</p> <p>Cosmos uses a light client-based cross-chain protocol called Inter-Blockchain Communication (IBC) for arbitrary message-passing. In the current design, IBC chains create 1:1 Connections with each other, over which Channels can be established. IBC data packets are sent between application modules on different chains over these channels. In the case of IBC, as chains do not share state, receiving chains must trust the security of a message's origin.</p>"},{"location":"learn/learn-comparisons-cosmos/#governance","title":"Governance","text":"<p>Polkadot has OpenGov framewok with several trackss to pass proposals as public referenda, where the majority of tokens can always control the outcome. Referenda can contain a variety of proposals, including fund allocation from an on-chain Treasury. Decisions get enacted on-chain and are binding and autonomous.</p> <p>Cosmos uses coin-vote signaling to pass referenda. The actual enactment of governance decisions is carried out via a protocol fork, much like other blockchains. All token holders can vote, however, if a delegator abstains from a vote then the validator they delegate to assume their voting power. Validators in Polkadot do not receive any voting power based on their nominators.</p>"},{"location":"learn/learn-comparisons-cosmos/#upgrades","title":"Upgrades","text":"<p>Using the Wasm meta-protocol, Polkadot can enact chain upgrades and successful proposals without a hard fork. Anything that is within the STF, the transaction queue, or off-chain workers can be upgraded without forking the chain.</p> <p>As Cosmos is not based on a meta-protocol, it must enact upgrades and proposals via a normal forking mechanism.</p>"},{"location":"learn/learn-comparisons-cosmos/#development-framework","title":"Development Framework","text":"<p>Both Cosmos and Polkadot are designed such that each chain has its STF and both provide support for smart contracts in both Wasm and the Ethereum Virtual Machine (EVM). Polkadot provides an ahead-of-time Wasm compiler as well as an interpreter (Wasmi) for execution, while Cosmos only executes smart contracts in an interpreter.</p> <p>Cosmos chains can be developed using the Cosmos SDK, written in Go. The Cosmos SDK contains about 10 modules (e.g. staking, governance, etc.) that can be included in a chain's STF. The SDK builds on top of Tendermint.</p> <p>The primary development framework for parachains is Substrate, written in Rust. Substrate comes with FRAME, a set of about 40 modules (called \"pallets\") to use in a chain's STF. Beyond simply using the pallets, Substrate adds a further layer of abstraction that allows developers to compose FRAME's pallets by adding custom modules and configuring the parameters and initial storage values for the chain.</p> <p>Polkadot can support an STF written in any language</p> <pre><code>So long as it compiles to its meta-protocol Wasm. Likewise, it could still use the Substrate client (database, RPC, networking, etc.); it only needs to implement the primitives at the interface.\n</code></pre>"},{"location":"learn/learn-comparisons-cosmos/#conclusion","title":"Conclusion","text":"<p>Polkadot was designed on the principle that scalability and interoperability require shared validation logic to create a trust-free environment. As more blockchains are developed, their security must be cooperative, not competitive. Therefore, Polkadot provides the shared validation logic and security processes across chains so that they can interact knowing that their interlocutors execute within the same security context.</p> <p>The Cosmos network uses an Internet-like unstructured network that uses IBC to connect chains with independent security guarantees, meaning that when data is sent from one chain to another, the receiving chain must trust the sending chain. Thus, each blockchain in the Cosmos network has its independent security mechanisms. Chains also have the option to share security with the Cosmos Hub and thereby leverage its economic security.</p>"},{"location":"learn/learn-comparisons-kusama/","title":"Polkadot vs. Kusama","text":"<p>Although they are like cousins and share many parts of their code, Polkadot and Kusama are independent, standalone networks with different priorities. Kusama is wild and fast, and great for bold experimentation and early-stage deployment. Polkadot is more conservative, prioritizing stability and dependability. Cousins have their differences after all.</p> <p>Info</p> <p>To get a better understanding of the key similarities and difference between Polkadot and Kusama, checkout this support article.</p>"},{"location":"learn/learn-comparisons-kusama/#cost-and-speed","title":"Cost and Speed","text":"<p>Teams wishing to run a parachain are required to bond tokens as security. The bonding requirement on Kusama is lower than on Polkadot, making it the more affordable development environment.</p> <p>Another key technical difference between Polkadot and Kusama is that Kusama has modified governance parameters that allow for faster upgrades. Kusama is up to four times faster than Polkadot. This does not mean that the Kusama blockchain itself is faster, in the sense of faster block times or transaction throughput (these are the same on both networks), but that there's a shorter amount of time between governance events such as proposing new referenda, voting, and enacting approved upgrades. This allows Kusama to adapt and evolve faster than Polkadot.</p>"},{"location":"learn/learn-comparisons-kusama/#canary-network","title":"Canary network","text":"<p>The initial use case for Kusama was as a pre-production environment, a \u201ccanary network\u201d.</p> <p>Canary is a type of bird: back in the day, coal miners would put canaries into coal mines as a way to measure the amount of toxic gases in the tunnels. Similarly, canary testing is a way to validate software by releasing software to a limited number of users, or perhaps, an isolated environment - without hurting a wide range of users.</p> <p>Releases made onto Kusama can be thought of as Canary Releases. These releases are usually staged. In Kusama's early days, the network won't just be used for parachain candidates to innovate and test changes, but a proof of concept for Polkadot's sharded model.</p> <p>Kusama is not simply a testnet, the blockchain is fully functional with attached economic value, and own governance. The future of Kusama is in the hands of its participants. In a typical blockchain development pipeline, Kusama would sit in between a \"testnet\" and a \"mainnet\":</p> <p>!!!info Testnet \u2192 Kusama \u2192 Polkadot</p> <p>As you can imagine, building on Kusama first allows teams to test things out in a live, fully decentralized, and community-controlled network with real-world conditions and lower stakes in the event of problems or bugs than on Polkadot.</p> <p>Many projects will maintain parachains on both networks, experimenting and testing new technologies and features on Kusama before deploying them to Polkadot. Some teams will decide just to stay on Kusama, which is likely to be a place where we see some exciting experimentation with new technologies going forward. Projects that require high-throughput but don\u2019t necessarily require bank-like security, such as some gaming, social networking, and content distribution applications, are particularly good candidates for this use case.</p> <p>Kusama may also prove to be the perfect environment for ambitious experiments with new ideas and innovations in areas like governance, incentives, monetary policy, and DAOs (decentralized autonomous organizations). Future upgrades to the Polkadot runtime will also likely be deployed to Kusama before Polkadot mainnet. This way, not only will we be able to see how these new technologies and features will perform under real-world conditions before bringing them to Polkadot, but teams who have deployed to both networks will also get an advanced look at how their own technology will perform under those upgrades.</p>"},{"location":"learn/learn-comparisons-kusama/#going-forward","title":"Going forward","text":"<p>Ultimately, Kusama and Polkadot will live on as independent, standalone networks with their own communities, their own governance, and their own complementary use cases, though they will continue to maintain a close relationship, with many teams likely deploying applications to both networks. Web3 Foundation remains committed to both networks going forward, providing crucial support and guidance to teams building for the ecosystem.</p>"},{"location":"learn/learn-comparisons/","title":"Polkadot Comparisons","text":""},{"location":"learn/learn-comparisons/#rollup-comparison","title":"Rollup Comparison","text":"<p>Rollups are an L2 scaling solution. At the most basic level, a rollup L2 solution is responsible for \"rolling up\" transactions by batching them before publishing them to the L1 chain, usually through a network of sequencers. In theory, separate entities could assume the role of sequencing transactions and publishing them. In practice, they are the same machine, but this will likely change as rollups decentralize more. This mechanism could include thousands of transactions in a single rollup.</p> <p>Layer Two Definition</p> <p>Layer two (L2) networks are a key approach to blockchain scalability, off-loading the majority of computation from layer one (L1) networks. These solutions leverage the security of L1 to create an additional layer that is faster, reduces fees, and addresses platform-specific challenges. L2 solutions also focus on utilizing L1 blockspace efficiently and cost-effectively.</p> <p>By adopting modular designs and re-using functionality, L2 networks enable the deployment of scalable rollups for various virtual machine environments, including Ethereum Virtual Machine (EVM), Solana Virtual Machine (SVM) and Move-based systems. These rollups settle back to Ethereum, ensuring a robust and secure foundation for diverse blockchain ecosystems.</p> <p>In this section, we explore the main differences in rollup technology between:</p> <ul> <li>Zero-knowledge rollups,</li> <li>Optimistic rollups, and</li> <li>Polkadot rollups (i.e., parachains).</li> </ul> <p>Before diving into the differences between these rollup technologies, it is crucial to understand the difference between non-interactive and interactive methods.</p>"},{"location":"learn/learn-comparisons/#fraud-proofs-vs-validity-proofs","title":"Fraud Proofs vs. Validity Proofs","text":"<p>In the context of rollups, interactive and non-interactive methods are commonly used to describe how the validity of transactions or state changes is established between the rollup layer and the main blockchain (L1). These terms correspond closely to the mechanisms of fraud proofs and validity proofs, which are the standard terminology.</p> <p>An interactive method (associated with fraud proofs) involves a back-and-forth process to validate transactions. A \"prover\" submits transaction data or state changes to L1, assuming it is valid. A challenge mechanism is triggered if a dispute arises, requiring participants to provide evidence (fraud proofs) to demonstrate invalidity. This process ensures correctness but introduces latency due to dispute resolution periods, which can vary depending on the implementation. For example, optimistic rollups often have challenge periods of several hours or even up to seven days.</p> <p>A non-interactive method (associated with validity proofs) relies on cryptographic mechanisms, such as SNARKs or STARKs, to validate transactions upfront. These proofs are generated off-chain and submitted to L1 for verification without requiring dispute resolution. While these methods offer near-instant finality, in theory, in practice delays are sometimes intentionally introduced as safeguards. For instance, zkSync rollups may take up to a day to finalize transactions, not due to technical limitations but as a precautionary measure while the technology matures and secures high-value assets.</p> <p>Below is a comparison of the two mechanisms:</p> Aspect Fraud Proofs (Interactive) Validity Proofs (Non-Interactive) Mechanism Challenge-based system where disputes are resolved interactively. Cryptographic proofs validate all transactions upfront, eliminating disputes. Latency Time to finality depends on challenge periods. Optimistic rollups often take hours or even days to finalize. Polkadot rollups reduce this to around 30 minutes. Near-instant finality in theory. In practice, systems like zkSync can take up to a day to finalize, often due to artificial safeguards rather than inherent technical limitations. Security Basis Crypto-economic incentives and participant monitoring ensure validity. Cryptographic guarantees ensure correctness upfront, reducing the need for external monitoring. Complexity Simpler to implement but requires active monitoring and challenge resolution. Computationally intensive and complex to build, especially for ZK systems. Use Cases Suitable for applications needing broad compatibility with existing systems and tolerating some latency for finality. Ideal for high-security applications or scenarios where upfront validation and near-instant finality are critical. <p>Both approaches address different trade-offs between scalability, security, latency, and implementation complexity. Future innovations may blur the lines between these mechanisms, enabling hybrid approaches such as non-interactive dispute systems.</p>"},{"location":"learn/learn-comparisons/#zero-knowledge-rollups","title":"Zero-knowledge Rollups","text":"<p>Zero-knowledge rollups (commonly referred to as ZK rollups) are a non-interactive method that utilizes cryptographic proofs, often in the form of SNARKs, to compute the validity of a particular set of state changes. While the industry has adopted the term \"ZK rollups,\" it is worth noting that many implementations do not strictly involve zero-knowledge properties, as the proofs do not necessarily conceal information. These rollups are better described simply as SNARK-based rollups, but the term \"ZK rollups\" remains widely used.</p> <p>In contrast to optimistic rollups, which rely on fraud proofs and interactive challenge mechanisms, ZK rollups rely entirely on cryptographic validation, with SNARKs providing upfront proof of correctness. This approach allows ZK rollups to achieve significantly faster finalization, as the validity proof ensures that all state transitions are correct without requiring a challenge period.</p> <p>However, ZK rollups face performance challenges due to the computational complexity involved in proof generation and the difficulty of implementing these proofs in resource-constrained environments. This complexity also makes achieving Turing completeness more challenging, which can limit their generalizability in terms of blockspace usage. Despite these challenges, ZK rollups are becoming increasingly viable for specialized applications. For example, Hyperbridge is a SNARK-based rollup on Polkadot that acts as a scalable, trustless bridge. It produces a single proof for multiple blockchains, which can be instantly verified on Polkadot, demonstrating the potential of these rollups in niche use cases.</p>"},{"location":"learn/learn-comparisons/#optimistic-rollups","title":"Optimistic Rollups","text":"<p>Optimistic rollups are an interactive scaling method for L1 blockchains. They assume optimistically that every proposed transaction is valid by default.</p> <p>In the case of mitigating potentially invalid transactions, optimistic rollups introduce a challenge period during which participants may challenge a suspect rollup. A fraud-proving scheme can be in place to allow for several fraud proofs to be submitted. Those proofs could make the rollup valid or invalid. State changes may be disputed, resolved, or included during the challenge period if no challenge is presented (and the required proofs are in place).</p> <p>Optimistic rollups are often used in the Ethereum ecosystem. Optimism and Arbitrium are an example of optimistic EVM-based rollups.</p>"},{"location":"learn/learn-comparisons/#polkadot-rollups","title":"Polkadot Rollups","text":"<p>Polkadot Rollups work similarly to optimistic rollups. They are an interactive method with fraud proof mechanism. Like optimistic rollups and zk rollups are secured by Ethereum, Polkadot rollups are secured by the Polkadot Relay Chain. The checking and fraud-proof mechanics are natively implemented in Polkadot. Collators are in principle similar to sequencers, as they pass data with a proof-of-validity (PoV) function for liveness and communication with the Relay Chain.</p> <p>Additionally, Polkadot operates as a stateless client of its rollups, meaning the Relay Chain does not maintain the entire state of each parachain. Instead, it verifies state transitions using PoV blocks submitted by collators. This is analogous to block witnesses in the Ethereum ecosystem, which proves transaction validity without requiring full state storage. This design ensures scalability by delegating state maintenance to rollups while enabling secure validation through cryptographic proofs.</p> <p>Polkadot rollups have the following main differences compared to optimistic rollups:</p> <ul> <li>Polkadot implements rollup functionality at the native level (i.e., without using L2 scaling   solutions), allowing for shared security and scalability for each rollup through the   Parachains Protocol. Polkadot handles data coordination from   parachains into an aggregated, representative state, similar to L2 rollups.</li> <li>If optimistic rollups are based on the assumption that all transactions are valid, Polkadot   rollups are \"cynical\" and always check the validity of transactions using a subset of the   validators. In case of disputes, an escalation effect involving more validators is triggered,   and dispute resolution will end with the malicious actor being slashed.</li> <li>Polkadot has multiple virtual cores that are made possible thanks to the Parachain Protocol, which   allows execution sharding. Rollups access Polkadot by reserving time on those cores via   coretime.</li> </ul> <p>A more detailed comparison of Polkadot rollups with optimistic and zk rollups can be found in the comparison table below.</p>"},{"location":"learn/learn-comparisons/#rollup-comparison-table","title":"Rollup Comparison Table","text":"<p>Here below there is a comparison table summarizing the main differences between Polkadot, ZK, and Optimistic rollups. An in-depth comparison between different types of optimistic and ZK rollups can be found on l2beat.</p> Feature ZK Rollups Optimistic Rollups Polkadot Parachains/Rollups Finality Near-instant finality. Because the proof is immediately available, finality is also instantaneous. Delayed finality (a week) due to fraud-proof mechanisms. Fast finality (under 1 minute) via relay chain consensus. Security Model Relies on cryptographic validity proofs, ensuring high security and no reliance on game-theoretic assumptions. Relies on economic incentives and a challenge period to catch fraud. Optimistic assumption makes it less secure than ZK Rollups. \"Cynical\" model, where every transaction is checked by a subset of validators, with escalation and slashing in case of disputes. Scalability Limited scalability as they are a single state machine and are only as scalable as the prover machine and computation requirement. Many zk-rollups disable cryptographic precompiles on the mainnet as a result of the immense computational requirement for them. High, with parallelization, but limited by gas costs on L1 chains like Ethereum. Inherently scalable through native execution sharding and parachains operating in parallel. Pipelining and core scheduling increase throughput and scalability for the single rollup. Execution sharding is enabled by multiple virtual cores using coretime. Interoperability Limited interoperability<sup>1</sup>, often restricted to compatible L1s. Limited interoperability<sup>1</sup>, often confined to the parent blockchain ecosystem. See the comparison about interoperability for more information. Native interoperability through XCM, allowing seamless communication between parachains having different logic. Trustless bridges can connect Polkadot to other blockchains. State Transition Logic General-purpose but constrained by zk-circuit implementation complexity. Can support state transitions beyond EVM compatibility by interpreting other virtual machine (VM) logic within the EVM environment<sup>2</sup>. Each parachain can define its unique state transition function (STF), which is compiled to Wasm and validated per Parachain Protocol rules. Development Complexity Complex due to the mathematics of zero-knowledge proofs. Moderate complexity, requiring fraud-proof implementation. Moderate to high complexity; parachain runtimes must be written in WASM-compatible languages but can define custom logic and governance. Parachain maintenance can be an overhead. Data Availability Data availability requirements posted by the optimistic and ZK rollups are the same. Data availability requirements posted by the optimistic and ZK rollups are the same. Built-in data availability with validators ensuring distributed state storage and reconstruction in case of disputes. Cost Efficiency High efficiency but expensive prover computation. More cost-effective but susceptible to congestion during high usage. Cost-effective as parachains are independently scalable and not tied to L1 gas fees. Governance Upgrades Subject to parent chain governance. Governed by parent L1 network governance. Forkless upgrades are supported through Polkadot\u2019s native governance mechanisms. Fraud/Validity Proofs Non-interactive validity proofs, ensuring correctness off-chain. Fraud proofs requiring active challenges during the dispute window. Continuous validity checks by validators with dispute escalation effects, ending in slashing malicious actors. Applications Ideal for high-security use cases like financial transactions and privacy-preserving applications. Suitable for general-purpose dApps with moderate security needs. Fully-fledged state machines capable of defining governance, logic, and custom runtime environments, ideal for diverse blockchain apps. Escape Hatch<sup>3</sup> No built-in escape hatch; relies on zk circuits functioning correctly. Can include an escape hatch to withdraw funds if sequencers fail. No native escape mechanism; funds could be trapped if parachain collators fail. Permissioning Typically relies on permissioned sequencers. Sequencers can be permissioned or partially permissionless. Parachains support permissioned and permissionless collator sets, providing flexibility for private or public use cases. Shared Security Relies on the parent chain's security guarantees, leveraging zk-proofs. Security shared with the L1 via fraud-proof mechanisms. Security shared with the Relay Chain via Parachian Protocol. Sharding Only data sharding. Execution sharding does not apply to Ethereum ZK rollups. Only data sharding. Execution sharding does not apply to Ethereum Optimistic rollups. Data sharding and execution sharding enabled through the Parachain Protocol, leveraging multiple virtual cores and reserving coretime for rollup operations. <p><sup>1</sup>There are efforts to allow native interoperability within rollup hubs, e.g., there will be \"better\" interoperability within the OP Stack ecosystem than independent L2s.</p> <p><sup>2</sup>Optimistic rollups rely on Ethereum's EVM (Ethereum Virtual Machine) for their fraud-proof mechanisms and dispute resolution. However, rather than natively executing L2 opcodes, the EVM interprets the logic of the rollup's virtual machine.</p> <p>Opcodes</p> <p>An opcode (short for operation code) is the fundamental instruction used by a virtual machine to perform specific operations. In the context of the EVM, opcodes define low-level commands that execute computations, manage storage, and interact with smart contracts. Rollups process their opcodes, which the EVM interprets during dispute resolution and other operations.</p> <p>While optimistic rollups often support EVM-compatible state transitions for seamless integration with Ethereum and its ecosystem, they are not inherently restricted to EVM logic. Developers could implement interpretation logic for other virtual machines, such as WASM or custom environments, enabling optimistic rollups to support diverse computational frameworks. This flexibility expands their potential beyond traditional EVM-based boundaries, contrasting with the perception that they are strictly tied to Ethereum\u2019s computational model.</p> <p><sup>3</sup>An escape hatch is a method by which users of a rollup can recover digital assets or program state from a rollup when the operators (sequencers) are offline.</p>"},{"location":"learn/learn-comparisons/#interoperability-comparison","title":"Interoperability Comparison","text":"<p>In this section, we explore the main differences in interoperability between Polkadot, Optimism Superchain Ecosystem and Chainlink CCIP (Cross-chain Interoperability Protocol).</p> Feature Polkadot XCM Optimism Superchain Interoperability Chainlink CCIP Architecture Direct communication between parachains within the Polkadot ecosystem using a unified relay chain. Cross-rollup interoperability built on Ethereum, extending rollups\u2019 compatibility. Universal standard enabling cross-chain communication for any blockchain network. Scope Limited to parachains and relay chains in the Polkadot/Kusama ecosystem. Focused on rollups in Ethereum Layer 2 (e.g., Optimism, Base). Blockchain-agnostic, supporting public and private chains. Consensus Dependency Relies on Polkadot's shared relay chain consensus. Depends on Ethereum Layer 1 for security and sequencer trust within Superchain rollups. Independent of any specific chain\u2019s consensus, it uses an oracle network for secure messaging. Interoperability Model Messages are trustlessly passed between parachains using XCMP and HRMP channels. Rollups communicate through the Superchain\u2019s sequencer infrastructure. Relies on Chainlink decentralized oracles to transmit data securely across chains. Scalability High scalability within the ecosystem; limited by relay chain capacity. Limited by Ethereum throughput and Superchain architecture. Scalable; offloads cross-chain messaging to oracle networks. Security Model Secured by Polkadot's relay validators and stake. Secured by Ethereum\u2019s base layer and rollup-specific fraud or validity proofs. Security ensured by Chainlink oracles and cryptographic proofs. Ease of Integration Requires Substrate-based parachains and compliance with Polkadot protocols. Requires rollups to align with Optimism\u2019s OP stack architecture. Blockchain-agnostic, integrates with any chain using CCIP libraries. Interoperability Speed Near-instant, as Polkadot\u2019s shared relay chain validates interactions. Relatively slower due to dependency on Layer 1 Ethereum finality and rollup delays. Fast, as it relies on Chainlink oracle nodes for data transmission. Use Cases Native token transfers, contract execution (though Polkadot allows smart contract execution through XCM, it is almost impossible to use trustlessly in practice, as only straightforward calls can be passed without read access), and shared staking pools. Bridging assets and state between rollups. Cross-chain DeFi, gaming, enterprise blockchain communication. Prone to Centralization Low; while Polkadot's design enforces decentralization, it allows the decentralization of collators but does not mandate it, as there are chains with teams operating all collators. Optimism does not currently give a choice; sequencers must be centralized. Depends on the decentralization level of Chainlink's oracle network. Current Deployment Actively deployed in Polkadot and Kusama ecosystems. Early stage; foundational elements are live, expanding with OP stack rollups. Widely adopted across multiple chains in both testnet and mainnet. Key Strengths Seamless, low-latency native communication within the ecosystem. Interoperability focused on Ethereum scalability and Layer 2 adoption. Universal, chain-agnostic standard with flexible use cases. Limitations Limited to Polkadot-compatible parachains. Restricted to Ethereum and rollups using OP stack. It depends on the oracle network security and adoption rate."},{"location":"learn/learn-comparisons/#other-comparisons","title":"Other Comparisons","text":""},{"location":"learn/learn-consensus/","title":"Polkadot's Consensus Protocols","text":"<p>In traditional PoS systems, block production participation is dependent on token holdings as opposed to computational power. While PoS developers usually have a proponent for equitable participation in a decentralized manner, most projects propose some level of centralized operation, where the number of validators with full participation rights is limited. These validators are often seen to be the most wealthy and, as a result, influence the PoS network as they are the most staked. Usually, the number of candidates to maintain the network with the necessary knowledge (and equipment) is limited; this can also increase operational costs. Systems with a large number of validators tend to form pools to decrease the variance of their revenue and profit from economies of scale. These pools are often off-chain.</p> <p>A way to alleviate this is to implement pool formation on-chain and allow token holders to vote with their stake for validators to represent them.</p>"},{"location":"learn/learn-consensus/#nominated-proof-of-stake","title":"Nominated Proof of Stake","text":"<p>Polkadot uses NPoS (Nominated Proof-of-Stake) as its mechanism for selecting the validator set. It is designed with the roles of validators and nominators, to maximize chain security. Actors who are interested in maintaining the network can run a validator node.</p> <p>Validators assume the role of producing new blocks, validating parachain blocks, and guaranteeing finality. Nominators can choose to backselect validators with their stake. Nominators can approve candidates that they trust and back them with their tokens.</p>"},{"location":"learn/learn-consensus/#hybrid-consensus","title":"Hybrid Consensus","text":"<p>Polkadot uses a hybrid consensus composed by the finality gadget (GRANDPA) and the block production mechanism (BABE).</p> <p>This is a way of getting the benefits of probabilistic finality (the ability always to produce new blocks) and provable finality (having a universal agreement on the canonical chain with no chance for reversion). It also avoids the corresponding drawbacks of each mechanism (the chance of unknowingly following the wrong fork in probabilistic finality, and a chance for \"stalling\" - not being able to produce new blocks - in provable finality). The combination of these two mechanisms allows for blocks to be rapidly produced, and the slower finality mechanism to run in a separate process to finalize blocks without risking slower transaction processing or stalling.</p> <p>Hybrid consensus has been proposed in the past. Notably, it was proposed (now defunct) as a step in Ethereum's transition to proof of stake in EIP 1011, which specified Casper FFG.</p>"},{"location":"learn/learn-consensus/#block-production-babe","title":"Block Production: BABE","text":"<p>BABE (Blind Assignment for Blockchain Extension) is the block production mechanism that runs between the validator nodes and determines the authors of new blocks. BABE is comparable as an algorithm to Ouroboros Praos, with some key differences in chain selection rule and slot time adjustments. BABE assigns block production slots to validators according to stake and using the relay chain's randomness cycle. The chain\u2019s runtime is required to provide the BABE authority list and randomness to the host via a consensus message in the header of the first block of each epoch.</p> <p>BABE execution happens in sequential non-overlapping phases known as epochs. Each epoch is divided into a predefined number of slots. All slots in each epoch are sequentially indexed starting from 0 (slot number). At the beginning of each epoch, the BABE node needs to run the Block-Production-Lottery algorithm to find out in which slots it should produce a block and gossip to the other block producers.</p> <p>Validators participate in a lottery for every slot, which will inform whether or not they are the block producer candidate for that slot. Slots are discrete units of time of approximately 6 seconds in length. Because the mechanism of allocating slots to validators is based on a randomized design, multiple validators could be candidates for the same slot. Other times, a slot could be empty, resulting in inconsistent block time.</p>"},{"location":"learn/learn-consensus/#multiple-validators-per-slot","title":"Multiple Validators per Slot","text":"<p>When multiple validators are block producer candidates in a given slot, all will produce a block and broadcast it to the network. At that point, it's a race. The validator whose block reaches most of the network first wins. Depending on network topology and latency, both chains will continue to build in some capacity until finalization kicks in and amputates a fork. See Fork Choice below for how that works.</p>"},{"location":"learn/learn-consensus/#no-validators-in-slot","title":"No Validators in Slot","text":"<p>When no validators have rolled low enough in the randomness lottery to qualify for block production, a slot can remain seemingly blockless. Polkadot protocol runs a secondary validator selection algorithm in the background. The validators selected through this predictable algorithm always produce blocks. These secondary blocks are ignored if the same slot has a primary block produced from a VRF-selected validator. Thus, a slot can have either a primary or a secondary block, and no slots are ever skipped.</p> <p>For more details on BABE, please see the BABE paper.</p>"},{"location":"learn/learn-consensus/#finality-gadget-grandpa","title":"Finality Gadget: GRANDPA","text":"<p>GRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) is the finality gadget that is implemented for the relay chain.</p> <p>The Polkadot Host uses the GRANDPA Finality protocol to finalize blocks. Finality is obtained by consecutive rounds of voting by the validator nodes. Validators execute the GRANDPA finality process in parallel to Block Production as an independent service.</p> <p>It works in a partially synchronous network model as long as \u2154 of nodes are honest and can cope with \u2155 Byzantine nodes in an asynchronous setting.</p> <p>A notable distinction is that GRANDPA reaches agreements on chains rather than blocks, greatly speeding up the finalization process, even after long-term network partitioning or other networking failures.</p> <p>In other words, as soon as more than \u2154 of validators attest to a chain containing a particular block, all blocks leading up to that one are finalized at once.</p> <p>GRANDPA description and implementation</p> <p>Please refer to the GRANDPA paper for a full description of the protocol. GRANDPA is implemented as a module of the Substrate Frame System.</p>"},{"location":"learn/learn-consensus/#probabilistic-vs-provable-finality","title":"Probabilistic vs. Provable Finality","text":"<p>A pure Nakamoto consensus blockchain that runs PoW is only able to achieve the notion of probabilistic finality and reach eventual consensus. Probabilistic finality means that under some assumptions about the network and participants, if we see a few blocks building on a given block, we can estimate the probability that it is final. Eventual consensus means that at some point in the future, all nodes will agree on the truthfulness of one set of data. This eventual consensus may take a long time, and will not be able to determine how long it will take ahead of time. However, finality gadgets such as GRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) or Ethereum's Casper FFG (the Friendly Finality Gadget) are designed to give stronger and quicker guarantees on the finality of blocks - specifically, that they can never be reverted after some process of Byzantine agreements has taken place. The notion of irreversible consensus is known as provable finality.</p> <p>In the GRANDPA paper, it is phrased in this way:</p> <p>Note</p> <p>We say an Oracle A in a protocol is eventually consistent if it returns the same value to all participants after some unspecified time.</p>"},{"location":"learn/learn-consensus/#fork-choice","title":"Fork Choice","text":"<p>Bringing BABE and GRANDPA together, the fork choice of the relay chain becomes clear. BABE must always build on the chain that GRANDPA has finalized. BABE provides probabilistic finality when there are forks after the finalized head by building on the chain with the most primary blocks.</p> <p></p> <p>In the above image, the black blocks are finalized, and the yellow blocks are not. Blocks marked with a \"1\" are primary blocks; those marked with a \"2\" are secondary blocks. Even though the topmost chain is the longest chain on the latest finalized block, it does not qualify because it has fewer primaries at the time of evaluation than the one below it.</p>"},{"location":"learn/learn-consensus/#comparisons","title":"Comparisons","text":""},{"location":"learn/learn-consensus/#nakamoto-consensus","title":"Nakamoto consensus","text":"<p>Nakamoto consensus consists of the longest chain rule using proof of work as its Sybil resistance mechanism and leader election.</p> <p>Nakamoto consensus only gives us probabilistic finality. Probabilistic finality states that a block in the past is only as safe as the number of confirmations it has, or the number of blocks that have been built on top of it. As more blocks are built on top of a specific block in a Proof of Work chain, more computational work has been expended behind this particular chain. However, it does not guarantee that the chain containing the block will always remain the agreed-upon chain since an actor with unlimited resources could potentially build a competing chain and expend enough computational resources to create a chain that did not contain a specific block. In such a situation, the longest chain rule employed in Bitcoin and other proof of work chains would move to this new chain as the canonical one.</p>"},{"location":"learn/learn-consensus/#pbft-tendermint","title":"PBFT / Tendermint","text":"<p>Please see the relevant section in the Cosmos comparison article.</p>"},{"location":"learn/learn-consensus/#casper-ffg","title":"Casper FFG","text":"<p>The two main differences between GRANDPA and Casper FFG are:</p> <ul> <li>in GRANDPA, different voters can cast votes simultaneously for blocks at different heights</li> <li>GRANDPA only depends on finalized blocks to affect the fork-choice rule of the underlying block   production mechanism</li> </ul>"},{"location":"learn/learn-consensus/#bridging-beefy","title":"Bridging: BEEFY","text":"<p>The BEEFY (Bridge Efficiency Enabling Finality Yielder) is a secondary protocol to GRANDPA to support efficient bridging between relay chains (Polkadot and Kusama) and remote, segregated blockchains, such as Ethereum, which were not built with the Polkadot native interoperability in mind. The protocol allows participants of the remote network to efficiently verify finality proofs created by validators on the relay chain, i.e. clients in the Ethereum network can verify that the Polkadot network is at a specific state.</p> <p>Storing all the information necessary to verify the state of the remote chain, such as the block headers, is too expensive. In BEEFY, all honest validators sign on a GRANDPA finalized block. This reduces the efforts on the light client side, as tracking forks, GRANDPA justifications, etc., is no longer necessary. Moreover, BEEFY utilizes Merkle Mountain Ranges (MMR) as an efficient data structure for storing and transmitting block headers and signatures to light clients and the ECDSA signature schemes (more efficiently verifiable on EVM). Light clients now only have to check if the block has a super-majority of BEEFY votes by validators.</p> <p>Overall, BEEFY addresses the limitations of GRANDPA finality for bridges to chains like Ethereum by providing a more lightweight and efficient finality solution.</p> <p>For additional implementation details about BEEFY, see the Polkadot Specification.</p>"},{"location":"learn/learn-consensus/#resources","title":"Resources","text":"<ul> <li>BABE paper - The   academic description of the BABE protocol.</li> <li>GRANDPA paper - The academic   description of the GRANDPA finality gadget. Contains formal proofs of the algorithm.</li> <li>Rust implementation - The reference   implementation and the accompanying   Substrate pallet.</li> <li>Block Production and Finalization in Polkadot -   An explanation of how BABE and GRANDPA work together to produce and finalize blocks on Kusama with   Bill Laboon.</li> <li>Block Production and Finalization in Polkadot: Understanding the BABE and GRANDPA Protocols -   An academic talk by Bill Laboon, given at MIT Cryptoeconomic Systems 2020, describing Polkadot's   hybrid consensus model in-depth.</li> </ul>"},{"location":"learn/learn-cryptography/","title":"Cryptography on Polkadot","text":"<p>This is a high-level overview of the cryptography used in Polkadot. It assumes that you have some knowledge about cryptographic primitives that are generally used in blockchains such as hashes, elliptic curve cryptography (ECC), and public-private keypairs.</p> <p>For detailed descriptions on the cryptography used in Polkadot please see the more advanced research wiki.</p>"},{"location":"learn/learn-cryptography/#hashing-algorithm","title":"Hashing Algorithm","text":"<p>The hashing algorithm used in Polkadot is Blake2b. Blake2 is considered to be a very fast cryptographic hash function that is also used in the cryptocurrency Zcash.</p>"},{"location":"learn/learn-cryptography/#keypairs-and-signing","title":"Keypairs and Signing","text":"<p>Polkadot uses Schnorrkel/Ristretto x25519 (\"sr25519\") as its key derivation and signing algorithm.</p> <p>Sr25519 is based on the same underlying Curve25519 as its EdDSA counterpart, Ed25519. However, it uses Schnorr signatures instead of the EdDSA scheme. Schnorr signatures bring some noticeable benefits over the ECDSA/EdDSA schemes. For one, it is more efficient and still retains the same feature set and security assumptions. Additionally, it allows for native multisignature through signature aggregation.</p> <p>The names Schnorrkel and Ristretto come from the two Rust libraries that implement this scheme, the Schnorrkel library for Schnorr signatures and the Ristretto library that makes it possible to use cofactor-8 curves like Curve25519.</p>"},{"location":"learn/learn-cryptography/#keys","title":"Keys","text":"<p>Public and private keys are an important aspect of most crypto-systems and an essential component that enables blockchains like Polkadot to exist.</p>"},{"location":"learn/learn-cryptography/#account-keys","title":"Account Keys","text":"<p>Account keys are keys that are meant to control funds. They can be either:</p> <ul> <li>The vanilla <code>ed25519</code> implementation using Schnorr signatures.</li> <li>The Schnorrkel/Ristretto <code>sr25519</code> variant using Schnorr signatures.</li> <li>ECDSA signatures on secp256k1</li> </ul> <p>There are no differences in security between <code>ed25519</code> and <code>sr25519</code> for simple signatures. We expect <code>ed25519</code> to be much better supported by commercial HSMs for the foreseeable future. At the same time, <code>sr25519</code> makes implementing more complex protocols safer. In particular, <code>sr25519</code> comes with safer version of many protocols like HDKD common in the Bitcoin and Ethereum ecosystem.</p>"},{"location":"learn/learn-cryptography/#stash-and-staking-proxy-keys","title":"Stash and Staking Proxy Keys","text":"<p>When we talk about stash and staking proxy keys, we usually talk about them in the context of running a validator or nominating, but they are useful concepts for all users to know. Both keys are types of account keys. They are distinguished by their intended use, not by an underlying cryptographic difference. All the info mentioned in the parent section applies to these keys. When creating new staking proxy or stash keys, all cryptography supported by account keys are an available option.</p> <p>The staking proxy key is a semi-online key that will be in the direct control of a user, and used to submit manual extrinsics. For validators or nominators, this means that the proxy key will be used to start or stop validating or nominating. Proxy keys should hold some native tokens to pay for fees, but they should not be used to hold huge amounts or life savings. Since they will be exposed to the internet with relative frequency, they should be treated carefully and occasionally replaced with new ones.</p> <p>The stash key is a key that will, in most cases, be a cold wallet, existing on a piece of paper in a safe or protected by layers of hardware security. It should rarely, if ever, be exposed to the internet or used to submit extrinsics. The stash key is intended to hold a large amount of funds. It should be thought of as a saving's account at a bank, which ideally is only ever touched in urgent conditions. Or, perhaps a more apt metaphor is to think of it as buried treasure, hidden on some random island and only known by the pirate who originally hid it.</p> <p>Since the stash key is kept offline, it must be set to have its funds bonded to a particular staking proxy. For non-spending actions, the staking proxy has the funds of the stash behind it. For example, in nominating, staking, or voting, the proxy can indicate its preference with the weight of the stash. It will never be able to actually move or claim the funds in the stash key. However, if someone does obtain your proxy key, they could use it for slashable behavior, so you should still protect it and change it regularly.</p>"},{"location":"learn/learn-cryptography/#session-keys","title":"Session Keys","text":"<p>Session keys are hot keys that must be kept online by a validator to perform network operations. Session keys are typically generated in the client, although they don't have to be. They are not meant to control funds and should only be used for their intended purpose. They can be changed regularly; your staking proxy only need to create a certificate by signing a session public key and broadcast this certificate via an extrinsic.</p> <p>Polkadot uses six session keys:</p> <ul> <li>Authority Discovery: sr25519</li> <li>BABE: sr25519</li> <li>BEEFY: ecdsa</li> <li>GRANDPA: ed25519</li> <li>Parachain Assignment: sr25519</li> <li>Parachain Validator: ed25519</li> </ul> <p>BABE requires keys suitable for use in a Verifiable Random Function as well as for digital signatures. Sr25519 keys have both capabilities and so are used for BABE.</p> <p>In the future, we plan to use a BLS key for GRANDPA because it allows for more efficient signature aggregation.</p>"},{"location":"learn/learn-cryptography/#faq-about-keys","title":"FAQ about Keys","text":""},{"location":"learn/learn-cryptography/#why-was-ed25519-selected-over-secp256k1","title":"Why was <code>ed25519</code> selected over <code>secp256k1</code>?","text":"<p>The original key derivation cryptography that was implemented for Polkadot and Substrate chains was <code>ed25519</code>, which is a Schnorr signature algorithm implemented over the Edward's Curve 25519 (so named due to the parameters of the curve equation).</p> <p>Most cryptocurrencies, including Bitcoin and Ethereum, currently use ECDSA signatures on the secp256k1 curve. This curve is considered much more secure than NIST curves, which have possible backdoors from the NSA. The Curve25519 is considered possibly even more secure than this one and allows for easier implementation of Schnorr signatures. A recent patent expiration on it has made it the preferred choice for use in Polkadot.</p> <p>The choice of using Schnorr signatures over using ECDSA is not so cut and dried. Jeff Burdges (a Web3 researcher) provides additional details on the decision in this research post on the topic:</p> <p>Choosing Schnorr signatures over ECDSA signatures</p> <p>There is one sacrifice we make by choosing Schnorr signatures over ECDSA signatures for account keys: Both require 64 bytes, but only ECDSA signatures communicate their public key. There are obsolete Schnorr variants that support recovering the public key from a signature, but they break important functionality like hierarchical deterministic key derivation. In consequence, Schnorr signatures often take an extra 32 bytes for the public key.</p> <p>But ultimately the benefits of using Schnorr signatures outweigh the tradeoffs, and future optimizations may resolve the inefficiencies pointed out in the quote above.</p>"},{"location":"learn/learn-cryptography/#what-is-sr25519-and-where-did-it-come-from","title":"What is <code>sr25519</code> and where did it come from?","text":"<p>Some context: The Schnorr signatures over the Twisted Edward's Curve25519 are considered secure, however Ed25519 has not been completely devoid of its bugs. Most notably, Monero and all other CryptoNote currencies were vulnerable to a double spend exploit that could have potentially led to undetected, infinite inflation.</p> <p>These exploits were due to one peculiarity in Ed25519, which is known as its cofactor of 8. The cofactor of a curve is an esoteric detail that could have dire consequences for the security of implementation of more complex protocols.</p> <p>Conveniently, Mike Hamburg's Decaf paper provides a possible path forward to solving this potential bug. Decaf is basically a way to take Twisted Edward's Curves cofactor and mathematically change it with little cost to performance and gains to security.</p> <p>The Decaf paper approach by the Ristretto Group was extended and implemented in Rust to include cofactor-8 curves like the Curve25519 and makes Schnorr signatures over the Edward's curve more secure.</p> <p>Web3 Foundation has implemented a Schnorr signature library using the more secure Ristretto compression over the Curve25519 in the Schnorrkel repository. Schnorrkel implements related protocols on top of this curve compression such as HDKD, MuSig, and a verifiable random function (VRF). It also includes various minor improvements such as the hashing scheme STROBE that can theoretically process huge amounts of data with only one call across the Wasm boundary.</p> <p>The implementation of Schnorr signatures that is used in Polkadot and implements the Schnorrkel protocols over the Ristretto compression of the Curve25519 is known as sr25519.</p>"},{"location":"learn/learn-cryptography/#are-bls-signatures-used-in-polkadot","title":"Are BLS signatures used in Polkadot?","text":"<p>Not yet, but they will be. BLS signatures allow more efficient signature aggregation. Because GRANDPA validators are usually signing the same thing (e.g. a block), it makes sense to aggregate them, which can allow for other protocol optimizations.</p> <p>From the BLS library's README</p> <p>Boneh-Lynn-Shacham (BLS) signatures have slow signing, very slow verification, require slow and much less secure pairing friendly curves, and tend towards dangerous malleability. Yet, BLS permits a diverse array of signature aggregation options far beyond any other known signature scheme, which makes BLS a preferred scheme for voting in consensus algorithms and for threshold signatures.</p> <p>Even though Schnorr signatures allow for signature aggregation, BLS signatures are much more efficient in some fashions. For this reason it will be one of the session keys that will be used by validators on the Polkadot network and critical to the GRANDPA finality gadget.</p>"},{"location":"learn/learn-cryptography/#randomness","title":"Randomness","text":"<p>Randomness in Proof of Stake blockchains is important for a fair and unpredictable distribution of validator responsibilities. Computers are bad at random numbers because they are deterministic devices (the same input always produces the same output). What people usually call random numbers on a computer (such as in a gaming application), are pseudo-random - that is, they depend on a sufficiently random seed provided by the user or another type of oracle, like a weather station for atmospheric noise, your heart rate, or even lava lamps, from which it can generate a series of seemingly-random numbers. But given the same seed, the same sequence will always be generated.</p> <p>Though, these inputs will vary based on time and space, and it would be impossible to get the same result into all the nodes of a particular blockchain around the world. If nodes get different inputs on which to build blocks, forks happen. Real-world entropy is not suitable for use as a seed for blockchain randomness.</p> <p>There are two main approaches to blockchain randomness in production today: <code>RANDAO</code> and <code>VRF</code>. Polkadot uses VRF.</p>"},{"location":"learn/learn-cryptography/#vrf","title":"VRF","text":"<p>A verifiable random function (VRF) is a mathematical operation that takes some input and produces a random number along with a proof of authenticity that this random number was generated by the submitter. The proof can be verified by any challenger to ensure the random number generation is valid.</p> <p>The VRF used in Polkadot is roughly the same as the one used in Ouroboros Praos. Ouroboros randomness is secure for block production and works well for BABE. Where they differ is that Polkadot's VRF does not depend on a central clock (the problem becomes - whose central clock?), rather, it depends on its own past results to determine present and future results, and it uses slot numbers as a clock emulator, estimating time.</p>"},{"location":"learn/learn-cryptography/#heres-how-it-works-in-detail","title":"Here's how it works in detail:","text":"<p>Slots are discrete units of time six seconds in length. Each slot can contain a block, but may not. Slots make up epochs - on Polkadot, 2400 slots make one epoch, which makes epochs four hours long.</p> <p>In every slot, each validator \"rolls a die\". They execute a function (the VRF) that takes as input the following:</p> <ul> <li>The \"secret key\", a key specifically made for these die rolls.</li> <li>An epoch randomness value, which is the hash of VRF values from the blocks in the epoch before   last (N-2), so past randomness affects the current pending randomness (N).</li> <li>The slot number.</li> </ul> <p></p> <p>The output is two values: a <code>RESULT</code> (the random value) and a <code>PROOF</code> (a proof that the random value was generated correctly).</p> <p>The <code>RESULT</code> is then compared to a threshold defined in the implementation of the protocol (specifically, in the Polkadot Host). If the value is less than the threshold, then the validator who rolled this number is a viable block production candidate for that slot. The validator then attempts to create a block and submits this block into the network along with the previously obtained <code>PROOF</code> and <code>RESULT</code>. Under VRF, every validator rolls a number for themselves, checks it against a threshold, and produces a block if the random roll is under that threshold.</p> <p>The astute reader will notice that due to the way this works, some slots may have no validators as block producer candidates because all validator candidates rolled too high and missed the threshold. We clarify how we resolve this issue and make sure that Polkadot block times remain near constant-time in the wiki page on consensus.</p>"},{"location":"learn/learn-cryptography/#randao","title":"RANDAO","text":"<p>An alternative method for getting randomness on-chain is the RANDAO method from Ethereum. RANDAO requires each validator to prepare by performing many thousands of hashes on some seed. Validators then publish the final hash during a round and the random number is derived from every participant's entry into the game. As long as one honest validator participates, the randomness is considered secure (non-economically viable to attack). RANDAO is optionally augmented with VDF.</p>"},{"location":"learn/learn-cryptography/#vdfs","title":"VDFs","text":"<p>Verifiable Delay Functions are computations that take a prescribed duration of time to complete, even on parallel computers. They produce unique output that can be independently and efficiently verified in a public setting. By feeding the result of RANDAO into a VDF, a delay is introduced that renders any attacker's attempt at influencing the current randomness obsolete.</p> <p>VDFs will likely be implemented through ASIC devices that need to be run separately from the other types of nodes. Although only one is enough to keep the system secure, and they will be open source and distributed at nearly no charge, running them is neither cheap nor incentivized, producing unnecessary friction for users of the blockchains opting for this method.</p>"},{"location":"learn/learn-cryptography/#resources","title":"Resources","text":"<ul> <li>Key discovery attack on BIP32-Ed25519 -   Archive of forum post detailing a potential attack on BIP32-Ed25519. A motivation for transition   to the sr25519 variant.</li> <li>Account signatures and keys in Polkadot -   Research post by Web3 researcher Jeff Burdges.</li> <li>Are Schnorr signatures quantum computer resistant?</li> <li>Polkadot's research on blockchain randomness and sortition -   contains reasoning for choices made along with proofs</li> <li>Discussion on Randomness used in Polkadot - W3F   researchers discuss the randomness in Polkadot and when it is usable and under which assumptions.</li> </ul>"},{"location":"learn/learn-cryptography/#appendix-a-on-the-security-of-curves","title":"Appendix A: On the security of curves","text":"<p>From the Introduction of Curve25519 into <code>libssl</code></p> <p>The reason is the following: During summer of 2013, revelations from ex- consultant at [the] NSA Edward Snowden gave proof that [the] NSA willingly inserts backdoors into software, hardware components and published standards. While it is still believed that the mathematics behind ECC (Elliptic-curve cryptography) are still sound and solid, some people (including Bruce Schneier [SCHNEIER]), showed their lack of confidence in NIST-published curves such as nistp256, nistp384, nistp521, for which constant parameters (including the generator point) are defined without explanation. It is also believed that [the] NSA had a word to say in their definition. These curves are not the most secure or fastest possible for their key sizes [DJB], and researchers think it is possible that NSA have ways of cracking NIST curves. It is also interesting to note that SSH belongs to the list of protocols the NSA claims to be able to eavesdrop. Having a secure replacement would make passive attacks much harder if such a backdoor exists.</p> <p>However an alternative exists in the form of Curve25519. This algorithm has been proposed in 2006 by DJB [Curve25519]. Its main strengths are its speed, its constant-time run time (and resistance against side-channel attacks), and its lack of nebulous hard-coded constants.</p>"},{"location":"learn/learn-elastic-scaling/","title":"Parallel Computing","text":"<p>     To fully follow the material on this page, it is recommended to be familiar with the primary stages of the             Parachain Protocol.      </p> \u2716 <p>Parallel computing involves performing many calculations or processes simultaneously by dividing tasks into sub-tasks that run on multiple processors or cores. This is essential for high-performance computing tasks, where many operations are executed in parallel to speed up processing.</p> <p>Polkadot uses pipelining and multi-threading to increase throughput and achieve concurrency, respectively. Polkadot also provides throughput boost via parallel computation for a single task with elastic scaling: parachains can use multiple cores to include multiple parablocks within the same relay chain block.</p> <p>The relay chain receives a sequence of parachain blocks on multiple cores, which are validated and checked if all their state roots line up during their inclusion, but assume they\u2019re unrelated parachain blocks during backing, availability, and approvals. With elastic scaling implemented, a parachain's throughput depends upon its collator infrastructure.</p> <p>The elastic scaling implementation will be rolled out in multiple phases. In the first phase, elastic scaling is set to work on parachains with a trusted/permissioned collator set. With this restriction, it is possible to launch elastic scaling without changing the candidate receipt. After successfully implementing the first phase, changes can be made to the candidate receipt so the collator set can be untrusted/permissionless again. The final phase will feature full integration with the Cumulus framework, enabling parachains to be configured to access multiple cores continuously.</p> <p>Take, for example, a parachain that wants to submit four parablocks to the relay chain. Without elastic scaling, it will take 24 seconds to include all of them through one core. Remember that a core is occupied after backing and before inclusion, i.e., for the whole data availability process. A block cannot enter a core before the previous block has been declared available.</p> <pre><code>              R1 &lt;----- R2 &lt;----- R3 &lt;----- R4 &lt;----- R5\n\nC1    |P1     B          I\n      |P2                B         I\n      |P3                          B         I\n      |P4                                    B         I\n</code></pre> <p>The diagram above shows how the backing and inclusion of parablocks (P) happen within the same relay chain block (R). With one core (C1), a parablock is included every 6 seconds. Note how P4 is included after 30 seconds (not 24 seconds) because when P1 was pushed to the relay chain for being backed, there was no previous parablock.</p> <p>With elastic scaling, it will take just 12 seconds (3-second block time) to include all four parablocks using two cores.</p> <pre><code>              R1 &lt;----- R2 &lt;----- R3\n\nC1    |P1     B          I\n      |P2                B         I\nC2    |P3     B          I\n      |P4                B         I\n</code></pre> <p>The diagram above shows how four parablocks are backed and included in the relay chain using two cores (C1 and C2). Note how P2 and P4 are included after 18 seconds (not 12 seconds) because when P1 and P3 were pushed to the relay chain for being backed, there were no other parablocks before them.</p>"},{"location":"learn/learn-elastic-scaling/#technical-considerations","title":"Technical Considerations","text":"<p>If the pace per core on the relay chain will not change (backing and inclusion every 6 seconds per core), on the parachain side, collators will need to increase the parablock production rate to push P1 and P2 to the two relay chain cores.</p> <p>Assuming a constant number of cores, from the relay chain side, elastic scaling will not see major upgrades as a parachain will use multiple existing cores instead of just one. However, from the parachain side, collators must produce more parablocks per unit of time, implying that technical specifications for collators will likely increase.</p> <p>For more advanced technical challenges, see the Elastic Scaling GitHub PR.</p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/","title":"Polkadot and Kusama Bridge Guides","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The fully functional Polkadot &lt; &gt; Kusama bridge facilitates secure asset transfers between the chains in both the ecosystems. The progress of Polkadot &lt; &gt; Kusama bridge implementation can be tracked here.</p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/#transfer-dot-to-kusama-asset-hub","title":"Transfer DOT to Kusama Asset Hub","text":"<p>This tutorial shows how to transfer DOT on Polkadot Asset Hub to Kusama Asset Hub. The first step is to ensure that your account on Polkadot Asset Hub has enough DOT to cover the XCM transfer fee and the bridge fee (which is around 2 DOT). The next step is to craft an XCM message to be sent from Polkadot Asset Hub.</p> <p>BagPipes (formerly called xcmsend) is an opensource application that lets you create workflows in a drag and drop style interface in order to build execution flows of cross chain assets transfers using XCM. Check Bagpipes docs for more information on how to create workflows for crafting XCM transfers. The snapshot below shows a workflow on BagPipes that is designed to send 3 DOT from an account Polkadot Asset Hub to Kusama Asset Hub.</p> <p></p> <p>This workflow crafts an XCM transfer as shown below.</p> <pre><code>{\n  \"isSigned\": false,\n  \"method\": {\n    \"args\": {\n      \"dest\": {\n        \"V3\": {\n          \"parents\": \"2\",\n          \"interior\": {\n            \"X2\": [\n              {\n                \"GlobalConsensus\": \"Kusama\"\n              },\n              {\n                \"Parachain\": \"1,000\"\n              }\n            ]\n          }\n        }\n      },\n      \"beneficiary\": {\n        \"V3\": {\n          \"parents\": \"0\",\n          \"interior\": {\n            \"X1\": {\n              \"AccountId32\": {\n                \"network\": null,\n                \"id\": \"this has to be the intended address\"\n              }\n            }\n          }\n        }\n      },\n      \"assets\": {\n        \"V3\": [\n          {\n            \"id\": {\n              \"Concrete\": {\n                \"parents\": \"1\",\n                \"interior\": \"Here\"\n              }\n            },\n            \"fun\": {\n              \"Fungible\": \"30,000,000,000\"\n            }\n          }\n        ]\n      },\n      \"fee_asset_item\": \"0\",\n      \"weight_limit\": \"Unlimited\"\n    },\n    \"method\": \"limitedReserveTransferAssets\",\n    \"section\": \"polkadotXcm\"\n  }\n}\n</code></pre> <p>Once this extrinsic is signed and submitted, it is broadcast to Polkadot Asset Hub nodes. As this is a reserve asset transfer, the DOT is transferred to the destination's sovereign account on Polkadot Asset Hub and DOT is issued as a foreign asset and deposited onto the destination account on Kusama Asset Hub. The foreign asset balances of any account on Kusama Asset Hub can be queried on-chain through the <code>foreignAssets</code>pallet as shown below.</p> <p></p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/#transfer-dot-from-kusama-asset-hub-to-polkadot-asset-hub","title":"Transfer DOT from Kusama Asset Hub to Polkadot Asset Hub","text":"<p>This tutorial shows how to transfer DOT on Kusama Asset Hub to Polkadot Asset Hub. The first step is to ensure that your account on Kusama Asset Hub has enough KSM to cover the XCM transfer fee and the bridge fee (which is around 0.4 KSM). The next step is to craft an XCM message to be sent from Kusama Asset Hub.</p> <p>DOT which is registered as a foreign asset on Kusama Asset Hub can be transferred to Polkadot Asset Hub through an extrinsic like the one below, whose call data is <code>0x1f0b040202090200a10f04000101009e4e7009937c56d267338762a60ed004293afd40e7c2081847c12cb63c76a818040402010902000700e40b54020000000000</code>.</p> <p>If you plan on reusing this extrinsic, ensure that you change the Account ID and the transfer amount below.</p> <p></p> <p>For reference, this extrinsic is signed and submitted successfully, and the destination account on Polkadot Asset Hub received DOT.</p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/#transfer-ksm-to-polkadot-asset-hub","title":"Transfer KSM to Polkadot Asset Hub","text":"<p>This tutorial shows how to transfer KSM on Kusama Asset Hub to Polkadot Asset Hub. The first step is to ensure that your account on Kusama Asset Hub has enough KSM to cover the XCM transfer fee and the bridge fee (which is around 0.4 KSM). The next step is to craft an XCM message to be sent from Kusama Asset Hub.</p> <p>The XCM transfer extrinsic shown below can be accessed here.</p> <p>If you plan on reusing this extrinsic, ensure that you change the Account ID and the transfer amount highlighted in the snapshot below.</p> <p></p> <p>Once this extrinsic is signed and submitted, it is broadcast to Kusama Asset Hub nodes. As this is a reserve asset transfer, the KSM is transferred to the sovereign account on Kusama Asset Hub and KSM is issued as a foreign asset and deposited onto the destination account on Kusama Asset Hub. The foreign asset balances of any account on Kusama Asset Hub can be queried on-chain through the <code>foreignAssets</code>pallet as shown below.</p> <p></p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/#transfer-ksm-from-polkadot-asset-hub-to-kusama-asset-hub","title":"Transfer KSM from Polkadot Asset Hub to Kusama Asset Hub","text":"<p>This tutorial shows how to transfer KSM on Polkadot Asset Hub to Kusama Asset Hub. The first step is to ensure that your account on Polkadot Asset Hub has enough DOT to cover the XCM transfer fee and the bridge fee (which is around 2 DOT). The next step is to craft an XCM message to be sent from Polkadot Asset Hub.</p> <p>KSM which is registered as a foreign asset on Polkadot Asset Hub can be transferred to Kusama Asset Hub through an extrinsic like the one below, whose call data is <code>0x1f0b040202090300a10f04000101008479c8ea5480acca5a847133cd97a87801b6e698a98f2eab0e8e9d5c51b14a33040402010903000700a0db215d0000000000</code></p> <p></p> <p>For reference, this extrinsic was signed and submitted successfully, and the destination account on Kusama Asset Hub received KSM.</p>"},{"location":"learn/learn-guides-DOT-KSM-bridge/#transfer-of-arbitrary-assets-between-polkadot-asset-hub-and-kusama-asset-hub","title":"Transfer of arbitrary assets between Polkadot Asset Hub and Kusama Asset Hub","text":"<p>Transfer functionality of assets other than DOT and KSM between Asset Hubs is yet to be enabled. Once this functionality is enabled, assets which are sufficient or non-sufficient on the Asset Hubs can be bridged.</p> <p>Avoid Asset Traps</p> <p>To avoid issues on the receiving side for non-sufficient assets, make sure to call pallet_assets::touch() or pallet_assets::touch_other() effectively guaranteeing the ability to successfully receive and accept the bridged assets in your account on the destination chain. This eliminates issues like your account on destination not existing or not having enough ED or having reached the maximum limit of different assets it can hold. Without this sanity step, you risk that the bridged assets will make their way to the destination chain but will not be accepted by your account, and instead get trapped in the Asset Trap on the destination chain.</p> <p>Once arbitrary asset transfers are enabled by the Asset Hubs, a guide will be posted to this Wiki page.</p>"},{"location":"learn/learn-guides-accounts-multisig/","title":"Polkadot-JS Guides about Multi-signature Accounts","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-accounts-multisig/#creating-a-multisig-account","title":"Creating a Multisig Account","text":"<p>Check the \"How to create a multisig account\" section on this support page. We recommend trying out the tutorial on Westend network - Polkadot's testnet.</p>"},{"location":"learn/learn-guides-accounts-multisig/#multisig-transactions-with-accounts-tab","title":"Multisig Transactions with Accounts Tab","text":"<p>Walkthrough Video Tutorial</p> <p>See this video tutorial to learn how to transact with a multisig account using the Accounts Tab in the Polkadot-JS UI.</p> <p>You can create a multisig account directly on the Accounts Tab of the Polkadot-JS UI, and use this account to send funds. See this support article for more information.</p>"},{"location":"learn/learn-guides-accounts-multisig/#multisig-transactions-with-extrinsic-tab","title":"Multisig Transactions with Extrinsic Tab","text":"<p>See the video tutorial below to learn about multi-signature accounts and how you can transact with them using the Polkadot-JS UI.</p> <p> Transact with Multi-signature Accounts </p> <p>There are three types of actions you can take with a multisig account:</p> <ul> <li>Executing a call <code>asMulti</code>. This is used to begin or end a multisig transaction.</li> <li>Approving a call <code>approveAsMulti</code>. This is used to approve an extrinsic and pass-on to the next   signatory (see example below for more information).</li> <li>Cancelling a call <code>cancelAsMulti</code>.</li> </ul> <p>Info</p> <p>Check out this page for more information about the actions you can take with a multi-signature account.</p> <p>In scenarios where only a single approval is needed, a convenience method <code>as_multi_threshold_1</code> should be used. This function takes only the other signatories and the raw call as arguments. Note that the Polkadot-JS UI does not have integration for this call because it is not possible to create multisig accounts with <code>threshold=1</code>. If you want to create a multisig with threshold 1, you can use txwrapper-core, which is developed and supported by Parity Technologies. There is a detailed multisig example that you can try out and change to see how it works.</p> <p>However, in anything but the simple one approval case, you will likely need more than one of the signatories to approve the call before finally executing it.</p>"},{"location":"learn/learn-guides-accounts-multisig/#multisig-call-deposit","title":"Multisig Call Deposit","text":"<p>When you create a new multi-sig call, you will need to place a deposit. The deposit stays locked until the call is executed. This deposit is to establish an economic cost on the storage space that the multisig call takes up in the chain state and discourage users from creating multisig calls that never get executed. The deposit will be reserved in the call initiator's account.</p> <p>The deposit is dependent on the <code>threshold</code> parameter and is calculated as follows:</p> <pre><code>Deposit = depositBase + threshold * depositFactor\n</code></pre> <p>Where <code>depositBase</code> and <code>depositFactor</code> are chain constants set in the runtime code.</p> <p>The other signatory accounts should have enough funds to pay for the transaction fees associated with approving the multisig call. The deposit is for the call; that is, other signatories will not need to place additional deposits. Once the multisig call is executed or rejected, the deposit is released on the account that initiated the call.</p>"},{"location":"learn/learn-guides-accounts-multisig/#example-using-multisig-accounts","title":"Example using Multisig Accounts","text":"<p>Walk-through video tutorial</p> <p>See this video tutorial to learn how to transact with a multisig account using the Extrinsic Tab in the Polkadot-JS UI.</p> <p></p> <p>Let's consider an example of a multisig on Polkadot with a threshold of 2 and 3 signers: Charlie, Dan, and Eleanor. First, Charlie will create the call on-chain by calling the <code>multisig.asMulti</code> extrinsic with the raw call, in this case, a balance transfer (<code>balances.transferKeepAlive</code> extrinsic) from multisig CDE to Frank's account. When doing this, Charlie will have to deposit <code>DepositBase + (2 * DepositFactor) = 20.152 DOT</code> while he waits for either Dan or Eleanor also to approve the balance transfer call using the <code>multisig.approveAsMulti</code> or the <code>multisig.asMulti</code> extrinsics.</p> <p>If Dan submits the <code>multisig.approveAsMulti</code> extrinsic, he approves Charlie's call but he passes on the final approval to Eleanor. So, although the multisig has threshold 2, in this case all 3/3 signatories need to participate in the transaction approval. Eleanor will need to submit a <code>multisig.asMulti</code> or <code>multisig.approveAsMulti</code> extrinsic to transfer funds from CDE to Frank.</p> <p>Alternatively, Dan or Eleanor can just submit a <code>multisig.asMulti</code> extrinsic after Charlie to transfer the funds. In this case, \u2154 signatories will participate in the transaction approval. The accounts approving Charlie's call will not need to place the deposit, and Charlie will receive his deposit back once the transfer is successful or canceled. To cancel the transaction, Dan or Eleanor can use the <code>multisig.cancelAsMulti</code> extrinsic.</p> <p>Note that multisigs are deterministic, which means that multisig addresses are generated from the addresses of signers and the threshold of the multisig wallet. No matter the order of the signatories' accounts, the multisig will always have the same address because accounts' addresses are sorted in ascending order.</p> <p>Addresses that are provided to the multisig wallet are sorted</p> <p>Public keys of signers' wallets are compared byte-for-byte and sorted ascending before being used to generate the multisig address. For example, consider the scenario with three addresses, A, B, and C, starting with <code>5FUGT</code>, <code>5HMfS</code>, and <code>5GhKJ</code>. If we build the ABC multisig with the accounts in that specific order (i.e. first A, then B, and C), the real order of the accounts in the multisig will be ACB. If, in the Extrinsic tab, we initiate a multisig call with C, the order of the other signatories will be first A, then B. If we put first B, then A, the transaction will fail.</p> <p>This has some implications when using the Extrinsics tab on the Polkadot-JS UI to perform multisig transactions. If the order of the other signatories is wrong, the transaction will fail. This does not happen if the multisig is executed directly from the Accounts tab (recommended). The Polkadot-JS UI supports multisig accounts, as documented on the Account Generation page. You can see our video tutorials for more information about creating multisig accounts and transacting with them using both the Accounts Tab and the Extrinsic Tab in the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-accounts-multisig/#decoding-multisig-call-data","title":"Decoding Multisig Call Data","text":"<p>Info</p> <p>Before signing a transaction, it is important to know the exact specifics of what is being signed. Check the \"How to use a multisig account\" in the support docs on how to decode the multisig call data.</p>"},{"location":"learn/learn-guides-accounts-proxy-pure/","title":"Polkadot-JS Guides about Pure Proxy Accounts","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The Account Tab in the Polkadot-JS UI cannot handle complex proxy setups</p> <p>The Accounts Tab in the Polkadot-JS UI cannot handle complex proxy setups (e.g. a proxy -&gt; multisig -&gt; a pure proxy which is part of another multisig). These complex setups must be done using the Extrinsics Tab directly.</p> <p>We recommend to use the Westend Testnet if you are testing features for the first time. By performing the complex proxy setups on the testnet, you can comfortably replicate the procedure on the main networks.</p> <p>Risk of loss of funds</p> <p>Read carefully the text below and before performing any action using pure proxies, experiment on the Westend testnet.</p>"},{"location":"learn/learn-guides-accounts-proxy-pure/#create-and-remove-pure-proxies-with-polkadot-js","title":"Create and Remove Pure Proxies with Polkadot-JS","text":"<p>To create a pure proxy see this support article, or watch this technical explainer video.</p> <p>Removing Pure Proxies</p> <p>The procedure for removing a pure proxy is different from the one used to remove other proxies. Visit the section \"Removing an Anonymous Proxy\" on this support article, or watch this technical explainer video.</p> <p>Learn more about pure proxies from our technical explainer video.</p>"},{"location":"learn/learn-guides-accounts-proxy-pure/#advanced-account-management-with-pure-proxies","title":"Advanced Account Management with Pure Proxies","text":"<p>Walk-through tutorial video of Account Management</p> <p>You can see this video tutorial that goes through the example below. The tutorial requires some familiarity with the Extrinsic Tab of the Polkadot-JS UI.</p> <p>Let's take for example 3 accounts belonging to Charlie, Dan and Eleanor working for Company X. Charlie holds funds belonging to Company X, but he wants to leave the company and transfer the economic responsibility to Eleanor. Dan is a staking proxy of Charlie.</p> <p>Without Pure Proxy, Charlie must (see left side of the Figure below):</p> <ul> <li>Remove Dan as a staking proxy, this step requires 1 signature</li> <li>Stop nominating and unbound all funds , this step requires 2 signatures</li> <li>Transfer the funds to Eleanor, this step requires 1 signature</li> </ul> <p>Then Eleanor adds Dan as a staking proxy (1 signature). The whole process requires 5 signatures. Here we are presenting a simple example, in fact, with multi-signature accounts and multiple proxies the procedure would be more time-consuming and labor-intensive.</p> <p></p> <p>With Pure Proxy (see right side of the Figure above), Charlie must add Eleanor as any proxy of the pure proxy, and remove himself (or Eleanor can remove him). The process requires just 2 signatures (1 signature to add the new any proxy and 1 signature the remove the old one). The funds remain in the pure proxy, and it is not necessary to stop nominating or unbond funds. Also, any proxy relationships with the pure proxy stay in place. Thus, if we use the pure proxy, with an increasing number of proxies we will always have to sign twice (not necessarily true in multi-signature accounts). While if we are not using the pure proxy, the more the proxies the more signatures we need to detach them from the old stash and attach them to the new stash (see Figure below).</p> <p></p>"},{"location":"learn/learn-guides-accounts-proxy-pure/#pure-proxies-and-multisigs","title":"Pure Proxies and Multisigs","text":""},{"location":"learn/learn-guides-accounts-proxy-pure/#scenario-one-one-pure-proxy-within-a-multisig","title":"Scenario One: One Pure Proxy within a Multisig","text":"<p>Walk-through tutorial video</p> <p>You can see this video tutorial that goes through this scenario. The tutorial requires some familiarity with the Extrinsic Tab of the Polkadot-JS UI.</p> <p>It is possible to put a pure proxy within a multisig, and then transactions will be signed by the any proxy on behalf of the pure proxy (proxied account). Let's take for example the diagram below. Alice, Bob and Anon are part of the multisig ABC, a multisig account with threshold 2. P-C is a pure proxy spawned by Charlie, who now acts as any proxy and thus signs anything on behalf of P-C. The pure proxy cannot sign directly because it does not have a private key. So, for example, to send funds from the multisig to Dan, Charly needs to submit a <code>proxy.proxy</code> extrinsic to P-C, which in turn will submit a <code>multisig.asMulti</code> extrinsic to ABC containing the call data for the <code>balances.transferKeepAlive</code> extrinsic about the transfer of some funds from ABC to Dan. Alice can then approve the transfer by submitting a <code>multisig.asMulti</code> extrinsic also containing the call data for the <code>balances.transferKeepAlive</code> extrinsic about the transfer of some funds from ABC to Dan.</p> <p></p> <p>If Charly wants to leave the multisig, a new any proxy can be added to P-C and Charly can be removed (by himself or by the new any proxy). Note that the multisig also contains Bob that in this specific example does not do anything.</p> <p>Proxy calls</p> <p>To use a pure proxy within a multisig you need to use the Extrinsic Tab and generate a <code>proxy.proxy</code> extrinsic. If you try to sign a multisig transaction using the pure proxy you will be prompted with a warning. Remember, you cannot sign something directly if you do not have a private key.</p>"},{"location":"learn/learn-guides-accounts-proxy-pure/#scenario-two-multisig-made-of-pure-proxies","title":"Scenario Two: Multisig made of Pure Proxies","text":"<p>Walk-through Tutorial Video</p> <p>You can see this video tutorial that goes through this scenario. The tutorial requires some familiarity with the Extrinsic Tab of the Polkadot-JS UI.</p> <p>The diagram below shows a multisig that is made only with pure proxies (P-A, P-B and P-C). In this situation Alice, Bob or Charly can leave the multisig at any time without the requirement of creating a new multisig. If for example, Bob leaves the multisig the procedure will require somebody else to be added as any proxy to P-B, and then Bob can remove himself (or the new any proxy can remove Bob).</p> <p></p> <p>In the diagram above, Alice submits the <code>proxy.proxy</code> extrinsic to P-A, which in turn submits the <code>multisig.asMulti</code> extrinsic containing the <code>balances.transferKeepAlive</code> extrinsic about the transfer of some tokens from ABC to Dan. Then, Charly does the same to confirm the transaction. Note that Charly will need to pay for some weight, for the computation that is necessary to execute the transaction.</p>"},{"location":"learn/learn-guides-accounts-proxy-pure/#scenario-three-multisig-controlling-a-pure-proxy","title":"Scenario Three: Multisig controlling a Pure Proxy","text":"<p>This setup is used by the MultiX tool.</p> <p>After its creation, a multi-signature account creates a pure proxy that becomes the proxied account. The multi-signature account behaves as any proxy of the pure. If signatories of the multi-signature account change, a new multisig can be created, assigned as any proxy of the pure, and then the old multisig can be removed as a proxy.</p> <p></p> <p>Compared to Scenario Two, signatories do not need to create pure proxies here. Multisig controlling a Pure Proxy is a more practical solution, where the signatories, number of signatories and/or the threshold can be changed, which changes the multisig address but does not impact the pure proxy address. In Scenario Two, if signatories behind the pure proxies change, the address of the multisig stays the same. However, changing the number of signatories and threshold would not be possible.</p>"},{"location":"learn/learn-guides-accounts-proxy/","title":"Polkadot-JS Guides about Proxy Accounts","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>Proxies allow users to use an account (it can be in cold storage or a hot wallet) less frequently but actively participate in the network with the weight of the tokens in that account. Proxies are allowed to perform a limited amount of actions related to specific substrate pallets on behalf of another account. The videos below contain more information about using proxies.</p> <p> Proxy Accounts Tutorial </p> <p> Proxy Accounts Advanced Tutorial </p> <p>Know how to check the calls and pallets accessible by proxies</p> <p>For the latest information on the calls and pallets that can be fully accessed by proxies, check the source code in the runtime folder on the Polkadot repository</p>"},{"location":"learn/learn-guides-accounts-proxy/#creating-proxy-with-polkadot-js","title":"Creating Proxy with Polkadot-JS","text":"<p>To create a proxy account with Polkadot-JS read this support article.</p>"},{"location":"learn/learn-guides-accounts-proxy/#removing-proxy-with-polkadot-js","title":"Removing Proxy with Polkadot-JS","text":"<p>Read the section \"Removing Proxies\" on this support page to learn how to remove proxies.</p>"},{"location":"learn/learn-guides-accounts-proxy/#view-your-proxy-on-polkadot-js","title":"View your Proxy on Polkadot-JS","text":"<p>To view your proxy, just go on the Accounts menu in the Polkadot-JS UI, next to the proxied account you will notice a blue icon. Hover on it, and you will see Proxy overview. Click on it and you will be presented with a list of all proxies for that account.</p> <p></p> <p>Additionally, you can head over to the Chain State tab (underneath the Developer menu) on Polkadot-JS Apps. If you've created your proxy on a Polkadot account, it is required to change your network accordingly using the top left navigation button. On this page, the proxy pallet should be selected, returning the announcements and proxies functions. The proxies function will allow you to see your created proxies for either one account or for all accounts (using the toggle will enable this). Proxy announcements are what time lock proxies do to announce they are going to conduct an action.</p> <p></p>"},{"location":"learn/learn-guides-accounts-proxy/#set-up-and-use-of-time-delayed-proxies-with-polkadot-js","title":"Set-up and Use of Time-delayed Proxies with Polkadot-JS","text":"<p>Info</p> <p>See this video tutorial to learn how you can setup and use time-delayed proxies. The video goes through the example below.</p> <p>Initially the time time-delayed proxy announces its intended action using the <code>proxy.announce</code> extrinsic and will wait for the number of blocks defined in the delay time before executing it. The proxy will include the hash of the intended function call in the announcement. Within this time window, the intended action may be canceled by accounts that control the proxy. This can be done by the proxy itself using the <code>proxy.removeAnnouncement</code> extrinsic or by the proxied account using the the <code>proxy.rejectAnnouncement</code> extrinsic. Now we can use proxies knowing that any malicious actions can be noticed and reverted within a delay period. After the time-delay, the proxy can use the <code>proxy.proxyAnnounced</code> extrinsic to execute the announced call.</p> <p>Let's take for example the stash account Eleanor setting Bob as a time-delayed staking proxy. In this way, if Bob submits an extrinsic to change the reward destination, such extrinsic can be rejected by Eleanor. This implies that Eleanor monitors Bob, and that within the time-delay she can spot the announced extrinsic. Eleanor can check all the proxy call announcements made by her account's proxies on-chain. On Polkadot-JS UI, go to Developer &gt; Storage &gt; Proxy &gt; Announcements to check the hashes for the calls made by the proxy accounts and the block height at which they are enabled for execution.</p> <p></p> <p>Info</p> <p>If you try to use <code>proxy.proxyAnnounced</code> to execute the call within the time-delay window you will get an error \"Proxy unannounced\" since the announcement will be done after the time delay. Also note that regular <code>proxy.proxy</code> calls do not work with time-delayed proxies, you need to announce the call first and then execute the announced call on a separate transaction.</p>"},{"location":"learn/learn-guides-accounts-proxy/#proxy-calls","title":"Proxy calls","text":"<p>Proxy calls are used by proxies to call proxied accounts. These calls are important for example in the case of pure proxies, as any attempt to sign transactions with a pure proxy will fail. For more details see the dedicated section about pure proxies.</p>"},{"location":"learn/learn-guides-accounts-proxy/#nested-proxy-calls","title":"Nested Proxy Calls","text":"<p>As the term suggests, nested proxy calls are proxy calls within proxy calls. Such calls are needed if there are proxied accounts that are proxies themselves. In the example diagram below, Alice has a stash account that has a staking proxy account, P-C. P-C is a pure proxy, a proxied account originally spawned by Charly that is now an any proxy of P-C and signs everything on its behalf.</p> <p></p> <p>For example, to bond more funds, Charly needs to submit a <code>prox.proxy</code> extrinsic to P-C, which in turn submits a <code>proxy.proxy</code> extrinsic to Alice including for example a <code>staking.bondExtra</code> extrinsic, specifying the number of extra tokens that need to be bounded. If Charly wants to leave, a new account can take his place as any proxy (before Charly leaves!). There is no need to change the staking proxy account. Also, Alice is the only one who can remove P-C as a staking proxy, and P-C can only perform staking-related tasks. For example, P-C cannot send funds out from Alice's account.</p> <p>Proxy calls can be done using the Extrinsic Tab in the Polkadot-JS UI. Nested proxy calls can be done by calling each <code>proxy.proxy</code> extrinsic separately, or in some cases by just calling the last <code>proxy.proxy</code> extrinsic. In the diagram above, submitting the proxy call from P-C to Alice will automatically ask for Charly's signature. Thus one proxy call will trigger the second one because Charly's is the only any proxy of P-C, and P-C cannot sign anything. While if we want to use Bob's account we will need to submit all three proxy calls.</p>"},{"location":"learn/learn-guides-accounts/","title":"Polkadot-JS Guides about Accounts","text":"<p>import Tabs from \"@theme/Tabs\"; import TabItem from \"@theme/TabItem\"; import DocCardList from '@theme/DocCardList';</p> <p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-accounts/#account-address-format","title":"Account Address Format","text":"<p>An account created on the relay chain can also be used on multiple chains in the ecosystem. More specifically, the account of a chain that uses the <code>*25519</code> account address format (the latest list can be accessed on the ss58 registry repository) is cross-compatible with all the chains that use the similar format. To switch between the accounts on different chains, you can follow the guidelines in this support article. Subscan has a tool you can use to convert your address between the different chain formats.</p> <p>Using the same account on multiple chains - Pros and Cons</p> <p>The address format differs from chain to chain, but that difference is only visual. The same private</p> <p>key can be used to sign transactions on behalf of the respective accounts on multiple chains. Using a single account on multiple chains is convenient, as you do not have to deal with multiple mnemonic phrases or private keys. But, if your account gets compromised on one chain, the attacker can gain full access to the accounts on all other chains. This also has implications for the account holder's privacy, as knowing the identity of an account on one chain can expose the account holder's identity on all the chains. In the Accounts tab, the Polkadot-JS UI displays a warning message next to each Account you are using on multiple chains and recommends using different Accounts on different chains (see below).</p> <p></p> <p>On Polkadot-JS Extension, you can copy your address by clicking the account's icon while the desired chain format is active. E.g. selecting \"Substrate\" as the format will change your address, and clicking the colorful icon of your account will copy it in that format.</p>"},{"location":"learn/learn-guides-accounts/#polkadot-js-browser-extension","title":"Polkadot-JS Browser Extension","text":"<p> Polkadot-JS Browser Extension Tutorial </p> <p>Info</p> <p>For guidelines about how to create an account using the Polkadot Extension, see</p> <p>this video tutorial and visit this support article.</p> <p>The Polkadot-JS Browser Extension (the Polkadot Extension) provides a reasonable balance of security and usability. It provides a separate local mechanism to generate your address and interact with Polkadot.</p> <p>This method involves installing the Polkadot Extension and using it as a \u201cvirtual vault,\" separate from your browser, to store your private keys. It also allows the signing of transactions and similar functionality.</p> <p>It is still running on the same computer you use to connect to the internet and thus is less secure than using Parity Signer or other air-gapped approaches.</p>"},{"location":"learn/learn-guides-accounts/#account-backup-using-the-polkadot-js-browser-extension","title":"Account Backup using the Polkadot-JS Browser Extension","text":"<p>See this video tutorial and visit this support page to know how to back up your account.</p>"},{"location":"learn/learn-guides-accounts/#reset-password-using-the-polkadot-js-browser-extension","title":"Reset Password using the Polkadot-JS Browser Extension","text":"<p>Info</p> <p>See this video tutorial to learn how to change the password for an account that has been created on the Polkadot-JS browser extension (i.e. an injected account).</p> <p>Warning</p> <p>Before following the instructions below, make sure you have your mnemonic phrase stored in a safe place accessible to you.</p> <p>Let's say you created <code>ACCOUNT 1</code> protected by password <code>PSW 1</code>. To reset the password of your <code>ACCOUNT 1</code> using the browser extension, you must follow the following steps:</p> <ul> <li>Go to <code>ACCOUNT 1</code> on the browser extension and click \"Forget account\". This action will delete the   access to your account. Note that your tokens are still in your account on the Polkadot network.</li> <li>On the browser extension click the \"+\" button in the top right corner and select the option   \"Import account from pre-existing seed\". After entering the mnemonic phrase, you can choose a new   password, <code>PSW 2</code>.</li> </ul> <p>JSON files do not allow changing account passwords</p> <p>If you add the account to the extension using the option \"Restore account from backup JSON file\", this will allow you to restore access to your account using a JSON file protected by the password <code>PSW 1</code>, but does not let you set a new password. Thus, <code>PSW 1</code> will become the account password by default.</p> <p>Accounts on Cold wallets do not need passwords</p> <p>For hardware wallets such as Ledger, you may have to set a PIN for accessing the accounts on the device, but you do not need to set a password for every individual account. When you need to make transactions with your account, you are required to sign using your Ledger device. Also, Ledger wallets let you generate multiple accounts for multiple blockchain networks without setting different passwords to access such accounts.</p>"},{"location":"learn/learn-guides-accounts/#restore-account-on-the-polkadot-js-browser-extension","title":"Restore Account on the Polkadot-JS Browser Extension","text":"<p>Info</p> <p>See this video tutorial and this support page to learn how to restore your account on the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-accounts/#polkadot-js-ui","title":"Polkadot-JS UI","text":"<p>Info</p> <p>For guidelines about how to create an account using Polkadot-JS UI, see this video tutorial and visit this support article.</p> <p>Caution</p> <p>If you use this method to create your account and clear your cookies in your browser, your account will be lost forever if you do not back it up. Make sure you store your seed phrase in a safe place or download the account's JSON file if using the Polkadot-JS browser extension. Learn more about account backup and restoration here.</p> <p>Local in-browser account storage is disabled by default on the Polkadot-JS UI. To create an account using the Polkadot-JS UI, navigate to settings &gt; account options and click on allow local in-browser account storage in the drop-down menu. Using the Polkadot-JS user interface without a browser extension is not recommended. It is the least secure way of generating an account. It should only be used if all other methods are not feasible.</p>"},{"location":"learn/learn-guides-accounts/#account-backup-using-the-polkadot-js-ui","title":"Account Backup using the Polkadot-JS UI","text":"<p>Info</p> <p>See this video tutorial and visit this support page to know how to back up your account.</p>"},{"location":"learn/learn-guides-accounts/#reset-password-using-the-polkadot-js-ui","title":"Reset password using the Polkadot-JS UI","text":"<p>To reset the password of an account created with Polkadot-JS Apps UI, you need to go to the \"Accounts\" tab, click the icon with three vertical dots on your account and select \"Change this account's password\".</p> <p>See this video tutorial to learn how to change the password for an account created on the Polkadot-JS UI (i.e. a non-injected account).</p> <p>Note</p> <p>If you create an account first using Polkadot-JS Apps UI and then add it to the browser extension, you need to follow the guidelines for the browser extension to change the password of such an account.</p>"},{"location":"learn/learn-guides-accounts/#restore-account-on-the-polkadot-js-ui","title":"Restore Account on the Polkadot-JS UI","text":"<p>See this video tutorial and this support page to learn how to restore your account on the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-accounts/#unlocking-locks","title":"Unlocking Locks","text":"<p>Locks do not stack!</p> <p>The biggest lock decides the total amount of locked funds. See this walk-through video tutorial that will guide you in the process of unlocking funds in the example above.</p> <p>In the example, the locked balance is 0.55 KSM because the biggest lock is on democracy and is 0.55 KSM. As soon as the democracy lock is removed the next biggest lock is on staking 0.5 KSM (bonded 0.4 KSM + redeemable 0.1 KSM). This means that the locked balance will be 0.5 KSM, and 0.05 KSM will be added to the transferrable balance. After redeeming the unbonded 0.1 KSM, the locked balance will be 0.4 KSM, and an additional 0.1 KSM will be added to the transferrable balance. Now the biggest lock is still the bonded one. This means that even if we remove the vested lock, the locked balance will still be 0.4 KSM and no tokens will be added to the transferrable balance. To free those bonded tokens we will need to unbond them and wait for the unbonding period to make them redeemable. If we remove the proxy the reserved funds will be automatically added to the transferrable balance.</p>"},{"location":"learn/learn-guides-accounts/#query-account-data-in-polkadot-js","title":"Query Account Data in Polkadot-JS","text":"<p>In the Polkadot-JS UI, you can also query account data under Developer &gt; Chain state. Under <code>selected state query</code> choose the system pallet followed by <code>account(AccountId32): FrameSystemAccountInfo</code>, under <code>Option</code> choose an account, and then click on the \"+\" button on the right.</p> <p></p> <p>Account information include:</p> <ul> <li><code>nonce</code>, the number of transactions the account sent.</li> <li><code>consumers</code>, the number of other modules that currently depend on this account's existence. The   account cannot be reaped until this is zero.</li> <li><code>providers</code>, the number of other modules that allow this account to exist. The account may not be   reaped until this and <code>sufficients</code> are both zero.</li> <li><code>sufficients</code>, the number of modules that allow this account to exist for their own purposes. The   account may not be reaped until this and <code>providers</code> are both zero.</li> <li><code>data</code>, the additional data that belongs to this account. Used to store the balance(s) in a lot of   chains.</li> </ul> <p>More in-depth information about the above data can be found in the substrate code base.</p> <p>The <code>AccountData</code> structure defines the balance types in Substrate. The three types of balances include:</p> <ul> <li><code>free</code>, is the balance that is free but not necessarily transferrable.</li> <li><code>reserved</code>, is the balance that is not free, and it is put on hold for on-chain activity such as   deposits for multi-signature calls, setting up proxies and identities, and other actions that hold   state on the network.</li> <li><code>frozen</code>, is the amount that is free to use for on-chain activity but is locked in staking,   governance, or vesting.</li> </ul> <p>The usable or transferrable balance of the account is currently calculated using the formula below:</p> <pre><code>transferable = free - max(frozen - reserved, ED)\n</code></pre> <p>Where ED is the existential deposit. The total balance of the account is the sum of <code>free</code> and <code>reserved</code> funds. The <code>flags</code> describe extra information about the account.</p> <p>More in-depth information about the above data can be found in the balances pallet in the Substrate code base.</p>"},{"location":"learn/learn-guides-accounts/#vanity-generator","title":"Vanity Generator","text":"<p>The vanity generator is a tool on Polkadot-JS UI that lets you generate addresses that contain a specific substring. For the tutorial on how to create an account using Vanity Generator, visit this support article.</p>"},{"location":"learn/learn-guides-accounts/#encryption-enhancement","title":"Encryption Enhancement","text":"<p>Some newly generated <code>JSON</code> account files cannot be imported (restored) into older wallet software. This is due to an enhanced encryption method, noticeable in a slight delay when encrypting/decrypting your wallet. If you cannot load a <code>JSON</code> file, please use the latest version of the wallet software. If you cannot load it, ensure that the wallet software uses the newest version of the Polkadot API.</p>"},{"location":"learn/learn-guides-asset-conversion/","title":"Asset Conversion Tutorials","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>Wallet and UI Developers</p> <p>The DOT ACP UI project is part of Polkadot initiative for building front-end and UI for Asset Conversion Pallet on Polkadot's Asset Hub. Currently, the app is deployed on Westend and Kusama here.</p> <p>The tutorial below demonstrates the complete journey from creating a liquidity pool on Paseo test net and exploring all of the key functionalities of Asset Conversion pallet.</p>"},{"location":"learn/learn-guides-asset-conversion/#create-a-liquidity-pool","title":"Create a Liquidity Pool","text":"<p>If there is no existing liquidity pool for an asset on Asset Hub, the first step is to create a liquidity pool. If you are looking for a guide on how to create an asset on Asset Hub, it is available here.</p> <p>The <code>create_pool</code> function is used to create an empty liquidity pool along with a new <code>lp_token</code> asset. This asset's ID is announced in the <code>Event::PoolCreated</code> event. After creating a pool, liquidity can be added to it via the <code>Pallet::add_liquidity</code> function.</p> <p>For example, the snapshot below shows how to create liquidity pool with <code>PAS</code> tokens and <code>EDU</code> tokens with the asset ID <code>149</code> on Paseo Asset Hub. Creating this extrinsic requires knowledge of XCM Multilocations. From the perspective of AssetHub, an Asset Hub, the asset with an <code>AssetId</code> of <code>149</code> has a MultiLocation of</p> <pre><code>{\n   parents: 0,\n   interior: {\n     X2: [{PalletInstance: 50}, {GeneralIndex: 149}]\n   }\n}\n</code></pre> <p>The PalletInstance of <code>50</code> represents the Assets pallet on Asset Hub and the <code>GeneralIndex</code> is the <code>AssetId</code> of the asset.</p> <p></p> <p>The <code>lp_token</code> ID created for this pool is <code>24</code>, and here is the event for reference.</p>"},{"location":"learn/learn-guides-asset-conversion/#liquidity-provision","title":"Liquidity Provision","text":"<p>The <code>add_liquidity</code> function allows users to provide liquidity to a pool composed of two assets. It requires specifying the desired amounts for both assets and minimum acceptable amounts. The function calculates an optimal contribution of assets, which may differ from the desired amounts but will not be less than the specified minimums. Liquidity providers receive liquidity tokens representing their share of the pool.</p> <p>For example, the snapshot below shows how to provide liquidity to the pool with <code>PAS</code> tokens and <code>EDU</code> tokens with the asset ID <code>149</code> on Paseo Asset Hub. The intention is to provide liquidity of 1 <code>PAS</code> token (<code>u128</code> value of <code>1000000000000</code> as it has 12 decimals) and 100 <code>EDU</code> tokens (<code>u128</code> value of <code>1000000000000</code> as it has 10 decimals).</p> <p></p> <p>After successful submission of the extrinsic above, LP tokens are minted to the specified account. Below is the snapshot of the liquidity pool on the DOT ACP UI.</p> <p></p>"},{"location":"learn/learn-guides-asset-conversion/#swap-assets","title":"Swap Assets","text":""},{"location":"learn/learn-guides-asset-conversion/#swap-from-an-exact-amount-of-tokens","title":"Swap from an exact amount of Tokens","text":"<p>The <code>swap_exact_tokens_for_tokens</code> function allows users to swap a precise amount of one asset for another within a specified liquidity pool, ensuring the user receives at least a minimum expected amount of the second asset in return. This function aims to provide predictability in trading outcomes, allowing users to manage their asset exchanges with confidence regarding the minimum return.</p> <p>For example, the snapshot below shows how to swap <code>PAS</code> tokens to <code>EDU</code> tokens with the asset ID <code>149</code> on Paseo Asset Hub. The intention is to swap 0.1 <code>PAS</code> tokens (<code>u128</code> value of <code>100000000000</code> as it has 12 decimals) to at least 9 <code>EDU</code> tokens (<code>u128</code> value of <code>90000000000</code> as it has 10 decimals).</p> <p></p> <p>Below is the snapshot of the liquidity pool on the DOT ACP UI. after successful submission of the extrinsic above. It can be observed that the pool now has 1.1 <code>ROC</code> tokens and around 9.06 <code>EDU</code> tokens are transferred out of it.</p> <p></p>"},{"location":"learn/learn-guides-asset-conversion/#swap-to-an-exact-amount-of-tokens","title":"Swap to an exact amount of Tokens","text":"<p>On the other hand, the <code>swap_tokens_for_exact_tokens</code> function allows users to trade a flexible amount of one asset to precisely obtain a specified amount of another asset. It ensures that users do not spend more than a predetermined maximum amount of the initial asset to acquire the exact target amount of the second asset, providing a way to control the cost of the transaction while achieving the desired outcome.</p> <p>For example, the snapshot below shows how to swap <code>EDU</code> tokens with the asset ID <code>149</code> on Paseo Asset Hub to <code>PAS</code> Tokens. The intention is to swap for obtaining 0.1 <code>PAS</code> tokens (<code>u128</code> value of <code>100000000000</code> as it has 12 decimals) for a maximum of 10 <code>EDU</code> tokens (<code>u128</code> value of <code>100000000000</code> as it has 10 decimals).</p> <p></p> <p>Below is the snapshot of the liquidity pool on the DOT ACP UI. after successful submission of the extrinsic above.</p> <p></p>"},{"location":"learn/learn-guides-asset-conversion/#withdraw-provided-liquidity","title":"Withdraw Provided Liquidity","text":"<p>The <code>remove_liquidity</code> function allows users to withdraw their provided liquidity from a pool, receiving back the original assets. When calling this function, users specify the amount of liquidity tokens (representing their share in the pool) they wish to burn. They also set minimum acceptable amounts for the assets they expect to receive back. This mechanism ensures users can control the minimum value they receive, protecting against unfavourable price movements during the withdrawal process\u200b.</p> <p>For example, the snapshot below shows how to remove liquidity by specifying the number of LP tokens. In exchange of removing around half of the liquidity of the pool, the expecation is that we receive at least 0.4 <code>ROC</code> tokens (<code>u128</code> value of<code>400000000000</code> as it has 12 decimals) and 40 <code>EDU</code> tokens (<code>u128</code> value of <code>400000000000</code> as it has 10 decimals).</p> <p></p> <p>Below is the snapshot of the liquidity pool on the DOT ACP UI. after successful submission of the extrinsic above.</p> <p></p>"},{"location":"learn/learn-guides-assets-create/","title":"Polkadot-JS Guides about Creating Assets","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The Asset Hub is a generic assets system parachain which provides functionality for deploying and transferring assets \u2014 both Fungible and Non-Fungible Tokens (NFTs). The native token of the Asset hub is the same as the relay chain's native asset (DOT or KSM). The Existential Deposit (ED), transaction fees, and the deposits for proxy/multisig operations are about 1/10<sup>th</sup> of the values on the relay chains. Apart from the native token, the assets held on the Asset Hub can be broadly categorized as</p> <ul> <li>Assets backed by an on-chain protocol\u2019s utility</li> <li>Assets with off-chain backing</li> <li>Assets without any backing</li> </ul> <p>For additional background on the Asset Hub check out this support article.</p>"},{"location":"learn/learn-guides-assets-create/#creating-assets-on-the-asset-hub-with-polkadot-js","title":"Creating Assets on the Asset Hub with Polkadot-JS","text":"<p>Info</p> <p>Before minting assets on the Asset Hub, we recommend that you try out this tutorial on Westend Asset Hub, which is a system parachain on Westend test network. The WND tokens (Westies) can be teleported from Westend to Westend Asset Hub, are available for free through a faucet.</p> <p>The images in the guides below are for Polkadot, but they also apply to Kusama.</p> <p>To create an asset on the Asset Hub, you would need to deposit some funds. Before you create an asset on the Asset Hub, ensure that your Asset Hub account balance is a bit more than the sum of those two deposits, which should seamlessly account for the required deposits and transaction fees. You can send the native token from a relay chain account to a the Asset Hub account using the teleport functionality. For instructions on teleporting tokens, check this page on Teleports.</p> <p>Assuming you have the required balance on your Asset Hub account, the following instructions should let you successfully create an asset on the Asset Hub</p> <ul> <li>Access the Asset Hub through Polkadot-JS UI.</li> <li>Check the next available Asset ID. This can be queried on-chain by navigating to Developer &gt; Chain   State &gt; Storage and then <code>assets.nextAssetId()</code>.</li> </ul> <p></p> <ul> <li>Navigate to Network &gt; Assets.</li> </ul> <p></p> <ul> <li>Click on the create button and you will be presented with a pop-up window. Choose the creator   account, name of the asset to be displayed on the Asset Hub, the asset's symbol, number of   decimals for the asset, the minimum balance required to hold this asset on an Asset Hub account   and the most important field of your asset - the unique asset ID. This has to be the value   returned by the <code>assets.nextAssetId()</code> query shown earlier. After all the details are entered,   click on the next button.</li> </ul> <p></p> <ul> <li>Choose the admin, issuer and the freezer accounts for your asset and click on the create button.</li> </ul> <p></p> <ul> <li>Sign and submit the transaction (If you like to verify the transaction details before signing, you   can click on the dropdown button pointed by the arrow in the snapshot below).</li> </ul> <p></p> <p>If the transaction is successful, you should see the asset and its details displayed in the Network &gt; Assets page on the Asset Hub.</p>"},{"location":"learn/learn-guides-assets/","title":"Polkadot-JS Guides about Asset Hub","text":"<p>import DocCardList from '@theme/DocCardList';</p> <p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-bounties/","title":"Polkadot-JS Guides about Bounties","text":"<p>Polkadot Support Team. For more user-friendly tools see the wallets, apps and dashboard pages.\" /&gt; <p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>See this page to learn about Bounties.</p> <p>Notify the Polkadot Direction Channel</p> <p>Remember always to notify the Polkadot Direction Element Channel about OpenGov referenda so that the community can start reviewing them and voting on them.</p>"},{"location":"learn/learn-guides-bounties/#submit-a-bounty-proposal","title":"Submit a Bounty Proposal","text":"<p>Step-by-step written tutorial</p> <p>See this written tutorial to learn more about how to submit a bounty proposal.</p> <p>See the video tutorial below to learn how you can create a bounty and submit it for approval through an OpenGov referendum.</p> <p> Introduction to Bounties </p> <p> Submit a Bounty </p> <p>When you add a bounty, this will show as \"proposed\" in the main Bounties page. Once the community approves your bounty proposal as an OpenGov referendum, the bounty will show as \"funded\" at the end of the spending period on the main Bounties page. You can then proceed with assigning curators to the bounty.</p> <p>To minimize storage on chain in the same way as any proposal, bounties don't contain contextual information. When a user submits a bounty spending proposal, they will need to find an off-chain medium to explain the proposal, for example a bounty proposal document on Polkassembly or Subsquare. This template can be used to submit all the information needed by OpenGov voters to make an informed decision.</p> <p>Submitting a bounty proposal will require a deposit.</p>"},{"location":"learn/learn-guides-bounties/#assign-a-curator-to-a-bounty","title":"Assign a Curator to a Bounty","text":"<p>Step-by-step written tutorial</p> <p>See this written tutorial to learn more about how to assign a curator to a bounty.</p> <p>Once your bounty is shown as \"funded\" on the main Bounties page, you can propose a bounty curator. The referendum must be submitted on the same track used for proposing the bounty or a track with a higher spending limit (see the code snippet). For example, if the bounty was submitted to the Medium Spender Track, the curator must be proposed using the same track or the Big Spender or Treasurer tracks. See the video tutorial below to learn how you can add a curator to a bounty and submit it for approval through an OpenGov referendum.</p> <p> Assign Curator to a Bounty </p> <p>Once your OpenGov referendum has been approved by the community and served the required spending period, the bounty will still show as \"funded\" on the main Bounties page and await the curator's acceptance. The curator must formally accept the curator role by signing a <code>bounties.acceptCurator</code> extrinsic. More information about when to do this can be found on the main Bounties page. Only after the curators claim their candidacy the bounty will show as \"active\" on the main Bounty page.</p> <p>Curator assignment call must be executed after bounty is funded</p> <p>Curator assignment must take place after the bounty has been funded, and approved bounties are funded after a spend period has been completed. A curator assignment referendum cannot be executed during the same spend period when the bounty is funded.</p> <p>If your bounty has been awarded but is not funded yet, you need to make sure that the curator assignment referendum gets enacted in the subsequent spending period (you can set a delay in Polkadot-JS when you submit the proposal during the current spend period).</p>"},{"location":"learn/learn-guides-bounties/#create-and-award-child-bounties","title":"Create and Award Child Bounties","text":"<p>Step-by-step written tutorial</p> <p>See this written tutorial to learn more about how to create and award child bounties.</p> <p>Remember to add contextual information about child bounties</p> <p>When you add child bounties, please add contextual information on the governance forums Polkassembly or Subsquare.</p> <p>See the video tutorial below to learn how to create a child bounty, assign a curator, and award a child bounty.</p> <p>The video will show how to create and award a child bounty using a batch call. We will also include proposing and approving curator candidacy for the child bounty. The calls can be executed separately, depending on the process curators consider appropriate for their bounty.</p> <p> Create and Award Child Bounties </p> <p>Once a child bounty is awarded, awardees can claim the child bounty.</p>"},{"location":"learn/learn-guides-bounties/#claim-a-child-bounty-reward","title":"Claim a Child Bounty Reward","text":"<p>Step-by-step written tutorial</p> <p>See this written tutorial to learn more about how to claim a child bounty reward.</p> <p>The status of child bounties can be viewed on the Polkassembly Bounty page under the specific parent bounty. A child bounty status can be \"Added\", \"Awarded\", or \"Claimed\". For example, the parent bounty 17 refers to the Community Events Bounty, which has 183 child bounties.</p> <p></p> <p>After the child bounty has been rewarded, follow the guidelines in the video tutorial below to learn how to claim a child bounty reward. Note that the extrinsic to claim the child bounty reward is permissionless, and anyone can initiate the claim on behalf of the beneficiary.</p> <p> Claim Child Bounty Reward </p>"},{"location":"learn/learn-guides-bounties/#close-child-bounties","title":"Close Child Bounties","text":"<p>Child bounties can be closed without awarding them. To close a child bounty, you must submit a <code>childBounties.closeChild.Bounty</code> extrinsic, specifying the parent bounty and child bounty IDs. Only the parent bounty curator can sign this transaction, resulting in the child bounty\u2019s curator deposit being returned.</p> <p>See the video tutorial below to learn how to close a child bounty.</p> <p> Close a Child Bounty </p> <p>If the child bounty curator acts maliciously, the parent bounty curator can submit a <code>childBounties.unassignCurator</code> that slashes the curator's deposit.</p>"},{"location":"learn/learn-guides-bounties/#refill-parent-bounties","title":"Refill Parent Bounties","text":"<p>To refill a parent bounty, an OpenGov referendum must be submitted.</p> <p>The preimage must contain a <code>treasury.spendLocal</code> extrinsic specifying the amount of tokens to be sent from the treasury to the receiver's address, in this case the system account of the parent bounty.</p> <p>To get the bounty system account of a parent bounty, go to Subsquare, search for the bounty name, and the address will be shown under Metadata.</p>"},{"location":"learn/learn-guides-bridges/","title":"Polkadot-JS Guides about Bridge Hub","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-claims/","title":"Polkadot-JS Guides about Claims","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>If you participated in a previous DOT sale before 2020 and received your DOT allocation indicator tokens, you can now claim your DOT (and a proportional amount of KSM on the Kusama network). The claim process connects the address where your DOT indicators have been stored on Ethereum with a native Polkadot address and, if your ETH address is eligible, will pay the tokens to the Polkadot address.</p> <p>To do this, you must sign a message on Ethereum containing the address of your Polkadot account. You can do this by using the Polkadot-JS UI Claims app. Ensure that you are connected to the Polkadot network (displayed in the upper-left-hand corner of the screen).</p> <p>Third-party claim processes</p> <p>Claiming using a third-party process can lead to losing your allocation; therefore, we cannot recommend using any third-party apps. Manually specifying your transaction data, as specified in our claims process below, is the only way to ensure you will receive your allocation.</p>"},{"location":"learn/learn-guides-claims/#generate-an-account","title":"Generate an Account","text":"<p>You will need to generate an account on the relay chain to claim DOT (or KSM on Kusama). See the available wallets and extensions for more information about wallets and browser extensions you can use to create an account. In terms of hardware wallet support, you can use the Ledger devices or Polkadot Vault.</p>"},{"location":"learn/learn-guides-claims/#claiming-tokens","title":"Claiming Tokens","text":"<p>The Polkadot-JS Claims app will guide you through the process of claiming the tokens.</p>"},{"location":"learn/learn-guides-claims/#select-accounts","title":"Select Accounts","text":"<p>Select the account you would like to claim the tokens into and click the \"Continue\" button to proceed. Your screen should look something like this:</p> <p></p>"},{"location":"learn/learn-guides-claims/#select-account-on-ethereum","title":"Select Account on Ethereum","text":"<p>Paste the Ethereum address with the DOT allocation indicator tokens and click the \"Continue\" button to proceed.</p> <p></p>"},{"location":"learn/learn-guides-claims/#sign-message-on-ethereum-claim","title":"Sign Message on Ethereum &amp; Claim","text":"<p>The hex-encoded string that follows the sentence \"Pay DOT to the Polkadot account:\" is the hex-encoded public key of your Polkadot account, minus the <code>0x</code> prefix.</p> <p></p> <p>Go to the \"Sign &amp; Verify Message\" tab on the MyCrypto web application. MyCrypto is good to use if you have stored the key to the Ethereum account holding your DOT indicator tokens on a hardware device like a Ledger Nano. It also supports raw private keys, mnemonics, and the Polkadot Vault. After unlocking your Ethereum wallet, copy and paste the outputted sentence on the Polkadot-JS UI into the message box on the MyCrypto app. When you click \"Sign Message\" you will get a JSON output signature as shown below:</p> <p></p> <p>Copy and paste the JSON output of the signed message from MyCrypto into the input box on the Polkadot-JS UI and click \"Confirm Claim.\"</p> <p></p> <p>At this point, if you are eligible, you will see a success message if everything went right and your tokens will now be in the account that you claimed to. Congratulations! You can now participate in aspects of the network such as governance and staking.</p>"},{"location":"learn/learn-guides-claims/#verifying-your-claim","title":"Verifying your Claim","text":"<p>After you make an on-chain claim, your Your account balance should be updated immediately.</p>"},{"location":"learn/learn-guides-coretime-marketplaces/","title":"Coretime Marketplaces","text":"<p>Info</p> <p>If you aren't sure what Agile Coretime is, be sure to read the introduction, terminology, and FAQ.</p> <p>The tutorials in this document utilize:</p> <ul> <li> <p>CoreHub on RegionX, a user interface for purchasing and managing   Coretime regions.</p> </li> <li> <p>Lastic, a Coretime marketplace user interface.</p> </li> </ul> <p>!!!caution Both RegionX and Lastic are under active development and are released only for testing purposes.</p>"},{"location":"learn/learn-guides-coretime-marketplaces/#regionx","title":"RegionX","text":"<p>The RegionX CoreHub offers options to purchase and manage cores.</p> <p></p>"},{"location":"learn/learn-guides-coretime-marketplaces/#purchasing-cores-with-regionx","title":"Purchasing Cores with RegionX","text":"<p>RegionX allows for purchasing core with accounts hosted on wallets like Subwallet, Talisman, Nova Wallet and Polkadot-JS Extension. Select the account to be used for the coretime purchase (displayed on top right) and ensure that both the relay chain and coretime chain are connected (displayed on bottom left). Then, click on the purchase button to sign and broadcast the transaction.</p> <p></p>"},{"location":"learn/learn-guides-coretime-marketplaces/#managing-cores-with-regionx","title":"Managing Cores with RegionX","text":"<p>The Regions dashboard lists all the cores purchased through the connected wallet account along with the basic information of the respective core. It allows for partitioning, interlacing, transfers, and assigning tasks.</p> <p></p>"},{"location":"learn/learn-guides-coretime-marketplaces/#lastic","title":"Lastic","text":"<p>Lastic is a marketplace for buying and selling blockspace. For more information, check Lastic's official documentation.</p>"},{"location":"learn/learn-guides-coretime-marketplaces/#purchasing-cores-with-lastic","title":"Purchasing Cores with Lastic","text":"<p>Lastic allows for purchasing core with accounts hosted on wallets like Subwallet, Talisman, Nova Wallet and Polkadot-JS Extension. Select the account to be used for the coretime purchase and then, click on \"buy core\" button to sign and broadcast the transaction.</p> <p></p>"},{"location":"learn/learn-guides-coretime-marketplaces/#managing-cores-with-lastic","title":"Managing Cores with Lastic","text":"<p>Lastic enables you to transfer your core to another account, utilize it for a parachain, split it up, change block production frequency, or assign it to a task.</p> <p></p>"},{"location":"learn/learn-guides-coretime-parachains/","title":"Agile Coretime for Parachains","text":"<p>Info</p> <p>If you aren't sure what Agile Coretime is, be sure to read the introduction, terminology, and FAQ.</p> <p>The landscape for parachains changes with the rollout of Agile Coretime. With parachain auctions being phased out in favor of direct coretime sales, the existing parachains on the relaychain and the prospective parachains are presented with the following scenarios:</p> <ul> <li>Migrating from a legacy parachain lease into a   bulk coretime model</li> <li>Starting with bulk coretime model from scratch</li> <li>Running a parachain with on-demand coretime purchases (\"pay as you go\")</li> </ul> <p>The parachain lease auctions stopped on-chain with the enactment of the runtime upgrade 1.2.0 on the 19<sup>th</sup> of September 2024, and the existing leases were migrated to bulk coretime automatically. Leases that had not started were canceled, and the locked tokens were refunded. The existing parachains benefit from coretime renewals, allowing for the continued assignment of bulk coretime for a core without going through the regular purchasing process.</p> <p>Info</p> <p>The tutorials below assume that you have already developed the parachain runtime and a fully configured parachain collator for the target relay chain using the Polkadot SDK.</p> <p>For the tutorials below, the adder test parachain on the Polkadot SDK has been used. To compile the <code>adder-collator</code>, run the command below in the root of the Polkadot SDK repository. You must have Rust and its associated tooling installed before following along.</p> <p>Ensure the Polkadot SDK is cloned, and you are within the root directory (<code>cd polkadot-sdk</code>)</p> <pre><code>cargo build -r -p test-parachain-adder-collator\n</code></pre> <p>After the test parachain collator node is successfully compiled, export its genesis state and the code using the following commands. If the export succeeds, these two files should appear in the Polkadot-SDK repository.</p> <pre><code>./target/release/adder-collator export-genesis-state genesis\n</code></pre> <pre><code>./target/release/adder-collator export-genesis-wasm genesis-wasm\n</code></pre>"},{"location":"learn/learn-guides-coretime-parachains/#reserve-paraid","title":"Reserve ParaID","text":"<p>Reserving a <code>ParaID</code> requires a deposit. The first step is to register a <code>ParaID</code> for the parachain. This can be done through Polkadot-JS UI by navigating to Network &gt; Parachains &gt; Parathreads and clicking on ParaID button. Ensure that you have sufficient tokens to reserve the displayed <code>ParaID</code> successfully.</p> <p></p>"},{"location":"learn/learn-guides-coretime-parachains/#register-parachain-state-and-code","title":"Register Parachain State and Code","text":"<p>Deposit requirements for registering a parachain</p> <p>Due to the reasons discussed here, instead of the usual per-byte method of charging for storing validation and genesis code upon registration, the cost is fixed to the maximum possible code size (<code>MAX_CODE_SIZE</code>), regardless of the actual size.</p> <p>On Kusama, the deposit required to register a parachain is ~1100 KSM and an estimated fee of ~5 KSM.</p> <p>On Polkadot, the deposit required to register a parachain is ~3300 DOT and an estimated fee of ~150 DOT.</p> <p>It is possible to deregister the parachain and withdraw the deposit if the parachain has not produced any blocks. If the parachain produced blocks, then the parachain can only be deregistered through the relay chain's governance.</p> <p>The next step is to register the parachain's genesis wasm and state, which you should have generated earlier. Note that for this example, we are using <code>adder-collator</code>, but in theory a custom runtime compiled from a template would work as well.</p> <p></p> <p>After successful registration, the parachain starts onboarding as a parathread.</p>"},{"location":"learn/learn-guides-coretime-parachains/#run-parachain-collator","title":"Run Parachain Collator","text":"<p>While the parachain is onboarding, start syncing the collator using the following command to rapidly sync with the specified relay chain.</p> <pre><code>./target/release/adder-collator --parachain-id= $ParaID --chain=paseo --sync warp\n</code></pre>"},{"location":"learn/learn-guides-coretime-parachains/#run-a-parachain-with-bulk-coretime","title":"Run a Parachain with Bulk Coretime","text":"<p>Info</p> <p>Note that we have two options: bulk coretime and on-demand coretime. Bulk coretime is purchased via the <code>broker</code> pallet, which is on the respective Coretime system parachain. On-demand coretime is ordered via the <code>OnDemandAssignment</code> pallet/module, which is located on the respective relay chain.</p> <p>You can purchase bulk coretime on Coretime chain and assign the purchased core to the registered <code>ParaID</code>. The snapshot below is from Lastic interface.</p> <p></p> <p>After successful assignment of the core, the <code>adder-collator</code> logs show new collations at regular intervals, gradually incrementing the state by <code>2</code>.</p> <p></p>"},{"location":"learn/learn-guides-coretime-parachains/#run-a-parachain-with-on-demand-coretime","title":"Run a Parachain with On-demand Coretime","text":"<p>After the collator node is fully synced with the relay chain, navigate to Developer &gt; Extrinsics on the relay chain and issue <code>onDemandAssignmentProvider.placeOrderAllowDeath</code> extrinsic from the account that registered the <code>ParaID</code> by specifying sufficient <code>maxAmount</code>for the transaction to go through successfully.</p> <p></p> <p>Info</p> <p>There are two extrinsics which allow you to place orders for on-demand coretime: - <code>onDemandAssignmentProvider.placeOrderAllowDeath</code> will reap the account once the provided funds run out. - <code>onDemandAssignmentProvider.placeOrderKeepAlive</code> includes a check which will not reap the account if the provided funds will run out, ensuring the account is kept alive.</p> <p>With each successful on-demand extrinsic, the parachain head changes (you may have to zoom out on the browser for parachain head details to show up on Polkadot-JS UI).</p> <p></p> <p>The successful collation can also be verified in the parachain collator logs. It can be noticed that with each parachain block, the state of <code>adder-collator</code> is incremented by <code>2</code>.</p> <p></p>"},{"location":"learn/learn-guides-coretime-swap/","title":"Coretime Lease Swap","text":"<p>The following is a guide to leverage the swap functionality to change leases between different paraIDs. This allows parachain teams to swap existing leases.</p> <p>Coretime swapping requires two chains to send a <code>swap</code> instruction from an origin with Root privileges. Depending on whether the parachain is locked or not, this can either be the manager account of the parachain on the relay chain (if parachain is not locked), or the governance system in place for the parachain (can be sudo) if the parachain is locked.</p> <p>In order to check if a parachain is locked or not, teams need to query <code>registrar.paras</code> with the corresponding paraID on the relay chain. It's important to note that since RFC #14, if a parachain never produced a block the it's by default unlocked.</p>"},{"location":"learn/learn-guides-coretime-swap/#initiate-swap-from-the-parachain","title":"Initiate Swap from the Parachain","text":"<p>To swap from a parachain, an XCM message needs to be sent from the parachain to the relay chain. This XCM message must be a send instruction that wraps the <code>registrar.swap</code> extrinsic that needs to be executed on the relay chain.</p> <p>Below, you can find an example hex encoded call for Composable Finance, assuming the team is still operating under SUDO.</p> <p>0x0200290003010003140004000000000700e876481713000000000700e87648170006000700e40b540282380100284603e3070000320d0000140d01000001008d1f</p> <p>As for weights (size and time), we use an overestimate compared with those returned by the Polkadot Relay Runtime API.</p> <p>To check the exact weights, you can navigate to Polkadot JS UI &gt; Developer &gt; Runtime Calls and then select <code>transactionPaymentCallInfo</code> and <code>queryCallInfo</code> and include the extrinsic being sent in the <code>send</code> instruction of the XCM message: 0x4603e3070000320d0000</p> <p></p>"},{"location":"learn/learn-guides-coretime-swap/#perform-swap-on-the-relay-chain-for-an-unlocked-parachain","title":"Perform Swap on the Relay chain for an unlocked Parachain","text":"<p>In the case a parachain is unlocked, then the manager of the parachain on the relaychain must send the extrinsic directly on the relaychain.</p> <p>In the case of paraID 3378 wanting to swap with Composable Finance, the extrinsic to send from its manager account <code>13B8Tdhi4EuruwzVt3gdcTopXpqbUzmncutiQKKNbd8cpU91</code> is:</p> <p>0x4603320d0000e3070000</p>"},{"location":"learn/learn-guides-coretime-swap/#coretime-swap-prerequisites","title":"Coretime Swap Prerequisites","text":"<p>We need to ensure the parachains have a valid cores to execute the swap instruction. This can be achieved either by getting a core in bulk from the coretime system chain, or by leveraging the onDemand functionality on relay chain. Assuming that teams have a working parachain (with a valid core) and a stalled parachain, the following instructions explain how to get a core <code>onDemand</code> for the stalled parachain.</p>"},{"location":"learn/learn-guides-coretime-swap/#swap-through-an-ondemand-core","title":"Swap through an OnDemand Core","text":"<p>This functionality exists on the relay chain and allows users to request for 1 block of validation of their parachain. In order to place an order for on demand, any account must call the <code>onDemand.placeOrderAllowDeath</code> extrinsic.</p> <p></p> <p>This extrinsic takes two parameters:</p> <ul> <li> <p>Amount: the amount the user is willing to pay for the parachain block to be validated by a core.   The minimum amount the system allows is 250,000,000 planckDOT (0.025 DOT) and the actual amount is   dynamic as it depends on the on-demand block production requests queued.</p> </li> <li> <p>paraID: This refers to the <code>paraID</code> of the on-demand Parachain whose block must be   validated by a core.</p> </li> </ul>"},{"location":"learn/learn-guides-coretime-swap/#core-swap-execution-steps","title":"Core Swap Execution Steps","text":"<p>If you are a team with two parachains, one that has a lease with a fresh paraID, and an old one that doesn't have a lease but contains the history of the chain then below is a list of steps to execute to swap these leases.</p> <p>Assumptions</p> <ul> <li>Your new paraID is unlocked and your old paraID is locked.</li> <li>You have access to the manager account on the relay chain for the new paraID</li> <li>You have your collators running on your old paraID and you can execute upward XCM messages from   that parachain.</li> <li>The sovereign account for the locked paraID has enough available funds to execute transactions on   the relay chain.</li> <li>The account that owns the unlocked paraID has enough available funds to execute transactions on   the relay chain. transactions on the relay chain.</li> </ul> <p>Steps</p> <ul> <li>Have the collator running for your original paraID.</li> <li>Send the XCM instruction detailed before.</li> <li>Get a onDemandCore for your original paraID. Once this gets executed, your XCM message should be   dispatched to the relay chain and you should see a pending swap.</li> <li>Use the manager account on your new paraID to send the   swap instruction directly on the   relay chain.</li> </ul>"},{"location":"learn/learn-guides-coretime-swap/#coretime-swap-time-for-effect","title":"Coretime Swap - Time for Effect","text":"<p>The swap of leases is effective immediately, however the Coretime chain communicates the changes of these leases to the relay chain with every new coretime cycle. Thus, the change will come into effect in the following coretime cycle. For information on when the new coretime cycle, you can view the coretime sales page.</p>"},{"location":"learn/learn-guides-identity/","title":"Polkadot-JS Guides about Identity","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The identity pallet is no longer on the Kusama relay chain.</p> <p>If you are on Kusama, any of the extrinsics which require you to use the relay chain now have to be called via the system parachain, which you can find here.</p> <p>The identity pallet, along with all of its data, has been migrated to the People Chain, a system parachain which can now be used for identity management.</p> <p>This is an advanced guide that is relevant for entities that would like to become registrars or would like to set sub-identities to an existing account with an identity. See this page to learn about how to set an identity and have it verified.</p>"},{"location":"learn/learn-guides-identity/#setting-an-identity","title":"Setting an Identity","text":"<p>Users can set an identity by registering through default fields such as legal name, display name, website, Twitter handle, Riot handle, etc. along with some extra, custom fields for which they would like attestations (see Judgements).</p> <p>Instructions for setting and clearing Identities</p> <p>The procedure to set and clear identities is explained in detail in this support article - How to set and clear an Identity</p> <p>!!!note The Ledger app on Nano S doesn't support the extrinsic for setting identity. As a workaround, create a primary identity with an on-chain account and then using that primary identity, assign a sub-identity to the Ledger stash.</p>"},{"location":"learn/learn-guides-identity/#format-caveat","title":"Format Caveat","text":"<p>Please note the following caveat: because the fields support different formats, from raw bytes to various hashes, a UI has no way of telling how to encode a given field it encounters. The Polkadot-JS UI currently encodes the raw bytes it encounters as UTF8 strings, which makes these values readable on-screen. However, given that there are no restrictions on the values that can be placed into these fields, a different UI may interpret them as, for example, IPFS hashes or encoded bitmaps. This means any field stored as raw bytes will become unreadable by that specific UI. As field standards crystallize, things will become easier to use but for now, every custom implementation of displaying user information will likely have to make a conscious decision on the approach to take, or support multiple formats and then attempt multiple encodings until the output makes sense.</p>"},{"location":"learn/learn-guides-identity/#request-judgement","title":"Request Judgement","text":"<p>Instructions for requesting and cancelling Identity judgements</p> <p>The procedure to request and cancel identity judgments is explained in detail in this support article</p> <p>To be judged after submitting your identity information, go to the Extrinsics tab in the Polkadot-JS UI and select the <code>identity</code> pallet, then <code>requestJudgement</code>. For the <code>reg_index</code> put the index of the registrar you want to be judged by, and for the <code>max_fee</code> put the maximum you're willing to pay for these confirmations.</p> <p>If you don't know which registrar to pick, first check the available registrars by going to Chain State tab in the Polkadot-JS UI and selecting <code>identity.registrars()</code> to get the full list.</p> <p>To find out how to contact the registrar after the application for judgement or to learn who they are, you can check their identity by adding them to your Address Book. Their identity will be automatically loaded.</p> <p></p> <p>Requesting judgement through Web3 Foundation Registrar</p> <p>If you requested judgement for your on-chain identity through the Web3 Foundation Registrar (i.e. Registrar #0) you will need to complete a few additional tasks. For more information visit this support article.</p> <p>Caution</p> <p>The set identity calls go on-chain. Hence, the contact information is available publicly, for both legitimate entities, like registrars or validators, but also scammers who might impersonate them. The strings in the identity fields are good candidates for homograph attacks, as someone could list a fraudulent website (web3.f0undation instead of web3.foundation for example) and still get verified by the registrar (if the checks are automated)!</p> <p>In a decentralized network, one should be cautious making transactions with accounts solely based on their identity. If an account on-chain claims to be of Web3 Foundation, it is wise to verify its authenticity by checking directly with Web3 Foundation or examining the established history of that account on-chain.</p>"},{"location":"learn/learn-guides-identity/#clearing-and-killing-an-identity","title":"Clearing and Killing an Identity","text":"<p>Info</p> <p>Visit the section \"Clear an Identity\" on this support article for guidelines about clearing identities.</p> <p>Clearing: Users can clear their identity information and have their deposit returned. Clearing an identity also clears all sub accounts and returns their deposits.</p> <p>Killing: It is possible to kill an identity that deems erroneous. This results in a slash of the deposit.</p>"},{"location":"learn/learn-guides-identity/#setting-sub-identities","title":"Setting Sub-Identities","text":"<p>To set up sub-identities with Polkadot-JS see the how to set sub-identities support article and this video tutorial.</p>"},{"location":"learn/learn-guides-identity/#setting-sub-identity-sub-id-for-your-ledger-account","title":"Setting Sub-Identity (Sub-ID) for your Ledger Account","text":"<p>Setting an Identity is not possible on Ledger app yet, but as a workaround, you can set the identity for an on-chain account  and then use it to set a sub-identity to your Ledger account.</p> <ul> <li>Go to https://polkadot.js.org/apps/#/accounts. Click on the three vertical dots corresponding to   the account to which you already set identity. You should see an option to set onchain   sub-identities. Click on it.</li> </ul> <p></p> <ul> <li>In the pop-up window, select your Ledger account from the dropdown and enter text in sub name   field. Then, click on set subs button.   </li> <li>Sign and submit the transaction from the parent account with the identity</li> </ul> <p>You should now see the sub-identity displayed on-chain. You need to be aware that the creation of identities and sub-identities requires deposits. This reserved account balance is freed once you clear the identities on the account.</p> <p></p>"},{"location":"learn/learn-guides-identity/#registrars","title":"Registrars","text":""},{"location":"learn/learn-guides-identity/#becoming-a-registrar","title":"Becoming a Registrar","text":"<p>To become a registrar, submit a pre-image and proposal on OpenGov, then wait for people to vote on it. For best results, write a post about your identity and intentions beforehand, and once the proposal is in the queue ask people to endorse it so that it gets ahead in the referendum queue.</p>"},{"location":"learn/learn-guides-ledger/","title":"Polkadot-JS Guides for Ledger Devices","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>The Ledger devices are hardware wallets that keep your private key secured on a physical device not directly exposed to your computer or the internet.</p> <p>The Polkadot Generic application allows you to manage your DOT/KSM on Polkadot/Kusama networks, tokens on their Asset Hubs and possibly all chains within the Polkadot ecosystem. It is versatile and capable of handling parachains and relay chains without being affected by their runtime upgrades.</p>"},{"location":"learn/learn-guides-ledger/#loading-your-account","title":"Loading Your Account","text":"<p>Info</p> <p>Ledger Live should be off while using Ledger with Polkadot-JS UI, as it can interfere with normal operation.</p> <p>You can import your Ledger account to Polkadot Extension or to the Polkadot-JS UI. For instructions on how to import Ledger accounts to the Polkadot Extension read through this support article, while if you want to import Ledger accounts to the Polkadot-JS UI, you can consult this other article.</p>"},{"location":"learn/learn-guides-ledger/#derivation-paths","title":"Derivation paths","text":"<p>When adding a Ledger account using the extension or the UI, you will be asked to select an <code>account type</code> and an <code>account index</code>. The first lets you select an account, while the second lets you pick a derivation path from that account - think of it like a formula from which child accounts are generated. When you are creating a Polkadot ledger account for the first time on Ledger Live with name <code>Polkadot 1</code>, this can be added to Polkadot-JS using the 0/0 derivation path (i.e. account type = 0 and account index = 0). If you add a second account called <code>Polkadot 2</code>, this will correspond to the 1/0 derivation path, and so on. We thus have multiple parent accounts that can be viewed and used in both Ledger Live and Polkadot-JS. Additionally, we can use Polkadot-JS UI to create multiple children accounts from each parent account. For example, <code>Polkadot 1</code> with 0/0 derivation path can have child 0/1, 0/2, etc. that can be used within the UI. However, such children accounts cannot be used in Ledger Live, as it only scans through the parent accounts. So, remember that the balances on the children accounts cannot be viewed, and you will not be able to transact with those accounts on Ledger Live.</p>"},{"location":"learn/learn-guides-ledger/#confirming-the-address-on-your-device","title":"Confirming the Address on your Device","text":"<p>If your Ledger account is directly imported into the Polkadot-JS UI, you can ask the UI to confirm the address on your Ledger device. There are a few methods to check the balance of your Ledger account. Check out this support article for information.</p>"},{"location":"learn/learn-guides-ledger/#navigating-your-account","title":"Navigating your Account","text":"<p>Once you have loaded your account on the \u201cAccounts\u201d tab, it should show a row with your Ledger account. Your account\u2019s DOT balance is on the row\u2019s far right. Expanding the balance arrow will show your balance details, such as locks or reserved amounts. For more information about the type of balances, visit the balances page.</p>"},{"location":"learn/learn-guides-ledger/#sending-a-transfer-with-ledger-devices","title":"Sending a Transfer with Ledger Devices","text":"<p>Verifying Extrinsics</p> <p>Visit the dedicated support page and see this video tutorial tutorial to learn how to verify extrinsics before signing them. The video will also mention potential attacks that can happen while signing transactions.</p> <p>Signature error message</p> <p>If you have already connected your device, but an error message appears before signing a transaction, make sure you have opened the Polkadot Ledger Generic application on your Ledger Nano device. Visit this support page for more information about signing transactions using your ledger.</p> <p>General instructions to send a transfer can be found on this support page. To sign transactions with your Ledger Nano check this support article or see this video tutorial.</p>"},{"location":"learn/learn-guides-ledger/#receiving-a-transfer","title":"Receiving a Transfer","text":"<p>To receive a transfer on the accounts stored on your Ledger device, you must provide the sender (i.e., the payer) with your address. To do so, follow the instructions on this support page.</p> <p>Sharing your account address</p> <p>Before giving anyone your address, ensure it matches what's on the Ledger by confirming the address on your device. Some malware will intercept clicks and clipboard requests and can change your copied value in-flight, so being extra vigilant around copy-paste operations makes sense.</p> <p>The easiest way to get your address is to click on the account name. This will open a sidebar showing your address and other information, such as on-chain identity. Another method is just clicking on your account's avatar icon - this immediately copies your address to the clipboard.</p> <p>Your Asset Hub address is the same as your relay chain address</p> <p>Make sure that you clarify to the sender that you wish to receive your tokens on the Asset Hub parachain, otherwise (if you're receiving DOT or KSM tokens) they could be sent on the Polkadot or Kusama relay chain.</p>"},{"location":"learn/learn-guides-ledger/#staking","title":"Staking","text":"<p>For staking using Ledger devices, follow the instructions on this support article.</p>"},{"location":"learn/learn-guides-ledger/#ledger-developer-release","title":"Ledger Developer Release","text":"<p>Warning</p> <p>This section is for developers only. It is recommended to install the application from Ledger Live unless you know precisely what you're doing.</p>"},{"location":"learn/learn-guides-ledger/#why-you-might-need-the-developer-release","title":"Why you might need the Developer Release","text":"<p>Ledger apps for the Polkadot ecosystem are developed by Zondax. When new functionalities are added to the Ledger apps, they are made available on a developer release for testing purposes. After a successful audit and review, the apps would be available for download and installation using Ledger Live. As it takes some time for Ledger to audit and review the release, the app upgrade option may not be available on Ledger Live when the new runtime is deployed on the network. If this happens, users cannot use Ledger devices to sign transactions. Suppose you cannot wait a few days until the app passes the Ledger audit, you can install the developer release from the shell using the latest version published on the Zondax GitHub repository.</p>"},{"location":"learn/learn-guides-ledger/#install-the-developer-release","title":"Install the Developer Release","text":"<p>Info</p> <p>See this video tutorial to learn how to install the developer release of your ledger app.</p> <p>Currently, the developer release can be installed only on the Nano S and S Plus devices and can't be installed on the Nano X.</p> <p>To install the developer version, make sure you have the latest <code>pip</code> version and follow the steps below:</p> <ul> <li>Install ledgerblue running the command <code>python3 -m pip install ledgerblue</code>.</li> <li>Download the developer release from the   Zondax GitHub repository. The file will be   named <code>installer_nanos_plus.sh</code> or something similar, depending on your ledger device.</li> <li>Locate the downloaded shell script and make it executable in your shell by typing the command   <code>chmod +x installer_nanos_plus.sh</code>.</li> <li>You can now use the <code>./installer_nanos_plus.sh --help</code> command to visualize the available options   (see below)</li> </ul> <p></p> <ul> <li>Attach your Ledger Nano (in this case, Nano S Plus) to your computer, enter the PIN code, and run   the command <code>./installer_nanos_plus.sh load</code>. Scroll with the right button until you see \"Allow   unsafe manager\", left and right press to confirm. You will be asked to confirm the action of   uninstalling the app and subsequently installing the newer version. After confirming both actions,   the shell script will install the version on your device. You must insert the PIN code to use the   device after the installation.</li> <li>If you wish to revert the version to the stable release, go to Ledger Live. The app will   automatically detect the developer release and give the option to install the previous stable   release.</li> </ul>"},{"location":"learn/learn-guides-nominator/","title":"Polkadot-JS Guides For Nominators","text":"<p>import DocCardList from '@theme/DocCardList';</p> <p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>See this page to learn about staking.</p>"},{"location":"learn/learn-guides-nominator/#nominate-using-polkadot-js","title":"Nominate Using Polkadot-JS","text":"<p>Video Tutorials</p> <ul> <li>How to Nominate/Stake</li> <li>Staking with a Ledger device and Polkadot-JS</li> <li>Staking with a Ledger device and Ledger Live</li> </ul>"},{"location":"learn/learn-guides-nominator/#bond-your-tokens","title":"Bond your tokens","text":"<p>Support Article</p> <p>Read the support article about How to Bond Tokens and Nominate.</p> <p>On the Polkadot-JS UI navigate to the \"Staking\" tab (within the \"Network\" menu).</p> <p>The \"Staking Overview\" subsection will show you all the active validators and their information - their identities, the amount of KSM that are staking for them, amount that is their own provided stake, how much they charge in commission, the era points they've earned in the current era, and the last block number that they produced. If you click on the chart button it will take you to the \"Validator Stats\" page for that validator that shows you more detailed and historical information about the validator's stake, rewards and slashes.</p> <p>The \"Account actions\" subsection (link) allows you to stake and nominate.</p> <p>The \"Payouts\" subsection (link) allows you to claim rewards from staking.</p> <p>The \"Targets\" subsection (link) will help you estimate your earnings and this is where it's good to start picking favorites.</p> <p>The \"Waiting\" subsection (link) lists all pending validators that are awaiting more nominations to enter the active validator set. Validators will stay in the waiting queue until they have enough KSM backing them (as allocated through the Phragm\u00e9n election mechanism). It is possible validator can remain in the queue for a very long time if they never get enough backing.</p> <p>The \"Validator Stats\" subsection (link) allows you to query a validator's stash address and see historical charts on era points, elected stake, rewards, and slashes.</p> <p>Pick \"Account actions\" underneath \"Network\" &gt; \"Staking\", then click the \"+ Nominator\" button.</p> <p>You will see a modal window that looks like the below:</p> <p></p> <p>Select a \"value bonded\" that is less than the total amount of KSM you have, so you have some left over to pay transaction fees. Transaction fees are currently at least 0.01 KSM, but they are dynamic based on a variety of factors including the load of recent blocks.</p> <p>Also be mindful of the reaping threshold - the amount that must remain in an account lest it be burned. That amount is 0.01 in Kusama, so it's recommended to keep at least 0.1 KSM in your account to be on the safe side.</p> <p>Choose whatever payment destination that makes sense to you. If you're unsure, you can choose \"Stash account (increase amount at stake)\" to simply accrue the rewards into the amount you're staking and earn compound interest.</p> <p></p>"},{"location":"learn/learn-guides-nominator/#nominate-a-validator","title":"Nominate a validator","text":"<p>Support Article</p> <p>Read the support article about How to Select Validators.</p> <p>You are now bonded. Being bonded means your tokens are locked and could be slashed if the validators you nominate misbehave. All bonded funds can be distributed to multiple validators. Be careful about the validators you choose since you will be slashed if your validator commits an offence.</p> <p>Click on \"Nominate\" on an account you've bonded and you will be presented with another popup asking you to select some validators.</p> <p></p> <p>Select them, confirm the transaction, and you're done - you are now nominating. Your nominations will become active in the next era. Eras last six hours on Kusama - depending on when you do this, your nominations may become active almost immediately, or you may have to wait almost the entire six hours before your nominations are active. You can check how far along Kusama is in the current era on the Staking page.</p> <p>Assuming at least one of your nominations ends up in the active validator set, you will start to get rewards allocated to you. In order to claim them (i.e., add them to your account), you must manually claim them. To initiate a claim, you can do it yourself or have the validator that you staked for initiate a claim. This is to help optimize the effectiveness and storage of payouts on Kusama. See the Claiming Rewards section of the Staking wiki page for more details.</p>"},{"location":"learn/learn-guides-nominator/#stop-nominating","title":"Stop nominating","text":"<p>Support Article</p> <p>Read the support article about How to Stop Nominating &amp; Unbond Tokens. See also the support article about How to Rebond Tokens.</p> <p>At some point, you might decide to stop nominating one or more validators. You can always change who you're nominating, but you cannot withdraw your tokens unless you unbond them.</p>"},{"location":"learn/learn-guides-nominator/#claiming-rewards-with-polkadot-js","title":"Claiming Rewards with Polkadot-JS","text":"<p>Anyone can trigger a payout for any validator, as long as they are willing to pay the transaction fee. Someone must submit a transaction with a validator ID and an era index. Polkadot will automatically calculate that validator's reward and distribute the rewards pro rata.</p> <p>These details are handled for you automatically if you use the Polkadot-JS UI, which also allows you to submit batches of eras at once.</p> <p>To claim rewards on Polkadot-JS UI, you will need to be in the \"Payouts\" tab underneath \"Staking\", which will list all the pending payouts for your stashes.</p> <p></p> <p>To then claim your reward, select the \"Payout all\" button. This will prompt you to select your stash accounts for payout.</p> <p></p> <p>Once you are done with payout, another screen will appear asking for you to sign and submit the transaction.</p> <p></p>"},{"location":"learn/learn-guides-nominator/#using-command-line-interface-cli","title":"Using Command-Line Interface (CLI)","text":"<p>Apart from using the Polkadot-JS UI to participate in the staking, you can do all these things in CLI instead. The CLI approach allows you to interact with the network without using Polkadot-JS.</p>"},{"location":"learn/learn-guides-nominator/#step-1-install-polkadotapi-cli","title":"Step 1: Install @polkadot/api-cli","text":"<p>We assume you have installed NodeJS with npm. Run the following command to install the <code>@polkadot/api-cli</code> globally:</p> <pre><code>npm install -g @polkadot/api-cli\n</code></pre>"},{"location":"learn/learn-guides-nominator/#step-2-bond-tokens","title":"Step 2: Bond Tokens","text":"<p>Controller accounts are deprecated</p> <p>Controller accounts are deprecated. For more information, see this discussion.</p> <p>Executing the following command:</p> <pre><code>polkadot-js-api --seed \"MNEMONIC_PHRASE\" tx.staking.bond CONTROLLER_ADDRESS NUMBER_OF_TOKENS REWARD_DESTINATION --ws WEBSOCKET_ENDPOINT\n</code></pre> <p><code>CONTROLLER_ADDRESS</code>: An address you would like to bond to the stash account. (Controller accounts are now deprecated. Refer to this discussion for additional context)</p> <p><code>NUMBER_OF_TOKENS</code>: The number of native tokens (in Plancks) you would like to stake to the network. For more information, see this page.</p> <p><code>REWARD_DESTINATION</code>:</p> <ul> <li><code>Staked</code> - Pay into the stash account, increasing the amount at stake accordingly.</li> <li><code>Stash</code> - Pay into the stash account, not increasing the amount at stake.</li> <li><code>Account</code> - Pay into a custom account that is not the stash (can be a proxy or another type of   account).</li> <li><code>Controller</code> - Pay into the controller account.</li> </ul> <p>Example for Kusama:</p> <pre><code>polkadot-js-api --seed \"xxxx xxxxx xxxx xxxxx\" tx.staking.bond DMTHrNcmA8QbqRS4rBq8LXn8ipyczFoNMb1X4cY2WD9tdBX 1000000000000 Staked --ws wss://kusama-rpc.polkadot.io\n</code></pre> <p>For wss endpoints see this page.</p> <p>Result:</p> <pre><code>...\n...\n    \"status\": {\n      \"InBlock\": \"0x0ed1ec0ba69564e8f98958d69f826adef895b5617366a32a3aa384290e98514e\"\n    }\n</code></pre> <p>You can check the transaction status by using the value of the <code>InBlock</code> in Subscan. Also, you can verify the bonding state under the Staking page on the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-nominator/#step-3-nominate-a-validator","title":"Step 3: Nominate a validator","text":"<p>To nominate a validator, you can execute the following command:</p> <pre><code>polkadot-js-api --seed \"MNEMONIC_PHRASE\" tx.staking.nominate '[\"VALIDATOR_ADDRESS\"]' --ws WS_ENDPOINT\n</code></pre> <pre><code>polkadot-js-api --seed \"xxxx xxxxx xxxx xxxxx\" tx.staking.nominate '[\"CmD9vaMYoiKe7HiFnfkftwvhKbxN9bhyjcDrfFRGbifJEG8\",\"E457XaKbj2yTB2URy8N4UuzmyuFRkcdxYs67UvSgVr7HyFb\"]' --ws wss://kusama-rpc.polkadot.io\n</code></pre> <p>After a few seconds, you should see the hash of the transaction, and if you would like to verify the nomination status, you can check that on the Polkadot-JS UI as well.</p>"},{"location":"learn/learn-guides-polkadot-opengov/","title":"Polkadot-JS Guides about OpenGov","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>See this page to learn about Polkadot OpenGov.</p> <p>This guide will instruct token holders how to propose and vote on public referenda using the Referenda module (OpenGov). Below are a few links to stay informed and directly engage with the community.</p> <ul> <li>Polkadot Direction - a place to discuss   governance and the future of Polkadot.</li> <li>Kusama Direction - a place to discuss   governance and the future of Kusama.</li> <li>Polkadot and Kusama   Polkassembly - for current referenda, latest proposals, motions, treasury proposals, tips,   bounties, and more.</li> <li>Polkadot Daily Digest - News about what is   happening in the Polkadot ecosystem, published every weekday except holidays.</li> </ul>"},{"location":"learn/learn-guides-polkadot-opengov/#create-a-referenda-proposal","title":"Create a Referenda Proposal","text":"<p>Before submitting a referendum, identify the right track and origin for it. For instance, if the referendum is for requesting funds from treasury, select the treasury track with appropriate spend limits. If the referendum is for a suggestion to make changes to the protocol, select the \"Wish for Change\" track. For more info, check the tracks and origins of Polkadot OpenGov.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#submitting-a-preimage","title":"Submitting a Preimage","text":"<p>The act of creating a proposal is split from submitting the preimage for the proposal since the storage cost of submitting a large preimage could be expensive. Allowing the preimage submission to come as a separate transaction means that another account could submit the preimage for you and pay the fee. The example below demonstrates the creation of a preimage to propose and approve a spend of treasury funds.</p> <p></p> <p>Follow the steps below to submit a preimage as shown in the screenshot above.</p> <ol> <li>Navigate to Governance -&gt; Referenda.</li> <li>Click on the \"Add preimage\" button.</li> <li>From the propose drop-down field, select <code>treasury</code>.</li> <li>From the unlabeled drop-down field to the right of the propose drop-down field, select    <code>spendLocal(amount, beneficiary)</code>.</li> <li>In the <code>amount: Compact&lt;u128&gt; (BalanceOf)</code> text field, enter the spend amount in    plancks.</li> <li>The <code>beneficiary: MultiAddress (AccountIdLookupOf)</code> drop-down field will have <code>Id</code> selected by    default. Select the beneficiary from the <code>Id: AccountId</code> drop-down field.</li> </ol> <p>!!!info Copy the <code>preimage hash</code> value before clicking the \"Submit preimage\" button.</p> <ol> <li>Click the \"Submit preimage\" button.</li> </ol> <p>After the preimage is submitted successfully on-chain, Polkadot-JS UI lists it under the tab of Governance -&gt; Preimages.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#submitting-a-proposal","title":"Submitting a Proposal","text":"<p>Submitting a proposal requires you to bond some tokens. On Polkadot-JS UI, you can navigate to the Governance -&gt; Referenda to make a new proposal. In order to submit a proposal, you will need to submit what's called the preimage hash. The preimage hash is simply the hash of the proposal to be enacted. The easiest way to get the preimage hash is by clicking on the \"Submit preimage\" button as shown in the previous section.</p> <p></p> <p>The proposal will be registered from the account selected and the balance lock will be applied to it. An appropriate origin must be chosen, as each origin has different privileges, and acceptance criteria. After entering the hash of the preimage for the proposal, the preimage length field is automatically populated. The enactment delay can be specified either as a block number, or as a specific number of blocks after the referendum is approved. The deposit for this proposal will be locked for the referendum duration.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#submitting-a-referendum-on-the-whitelisted-caller-track","title":"Submitting a Referendum on the Whitelisted Caller Track","text":"<p>Let's consider increasing the number of validators participating in parachain consensus. You could submit a preimage with the call that sets the number of validators to 1,000 and submit a referendum to the Root track directly. However, this requires a large decision deposit and has very conservative passing parameters such that it will probably need the entire 28-day voting period to pass.</p> <p>Operations that are deemed safe or time critical by the Polkadot Technical Fellowship can use the Whitelisted Caller track. This track requires less turnout in the first half of the decision period so that it can pass more quickly. This track is typically used for more neutral, technical proposals like runtime upgrades or changing the system's parachain validation configuration.</p> <p>Using the Whitelisted Caller track requires some special calls. Submitting a referendum in the same form as other tracks will not work. Namely, rather than voting on a particular <code>proposal</code>, the Whitelisted Caller track requires a vote to <code>dispatch</code> the <code>proposal</code> via the Whitelist pallet. Before opening a referendum on this track, you should also attempt to get a positive signal from the Fellowship that they will whitelist the proposal. If they do not, then even if the public referendum passes, it will not execute.</p> <p>Below are the steps to follow when submitting a proposal to the Whitelist track.</p> <ul> <li>Submit a preimage with the call to dispatch the proposal (<code>call</code>) you   want to submit -- <code>whitelist.dispatchWhitelistedCallWithPreimage(call)</code> -- and obtain the preimage   hash. This is the preimage for the public referendum on the Whitelisted Caller track.</li> </ul> <p></p> <ul> <li>Obtain the hash of <code>call</code>. The Polkadot Fellowship needs to start a Fellowship referendum to   whitelist the call with <code>whitelist.whitelistCall(callHash)</code>. The Fellowship referendum gets voted   on by the Polkadot Fellowship members only.</li> </ul> <p></p> <ul> <li>The public now votes on the referendum. Someone must place a decision deposit to go into the   deciding phase.</li> <li>Once passed, it gets enacted successfully as long as the call has been whitelisted by the   Fellowship.</li> </ul> <p>Note that the public referendum and Fellowship referendum can happen simultaneously. However, if the Fellowship does not whitelist the call, you must submit it directly to the Root origin.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#voting-on-referenda","title":"Voting on Referenda","text":"<p>As Polkadot OpenGov takes both the approval and support into account, there are four options to choose from when voting on a referendum:</p> <ul> <li>Aye</li> <li>Nay</li> <li>Split</li> <li>Abstain</li> </ul> <p>Also, you have to specify the conviction multiplier for this vote. The longer you are willing to lock your tokens, the stronger your vote will be weighted. Unwillingness to lock your tokens means that your vote only counts for 10% of the tokens that you hold.</p> <p>For detailed instructions on how to vote on Polkadot OpenGov referenda, check this support guide.</p> <p>Polkadot OpenGov uses Conviction Voting Pallet (Not Democracy Pallet)</p> <p>Use <code>convictionVoting.vote</code> for voting on Referenda in Polkadot OpenGov instead of <code>democracy.vote</code> (which only works for the old version of governance).</p>"},{"location":"learn/learn-guides-polkadot-opengov/#removing-votes","title":"Removing Votes","text":"<p>To remove votes, you need to use the Extrinsics tab and call the <code>removeVote</code> function through the <code>convictionVoting</code> pallet.</p> <p></p> <p>The <code>class</code> is the OpenGov track of the referendum you voted on and the <code>index</code> is the referendum number.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#removing-expired-voting-locks","title":"Removing Expired Voting Locks","text":"<p>To remove an expired lock, you need to use the Extrinsics tab and call the <code>unlock</code> function through the <code>convictionVoting</code> pallet. Note that if you voted on referenda in multiple tracks, the tokens will be unlocked after removing votes and unlocking on all the tracks. Similarly, if you you delegated on multiple tracks, the funds will be unlocked after undelegating and unlocking on all the tracks.</p> <p></p> <p>The <code>class</code> is the OpenGov track where you have the lock.</p> <p>For additional instructions, check this support guide.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#delegations","title":"Delegations","text":"<p>Video Tutorial about Delegations using the Polkadot-JS UI</p> <p>See this video tutorial to learn about how to delegate, modify delegations and remove delegations using the Polkadot-JS UI.</p> <p>For an overview of how delegation works in Polkadot OpenGov, check out the Multirole Delegation section on the Learn Polkadot OpenGov page.</p> <p>Instructions to do delegations with Polkadot-JS are also available on the Support Pages.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#delegate-votes","title":"Delegate Votes","text":"<p>You can start delegating your votes by clicking the \"Delegate\" button on Governance &gt; Referenda.</p> <p></p> <p>If it is the first time you delegate or vote, there will be a banner message. You can delegate on a single track or all the tracks. You have an option to specify the number of votes (i.e., the number of tokens) and the conviction multiplier. After clicking \"Next\", you will need to specify the account to delegate your votes to, and after clicking \"Delegate\" and \"Sign and Submit\" your delegations will appear for each track (see below).</p> <p></p> <p>Note that if you want to delegate just a few tracks, you have two options:</p> <ul> <li>Repeat the process using the \"Delegate\" button multiple times</li> <li>Issue a batch call with multiple <code>convictionVoting.delegate</code> extrinsics under   Developer &gt; Extrinsics</li> </ul> <p></p> <p>By clicking on \"Add item\" you can add new extrinsics for multiple tracks.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#undelegate-votes","title":"Undelegate Votes","text":"<p>The \"Delegate\" button on Governance &gt; Referenda is only for delegating votes. You cannot undelegate or modify your delegations. If you wish to undelegate, you will need to go to Developer &gt; Extrinsics and submit a <code>convictionVoting.undelegate</code> extrinsic, specifying the track you wish to undelegate.</p> <p></p> <p>Undelegated tracks will show up as \"0 votes\" on the Delegate tab.</p> <p></p> <p>After you undelegated, the conviction lock will start the countdown, and your funds will be available for unlocking after the countdown ends.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#remove-expired-locks-from-delegations","title":"Remove Expired Locks from Delegations","text":"<p>To remove expired locks from delegations, you can follow the same procedure as how to remove expired voting locks.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#modify-your-delegations","title":"Modify your Delegations","text":"<p>The \"Delegate\" button on Governance &gt; Referenda is only for delegating votes. You cannot undelegate or modify your delegations. If you wish to update the delegated account, the conviction, and the number of votes you will need to go to Developer &gt; Extrinsics, undelegate the track and delegate again with updated information.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#claiming-opengov-deposits","title":"Claiming OpenGov Deposits","text":"<p>Video Tutorial about OpenGov deposits using the Polkadot-JS UI</p> <p>See this video tutorial to learn about how to claim OpenGov deposits using the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#claiming-the-preimage-and-decision-deposits","title":"Claiming the Preimage and Decision Deposits","text":"<p>After a referendum finishes its life cycle (and gets approved or rejected or timed out), the preimage and decision deposits can be claimed. For claiming the preimage deposit, navigate to Polkadot-JS UI &gt; Governance &gt; Preimages and click on unnote button shown on the preimage you submitted.</p> <p></p> <p>Similarly, to claim the decision deposit, navigate to Polkadot-JS UI &gt; Governance &gt; Referenda and scroll down to the end of the page to click on the referenda with the decision deposit and claim it.</p> <p></p>"},{"location":"learn/learn-guides-polkadot-opengov/#claiming-the-referendum-submission-deposit","title":"Claiming the Referendum Submission Deposit","text":"<p>The submission deposit for a referendum can be claimed only if the referendum was <code>Approved</code> or <code>Canceled</code>. The submission deposit can be claimed by issuing the <code>refundSubmissionDeposit</code> extrinsic.</p> <p>Users can not refund their submission deposit while the referendum is <code>Ongoing</code> or <code>Rejected</code>. Similarly, users cannot refund their submission deposit if the proposal has <code>TimedOut</code> (failing to submit the decision deposit within specific period will lead to a referendum timeout). This behavior exists so that users can refrain from spamming the chain with proposals that have no interest from the community. If a proposal is in the <code>TimedOut</code> state, any user can call <code>slash_proposal_deposit</code>, which will move the funds from the user to a runtime-configured account, like the treasury.</p> <p>To refund your slashed deposit, you can start a new referendum and specifically request a refund from the treasury. You need to make sure you have enough balance for a new submission and decision deposit, and you will need to select the right track to ask for a refund. For example, the Small Tipper Track would be fine for any kind of deposit refund up to 250 DOT (8.25 KSM on Kusama).</p>"},{"location":"learn/learn-guides-polkadot-opengov/#cancel-or-kill-a-referendum","title":"Cancel or Kill a Referendum","text":"<p>Info</p> <p>Anybody can cancel an ongoing referendum (i.e., a referendum within the Lead-in or voting/confirmation period). For more information about the referenda timeline in Polkadot OpenGov, see the dedicated page.</p> <p>To successfully cancel a referendum through the track <code>20 / Referendum Canceller</code>, you will need to attain specific approval and support levels.</p> <p>To cancel a referendum, you need first to submit a preimage with the <code>referenda.cancel</code> extrinsic. Go to the Polkadot-JS UI &gt; Governance &gt; Referenda and click on the \"Add Preimage\" button. You must specify the <code>referenda.cancel</code> extrinsic with the index equal to the ongoing Referendum you wish to cancel. In the screenshot below, the Referendum to be cancelled is 249.</p> <p></p> <p>This call will cancel the referendum and return the deposit. You can also kill a referendum using the <code>referenda.kill</code> extrinsic. This will cancel the referendum and slash the deposit.</p> <p>Preimage Submission Deposit</p> <p>A deposit is required for the preimage to be stored on chain. The preimage deposit is proportional to the amount of information stored within the preimage. The deposit amount required for a preimage with a treasury spend transaction is around 41 DOT (1.4 KSM on Kusama). Ensure you have enough account balance to pay for this submission deposit as well as the transaction fees.</p> <p>Once a preimage is submitted, it can be checked under Governance &gt; Preimages.</p> <p></p> <p>You must copy the preimage to use it when you submit your proposal. To submit the proposal to cancel referendum 249, for example, you need to go under Governance &gt; Referenda and click the \"Submit Proposal\" button.</p> <p></p> <p>You must specify the account to submit the proposal (this can differ from the account used to create the preimage). Then you will need to specify the track <code>20 / Referendum Canceller</code> and add the preimage hash containing the specific action that will be enacted if the referendum passes. Note that a submission deposit will be reserved for submitting the proposal.</p> <p>Once the proposal has been submitted, it will stay in the Lead-in period until there is enough space within the track, and a track-dependent preparation period and decision deposit have been met. Failing to submit the decision deposit will ultimately lead to a referendum timeout.</p>"},{"location":"learn/learn-guides-polkadot-opengov/#interpreting-on-chain-voting-data","title":"Interpreting On-Chain Voting Data","text":"<p>Below is the numeric conversion of the type of vote and conviction displayed in a block explorer.</p> <pre><code>Nay 0.1x =&gt; 0\nNay 1x =&gt; 1\nNay 2x =&gt; 2\nNay 3x =&gt; 3\nNay 4x =&gt; 4\nNay 5x =&gt; 5\nNay 6x =&gt; 6\n\nAye 0.1x =&gt; 128\nAye 1x =&gt; 129\nAye 2x =&gt; 130\nAye 3x =&gt; 131\nAye 4x =&gt; 132\nAye 5x =&gt; 133\nAye 6x =&gt; 134\n</code></pre> <p>Take, for example, the information provided for this vote. The vote <code>131</code> means the account voted Aye with 3x conviction.</p> <p></p> <p>At first glance, it may not be easy to interpret what you voted on. We need to take a step back and consider the \"voting data\" at the binary level.</p> <p>The vote is stored as a byte using a bitfield data structure and displayed on the block explorer as a decimal integer. The bitfield stores both the conviction and aye/nay boolean, where the boolean is represented using the MSB of the byte. This would mean that the seven remaining bits are grouped to store the conviction.</p>"},{"location":"learn/learn-guides-staking-pools/","title":"Polkadot-JS Guides for Pool Creators","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>See this page to learn about nomination pools.</p>"},{"location":"learn/learn-guides-staking-pools/#pool-creation-with-polkadot-js","title":"Pool Creation with Polkadot-JS","text":"<p>Info</p> <p>You easily create a pool using the Polkadot Staking Dashboard. See this support article for more information.</p> <p>The depositor calls the <code>create</code> extrinsic, setting the administrative roles and transferring some funds to the pool to add themselves as the first member. As stated above, the depositor must always be a member as long as the pool exists; they will be the last member to leave, ensuring they always have some skin in the game. A significant stake from the depositor is always a good indicator of the pool's credibility.</p> <p>The current minimum bond to create a pool can be found here.</p> <p>The pool\u2019s \u2018nominator role\u2019 selects validators with the nominate extrinsic. On Polkadot JS Apps UI, navigate to Network &gt; Staking &gt; Pools and click on Add Pool button.</p> <p></p> <p>The UI automatically assigns an ID to the pool and allows for entering the name of the pools and the deposit to be bonded.</p> <p></p> <p>When creating a pool using Polkadot JS Apps UI, all the roles are mapped to the Depositor account by default. If any of these roles need to be assigned to a different account, create the pool using <code>create</code> extrinsic available in Developer &gt; Extrinsics &gt; nominationPools on Polkadot JS Apps UI.</p> <p></p>"},{"location":"learn/learn-guides-staking-pools/#pool-upkeep-with-polkadot-js","title":"Pool Upkeep with Polkadot-JS","text":"<p>The nominator can update the pool\u2019s validator selection. On Polkadot JS Apps UI, navigate to Network &gt; Staking &gt; Accounts page and click on Pooled button. If you have any pooled accounts with the role of nominator, you will notice the option to set nominees. Select the validators to nominate like you would normally using a nominator account.</p> <p></p> <p>The root and bouncer can update the pool\u2019s state to blocked through <code>setState</code> extrinsic and kick members by calling <code>unbond</code> and <code>withdrawUnbonded</code>. (The state can also be toggled back to open).</p>"},{"location":"learn/learn-guides-staking-pools/#pool-destruction-with-polkadot-js","title":"Pool Destruction with Polkadot-JS","text":"<p>Info</p> <p>As a pool admin, you can easily destroy a pool and permissionlessly remove all members using the Polkadot Staking Dashboard. See this support article for more information.</p> <p>A pool can be pushed into the \u201cdestroying\u201d state via one of:</p> <ul> <li>The root and bouncer set the pool to \u201cdestroying\u201d. This can be done by submitting the   <code>nominationPools.setState(poolId, state)</code> extrinsic using the   Polkadot-JS UI extrinsic tab. Where <code>poolId</code> is the   specific ID of the pool and <code>state</code> is the pool's state that must be set to \"destroying\". Other   possible states are \"open\" and \"blocked\".</li> <li>Any account can set the pool to destroying if over 90% of the pool's active bonded balance has   been slashed.</li> </ul> <p>When a pool is in \u2018destroying\u2019 state, <code>unbond</code> and <code>withdrawUnbonded</code> become permissionless, so anyone can help all the members exit.</p> <p>The pool is destroyed once the depositor withdraws, no members belong to the pool, and all the pool\u2019s resources are wiped from the state.</p>"},{"location":"learn/learn-guides-staking-pools/#claim-rewards-for-other-pool-members-with-polkadot-js","title":"Claim Rewards for Other Pool Members with Polkadot-JS","text":"<p>As a pool member you can claim rewards for any other members who set their claim permissions to one of the permissionless options.</p> <p>Let's take the example of ALICE setting the claim permissions to <code>PermissionlessAll</code>. Another account STASH can now claim ALICE's rewards (as a free balance or compound them to the existing bonded balance). To do so, STASH can go to the Polkadot-JS UI Extrinsic Tab and issue the following extrisics:</p> <ul> <li><code>nominationPools.claimPayoutOthers</code> extrinsic specifying ALICE's account. This will claim the   rewards as a free balance on ALICE's account.</li> </ul> <p></p> <ul> <li><code>nominationPools.bondExtraOthers</code> extrinsic specifying ALICE's account and the option to bond:</li> <li>the free balance currently available in ALICE's account (<code>FreeBalance</code>) or</li> <li>the pool rewards (<code>Rewards</code>) unclaimed by ALICE.</li> </ul> <p></p>"},{"location":"learn/learn-guides-staking/","title":"Polkadot-JS Guides about Staking","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-test-opengov-proposals/","title":"Test OpenGov Referenda before Submission","text":"<p>A Polkadot OpenGov referendum always contains a call that will be executed after the referendum is voted in successfully. The referendum proposer is responsible for checking if the call gets executed successfully on-chain and whether an appropriate origin and track have been chosen. In the case of referenda that send a cross-chain call to the system chains, it is important to check whether the XCM call gets dispatched successfully from Polkadot and is received/executed as expected on the system chain.</p> <p>This tutorial aims to show how to test the calls to be submitted with the referendum and ensure they work as expected. Let us consider the two examples below:</p> <ul> <li>Submitting a Treasury referendum that requests 4500 DOT</li> <li>Submitting a referendum to remove ambassadors   (Referendum 1247)</li> </ul>"},{"location":"learn/learn-guides-test-opengov-proposals/#test-a-polkadot-opengov-referendum","title":"Test a Polkadot OpenGov Referendum","text":"<p>To request 4500 DOT from the treasury, you must create a pre-image with the call <code>treasury.spendLocal(amount,beneficiary)</code>. The guide for creating pre-images for treasury proposals and submitting them is available here on the Wiki. The proposer needs to know the exact origin and track to submit this proposal. As this is a treasury proposal, it would be one of the treasury tracks - SmallSpender in the case of 4500 DOT.</p> <p><code>0x13030b00d00361ed28009e4e7009937c56d267338762a60ed004293afd40e7c2081847c12cb63c76a818</code></p> <p></p>"},{"location":"learn/learn-guides-test-opengov-proposals/#fork-a-network-locally-using-chopsticks","title":"Fork a Network Locally using Chopsticks","text":"<p>If you like to check whether the call above will get executed successfully, you can check that by performing a dry run using Chopsticks, which is embedded in Polkadot JS UI. You can run a Chopsticks instance of any Polkadot SDK based chain by clicking \"fork locally\" on the UI. The snapshot below shows it for Polkadot.</p> <p></p> <p>After forking locally, the Polkadot JS UI displays a local instance of the Polkadot network, which does not produce any blocks by default. You will notice a few test accounts with DOT balance that can interact with the network and test out Polkadot protocol features accessible through regular accounts. However, the treasury spend call cannot be submitted through a signed account origin, so it has to be tested with a treasury track origin. It can be tested by navigating to Developer &gt; Javascript tab on Polkadot JS UI, which dispatches the call on the next block via the scheduler with the specified origin.</p> <pre><code>const number = (await api.rpc.chain.getHeader()).number.toNumber()\nawait api.rpc('dev_setStorage', {\n scheduler: {\n   agenda: [\n     [\n       [number + 1], [\n         {\n           call: {\n             Inline: '0x13030b00d00361ed28009e4e7009937c56d267338762a60ed004293afd40e7c2081847c12cb63c76a818'\n           },\n           origin: {\n             origins: 'SmallSpender'\n           }\n         }\n       ]\n     ]\n   ]\n }\n})\nawait api.rpc('dev_newBlock')\n</code></pre> <p></p> <p>After clicking the play button in the Javascript console, the block number visible on the top left of the Polkadot JS UI should be incremented by 1. You can navigate to Polkadot JS UI Network &gt; Explorer to check the emitted events and see if the call was executed successfully. You should see the errors displayed here if the call is unsuccessful.</p> <p></p>"},{"location":"learn/learn-guides-test-opengov-proposals/#test-a-polkadot-opengov-referendum-with-cross-chain-calls","title":"Test a Polkadot OpenGov Referendum with Cross-chain Calls","text":"<p>Take the example of removing a member of the ambassador collective on the Collectives system chain through a Polkadot OpenGov referendum. Obtain the call data to remove a member from the ambassador collective in the Collectives system chain runtime.</p> <p></p> <p>Note down the call data and navigate to Developer &gt; Runtime calls and fetch the weights for execution of the call through <code>transactionPaymentCallApi.queryCallInfo</code>. Here is the call info used in our example for your reference: <code>0x4603000c691601793de060491dab143dfae19f5f6413d4ce4c363637e5ceacb2836a4e0300</code></p> <p></p> <p>Now you have all the information you need to create an XCM call that needs to be sent from Polkadot. No fee payment is required for an XCM call dispatched through OpenGov. The Collectives chain <code>ParaID</code> is 1001. With this information, we can construct the XCM call shown below.</p> <p><code>0x630004000100a50f04082f0000060303e3c4cc9589ad944603000c691601793de060491dab143dfae19f5f6413d4ce4c363637e5ceacb2836a4e0300</code></p> <p></p>"},{"location":"learn/learn-guides-test-opengov-proposals/#cross-chain-testing-setup-using-chopsticks","title":"Cross-chain Testing setup using Chopsticks","text":"<p>Testing this cross-chain call by forking locally will only perform the required checks on the sending chain, not the receiving chain. To do cross-chain testing, download and install Chopsticks on your machine and run the command below:</p> <p><code>npx @acala-network/chopsticks@latest xcm -r polkadot -p polkadot-collectives</code></p> <p>This should start the Polkadot and the Collectives instances available at ports 8001 and 8000 respectively. Connect to both these instances using Polkadot JS UI on two separate browser windows. To connect to these local machine instances at the designated ports, edit the custom endpoint for Polkadot JS UI as shown in the picture below and click on Switch button at the top.</p> <p></p> <p>Navigate to the Polkadot instance and open Javascript console to run the code below.</p> <pre><code>const number = (await api.rpc.chain.getHeader()).number.toNumber()\nawait api.rpc('dev_setStorage', {\n scheduler: {\n   agenda: [\n     [\n       [number + 1], [\n         {\n           call: {\n             Inline: '0x630004000100a50f04082f0000060303e3c4cc9589ad944603000c691601793de060491dab143dfae19f5f6413d4ce4c363637e5ceacb2836a4e0300'\n           },\n           origin: {\n             origins: 'FellowshipAdmin'\n           }\n         }\n       ]\n     ]\n   ]\n }\n})\nawait api.rpc('dev_newBlock')\n</code></pre> <p></p> <p>After clicking on the play button in the Javascript console, the block number visible on the top left of the Polkadot JS UI should be incremented by 1. You can navigate to Polkadot JS UI Network &gt; Explorer to check the emitted events and see if the call got executed successfully. If the call is unsuccessful, you should see the respective errors displayed here.</p> <p>Successful XCM call dispatch shown on the Polkadot network:</p> <p></p> <p>You can then navigate to the local Collectives instance and check the events to confirm the call is executed as expected.</p> <p>Successful XCM call receipt shown on the Collectives system chain:</p> <p></p> <p>Now, take the example of Referendum 1247 which executes a call that tries to remove 19 ambassadors from the collective at once. This is a very long call and exceeds the Javascript console <code>inLine</code> character limit. In that case, the code can be modified instead to lookup the preimage of call with the specified length and check if it is successfully executes.</p> <p><code>0x630004000100a50f04082f0000060307005847f80d824f12009d0b28045046030090bd3d091b8837f2f41c38b6e3bebd28a31ee280f82d15e687f95d798ef41c1703004603000c7f10142a81fedec753f7c556f5b93a400c280805e7fcdff668719637b13434030046030062d8c4e1c6fbab57ba4df15b8120db4cec5c150371d0755d8ee5312382f47f09030046030094c860705264b96854acc3cb307365132bd131524ef83a7c014378ed793737230300460300aeb6173b1b6d5933c79992954d1469e845a89a5c754f91a9cb2f7589d78b9970030046030018bd4fb6b90f5088bdc825c3d674bd72e705c6f1163e86f960eeb7969ab4833a03004603002add0af948eba3b1fcd5cacde1f6fcc70f11ef75056f88ca4d11dcc5b080220e03004603009a3a7fc4a0eba9a8bd47c96aedfb5436ecc4d39536af5fca275fbf88104eae070300460300f4792917b47917519e2c05619763a4e7b45b84815f902f62e16f23e9f2b2265303004603008e156836bd7dc0639ea54540eb6ec55aec2a3793876208bf5d71ff89eb746a07030046030008b712a589f5cb71cd7094809785ab0a924358d3cb52b27efd4933b6efc149630300460300cc10dd1946b0fc65c8993ff7f47052713e9aa4b1cb72c913bd397c34adf4f9490300460300d6b8ec23dc68f20b5d315007d9c1a6706f9bd5c883319181129e76a89e97815503004603000c691601793de060491dab143dfae19f5f6413d4ce4c363637e5ceacb2836a4e03004603000ef2cc1000f878a3880a09d698b5375f20c4ab3d8b3a1b783c8150faca3da65a03004603001eb38b0d5178bc680c10a204f81164946a25078c6d3b5f6813cef61c3aef48430300460300568191edc1aaf4bea93b17cf53ea49ab78e2d25d83dec8581854be93d3bc9609030046030088f28e17671ba1808d7b02cd3caaf80113066a467127666f4d80afc50bfbc1270300460300b430a1d38186a28164facec9010e36b1289eb6d3ad0f03f328188fd52bcb333a0300460300ce2490656709c33bdd50d72dc0ec562bb72db84945ef7a1be45be14bbc6fc8770300</code></p> <p>The preimage hash of this call is <code>0x82802c62d52a2431e422b58fff1fbdd0efc648e7c98351bd26048d169b94f956</code> and its length is <code>733</code> (obtained from Polkadot JS UI Governance &gt; Preimgaes tab for that lists the preimages that are already submitted).</p> <pre><code>const number = (await api.rpc.chain.getHeader()).number.toNumber()\nawait api.rpc('dev_setStorage', {\n scheduler: {\n   agenda: [\n     [\n       [number + 1], [\n         {\n           call: {\n             Lookup: {\n               hash: \"0x82802c62d52a2431e422b58fff1fbdd0efc648e7c98351bd26048d169b94f956\",\n               len: 733\n             }\n           },\n           origin: {\n             origins: 'FellowshipAdmin'\n           }\n         }\n       ]\n     ]\n   ]\n }\n})\nawait api.rpc('dev_newBlock')\n</code></pre> <p>If there are referenda that are to be submitted on Root track and you like to test it, you can use the same template as above and replace</p> <pre><code>           origin: {\n             origins: 'FellowshipAdmin'\n           }\n</code></pre> <p>with</p> <pre><code>           system: {\n             origin: 'Root'\n           }\n</code></pre>"},{"location":"learn/learn-guides-transfers/","title":"Polkadot-JS Guides about Transfers","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-guides-transfers/#metadata-updates-with-the-polkadot-js-browser-extension","title":"Metadata Updates with the Polkadot-JS Browser Extension","text":"<p>Before signing extrinsics with the Polkadot-JS Browser Extension, always check for metadata updates. This video tutorial will explain how to do it.</p> <p>Polkadot Vault vs Polkadot-JS Browser Extension</p> <p>The Polkadot Vault app updates the full metadata through the QR fountain while the extension updates the metadata index (the metadata is not loaded into it). As a consequence the process of updating metadata is different in this two cases (you will notice that on the Vault app the update takes longer for example). Having outdated metadata on the Vault app will prevent you from signing, while on the extension you will be able to click the sign button but the extrinsic will likely fail (similarly of having an outdated Ledger app). In general, failing to update metadata will most likely result in you not being able to sign extrinsics.</p>"},{"location":"learn/learn-guides-transfers/#transfers-using-the-polkadot-js-ui-and-browser-extension","title":"Transfers using the Polkadot-JS UI and Browser Extension","text":"<p>See this video tutorial to learn how to send funds using the Polkadot-JS UI and Browser Extension. See also the Polkadot Support pages for detailed information about signing transactions using the Polkadot-JS UI and the Polkadot-JS browser extension.</p>"},{"location":"learn/learn-guides-transfers/#verify-extrinsics-with-the-polkadot-js-browser-extension","title":"Verify Extrinsics with the Polkadot-JS Browser Extension","text":"<p>Visit the dedicated support page and see this video tutorial tutorial to learn about how to verify extrinsics before signing them. The video will also mention potential attacks that can happen to you while signing for transactions.</p>"},{"location":"learn/learn-guides-transfers/#verify-extrinsics-with-the-polkadot-js-ui","title":"Verify Extrinsics with the Polkadot-JS UI","text":"<p>Visit the dedicated support page and see this video tutorial tutorial to learn about how to verify extrinsics before signing them. The video will also mention potential attacks that can happen to you while signing for transactions.</p>"},{"location":"learn/learn-guides-transfers/#keep-alive-checks-with-the-polkadot-js-ui","title":"Keep-Alive Checks with the Polkadot-JS UI","text":"<p>Info</p> <p>See this video tutorial and this support page to learn about keep-alive checks and existential deposit.</p> <p>In Polkadot there are two main ways to transfer funds from one account to another:</p> <ul> <li><code>transfer keep-alive</code> (default option) will not allow you to send an amount that would allow the   sending account to be removed due to it going below the   existential deposit.</li> <li><code>transfer allow-death</code> will allow you to send tokens regardless of the consequence. If the balance   drops below the existential deposit your account will be reaped. It may be that you do not want to   keep the account alive (for example, because you are moving all of your funds to a different   address). To switch the keep-alive check off visit   this support article.</li> </ul> <p>Info</p> <p>Attempting to send less than the existential deposit to an account with zero balance will always fail, no matter if the keep-alive check is on or not.</p> <p>Even if the transfer fails due to a keep-alive check, the transaction fee will be deducted from the sending account if you attempt to transfer.</p>"},{"location":"learn/learn-guides-transfers/#vested-transfers-with-the-polkadot-js-ui","title":"Vested Transfers with the Polkadot-JS UI","text":"<p>You can watch this video tutorial to understand how to do vested transfers using the Polkadot-JS UI, including linear and cliff vesting. Note the tutorial uses the Westend Testnet, but the same applies to Polkadot and Kusama.</p> <p>There are two ways that vesting schedules can be created.</p> <ul> <li>One way is through an extrinsic type available in the Vesting pallet, <code>vested_transfer</code>. The   vested transfer function allows anyone to create a vesting schedule with a transfer of funds, as   long as the account for which the vesting schedule will be created does not already have one and   the transfer moves at least <code>MinVestedTransfer</code> funds, which is specified as a chain constant.</li> <li>A second way is as part of the genesis configuration of the chain. In the case of Polkadot, the   chain specification genesis script reads the state of the Claims contract that exists on the   Ethereum blockchain and creates vesting schedules in genesis for all the allocations registered as   being vested.</li> </ul> <p>Vesting schedules have three parameters:</p> <ul> <li>locked, the amount of tokens to be transferred in   Planck units</li> <li>per block, the number of tokens that are released per block</li> <li>starting block, the block number after which the vesting schedule starts</li> </ul> <p>The configuration of these three fields dictates the amount of funds that are originally locked, the slope of the unlock line and the block number for when the unlocking begins.</p>"},{"location":"learn/learn-guides-transfers/#lazy-vesting","title":"Lazy Vesting","text":"<p>Like simple payouts, vesting is lazy, which means that someone must explicitly call an extrinsic to update the lock that is placed on an account.</p> <ul> <li>The <code>vest</code> extrinsic will update the lock that is placed on the caller.</li> <li>The <code>vest_other</code> will update the lock that is placed on another \"target\" account's funds.</li> </ul> <p>These extrinsics are exposed from the Vesting pallet.</p> <p>If you are using the Polkadot-JS UI, when there are tokens available to vest for an account, you can unlock tokens that have already been vested from the Accounts page.</p> <p></p>"},{"location":"learn/learn-guides-transfers/#calculating-when-vesting-dot-will-be-available","title":"Calculating When Vesting DOT Will Be Available","text":"<p>Generally, you should be able to see from the Accounts by looking at your accounts and seeing when the vesting will finish. However, some DOT vest with \"cliffs\" - a single block where all the DOT are released, instead of vesting over time. In this case, you will have to query the chain state directly to see when they will be available (since technically, the vesting has not yet started - all of the vesting will occur in a single block in the future).</p> <ol> <li>Navigate to the    Chain State page on    Polkadot-JS.</li> <li>Query chain state for <code>vesting.vesting(ACCOUNT_ID)</code></li> <li>Note the <code>startingBlock</code> where the unlock starts, and how much DOT is unlocked per block    (<code>perBlock</code>).</li> <li>You will have to calculate the result into \u201chuman time\". To do this, remember that there are    approximately 14\u2019400 blocks per day, and you can see what the latest block is shown on the    Explorer page.</li> </ol>"},{"location":"learn/learn-guides-transfers/#batch-transfers-with-the-polkadot-js-ui","title":"Batch Transfers with the Polkadot-JS UI","text":"<p>Batch transfers are balances transfers to multiple accounts executed by one account. In order to construct a batch transfer you need to:</p> <ul> <li>Create a <code>utility.batch(calls)</code> extrinsic using the   utility pallet, and</li> <li>Within the batch call you can create multiple <code>balances.transferKeepAlive</code> extrinsics using the   balances pallet. You   can specify as many receivers as you desire.</li> </ul> <p>Info</p> <p>You can watch this video tutorial to learn how to do batch transfers. Note the tutorial uses the Westend Testnet, but the same applies to both Polkadot and Kusama.</p>"},{"location":"learn/learn-guides-transfers/#teleporting-tokens-using-the-polkadot-js-ui","title":"Teleporting Tokens using the Polkadot-JS UI","text":"<p>See this video tutorial and this additional support article to learn more about how to teleport tokens.</p> <p>Info</p> <p>If you do not see \"Accounts &gt; Teleport\" in the Polkadot-JS UI, the source chain that you have selected does not support teleportation yet.</p>"},{"location":"learn/learn-guides-transfers/#calculating-fees-with-polkadot-js","title":"Calculating Fees with Polkadot-JS","text":"<p>To calculate fees you can go to Developer &gt; Runtime Calls and select the following extrinsics:</p> <ul> <li><code>transactionPaymentApi.queryInfo</code></li> <li><code>transactionPaymentApi.queryFeeDetails</code></li> </ul> <p>and specify the <code>0x</code> prefixed hex call data and its length.</p> <p></p> <p>The sum of <code>baseFee</code>, <code>lenFee</code> and <code>adjustedWeightFee</code> will yield the <code>partialFee</code>.</p> <p>One useful utility for estimating transaction fees programmatically is the via the @polkadot/api. Check out the following script that logs some relevant fee information:</p> <pre><code>// Estimate the fees as RuntimeDispatchInfo using the signer\nconst info = await api.tx.balances.transfer(recipient, 123).paymentInfo(sender);\n\n// Log relevant info, partialFee is Balance, estimated for current\nconsole.log(`\n  class=${info.class.toString()},\n  weight=${info.weight.toString()},\n  partialFee=${info.partialFee.toHuman()}\n`);\n</code></pre> <p>For additional information on interacting with the API, checkout Polkadot-JS.</p>"},{"location":"learn/learn-guides-transfers/#existing-reference-error","title":"Existing Reference Error","text":"<p>If you are trying to reap an account and you receive an error similar to <code>\"There is an existing reference count on the sender account. As such the account cannot be reaped from the state\"</code>, then you have existing references to this account that must be first removed before it can be reaped. References may still exist from:</p> <ul> <li>Bonded tokens (most likely)</li> <li>Unpurged session keys (if you were previously a validator)</li> <li>Token locks</li> <li>Existing recovery info</li> <li>Existing assets</li> </ul>"},{"location":"learn/learn-guides-transfers/#bonded-tokens","title":"Bonded Tokens","text":"<p>If you have tokens that are bonded, you will need to unbond them before you can reap your account. Follow the instructions at Unbonding and Rebonding to check if you have bonded tokens, stop nominating (if necessary) and unbond your tokens.</p>"},{"location":"learn/learn-guides-transfers/#checking-for-locks","title":"Checking for Locks","text":"<p>Info</p> <p>See this video tutorial and this support page to learn how to check for locks and remove them.</p> <p>You can also check for locks by querying <code>system.account(AccountId)</code> in <code>Chain state</code> tab under the <code>Developer</code> drop-down menu in the Polkadot-JS UI. Select your account, then click the \"+\" button next to the dropdowns, and check the relative <code>data</code> JSON object. If you see a non-zero value for anything other than <code>free</code>, you have locks on your account that need to get resolved.</p>"},{"location":"learn/learn-guides-transfers/#purging-session-keys","title":"Purging Session Keys","text":"<p>If you used this account to set up a validator and you did not purge your keys before unbonding your tokens, you need to purge your keys. You can do this by seeing the How to Stop Validating page. This can also be checked by checking <code>session.nextKeys</code> in the chain state for an existing key.</p>"},{"location":"learn/learn-guides-transfers/#existing-recovery-info","title":"Existing Recovery Info","text":"<p>Currently, Polkadot does not use the Recovery Pallet, so this is probably not the reason for your tokens having existing references.</p> <p>On Kusama, you can check if recovery has been set up by checking the <code>recovery.recoverable(AccountId)</code> chain state. This can be found under <code>Developer &gt; Chain state</code> in PolkadotJS Apps.</p>"},{"location":"learn/learn-guides-transfers/#existing-non-native-assets","title":"Existing Non-Native Assets","text":"<p>Currently, Polkadot does not use the Assets Pallet, so this is probably not the reason for your tokens having existing references.</p>"},{"location":"learn/learn-guides-treasury/","title":"Polkadot-JS Guides about the Treasury","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>See this page to learn about the Polkadot Treasury.</p>"},{"location":"learn/learn-guides-treasury/#creating-a-treasury-proposal","title":"Creating a Treasury Proposal","text":"<p>Your proposal should address a problem, outline a goal, give a detailed account of how you will reach that goal, and include any ongoing maintenance needs. As much as possible, you should itemize the tasks to be completed so fees can be evaluated and milestones can be followed. You can check the guidelines below:</p> <ul> <li>Guidelines for a successful proposal on   Polkadot and   Kusama</li> <li>Treasury proposal template for Polkadot</li> </ul>"},{"location":"learn/learn-guides-treasury/#announcing-the-proposal","title":"Announcing the Proposal","text":"<p>To minimize storage on-chain, proposals don't contain contextual information. When a user submits a proposal, they will need to find an off-chain way to explain the proposal via community channels.</p> <p>Spreading the word about the proposal's explanation to the community is ultimately up to the proposer.</p> <p>Use Accounts with Verified On-Chain Identity for Treasury Proposals</p> <p>To ensure legitimacy, it is required that the account linked to the Treasury proposal has an identity set and is verified by an on-chain registrar.</p>"},{"location":"learn/learn-guides-treasury/#creating-a-treasury-proposal-spend-local","title":"Creating a Treasury Proposal - Spend Local","text":"<p>\"Spend\" vs. \"Spend Local\"</p> <p>You may notice that the Treasury pallet contains two extrinsics - <code>treasury.spend</code> and <code>treasury.spendLocal</code>. <code>treasury.spendLocal</code> (formally called <code>treasury.spend</code>) refers to a spend of DOT that is locally available, i.e., DOT from the relay chain's treasury account. <code>spend</code> actually allows the caller to specify an asset other than DOT, or even assets in other locations, e.g. Asset Hub.</p> <p>Unlike <code>treasury.spendLocal</code>, <code>treasury.spend</code> is not bound by a spend period, and must be claimed manually via the <code>treasury.payout</code> extrinsic. <code>treasuy.spendLocal</code> behavior remains unchanged.</p>"},{"location":"learn/learn-guides-treasury/#submit-treasury-proposal-preimage","title":"Submit Treasury Proposal Preimage","text":"<p>The example below shows how to create a preimage for a transaction that requests 100 DOT from Treasury.</p> <ul> <li>Navigate to Polkadot-JS UI &gt; Governance &gt; Preimages   and then click on Add Preimage.</li> <li>Select the account which will be used to submit the preimage.</li> <li>Choose <code>treasury</code> pallet in the \"propose\" dropdown and the <code>spendLocal(amount, beneficiary)</code>call</li> <li>Enter the DOT amount.</li> <li>Enter the AccountID of the beneficiary (which has a verified on-chain identity).</li> <li>Submit preimage</li> <li>Sign and submit the transaction by paying the specified transaction fees.</li> </ul> <p>Preimage Submission Deposit</p> <p>A deposit is required for the preimage to be stored on chain. The preimage deposit is proportional to the amount of information stored within the preimage. The deposit amount required for a preimage with a treasury spend transaction is around 41 DOT (1.4 KSM on Kusama). Ensure you have enough account balance to pay for the submission deposit and the transaction fees.</p> <p>Here is the preimage requesting for 100 DOT.</p> <p></p> <p>Balance entered is in Plancks</p> <p>Polkadot JS UI is for developers and the UI takes input of the balance in plancks. DOT has 10 decimals, which is 10000000000 plancks per DOT.</p> <p>After successful submission of the preimage, it is displayed on Polkadot-JS UI &gt; Governance &gt; Preimages page. Every preimage is associated with a unique preimage hash (highlighted in a box in the image below). Take a note of this preimage hash, which is required to submit a referendum.</p> <p></p>"},{"location":"learn/learn-guides-treasury/#submit-a-treasury-track-referendum","title":"Submit a Treasury Track Referendum","text":"<p>The example below shows how to submit a Treasury track referendum.</p> <ul> <li>Navigate to Polkadot-JS UI &gt; Governance &gt; Referenda   and then click on Submit proposal.</li> <li>Select the account which will be used to submit the proposal.</li> <li>Choose the appropriate submission track (The example below selected Small Spender track).</li> <li>Enter the preimage hash of the treasury spend transaction.(If the preimage exists on-chain, the   preimage length box is automatically populated)</li> <li>Click on Submit proposal.</li> <li>Sign and submit the transaction.</li> </ul> <p></p> <p>Once your submission is executed, your referendum will appear under your chosen track on the Polkadot-JS UI referenda page.</p>"},{"location":"learn/learn-guides-treasury/#place-a-decision-deposit-for-the-treasury-track-referendum","title":"Place a Decision Deposit for the Treasury Track Referendum","text":"<p>For the referendum to move from preparing phase to the deciding phase, a decision deposit needs to be placed. The decision deposit values for each individual Treasury Tracks are listed in a section above in this document.</p> <p></p> <p>The preimage and decision deposits can be claimed once the referendum ends.</p>"},{"location":"learn/learn-guides-treasury/#creating-a-multistage-payout-proposal-with-validfrom","title":"Creating a Multistage Payout Proposal with <code>validFrom</code>","text":"<p>Staged proposals are similar to a tranche or milestone-based funding model; instead of all spends being paid simultaneously, each portion is redeemable at a certain block height. This is done by specifying each milestone, set at its respective amount and block height at which it becomes redeemable.</p> <p>For example, take the following \"staged\" proposal, which has three milestones, each at 100 DOT, and is redeemable at the following block heights. Usually, block heights correspond to a date in the future:</p> <ul> <li>100 DOT paid out at block height 1000</li> <li>200 DOT paid out at block height 2000</li> <li>500 DOT paid out at block height 4000</li> </ul> <p>Governance can also propose to void a staged proposal before it has completed all of its payouts.</p> <p>Calculating dates from block heights</p> <p>Although not the most accurate form of measurement, block heights can be used to correspond to certain dates in the future.</p>"},{"location":"learn/learn-guides-treasury/#using-batch-for-multi-spend-proposals","title":"Using <code>batch</code> for Multi-Spend Proposals","text":"<p>Using the Utility pallet, one can batch multiple <code>treasury.spend</code> calls together. Each of these calls can have its own <code>validFrom</code> block height, which allows for scenarios such as the above to be possible.</p> <p>Multistage payout proposal example</p> <p>For reference on how to create a multistage payout proposal, please check Referendum 382 on Kusama.</p>"},{"location":"learn/learn-guides-treasury/#using-validfrom-for-a-milestone-based-proposal","title":"Using <code>validFrom</code> for a Milestone-Based Proposal","text":"<p>Once each spend is defined within the batched call, the <code>validFrom</code> field can be utilized to specify the \"date\", or block height, at which each spend will be executed.</p> <p>Treasury Spends have to be claimed manually. Spends can expire!</p> <p>Keep in mind that once the <code>validFrom</code> block height has been reached, you will have to claim the spend within 30 days. Check the claiming process for treasury spends here</p>"},{"location":"learn/learn-guides-treasury/#creating-a-usdt-treasury-proposal-spend-with-assethub","title":"Creating a USDT Treasury Proposal - Spend (with AssetHub)","text":"<p>The following tutorial mostly goes over how to utilize the <code>spend</code> extrinsic, which, unlike <code>spendLocal</code>, is able to specify assets besides the native asset in other locations, such as Asset Hub.</p>"},{"location":"learn/learn-guides-treasury/#creating-a-preimage","title":"Creating a Preimage","text":"<p>The example below shows how to create a preimage for a transaction that requests 100 USDT from AssetHub.</p> <ul> <li>Navigate to Polkadot-JS UI &gt; Governance &gt; Referenda   and then click on Add Preimage.</li> <li>Select the account to submit the preimage.</li> <li>Choose the <code>treasury</code> pallet in the \"propose\" dropdown and the   <code>spend(assetKind, amount, beneficiary, validFrom)</code> call.</li> </ul> <p>Now, let's go through each field one-by-one and fill them in accordingly:</p>"},{"location":"learn/learn-guides-treasury/#specifying-asset-kind","title":"Specifying Asset Kind","text":"<p><code>assetKind</code> refers to the asset to be used, specified via XCM. In short, we need to be able to find:</p> <ul> <li>The relative location of the asset, and</li> <li>How it is identified within this location.</li> </ul> <p>For this example, we are using USDT, which from the perspective of the relay chain would be:</p> <p><code>Parachain 1000 (AssetHub) &gt; AssetId (Concrete) &gt; PalletInstance 50 &gt; General Index 1984</code></p> <p>First, we specify the location - in this case, Asset Hub (parachain 1,000). <code>PalletInstance 50</code> refers to the Assets pallet instance on Asset Hub. The general index is <code>1984</code>, which is the ID of USDT in this instance of the Assets pallet.</p> <p>Bug on Polkadot-JS UI</p> <p>As the Polkadot-JS UI is interpreting the general index in DOT, it multiplies the entered values with <code>10000000000</code> (As DOT token has 10 decimals) and places it in the <code>u128</code> argument. As we would like to have <code>1984</code> as the input argument, we can offset this UI induced error by entering <code>0.0000001984</code>.</p> <p>The issue on Polkadot-JS repo can be tracked here.</p> <p>Here is how the final <code>assetKind</code> field should look:</p> <p></p>"},{"location":"learn/learn-guides-treasury/#specifying-the-amount","title":"Specifying the Amount","text":"<p>The amount should be simply the amount of USDT, where each <code>1</code> USDT is <code>1000000</code>. Because we are asking for 100 USDT, we put <code>100000000</code> as the input for the amount.</p> <p>Bug on Polkadot-JS UI</p> <p>As the Polkadot-JS UI is interpreting the asset balance in DOT, it multiplies the entered values with <code>10000000000</code> (As DOT token has 10 decimals) and places it in the <code>u128</code> argument. As we would like to have <code>100000000</code> as the input argument, we can offset this UI induced error by entering <code>0.01</code> for this particular example where we like to input 100 USDT.</p> <p>The issue on Polkadot-JS repo can be tracked here.</p> <p></p>"},{"location":"learn/learn-guides-treasury/#specifying-the-beneficiary","title":"Specifying the Beneficiary","text":"<p>The beneficiary account will be one on Asset Hub. For this reason, the XCM junction must be specified as follows, with one junction (<code>X1</code>) and the beneficiary account (<code>AccountId32</code>), which is an account address on the chain.</p>"},{"location":"learn/learn-guides-treasury/#specifying-validfrom-optional","title":"Specifying <code>validFrom</code> (optional)","text":"<p>The <code>validFrom</code> field is optional, and refers to the block height of the relay chain upon which the payout can be issued. If the <code>validFrom</code> parameter is not set, the spend can be paid out immediately after approval. For more information on this field, refer to the guide below.</p> <p>The final call should look like the following, where we:</p> <ul> <li>Specify our asset as USDT on Asset Hub.</li> <li>Specify the amount of USDT (100).</li> <li>Specify the beneficiary address.</li> <li>If applicable, use the <code>validFrom</code> field to specify a block number upon which the payout becomes   valid.</li> </ul> <p>The next steps are to:</p> <ul> <li>Copy the preimage (and its length)</li> <li>Sign and submit the preimage</li> </ul> <p>Once this is finished, one may submit a proposal as stated above. Keep in mind one will also need to provide the decision deposit as well.</p>"},{"location":"learn/learn-guides-treasury/#manually-claiming-payouts","title":"Manually Claiming Payouts","text":"<p>In order to claim the spend, you must manually call the <code>treasury.payout</code> extrinsic via a <code>Signed</code> origin. The <code>spendID</code> for the pending payout can be queried on-chain through Polkadot-JS UI &gt; Developer &gt; Chain State &gt; Storage &gt; treasury &gt; spends and unselect the include option and then click on the plus button to the right.</p> <p></p> <p>From the list of spends, find the <code>spendID</code> of your respetive payout and issue the payout extrinsic.</p> <p>payout example</p> <p>To claim the first payout of Referendum 382 on Kusama, this payout extrinsic was issued. After issuing the payout extrinsic, the status of the payout changes from <code>pending</code> to <code>Attempted</code> with a reference to a payment ID. If the payout is successful, the balance on Asset Hub should be updated. Here is the transfer extrinsic on Asset Hub for the first payout of Referendum 382.</p> <p>To clear the on-chain storage of a successful or expired spend, Treasury pallet's <code>checkStatus</code> extrinsic can be used. The transaction fees paid for issuing this extrinsic will be refunded.</p>"},{"location":"learn/learn-guides-treasury/#proposing-a-void-for-a-staged-proposal","title":"Proposing a \"Void\" for a Staged Proposal","text":"<p>If a proposal that hasn't completed all of its spends needs to be voided, the <code>treasury.voidSpend</code> extrinsic can be utilized via a governance proposal.</p> <p>Example proposal - Voiding a Treasury Spend</p> <p>For reference, check the referenda on Kusama that tests VoidSpend functionality for Treasury Payouts. Through this referenda, a treasury spend was successfully voided.</p>"},{"location":"learn/learn-guides-treasury/#submit-treasury-proposal-via-polkassembly","title":"Submit Treasury Proposal via Polkassembly","text":"<p>To submit a treasury track referendum via Polkassembly click on the FAB button in the bottom right corner. Then,</p> <ul> <li>Click on \"Create Treasury Proposal\" and choose an address for the proposer.</li> <li> <p>After choosing an address, you will enter a three-stage guideline:</p> </li> <li> <p>Write a proposal: you can add a detailed description for the proposal, which will be stored on     Polkassembly. Alternatively, you can link an existing discussion post.</p> </li> </ul> <p></p> <ul> <li>Create a preimage: an existing preimage can be linked, or a new one can be created. To create a     preimage, add the beneficiary address and the token amount. The track will be auto-selected and     the user can proceed with the creation of a preimage.</li> </ul> <p></p> <ul> <li>Create a proposal: final confirmation about the proposal creation. The description of the     proposal and the preimage are automatically linked to the proposal.</li> </ul>"},{"location":"learn/learn-guides-treasury/#requesting-tips-from-the-treasury","title":"Requesting Tips from the Treasury","text":"<p>To request a tip funded by the treasury, you can follow the above steps for creating a treasury proposal but instead of submitting the proposal to the <code>32 / Small Spender</code> track, you will need to submit it to the <code>30 / Small Tipper</code> or <code>31 / Big Tipper</code> tracks depending on the number of tokens to be requested.</p> <p>Briefly, you will need to:</p> <ul> <li>Create a preimage using the <code>treasury.spendLocal</code> extrinsic and specifying the number of tokens   and the beneficiary of the tip</li> <li>Submit a proposal to the right track (i.e. <code>30</code> or <code>31</code>) using the preimage hash</li> <li>Once you started the referendum go to Polkassembly, log in with the   proposer account and edit the referendum details</li> <li>Notify the Polkadot Direction Element Channel   or the Kusama Direction Element Channel about   your referendum</li> <li>Place the decision deposit   before the timeout</li> <li>Once the referendum ends you can   claim the preimage and decision deposits back</li> </ul>"},{"location":"learn/learn-guides-vault/","title":"Polkadot-JS Guides about the Vault App","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>!!!info These guides apply to both Parity Signer and Polkadot Vault apps.</p>"},{"location":"learn/learn-guides-vault/#sending-a-transfer-with-the-vault-app","title":"Sending a Transfer with the Vault App","text":"<p>Verifying Extrinsics</p> <p>Visit the dedicated support page and see this video tutorial tutorial to learn about how to verify extrinsics before signing them. The video will also mention potential attacks that can happen to you while signing for transactions.</p> <p>General instructions to send a transfer can be found on this support page. To sign transactions with the Polkadot Vault app check this support article or see this video tutorial.</p>"},{"location":"learn/learn-guides-vault/#import-vault-accounts-into-polkadot-js","title":"Import Vault Accounts into Polkadot-JS","text":"<p>See this support article to import a Polkadot Vault account into the Polkadot-JS Browser Extension or Parity Signer Companion. Accounts added to those extensions will be injected into the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-vault/#do-your-own-chain-spec-and-metadata-update","title":"Do Your Own Chain Spec and Metadata Update","text":"<p>This section is for developers and power users only</p> <p>By requesting the chain specification and metadata you trust the specific endpoint you are using (unless you are using you own node).</p> <p>The following guide bases on the Parity Signer Github page (to create the Chain Spec QR code and the metadata QR code fountain) and Metadata Portal Github page (to embed the Chain Spec and Metadata into a portal).</p>"},{"location":"learn/learn-guides-vault/#chain-specification","title":"Chain Specification","text":""},{"location":"learn/learn-guides-vault/#chain-spec-qr","title":"Chain Spec QR","text":"<p>To add more chains on the Vault app you can follow the instructions here. In this example we will add the Asset Hub system parachain. Briefly, fork the Parity Signer GitHub repository, start the terminal within the <code>/generate_message</code> folder and type the following:</p> <p><code>cargo run add-specs -d -u wss://kusama-asset-hub-rpc.polkadot.io --encryption sr25519</code></p> <p>where <code>wss://kusama-asset.hub-rpc.polkadot.io</code> is the Parity RPC endpoint for the Asset Hub on Kusama. This will create the file <code>sign_me_add_specs_statemine_sr25510</code> under the <code>files/in_progress</code> folder. See all endpoints listed for Polkadot and Kusama on the Polkadot-JS UI.</p>"},{"location":"learn/learn-guides-vault/#generating-signature","title":"Generating Signature","text":"<p>Use a hot account</p> <p>Make sure that the account used to sign the chain specification is a hot account. Never use a cold account from the Vault app or Ledger, as after typing the seed phrase into the terminal that account will be considered hot.</p> <p>Start the terminal within the <code>files/in_progress</code> folder and type the following:</p> <p><code>cat sign_me_add_specs_statemine_sr25519 | subkey sign --suri \"YOUR SEED PHRASE\"</code></p> <p>where <code>\"YOUR SEED PHRASE\"</code> is the seed phrase of the account that will be used to sign and authenticate both the chain spec and later on the metadata. Running the code above will return a signature similar to that below:</p> <p><code>0xc4ce72db959000b6166af96d3bda55a927fd837747bf1bf1ae8a69e57c9ef37c25a88707c47b105a9eb1fbcf9345680eff57eb978cf73919506f6c738834e78a</code></p>"},{"location":"learn/learn-guides-vault/#signing-chain-spec","title":"Signing Chain Spec","text":"<p>Now, go back to the <code>/generate_message</code> folder and type the following:</p> <p><code>cargo run --release make --goal qr --crypto sr25519 --msg add-specs --payload sign_me_add_specs_statemine_sr25519 --verifier-hex PUBLIC KEY --signature-hex SIGNATURE</code></p> <p>where <code>PUBLIC KEY</code> is the public key of the account with seed <code>\"YOUR SEED PHRASE\"</code>, and <code>SIGNATURE</code> is the signature generated in the previous step. Running the code above will create the file <code>add_specs_statemine-sr25519</code> under the <code>files/completed</code> folder.</p>"},{"location":"learn/learn-guides-vault/#metadata-updates","title":"Metadata Updates","text":"<p>Similarly to what we did for the chain specification, we now generate and sign the Asset Hub metadata.</p>"},{"location":"learn/learn-guides-vault/#metadata-qr-fountain","title":"Metadata QR Fountain","text":"<p>To update the chain metadata for the Asset Hub specs on the Vault app you can follow the instructions here. Briefly, in the Parity Signer repository, start the terminal within the <code>/generate_message</code> folder and type the following:</p> <p><code>cargo run load-metadata -d -u wss://kusama-asset-hub-rpc.polkadot.io</code></p> <p>where <code>wss://kusama-asset-hub-rpc.polkadot.io</code> is the Parity RPC endpoint for the Asset Hub on Kusama. This will create the file <code>sign_me_load_metadata_statemineV9370</code> under the <code>files/in_progress</code> folder. Note that for future metadata updates the file name will change as the version at the time of writing was <code>V9370</code>.</p> <p>Info</p> <p>Note that the name of the file changes according to the network version. That is, <code>????</code> in <code>sign_me_load_metadata_statemineV????</code> will be the latest version at fetch time.</p>"},{"location":"learn/learn-guides-vault/#generating-signature_1","title":"Generating Signature","text":"<p>Use a hot account</p> <p>Make sure that the account used to sign the metadata is a hot account. Never use a cold account from the Vault app or Ledger, as after typing the seed phrase into the terminal that account will be considered hot.</p> <p>Start the terminal within the <code>files/in_progress</code> folder and type the following:</p> <p><code>cat sign_me_load_metadata_statemineV9370 | subkey sign --suri \"YOUR SEED PHRASE\"</code></p> <p>where <code>\"YOUR SEED PHRASE\"</code> is the seed phrase of the account you used to sign the chain specification. Running the code above will return a signature similar to that below:</p> <p><code>0xde1ad7aeb252acb3cf42a522dcc8dc3f317a49be2ed636836dd6df8f7e47135f2c712480055822eba87e9ea5ac7d3bba96045992ae795856fdf4eea09a411f85</code></p> <p>Do not copy the code lines above</p> <p>Note that the name of the file changes according to the network version. That is, <code>????</code> in <code>sign_me_load_metadata_statemineV????</code> will be the latest version at fetch time. So, do not copy the code line above, but change the version with the appropriate one saved under the <code>files/in_progress</code> folder. The signature changes as well.</p>"},{"location":"learn/learn-guides-vault/#signing-metadata","title":"Signing Metadata","text":"<p>Now, go back to the <code>/generate_message</code> folder and type the following:</p> <p><code>cargo run --release make --goal qr --crypto sr25519 --msg load-metadata --payload sign_me_load_metadata_statemineV9370 --verifier-hex PUBLIC KEY --signature-hex SIGNATURE</code></p> <p>where <code>PUBLIC KEY</code> is the public key of the account with seed <code>\"YOUR SEED PHRASE\"</code>, and <code>SIGNATURE</code> is the signature generated in the previous step. Running the code above will create the file <code>load_metadata_statemineV9370</code> under the <code>files/completed</code> folder.</p>"},{"location":"learn/learn-guides-vault/#add-chain-update-metadata","title":"Add Chain &amp; Update Metadata","text":"<p>You can open <code>add_specs_statemine-sr25519</code> on your browser (just drag the file on an open tab). This is a .png file containing the QR code to add the Asset Hub chain specification into the Vault App. You can do the same with the <code>load_metadata_statemineV9370</code>. This is a .apng file containing the QR code fountain to do the metadata update for the Asset Hub on Kusama.</p>"},{"location":"learn/learn-guides-vault/#metadata-portal","title":"Metadata Portal","text":""},{"location":"learn/learn-guides-vault/#modify-config-file","title":"Modify <code>config</code> File","text":"<p>Alternatively, you can add the chain specification QR code and the metadata QR code fountain in a metadata portal. Briefly, fork the Parity's Metadata Portal GitHub repository. You can modify the following fields of the <code>config.toml</code> file:</p> <ul> <li><code>name</code>: your name / institution</li> <li><code>public_key</code>: the public key of the account you use to sign the chain spec and the metadata.</li> <li>At the bottom of the file add the following information:</li> </ul> <pre><code>[[chains]]\nname = \"Statemine\"\ntitle = \"Kusama Asset Hub\"\nrpc_endpoint = \"wss://kusama-asset-hub-rpc.polkadot.io\"\ncolor = \"#f27230\"\n\n[chains.github_release]\nowner = \"paritytech\"\nrepo = \"statemint\"\ngenesis_hash = \"0x48239ef607d7928874027a43a67689209727dfb3d3dc5e5b03a39bdc2eda771a\"\n</code></pre> <p>For each additional chain, you need to add the respective information. Information about the genesis hash can be found on the Polkadot-JS UI &gt; connect to the relevant chain &gt; Developer &gt; Chain State.</p>"},{"location":"learn/learn-guides-vault/#rename-chains-files","title":"Rename Chain's Files","text":"<p>Rename the signed chain specification and metadata files as follow:</p> <ul> <li> <p>Chain specification: <code>add_specs_statemine-sr25519</code> \u2192 <code>statemine_specs.png</code></p> </li> <li> <p>Metadata updates: <code>load_metadata_statemineV9370</code>\u2192 <code>statemine_metadata_9370.apng</code></p> </li> </ul> <p>Thus, for chain specification the file must be renamed to <code>chainName_specs.png</code> while for metadata the file must be renamed to <code>chainName_metadata_version.apng</code> where <code>chainName</code> is the name of the chain and <code>version</code> is the version of the metadata.</p> <p>Add the renamed files to the <code>/public/qr folder</code> within the Metadata Portal repository.</p>"},{"location":"learn/learn-guides-vault/#run-portal","title":"Run Portal","text":"<p>Open the terminal within the Metadata Portal repository and run <code>make updater</code>. Then run <code>make collector</code>; this will create the <code>_latest.apng</code> files for each of the chains (removed by the command <code>make cleaner</code>). Finally, run <code>yarn start</code> to load the metadata portal on your localhost.</p>"},{"location":"learn/learn-hyperbridge/","title":"Hyperbridge","text":"<p>Learn about Parachain and Bridges</p> <p>To follow the material on this page, it is recommended to be familiar with the concepts of Parachains and Bridges.</p> <p>Interoperability is the core vision of the Polkadot technology. Through years of blockchain development, much effort has been put into making a secure interoperability solution between blockchains. Polkadot provides secure interoperability between parachains through its Cross-Consensus Messaging (XCM), and Cross-Chain Message Passing (XCMP) protocol. However, these solutions work when there is a shared security. In the case of interaction between chains that do not belong to the same Polkadot's shared security, bridges are needed.</p> <p>Hyperbridge (short for hyper-scalable bridge) is innovated as a cross-chain solution built as an interoperability coprocessor. Hyperbridge is crafted to scale cryptographically secure, consensus, and state-proof-based interoperability across all blockchains.</p>"},{"location":"learn/learn-hyperbridge/#coprocessor-model","title":"Coprocessor Model","text":"<p>Ensuring secure cross-chain communication involves the meticulous verification of various aspects, including: Consensus Mechanisms, Consensus Faults, State Proofs and State Transitions.</p> <p>What is a coprocessor?</p> <p>Coprocessor, in the context of hardware, can be referred to as a microprocessor designed to supplement the capabilities of the primary processor. For example, a GPU is a coprocessor of the CPU to be optimized for graphical and simultaneous computation.</p> <p>Due to the complexity and expensiveness of the onchain verification process, in the coprocessor model, the computation is performed off-chain. The execution outcomes and cryptographic proofs validating their accuracy are subsequently presented on-chain.</p> <p>Expanding more about the coprocessor model, it has been applied in other solutions of offloading cryptographic computation as well, particularly Zero-knowledge (ZK) coprocessor or SNARK circuit.</p>"},{"location":"learn/learn-hyperbridge/#parachain-as-coprocessors","title":"Parachain as Coprocessors","text":"<p>By leveraging the cost-effective consensus proofs facilitated by BEEFY, Hyperbridge affirms the legitimacy of all parachain state transitions safeguarded by the network.</p> <p>This capability enables the distribution of the validation workload for consensus, state proofs, and state transition re-execution across various designated Parachain Cores. Hence, Polkadot is utilized by Hyperbridge as a verifiable computation layer to provide the \"Full Node Security\" in cross-chain bridges.</p> <p>Hence, an additional layer of security is provided, allowing Hyperbridge to detect and prevent Byzantine behaviors across connected chains.</p>"},{"location":"learn/learn-hyperbridge/#interoperable-state-machine-protocol-ismp","title":"Interoperable State Machine Protocol (ISMP)","text":"<p>Interoperable State Machine Protocol (ISMP) provides a familiar HTTP-like API for developers who want to make cross-chain requests to trigger certain logic on the counterparty chain. It allows POST requests to send arbitrary data to connected chains and GET requests to read the storage (verified through state proofs) of applications on connected chains.</p> <p>In addition to facilitating cross-chain message passing among connected chains, ISMP also serves as a synchronization primitive across Hyperbridge's internal state machines. This enables its parachain cores to communicate with each other and delegate tasks.</p>"},{"location":"learn/learn-hyperbridge/#underlying-technologies","title":"Underlying technologies","text":"<p>The underlying technologies of the Hyperbridge are integrated with:</p> <ul> <li>PLONK verifier: The PLONK Verifier within Hyperbridge can   be likened to a sophisticated security apparatus. It operates like an expert detective,   meticulously ensuring the legitimacy of every transaction without compromising private details.   Continuously enhancing its capabilities, particularly with advancements like UltraPLONK, this   integral component is pivotal in maintaining the utmost integrity and confidentiality of   cross-chain communications.</li> <li>BEEFY consensus: The BEEFY   (Bridge Efficiency Enabling Finality Yielder) protocol functions as a complementary system to   GRANDPA, specifically designed to facilitate efficient bridging between the Polkadot network's   relay chain and external, isolated blockchains like Ethereum. Notably, BEEFY addresses the   interoperability challenge with blockchains not initially constructed to integrate seamlessly with   the Polkadot interchain framework.</li> <li>The Barretenberg backend: Within the realm of   Hyperbridge, Barretenberg functions as a powerhouse engine, adeptly managing intricate   mathematical computations. As the backend infrastructure, it guarantees the swift, secure, and   reliable execution of all cryptographic operations within the Hyperbridge ecosystem.</li> </ul>"},{"location":"learn/learn-hyperbridge/#terminology","title":"Terminology","text":""},{"location":"learn/learn-hyperbridge/#state-proofs","title":"State Proofs","text":"<p>State proofs are a critical primitive of the blockchain stack that enables things like trustless bridges. These off-chain light clients can access on-chain data in a permissionless and secure manner and modular blockchain architectures where the execution layer can be decoupled from the consensus layer.</p>"},{"location":"learn/learn-hyperbridge/#consensus-proofs","title":"Consensus Proofs","text":"<p>Consensus Proofs in a blockchain system denote the mechanism by which participants, often nodes or validators, collectively agree on the validity of new transactions or blocks. The nature of consensus proofs varies across different blockchain architectures, such as Proof-of-Work, Proof-of-Stake, or other consensus algorithms.</p> <p>The ultimate goal is to ensure a widespread and verifiable agreement among network participants, enhancing the security and reliability of the distributed ledger.</p> <p>For example, Consensus Proofs in a proof of stake system are given as the signatures over the latest block header in the chain from a supermajority (two-thirds plus one) subset of the full authority set.</p>"},{"location":"learn/learn-hyperbridge/#resources","title":"Resources","text":"<p>To learn more about Hyperbridge, see the resources below.</p> <ul> <li>Introducing Hyperbridge: An Interoperability Coprocessor -   Article by Seun Lanlege, Polytope Lab founder.</li> <li>Hyperbridge: The New Interoperability Coprocessor on Polkadot -   Article by Erik from Simply Staking</li> <li>Digital Services as State Machines -   Lecture about state machine from Polkadot Blockchain Academy</li> <li>Hyperbridge Source Code - Public codebase   repository of hyperbridge.</li> <li>Interoperable State Machine Protocol (ISMP) Book - Guidebook   of the ISMP</li> <li>The Puzzle of Blockchain Interoperability</li> <li>ISMP, The Endgame for Parachain Interoperability | Sub0 2023</li> </ul>"},{"location":"learn/learn-identity/","title":"Account Identity","text":"<p>Setting your identity on Polkassembly</p> <p>You can set your identity using the Polkassembly dApp. Follow these support guides.</p> <p>Polkadot provides a naming system that allows participants to add personal information to their on-chain account and subsequently ask for verification of this information by registrars.</p> <p>Users must reserve funds in a bond to store their information on chain. These funds are locked, not spent - they are returned when the identity is cleared.</p> <p>Identities are managed on the People system chain.</p> <p>You can cross-chain transfer your DOT tokens to the People system chain using Nova Wallet. A guide on how to do this can be found here.</p>"},{"location":"learn/learn-identity/#sub-identities","title":"Sub-Identities","text":"<p>Users can also link accounts by setting \"sub accounts\", each with its own identity, under a primary account. The system reserves a bond for each sub account. An example of how you might use this would be a validation company running multiple validators. A single entity, \"My Staking Company\", could register multiple sub accounts that represent the Stash accounts of each of their validators.</p> <p>An account can have a maximum of 100 sub-accounts. Note that a deposit is required for every sub-account.</p>"},{"location":"learn/learn-identity/#judgements","title":"Judgements","text":"<p>After a user injects their information on chain, they can request judgement from a registrar. Users declare a maximum fee that they are willing to pay for judgement, and registrars whose fee is below that amount can provide a judgement.</p> <p>When a registrar provides judgement, they can select up to six levels of confidence in their attestation:</p> <ul> <li>Unknown: The default value, no judgement made yet.</li> <li>Reasonable: The data appears reasonable, but no in-depth checks (e.g. formal KYC process) were   performed (all the currently verified identities on-chain).</li> <li>Known Good: The registrar has certified that the information is correct (this step involves   verification of state issued identity documents, and at the moment no account has known good   identity, with the exception of registrars).</li> <li>Out of Date: The information used to be good, but is now out of date.</li> <li>Low Quality: The information is low quality or imprecise, but can be fixed with an update.</li> <li>Erroneous: The information is erroneous and may indicate malicious intent.</li> </ul> <p>A seventh state, \"fee paid\", is for when a user has requested judgement and it is in progress. Information that is in this state or \"erroneous\" is \"sticky\" and cannot be modified; it can only be removed by the complete removal of the identity.</p> <p>Registrars gain trust by performing proper due diligence and would presumably be replaced for issuing faulty judgments.</p>"},{"location":"learn/learn-identity/#registrars","title":"Registrars","text":"<p>Registrars can set a fee for their services and limit their attestation to certain fields. For example, a registrar could charge 1 DOT to verify one's legal name, email, and GPG key. When a user requests judgement, they will pay this fee to the registrar who provides the judgement on those claims. Users set a maximum fee they are willing to pay and only registrars below this amount would provide judgement.</p> <p>There are multiple registrars on Polkadot and Kusama. Unless no additional information is available here, you must reach out to specific registrars individually if you want to be judged by those.</p> <p>Decommissioned Registrar Service</p> <p>From the 1<sup>st</sup> of April 2024 onwards, Registrar 0 will still exist on-chain but will not accept any new judgment requests. The registrar fee is set to a substantial amount to dissuade identity judgement requests. Identities judged by the registrar before that date will not be affected. For new identity judgment, please use the other registrars.</p> PolkadotKusama <p>Registrar 0 :  URL: NA  Account: 12j3Cz8qskCGJxmSJpVL2z2t3Fpmw3KoBaBaRGPnuibFc7o8 Fee: 0 DOT </p> <p>Registrar 1:  URL: https://registrar.d11d.net/  Account: 1Reg2TYv9rGfrQKpPREmrHRxrNsUDBQKzkYwP1UstD97wpJ  Fee: 20 DOT </p> <p>Registrar 2:  Account: 1EpXirnoTimS1SWq52BeYx7sitsusXNGzMyGx8WPujPd1HB  Fee: 0 DOT </p> <p>Registrar 3:  Account: 13SceNt2ELz3ti4rnQbY1snpYH4XE4fLFsW8ph9rpwJd6HFC  Fee: 0.5 DOT  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their website.</p> <p>Registrar 4:  URL: https://polkaidentity.com/  Account: 16LYBUcQKWZjAYE4oAPWx9XFaEYnCAffwpPuPWrUvU1mqBZT  Fee: 0.5 DOT  PolkaIdentity (Registrar 4) provides setting on-chain ID as a service on their website.</p> <p>Registrar 0 :  URL: NA  Account: H4XieK3r3dq3VEvRtqZR7wN7a1UEkXxf14orRsEfdFjmgkF Fee: 0.04 KSM </p> <p>Registrar 1:  URL: https://registrar.d11d.net/  Account: Fom9M5W6Kck1hNAiE2mDcZ67auUCiNTzLBUdQy4QnxHSxdn  Fee: 4.5 KSM </p> <p>Registrar 2: is no longer offering registrar services on Kusama.  Account: EK8veMNH6sVtvhSRo4q1ZRh6huCDm69gxK4eN5MFoZzo3G7 Fee: 1 KSM </p> <p>Registrar 3:  Account: GLiebiQp5f6G5vNcc7BgRE9T3hrZSYDwP6evERn3hEczdaM  Fee: 1 KSM  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their website.</p> <p>Registrar 4:  Account: GhmpzxUyTVsFJhV7s2wNvD8v3Bgikb6WvYjj4QSuSScAUw6  Fee: 0.04 KSM </p> <p>Registrar 5:  Account: F1wAMxpzvjWCpsnbUMamgKfqFM7LRvNdkcQ44STkeVbemEZ  Fee: 0.04 KSM  Polkassembly (Registrar 5) provides setting on-chain ID as a service on their website.</p> <p>Registrar 6:  URL: https://polkaidentity.com/  Account: HurhThD66KBUf2zcE9Zhx46sCqNJXviKhWAct95rBCkPuix  Fee: 0.04 KSM  PolkaIdentity (Registrar 6) provides setting on-chain ID as a service on their website.</p> <p>See this page to learn how to become a Registrar.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about account identity.</p> <p>See also these Polkadot-JS support guides.</p>"},{"location":"learn/learn-implementations/","title":"Polkadot Implementations","text":"<p>Polkadot is the flagship protocol of the Web3 Foundation, and while Polkadot can be defined as a protocol, a network, or, a type of infrastructure, it best serves to be an ecosystem. For true decentralization, there should be multiple implementations of Polkadot. Even being a layer 0 protocol that attempts to build an interconnected, interoperable and secure Web3 ecosystem, Polkadot is a complex piece of software, and its formal implementation depends on being built on top of a tech stack.</p> <p>This page will focus on implementations of Polkadot's underlying infrastructure (i.e. runtime, host).</p>"},{"location":"learn/learn-implementations/#a-wasm-based-meta-protocol","title":"A Wasm-based Meta Protocol","text":"<p>Polkadot uses WebAssembly (Wasm) as a \"meta-protocol\". This allows for the use of any programming language that can be interpreted or compiled into Wasm - being the driver for Polkadot's multiple implementations.</p>"},{"location":"learn/learn-implementations/#parity-technologies-a-rustic-vision-for-polkadot","title":"Parity Technologies: A Rustic Vision for Polkadot","text":"<p>Parity Technologies is often in the spotlight for its core development of Polkadot, and while this is true, Parity Polkadot also serves to be the Rust client. Parity Tech has a rustic vision for Polkadot through the use of their main product, Substrate. Substrate can also be used for different chains and different networks, but in the case of Polkadot, Substrate acts as the tech stack that is used to implement Polkadot's sharded heterogeneous multi-chain model.</p> <p>Parity Tech focuses on blockchain infrastructure for the decentralised web, where they initially offered an Ethereum client (Parity Ethereum). Parity Tech was hired by the Web3 Foundation to foster the development of the first implementation of Polkadot.</p> <p>Polkadot can support parachains that are not built on Substrate, In particular, as long as the state transition function (STF) of a shard is abstracted into Wasm, the validators on the network can execute the STF within a Wasm environment.</p> <p>Note: chains can also be built on Substrate and are not required to be deployed onto Polkadot. More on Polkadot's architecture is available on the Architecture page.</p> <p>With this in mind, we can point to some other implementations of Polkadot. Having different implementations inherently promotes the decentralization of the technology and progresses it in a meaningful way. Other implementations of Polkadot that exist, many of whom have received a grant from the Web3 Foundation, are in programming languages like Go, C++, and JavaScript, which are all languages that can be compiled in Wasm.</p> <p>As stated in the Soramitsu grant announcement:</p> <pre><code>It is critically important to have multiple implementations of the Polkadot protocol for a number\nof reasons, including decentralization, knowledge dispersion, and better definitions of the\nprotocol... Multiple implementations of Polkadot improves network resilience and adds to the\ndecentralization of the network. The governance of the network is more democratized when multiple\nteams build clients that run the nodes in the network.\n</code></pre>"},{"location":"learn/learn-implementations/#alternative-implementations","title":"Alternative Implementations","text":""},{"location":"learn/learn-implementations/#chainsafe-systems-gossamer","title":"ChainSafe Systems: Gossamer","text":"<p>Gossamer is a Go implementation being built by ChainSafe Systems, a blockchain R&amp;D firm based in Toronto, Canada that is also building an Eth2.0 Serenity client. They were awarded a grant from the Web3 Foundation.</p>"},{"location":"learn/learn-implementations/#soramitsu-kagome","title":"SORAMITSU: Kagome","text":"<p>Kagome is a C++ implementation of the Polkadot Host being built by Soramitsu, a Japanese digital identity company that previously developed Hyperledger Iroha. They were awarded a grant from the Web3 Foundation and released the first version of Kagome in April 2020. As part of the process, they also released a libp2p networking layer in C++.</p>"},{"location":"learn/learn-implementations/#polkadot-js-project-polkadot-js","title":"Polkadot-JS Project: Polkadot-JS","text":"<p>Polkadot-JS is a JavaScript client and offers a collection of tools, interfaces, and libraries for Polkadot and Substrate.</p>"},{"location":"learn/learn-implementations/#other-implementations-that-have-received-grants","title":"Other implementations that have received grants","text":"<ul> <li>Golkadot</li> <li>Polkadot in Java</li> </ul> <p>While the ecosystem continues to grow rapidly, the continued development of alternative implementations will only make Polkadot stronger. Consider becoming a contributor to the ecosystem, and learn about the how you can receive a grant for your development.</p>"},{"location":"learn/learn-inflation/","title":"DOT Inflation Model","text":"<p>        In November 2024, Polkadot transitioned from a model that led to exponential growth in the token supply (but with a constant inflation rate) to one with linear growth (with a decreasing inflation rate).          The constant inflation rate model is still in use for            Kusama.      </p> \u2716 <p>DOT is an inflationary token, with fixed annual expansion of the token supply of 120,000,000 DOT, of which 15% goes to the treasury and 85% to stakers.</p> <p>It is essential to understand that the primary objective of inflation is to incentivize network participants through Nominated Proof of Stake (NPoS) and to grow the network through funding the on-chain treasury. The token inflation rate can be updated through on-chain governance based on thorough tokenomics research.</p> <p>Below is a 25-year prediction of DOT gross annual inflation (red line) and DOT total issuance (blue line), assuming the current fixed inflation rate.</p> <p></p> <p>The total issuance takes into account the gross DOT inflation and thus does not consider tokens that are burned.</p> <p>Net DOT inflation depends on treasury burns and coretime sales that are variables and thus cannot be predicted. Net inflation can be defined as follows:</p> <pre><code>Net Inflation = Gross fixed inflation - burned supply (treasury + coretime sales)\n</code></pre> <p>Where <code>Gross fixed inflation</code> is the annual inflation of 120M DOT and the <code>burned supply</code> is the annual burn supply due to treasury burns and coretime sale burns.</p>"},{"location":"learn/learn-jam-chain/","title":"Polkadot's JAM Chain","text":"<p>Info</p> <p>JAM paper is available at graypaper.com and the information regarding JAM prize is available at jam.web3.foundation. Download the printable version of the graypaper here.</p> <p>JAM, short for Join-Accumulate Machine, represents a prospective design to succeed the relay chain. Its name originates from CoreJAM, denoting Collect Refine Join Accumulate, which outlines the computation model the machine embodies and that was first described in an RFC by Gavin Wood. However, within the actual chain, only the Join and Accumulate functions are executed, while the Collect and Refine processes occur off-chain.</p> <p>Unlike the current iterative approach, JAM will be introduced as a comprehensive singular upgrade. Several factors contribute to this decision:</p> <ul> <li>A unified upgrade allows for precise restriction of post-upgrade actions, which is challenging   with an iterative approach.</li> <li>It mitigates the constant stream of minor upgrades and breaking changes that occur regularly over   weeks or months.</li> </ul> <p>While this shift entails a significant breaking change, efforts will be made to minimize its impact to manageable levels. Consolidating multiple smaller breaking changes into a single transition is deemed preferable, introducing a novel blockchain concept that uniquely integrates various existing ideas.</p>"},{"location":"learn/learn-jam-chain/#a-rollup-chain","title":"A Rollup Chain","text":"<p>JAM will be a domain-specific chain that handles one particular domain of problems. In this case, roll-ups. JAM's rollups are heavily bounded in terms of their security. This is what Polkadot has been doing for the last five years, it is already a highly domain-specific roll-up chain. JAM essentially makes it less opinionated and more generic.</p> <p>The JAM chain accepts outputs of roll-ups, in more general terms, bits of computation done elsewhere, and integrates the outputs into a shared state, similarly to how the Polkadot relay chain functions.</p> <p>The job of the JAM chain is to provide the necessary apparatus to ensure that the output correctly reflects the input when it goes through the transformation it's meant to have undergone.</p>"},{"location":"learn/learn-jam-chain/#smart-contract-similarity","title":"Smart Contract Similarity","text":"<p>JAM exhibits several similarities with a smart contract chain:</p> <ul> <li>Permissionless code execution occurs directly on the JAM chain itself.</li> <li>The state of the JAM chain is organized into distinct encapsulations.</li> <li>Alongside state, encapsulations encompass code and balance.</li> </ul> <p>These encapsulations of state are termed services. Thus, the JAM state is partitioned into services. The creation of a new service is permissionless, akin to deploying a smart contract on a smart contract chain. Consequently, adding a new service to the JAM chain does not necessitate approval from any authority or adherence to governance mechanisms, unlike Substrate-based chains that mandate governance approval for adding new pallets. Services encompass code, balance, and certain state components, resembling the structure commonly observed on a smart contract chain.</p>"},{"location":"learn/learn-jam-chain/#service-entry-points","title":"Service Entry Points","text":"<p>JAM services' code is split into three different entry points:</p> <ul> <li>Refine is the function that does the mostly stateless computation. It defines the   transformation for the rollup for a specific service.</li> <li>Accumulate is the function that takes the output of that and folds it into the overall state   of the service</li> <li>OnTransfer handles information coming from other services.</li> </ul> <p>Work packages are the input to a service. Work packages can have many work items in them. Every work item is associated with a service, and it reflects the actual input to the service. For the parachains service, this is where the transactions and all of the blockchain inputs are entered.</p> <p>The JAM security apparatus consists a two-stage processing where the Refine function accepts a work item as an input and yields a work result as an output, which gets fed into the Accumulate function (first Refine, then Accumulate). Work items are refined into work results, and therefore, a work package containing many work items is refined into a work report, which is the corresponding results of several items. A work package can be assigned that uses one core for a specific time slot (typically a period of 6 seconds).</p> <p></p>"},{"location":"learn/learn-jam-chain/#jam-is-transactionless","title":"JAM is Transactionless","text":"<p>JAM distinguishes itself from smart contract chains by operating transactionlessly. There are no transactions within JAM; all actions are permissionless and initially undergo a Refine stage. During this stage, the service pre-refines input data, transforming it into work reports consisting of work results. Subsequently, these work results are transferred onto the chain.</p> <p>Despite the absence of transactions, JAM still accommodates extrinsic information of a specific format. There are five types of extrinsic information:</p> <ul> <li>Guarantees</li> <li>Assurances</li> <li>Judgments</li> <li>Preimages</li> <li>Tickets</li> </ul> <p>The first three types form part of the JAM chain's security framework. Guarantees and assurances involve validators collectively attesting that a work result accurately reflects the outcome of its corresponding work item after transformation through the service's refine function.</p> <p>Judgments occur when then integrity of a work result is considered uncertain and a large plurality of validators attest to its validity or lack thereof. In this case an invalid work item may already have been integrated into the service\u2019s state and a rollback may need to happen. Judgments must occur within one hour of submitting the work report to the chain, during which finality is temporarily paused.</p> <p>Preimages represent a feature provided by the JAM chain for the refine function. While the refine function is typically stateless, it can perform one stateful operation: looking up the preimage of a hash. This feature is the only opinionated aspect of the refine function.</p> <p>Tickets serve as anonymous entries into the block production mechanism. They are not immediately required for block production; instead, the system operates two epochs in advance. This mechanism is part of the SAFROLE algorithm, a refined version of the original SASSAFRAS algorithm.</p>"},{"location":"learn/learn-jam-chain/#refine-function","title":"Refine Function","text":"<p>In the Refine processing stage within JAM, up to 15 MB of data can be accepted during each time slot, which lasts 6 seconds. However, Refine yields a maximum of 90 kB of data, resulting in significant data compaction that is necessary due to the distributed nature of the availability system. For instance, in the context of a parachain, the 15 MB of data represents the Proof of Validity (PoV), while the 90 kB of data corresponds to the candidate receipt.</p> <p>Refine can execute for up to 6 seconds of PVM gas, equivalent to the full block period of the relay chain. This extended execution time, compared to the current limit of two seconds for PVFs, is facilitated by secure metering and other optimizations inherent to PVM.</p> <p>Preimage lookups can also be conducted within Refine. If a hash and its associated preimage are believed to be available on the JAM chain, the preimage can be requested by providing the hash. This capability enables efficient storage and retrieval of code, such as parachain code, by storing the code on the JAM chain and referencing its hash in the work package.</p> <p>Refine is the primary processing workhorse, handling tasks with largely stateless operations.</p>"},{"location":"learn/learn-jam-chain/#accumulate-function","title":"Accumulate Function","text":"<p>The accumulate function is responsible for integrating the output generated by the Refine function into the chain state. Accumulate can accept multiple outputs from Refine, all originating from the same service. Both Refine and Accumulate serve as entry points from a service-specific code blob.</p> <p>Accumulate's execution time per output is considerably shorter than Refine\u2019s, typically around 10 milliseconds at most. However, the duration depends on factors such as the number of work items in the work package. If a work package contains multiple items, the available time is divided among them.</p> <p>Unlike Refine, Accumulate is stateful, granting it access to the JAM chain's state. It can read storage from any service, write to its key-value store, transfer funds, and include a memo with fund transfers. Additionally, Accumulate can create new services, upgrade its code, and request preimage availability, among other functionalities.</p> <p>Moreover, Refine can invoke child instances of the PVM. This allows for creating sub-instances, or virtual machines, where code and data can be deployed, memory and stack configurations can be customized, and computations can be executed within a flexible framework.</p>"},{"location":"learn/learn-jam-chain/#on-transfer-function","title":"On-transfer Function","text":"<p>The onTransfer function within the JAM system is also stateful, enabling it to modify the service's state. It has the capability to inspect the state of other services and make changes to its own state. This functionality facilitates communication between services, albeit in an asynchronous manner.</p> <p>Unlike many smart contract platforms, where interactions occur synchronously, in JAM the interaction between encapsulated components, such as smart contracts or services in this case, happens asynchronously. Messages, along with tokens, are sent, and at some point later during the same six-second execution period, the receiving service processes them. There is no immediate return path; if a return path is needed, the sending service must initiate another transfer or modify its state in a way that the receiving service can later interpret.</p> <p>Both Accumulate and onTransfer are designed to be executed in parallel, allowing different services' accumulation and transfers to occur simultaneously. This design opens the possibility for future enhancements, such as allocating more than the current 10 milliseconds of gas input. In theory, a secondary core could be utilized to execute certain accumulations, providing them with significantly more gas to utilize.</p>"},{"location":"learn/learn-jam-chain/#jam-chains-generalization","title":"JAM Chain's Generalization","text":"<p>Polkadot, as outlined in the original Polkadot white paper, is primarily tailored to a specific service profile: delivering parachains. In pursuit of this service, Polkadot has developed two essential subcomponents:</p> <ul> <li>the distributed data availability system</li> <li>the auditing and guarantees system for computation (i.e. a roll-up system with robust security   guarantees)</li> </ul> <p>JAM represents a reduction in the level of opinionation compared to Polkadot, offering a higher level of abstraction and generalization. This facilitates easier utilization of underlying components according to individual preferences.</p> <p>JAM operates in a permissionless manner, akin to smart contract chains, allowing individuals to upload and expect the execution of code. Additionally, it hosts data, enables preimage lookup, and manages state, resembling a key-value pair system. The genesis block of JAM includes a service to facilitate the creation of new services since JAM lacks a mechanism for accepting transactions directly.</p> <p>Services within JAM have no predefined limits on the amount of code, data, or state they can accommodate. Their capabilities are determined by crypto-economic factors; the more DOT tokens deposited, the greater capacity for data and state. For instance, the parachains service consolidates all Polkadot 1.1 functionality within a single service on JAM, with the potential for additional services to leverage Polkadot's distributed availability system, and auditing and guarantees system for computation.</p>"},{"location":"learn/learn-jam-chain/#polkadot-virtual-machine-pvm","title":"Polkadot Virtual Machine (PVM)","text":"<p>The PVM design is rooted in the RISC-V ISA (Instruction Set Architecture), known for its simplicity and versatility. The RISC-V ISA offers several advantages:</p> <ul> <li>It is easy to transpile into common hardware formats such as x86, x64, and ARM.</li> <li>It is well-supported by tooling like LLVM</li> </ul> <p>The PVM itself embodies simplicity and security, being sandboxable and offering various execution guarantees. It is deterministic, consensus-sensitive, and friendly to metering. Unlike other VMs, the PVM lacks complexity and excessive opinionation.</p> <p>WASM, while optimized for web use cases, presents challenges with stack management, particularly in handling continuations. RISC-V addresses this issue by placing the stack in memory, facilitating continuations handling naturally without additional complexity.</p> <p>Additionally, the PVM demonstrates exceptional execution speeds, especially when run on conventional hardware like X64 and ARM, offering advantages such as free metering compared to WASM.</p> <p>The incorporation of RISC-V-enabled continuations is poised to establish a new standard for scalable coding across multi-core platforms like JAM. Asynchronous, parallelized architectures are increasingly essential for scalability in both hardware and software platforms, a trend that is expected to extend to blockchain and consensus algorithms.</p>"},{"location":"learn/learn-jam-chain/#safrole","title":"SAFROLE","text":"<p>SAFROLE is a block production algorithm, a simplification of SASSAFRAS. It excludes some components that may be useful for parachains. So parachains may probably stick with SASSAFRAS rather SAFROLE. SAFROLE will be as simple as possible to:</p> <ul> <li>Ensure that it is as minimally opinionated as possible to maximize the potential future use cases</li> <li>To follow in the footsteps of Ethereum yellow paper, and really try to get as many implementations   as possible to try and spread the expertise.</li> </ul> <p>Understanding how Polkadot 1.0 works end-to-end is challenging. With JAM, someone who is capable of reading and understanding the yellow paper would be able to read and understand fairly quickly how JAM works. So simplicity is crucial.</p>"},{"location":"learn/learn-jam-chain/#networking","title":"Networking","text":"<p>Networking for JAM uses the QUIC protocol. This allows direct point-to-point connections between a large numbers of validators. So essentially all 1,000-plus validators on Polkadot can have a persistent connection to each other without potential issues with sockets. Gossip is avoided, mostly because it is not needed, because JAM will not handle transactions. In case of distributing something that's not point-to-point or within a very small subset validators, grid-diffusal will be used, in which validators are arranged into a grid, and packages are sent by a row, and then each node on the row sends it to all members of its column.</p>"},{"location":"learn/learn-jam-chain/#pipelining-for-efficient-block-processing","title":"Pipelining for Efficient Block Processing","text":"<p>In state-based blockchains like Ethereum, the header of blocks typically contains the posterior state root, summarizing the state after all block computations. Consequently, the header cannot be sent until all computations are complete. However, some computations can be performed before sending the header, as their outcomes determine the block's validity.</p> <p>In JAM, a different approach is adopted by placing the prior state root in the header instead of the posterior state root. This means that the state roots featured in the header lag by one block. As a result, lightweight computations, comprising approximately 5% of the block's workload or execution time, can be executed, and the block can be distributed immediately afterward. The remaining 95% of the block's computation, primarily accumulation tasks, can be completed subsequently. This enables the next block to be started before the execution of the current block is finished.</p> <p>This approach allows for more efficient utilization of time between blocks. In traditional setups like Polkadot's six-second block time, where the posterior state root must be provided, only a portion of the time can be used for computation. However, with pipelining in JAM, the entire block time can be effectively utilized for computations, maximizing efficiency.</p> <p>While using the full block time for computation may not be ideal, as it could lead to perpetual catching up and delayed block imports, JAM's approach enables significantly more time for computation compared to traditional setups. This means that approximately three to three and a half seconds of effective block computation time can be achieved, a substantial improvement over the current setup.</p>"},{"location":"learn/learn-jam-chain/#architectural-differences-jam-vs-relay-chain","title":"Architectural Differences: JAM vs. Relay Chain","text":"<p>One of the architectural distinctions between JAM and the relay chain lies in the degree to which functionality is fixed. While the relay chain fixes certain elements, such as the language used to define the protocol (WASM), JAM goes further in this regard. For instance, it dictates the type used for encoding the block header and the hashing scheme, making alterations to these aspects challenging.</p> <p>However, flexibility comparable to that enabled by the WebAssembly meta-protocol in the relay chain is preserved in JAM through its service model. In this model, upgradability responsibility is shifted to services, freeing the chain itself from the burden of being upgradable. Three primary reasons support this decision:</p> <ul> <li>Simplicity is prioritized. Maintaining a non-upgradable chain significantly reduces complexity.</li> <li>The relay chain's tendency to introduce complex functionalities without removing older ones   complicates matters. Because upgrades are easily implemented, there's little incentive to simplify   the Substrate SDK. Consequently, replicating Polkadot becomes impractical.</li> <li>The potential for optimization afforded by JAM's fixed parameters. With a clear understanding of   the specific tasks the JAM chain must perform and the ability to set fixed parameters,   optimizations in areas like network topology and timing become feasible. This contrasts with the   challenges posed by the relay chain's highly upgradable nature, where such optimizations are more   complex due to the frequent alterations possible with each upgrade.</li> </ul> <p>Despite these differences, JAM retains flexibility in application-level functionalities, such as coretime sales, staking, and governance, all managed within services. Additionally, JAM introduces a novel concept by associating a token balance with a service, providing opportunities for economic model adjustments that are not easily achievable in purely upgradable chains like the relay chain.</p>"},{"location":"learn/learn-jam-chain/#jam-toaster","title":"JAM Toaster","text":"<p>One of the ongoing efforts in ensuring that JAM meets its original expectations involves establishing a comprehensive test environment for the JAM chain. Unlike small-scale test networks running on unreliable hardware to manage cloud computing costs, this initiative entails a substantial investment. Introducing the JAM toaster, essentially a test platform designed for conducting large-scale trials and performance assessments of JAM. This addresses a prior challenge encountered during the development of the Polkadot relay chain, where understanding the emergent effects and dynamics of operating a network at such scale proved difficult. Previous attempts were limited to a few dozen nodes on a test network and the Kusama network, which lacks comprehensive monitoring capabilities due to restrictions on accessing validator nodes. Conversely, the small-scale test network failed to accurately simulate the network dynamics of a larger-scale deployment. The JAM toaster aims to bridge this gap by enabling in-depth research at the scale of the entire JAM network, comprising 1,023 nodes. This platform facilitates the investigation of network behavior and performance characteristics, providing valuable insights for developers regarding the expected performance of their parachains.</p>"},{"location":"learn/learn-jam-chain/#jam-and-substrate","title":"JAM and Substrate","text":""},{"location":"learn/learn-jam-chain/#benchmarks-vs-metering","title":"Benchmarks vs. Metering","text":"<p>Benchmarks, or performance tests, can be optional when working with JAM. While they may still be necessary on occasion, JAM's metered system can often obviate the need for frequent benchmarking. JAM operates on a metered system, allowing users to assess computational workload after completion. Additionally, there's a theoretical mechanism to control computation, typically implemented at block construction time.</p> <p>However, there are scenarios where benchmarking remains relevant. For instance, when metering is deemed too conservative for certain use cases, benchmarking might be necessary to enhance performance. Additionally, benchmarking could be useful for tasks requiring extended execution times, ensuring they aren't run excessively long.</p>"},{"location":"learn/learn-jam-chain/#xcmp","title":"XCMP","text":"<p>Moving on to Cross-Chain Message Passing (XCMP), JAM mandates full XCMP support. This is because within the relay chain, there's a provision for passing more data via a candidate receipt than would be practical if all parachains transmitted all data all the time. JAM adheres strictly to rules, even for parachain services, including limitations on data transmission between the \"refine\" and \"accumulate\" phases. Currently, with Horizontal relay chain Message Passing (HRMP), all messages traverse the relay chain, constraining the data payload to 4 kB or less, which might not be realistic. Thus, XCMP, where only message headers are relayed via the chain while the actual message data is transmitted off-chain, emerges as a necessary and overdue improvement.</p>"},{"location":"learn/learn-jam-chain/#accords","title":"Accords","text":"<p>Accords essentially encapsulate state and logic, resembling smart contracts, with multiple instances residing alongside each parachain. They facilitate message exchange between instances and enable synchronous interactions with parachains. Accords find utility in scenarios where trust between parachains is lacking, such as token transfers. Unlike the existing method involving a reserve intermediary, Accords streamline direct token teleportation between parachains, eliminating the need for trust-compromising intermediaries. Moreover, Accords could function as XCM forwarding mechanisms, ensuring message integrity even when relayed through third-party intermediaries, thus eliminating the need for explicit origin markers.</p>"},{"location":"learn/learn-jam-chain/#boosting-efficiency","title":"Boosting Efficiency","text":"<p>Lastly, JAM's broader, less opinionated approach to leveraging underlying consensus mechanisms makes it conducive to implementing more innovative solutions. For instance, distributed availability for complex tasks like zero-knowledge proofs becomes more practical and efficient with JAM. Additionally, JAM supports a mixed resource consumption model, wherein work packages can contain both computationally intensive tasks and data-heavy operations. By pairing services with diverse resource requirements, such as those needing extensive computation with those necessitating high data availability, JAM optimizes the utilization of validators' resources, thereby reducing costs. This flexible approach enables the combination of tasks like distributed availability and SNARK verification with parachain workloads, driving down costs while enhancing efficiency.</p>"},{"location":"learn/learn-jam-chain/#enhancements-and-compatibility-in-jam","title":"Enhancements and Compatibility in JAM","text":"<p>JAM's design prioritizes compatibility with existing Polkadot 1 parachains. While it maintains compatibility with the Polkadot SDK, the Polkadot Validator Function (PVF) undergoes retargeting. Instead of WebAssembly, it will target the Polkadot Virtual Machine (PVM). This transition is facilitated by the fact that PVM is a minor modification of RISC-V, which has already been established as an official LLVM target. Consequently, PVM could become an official LLVM target before the deployment of JAM.</p> <p>Beyond serving as a host for parachains, JAM introduces significant enhancements. It offers the potential to streamline benchmarking efforts and alleviate future benchmarking requirements. Additionally, JAM introduces the concept of accords, multi-instance, multi-sharded smart contracts that govern and enforce specific interaction protocols between parachains. Furthermore, full Cross-Chain Message Passing (XCMP) support is essential, enabling the removal of limitations on information transfer between parachains, typically facilitated by Cross-Chain Messages (XCM).</p> <p>Regarding Agile Coretime, JAM retains compatibility with existing setups. However, it introduces the capability to target coretime not only at parachains but also at arbitrary sets of work packages. This flexibility enhances the versatility and efficiency of resource allocation within the JAM ecosystem.</p>"},{"location":"learn/learn-jam-faq/","title":"FAQ for Polkadot's JAM Chain","text":"<p>Technical information about JAM</p> <p>For an in-depth overview of JAM, see the Wiki page about the JAM Chain.</p>"},{"location":"learn/learn-jam-faq/#what-is-jam","title":"What is JAM?","text":"<p>JAM is a research and development project initiated by Parity Technologies. It's a computational model that focuses on the process of collecting, refining, joining, and accumulating data within a blockchain network.</p>"},{"location":"learn/learn-jam-faq/#what-does-jam-stand-for","title":"What does \"JAM\" stand for?","text":"<p>\"JAM\" stands for \"Join Accumulate Machine.\" It represents the core principles of the computational model to be implemented on the JAM chain.</p>"},{"location":"learn/learn-jam-faq/#why-is-jam-groundbreaking","title":"Why is JAM groundbreaking?","text":"<p>The dilemma of achieving ultimate performance and scalability while still being flexible to build any use case is as old as blockchains. Current Web3 developers have to choose whether or not to build a smart contract or an appchain. Smart contracts on L1s are faster to write but come with downsides. They are limited to the underlying protocol, are not as efficient, do not offer the flexibility teams need and compete with the rest of the ecosystem for resources. Appchains provide a more efficient and flexible development environment, as the chains are custom-made for a specific purpose. With JAM, groundbreaking scalability currently only seen through rollups is brought to the consensus layer. Developers no longer need to decide if they build appchains or smart contracts; with JAM, they have a flexible and rich environment for both. So, in short, there will be L2 scalability without the need for rollup solutions while being fully flexible to build any application.</p>"},{"location":"learn/learn-jam-faq/#what-are-services","title":"What are services?","text":"<p>Services are modules that run on top of JAM. One of these services would be, for example, the ChainService. This service would implement the parachain logic that is currently enshrined in the Polkadot protocol. JAM\u2019s <code>refine</code> and <code>accumulate</code> phases are generic entry points that will be used to implement specific permissionless services.</p>"},{"location":"learn/learn-jam-faq/#how-does-jam-differ-from-traditional-blockchain-networks","title":"How does JAM differ from traditional blockchain networks?","text":"<p>JAM is built as a distributed computer. This means that it can run almost any task that can be expressed as a service. The JAM chain will have almost no functionality, meaning there will be no user transactions. All the logic, like governance, staking, etc., would live on system services. JAM will provide synchronous composability across heterogeneous services, enabling new kinds of interoperability.</p>"},{"location":"learn/learn-jam-faq/#will-agile-coretime-remain-part-of-the-polkadot-vision","title":"Will Agile Coretime remain part of the Polkadot vision?","text":"<p>Yes. Agile Coretime, an innovation that transforms Polkadot into a computational resource, will be rolled out onto the Polkadot network in the near future. JAM is further down the line, but Coretime will similarly be available to purchase on JAM.</p>"},{"location":"learn/learn-jam-faq/#how-do-services-interact-with-jam","title":"How do services interact with JAM?","text":"<p>Services interact with JAM through predefined entry points: Refine, Accumulate, and onTransfer (see more information on the JAM Chain page). Each service defines its specific functions and workflows, executed within the JAM framework according to the network's requirements.</p>"},{"location":"learn/learn-jam-faq/#what-are-the-main-components-of-jam","title":"What are the main components of JAM?","text":"<p>JAM consists of four main components: Refine, Accumulate, and onTransfer (see more information on the JAM Chain page). These components define the workflow for processing and integrating data within the network.</p>"},{"location":"learn/learn-jam-faq/#what-is-the-goal-of-jam","title":"What is the goal of JAM?","text":"<p>JAM's primary goal is to provide a flexible and efficient framework for managing data and computations within a network. It aims to streamline data integration and maintenance while ensuring the network's integrity and security.</p>"},{"location":"learn/learn-jam-faq/#is-jam-related-to-polkadot","title":"Is JAM related to Polkadot?","text":"<p>Yes, JAM is a potential candidate for evolving the Polkadot relay chain. The key change is that parachains are no longer enshrined on the relay chain and will be running on top of a service that is compatible with parachain protocol. One service will be, for example, the current parachains service. Anyone can permissionlessly add a service to the JAM Chain by specifying the entry points Refine, Accumulate and onTransfer.</p>"},{"location":"learn/learn-jam-faq/#how-would-the-relay-chain-change-with-jam","title":"How would the Relay Chain change with JAM?","text":"<p>JAM would be a successor to the relay chain, with a more straightforward and flexible architecture. Only the consensus functionality would be kept, while the rest, such as security, governance, etc., would run on system-level services. The current relay chain will run on multiple cores in the new JAM architecture, guaranteeing full compatibility.</p>"},{"location":"learn/learn-jam-faq/#in-the-new-architecture-what-does-the-tech-stack-look-like","title":"In the new architecture, what does the tech stack look like?","text":"<p>From the point of view of parachains, the tech stack doesn\u2019t look that much different. They will continue to get validated by the validators, etc. JAM will offer the possibility of running smart contracts on the same level as parachains. This means a potential service can be written that enables people to run Solidity-based smart contracts directly on top of JAM without running on any parachain. The other more future-oriented development will be CorePlay. CorePlay will be an actor-based framework. The idea is to support long-running tasks/actors on top of JAM. Long-running here means that programs will continue running intermittently (can pause and resume). This provides quite a lot of simplifications for the developer when writing contracts. Ultimately, it should be much simpler to write a program that can run on top of a (decentralized) blockchain than it is now.</p>"},{"location":"learn/learn-jam-faq/#how-can-developers-get-involved-with-jam","title":"How can developers get involved with JAM?","text":"<p>Developers interested in JAM can explore and participate once the RFC is out. Additionally, they can stay updated on announcements and events related to JAM and its integration with other technologies via Parity\u2019s communication channels.</p>"},{"location":"learn/learn-jam-faq/#what-are-some-potential-applications-of-jam","title":"What are some potential applications of JAM?","text":"<p>JAM's flexible and efficient computational model opens up possibilities for various applications, but it is too early to jump into specific use cases just yet.</p>"},{"location":"learn/learn-jam-faq/#is-there-a-roadmap-for-jams-development","title":"Is there a roadmap for JAM's development?","text":"<p>While specific timelines may vary, the development of JAM typically involves ongoing research, testing, and iteration. The RFC will be published as a first step, where the community gives feedback and iterates on it.</p>"},{"location":"learn/learn-jam-faq/#what-about-polkadot-will-there-be-a-hard-fork","title":"What about Polkadot? Will there be a hard fork?","text":"<p>JAM isn\u2019t a successor to Polkadot but a potential evolution of the Polkadot relay chain. It can only proceed if it passes through Polkadot\u2019s decentralized governance system, winning approval from token holders. The current parachain-centered logic would continue as a service on top of the new JAM architecture. Part of the proposal will include tooling and hard-coded compatibility guarantees. The relay chain will upgrade, and parachains can then enjoy a much richer environment, synchronous compatibility, and excellent scaling capabilities better than current L2s but built inside the L0/L1 layer.</p>"},{"location":"learn/learn-jam-faq/#do-parachains-need-to-rewrite-their-code-how-much-work-is-it-to-build","title":"Do parachains need to rewrite their code? How much work is it to build?","text":"<p>Parachains will be one of the \u201cproducts\u201d that can run on JAM. JAM will only remove the enshrined parachain consensus and replace it with a model that supports different services. For some time, it will likely be easier to develop parachains, as the necessary tooling for developing services needs to be developed and adopted. For migration support, full compatibility guarantees will be written into the code.</p>"},{"location":"learn/learn-jam-faq/#does-it-even-make-sense-now-to-build-a-parachain-on-polkadot","title":"Does it even make sense now to build a parachain on Polkadot?","text":"<p>Of course! Parachains will be one of the \u201cproducts\u201d that can run on JAM, and they will stay first-class citizens. There will be different use cases, some suitable for parachains and some suitable for services.</p>"},{"location":"learn/learn-jam-faq/#what-about-dot","title":"What about DOT?","text":"<p>DOT will continue to be JAM\u2019s native token. No other native token will be issued.</p>"},{"location":"learn/learn-jam-faq/#where-can-i-learn-more-about-jam","title":"Where can I learn more about JAM?","text":"<ul> <li>Read the JAM Chain page.</li> <li>Explore official communication on https://graypaper.com and from W3F, Parity, and Polkadot to   learn more about JAM. You can also join discussions on the forum and the fellowship calls.</li> <li>Read   this blog post   about the original talk by Gavin Wood at Token2049 in Dubai.</li> <li>Read the \"Demystifying JAM\" blog post   by Kian Paimani.</li> </ul>"},{"location":"learn/learn-kusama-inflation/","title":"Kusama Inflation Model","text":"<p>        Learn about Polkadot's native token DOT inflation.      </p> \u2716 <p>KSM is an inflationary token. Inflation is set to be 10% annually. Depending on the supply staked and the ideal staking rate (more about this below), part of the inflation is distributed to the stakers and part to the treasury.</p> <p>Info</p> <p>The current KSM token supply can be seen here.</p> <p>It is essential to understand that the primary objective of inflation is to incentivize network participants through Nominated Proof of Stake (NPoS) and to grow the network through funding the on-chain treasury. There is an opportunity cost of keeping the number of tokens idle with the current inflation model as the tokens get diluted over time. Economics and game theory suggest that setting an ideal inflation rate is essential for incentivizing the network participants as well as the growth of the network, and any deviation from it can have adverse effects. Reducing the inflation rate could limit growth, while increasing the inflation rate could break the incentive model of the token. Hence, token inflation rate is not a forever fixed value, and inflation can be updated in the future through on-chain governance based on thorough tokenomics research.</p>"},{"location":"learn/learn-kusama-inflation/#kusama-inflation-model","title":"Kusama Inflation Model","text":"<p>The chart below shows the inflation model of the network. Depending on the number of staked tokens, the distribution of the inflation to validators and nominators versus the treasury will change dynamically to provide incentives to participate (or not participate) in staking.</p> <p>There is a dynamic ideal staking rate (in the figure set to 0.6 or 60%) that the network tries to maintain. The inflation model will incentivize network participants to stake when the current staking rate &lt; ideal staking rate and disincentivize staking when current staking rate &gt; ideal staking rate. The goal is to have the staking rate meet the ideal staking rate. The current staking rate would be the total amount staked in the current era over the total token supply, where the total amount staked is the stake of all validators and nominators on the network. The ideal staking rate accounts for having sufficient backing of tokens to prevent the possible compromise of security while keeping the native token liquid.</p> <p></p> <p>Source: Research - Web3 Foundation</p> <ul> <li>x-axis: Proportion of staked tokens</li> <li>y-axis: Annualized percentage (inflation and staking rewards, see below)</li> <li>Blue line: Annual inflation rate diverted to NPoS, i.e., the total amount of tokens minted to   pay validators and nominators. For instance, 0.1 corresponds to 10% of token inflation diverted to   stakers. Since annual token inflation is 10%, all inflation is used to pay validators and   nominators, and 0% of token inflation is diverted to the treasury.</li> <li>Green line: Annual rewards rate for stakers. For instance, 0.2 corresponds to 20% of annual   returns on the staked tokens. You can determine the current annual staking rewards rate by looking   at the top bar of the staking overview on   the Polkadot Staking Dashboard.</li> </ul> <p>Assuming that the ideal staking rate is 60%, all of the inflation would go to the validators and nominators if 60% of all tokens are staked. Any deviation from the 60% - positive or negative - sends the proportional remainder to the treasury. Deviations from the ideal staking rate are referred to as staking inefficiencies. Thus, the treasury does not receive an inflow of funds from inflation when the system staking rate equals the ideal staking rate. See this page for more information about treasury inflow sources.</p> <p>For those who are interested in knowing more about the design of the inflation model for the network, please see here.</p>"},{"location":"learn/learn-kusama-inflation/#ideal-staking-rate","title":"Ideal Staking Rate","text":"<p>The ideal staking rate can vary between 45% to 75% based on the number of parachains that occupied a core (this excludes the system parachains), based on the implementation here.</p> <p>Briefly, the ideal staking rate can be calculated as follows:</p> <p><code>0.75 - auction_proportion</code></p> <p>where <code>auction_proportion</code> is obtained by computing <code>min(auctioned_slots, 60) / 300</code>. The <code>auctioned_slots</code> are all the auctioned slots (or cores) without the cores for system parachains.</p> <p>Assuming there are 50 filled cores, of which five are dedicated to system parachains, there are 45 auctioned cores. The <code>auction_proportion</code> is thus <code>45 / 300 = 0.15</code>. The ideal staking rate is <code>0.75 - 0.15 = 0.6</code>.</p> <p>If the amount of tokens staked goes below 60%, then staking rewards for nominators increase, incentivizing them to stake more tokens on the network. On the contrary, staking rewards drop if staked tokens exceed the ideal staking rate. This results from the change in the percentage of staking rewards that go to the Treasury.</p>"},{"location":"learn/learn-nft-pallets/","title":"NFT Pallets","text":"<p>NFT pallets allow developers to easily implement NFT-related actions within their dApp.</p> <p>Polkadot as a decentralized ecosystem currently has 5 NFT Pallets for developers to choose from:</p> <ol> <li>Uniques: It is compact, simple and therefore a good candidate for parachains that want native NFT functionality for a  limited number of use cases.  </li> <li>NFTs: Utilized among others by AssetHub and Mythical Games. Has the largest number of NFTs and transactions. It is fairly rich in functionalities and is the pallet of choice for use in a wide range of use cases by dApps that deploy to AssetHub (see KodaDot for example).  </li> <li>Uniques: The first NFT pallet created for Polkadot. It includes features like Nested NFTs, Dynamic NFTs, Re-Fungibile (fractionalised) NFTs, transaction fee sponsoring as well as full interoperability between it's EVM and Substrate. See https://unique.network/developer/#why-unique for a more comprehensive overview.  </li> <li>ORML: It was nitially created to serve as a simple pallet for NFTs, but was overtaken by the Uniques pallet in adoption and is currently only used by the Acala parachain.  </li> <li>NFT Manager: It is another simple NFT pallet used only by its creator - the Aventus Network.  </li> </ol> <p>For detailed comparison of pallets see NFT Pallets in the Polkadot ecosystem </p> <p>Below are the introductory technical descriptions of the two main pallets - NFTs pallet, used on AssetHub, and Uniques pallet. These two pallets are used by many parachains to date that may wish to implement NFTs. For further information on Unique Network see NFT Pallets in the Polkadot Ecosystem. ORML and NFT Managers are examples of custom-built NFT pallets for parachain-specific use cases.</p>"},{"location":"learn/learn-nft-pallets/#nfts-pallet","title":"NFTs Pallet","text":"<p>For Developers Only</p> <p>The information presented here below is for developers. A user-friendly portal for NFTs, DEX and Assets is under construction.</p> <p>NFTs is a FRAME pallet that provides a multitude of functions to interact with NFTs.</p> <p>The pallet comes with a new way to configure NFTs, as well as configure collections and items. Pallet-level feature flags allow disabling functionalities not needed in the runtime.</p> <p>Polkadot JS API for NFTs FRAME pallet can be found here.</p>"},{"location":"learn/learn-nft-pallets/#roles","title":"Roles","text":"<p>Setting up a collection implies different roles with different permissions:</p> <ul> <li> <p>Owner:</p> </li> <li> <p>destroy collection (to destroy the collection, there should be 0 items left).</p> </li> <li>redeposit: re-evaluate the deposit on some items.</li> <li>set team: change the collection\u2019s Issuer, Admin, Freezer.</li> <li>set collection max supply: set the maximum number of items for a collection.</li> <li> <p>lock collection: this can include making a collection\u2019s items non-transferable, fixing its max     supply, and locking collection metadata and attributes.</p> </li> <li> <p>Admin:</p> </li> <li> <p>set attributes and metadata of a collection.</p> </li> <li>set attributes pre-signed: set attributes for an item by providing the Admin pre-signed     approval.</li> <li> <p>lock item properties: lock item metadata and attributes.</p> </li> <li> <p>Freezer:</p> </li> <li> <p>lock item transfer: disallow further item transfers.</p> </li> <li> <p>unlock item transfer: lift a previous lock to transfer an item.</p> </li> <li> <p>Issuer</p> </li> <li>mint</li> <li>force mint (with custom item configuration).</li> <li>mint pre-signed: mint an item by providing the Issuer pre-signed approval.</li> <li>update mint settings.</li> </ul> <p>Those roles can also be set to <code>none</code> without the ability to change them back. This is useful when a collection is created and all the items are minted. Now, by setting roles to <code>none</code> we remove the possibility of minting any more items, changing the metadata, or disallowing some item's transfer.</p>"},{"location":"learn/learn-nft-pallets/#attributes","title":"Attributes","text":"<p>An item can hold the following types of attributes:</p> <ul> <li>System attributes. These attributes can only be set or unset by the pallet. Examples include   locking an item for runtimes that use the fractionalization pallet. This is also how users can   mint from a collection if they hold a valid item from another collection (the system attribute   <code>UsedToClaim</code> is set).</li> <li>Collection owner\u2019s attributes. These are attributes that can only be set or unset by the   collection's admin.</li> <li>User attributes. These are attributes used to store various user-defined settings/values that   can only be changed by the NFT's owner. No other account can restrict modifying those attributes.</li> <li>External attributes. These are attributes that an NFT owner can use to allow external services   (e.g. oracles, smart contracts on another chain, etc..) to set or modify.</li> </ul>"},{"location":"learn/learn-nft-pallets/#creating-a-collection","title":"Creating a Collection","text":"<p>You can use the NFTs pallet to create NFT collections. In the Polkadot-JS UI, go to Developer &gt; Extrinsic and select the <code>nfts.create</code> extrinsic. When you create a collection, you must specify who the admin is. Then, under <code>config: PalletNftsCollectionConfig</code>, you can configure your collection by specifying different settings:</p> <ul> <li> <p><code>settings</code> you can specify (in a bitflag-format) settings for your collection:</p> </li> <li> <p><code>Transferrable items</code>: When disabled, the items will be non-transferrable (good for soul-bound     NFTs),</p> </li> <li><code>Unlocked metadata</code>: When disabled, the metadata will be locked,</li> <li><code>Unlocked attributes</code>: When disabled, the attributes in the <code>CollectionOwner</code> namespace will be     locked,</li> <li><code>Unlocked max supply</code>: allows to change the max supply until it gets locked (i.e. the     possibility to change the supply for a limited amount of time),</li> <li><code>Deposit required</code>: when disabled, no mint deposit will be taken for items. This option can be     set by a super-user only.</li> </ul> <p>Info</p> <p>Note that currently, Polkadot-JS UI does not support bitflags. Leave the settings field as it is. Everything is unlocked by default (bitflag value <code>0</code>).</p> <ul> <li><code>maxSupply</code> (toggle option) allows you to specify the maximum number of items that can be minted.</li> <li><code>mintSettings: PalletNftsMintSettings</code> allows you to specify different settings for your   collection.</li> <li><code>mintType</code> gives you the possibility to specify who can mint in your collection:<ul> <li><code>\u00ccssuer</code>: only you can mint in your collection.</li> <li><code>Public</code>: everyone can mint in your collection.</li> <li><code>HoderOf</code>: only holders of items in another collection can mint in your collection. This   requires knowledge about the ID of the other collection. This avoids looping through all   existing collections and spamming RPC nodes with requests to find available IDs.</li> </ul> </li> <li><code>price</code> (toggle option) allows you to specify the price of the items.</li> <li><code>startBlock</code>and <code>endBlock</code> give you the possibility to specify a time frame during which the     collection's configuration is valid (i.e. all options within     <code>config: PalletNftsCollectionConfig</code>).</li> <li>other mint settings include:<ul> <li>wave minting, for example mint X number of items that go to collection owners and Y number of   items for the public</li> <li>force mint: minting bypassing mint settings</li> </ul> </li> </ul> <p>Info</p> <p>The user can decide to lock an item or collection\u2019s metadata, attributes, and settings. Also, a locking mechanism can prevent unauthorized and unprivileged transfers (unprivileged actions can be re-allowed anytime).</p> <p>With all these options, one can decide to modify the price of the collection's items and who can mint, receive or buy items in that collection. Time constraints are available with <code>startBlock</code> and <code>endBlock</code> parameters. It is thus possible, for example, to create a schedule in which holders of items in collection A (<code>HolderOf</code> parameter) will be able to claim a limited number of NFTs from Collection X (<code>maxSupply</code> parameter) only within a specific time frame.</p> <p>In Collection X, people can mint the number of NFTs they have in Collection A. It's a one-to-one ratio. So if they have 3 nfts in collection A, they can mint 3 nfts in collection X. Each time they use one nft in Collection A, the said NFT will have an attribute that will block its further use to mint in Collection X. But it will be possible to mint in another collection Y if it also uses collection A as a <code>HolderOf</code>.</p> <p>You can modify the parameters, so anyone can buy more NFTs from Collection X. To buy an NFT you must pay the item price + transaction fee. Even if the item is free, the transaction fee always apply.</p> <p>This can be useful for events such as Hackathons where participants who bought a ticket receive the NFT ticket from Collection A. Then, all holders of at least one item in Collection A (i.e. all ticket holders) will be given free avatar NFT from Collection X within the event schedule. After the event, any additional remaining items in Collection X can be made available to the public through a marketplace.</p> <p>The requirement to get the free avatar is to hold at least one NFT in Collection A. One can only claim the avatar specifying which NFT (i.e. the ID) they own in Collection A. The same NFT cannot be used twice. Holders of multiple NFTs in Collection A (for example, participants in multiple Hackathons) can claim multiple avatars specific to each event.</p> <p>Time frame must be updated</p> <p>Someone trying to mint an NFT outside the specified time frame will trigger a <code>NoConfig</code> error, as the collection\u2019s admin has specified no configuration after the time frame ends. The collection's admin must call the <code>updateMintSettings</code> extrinsic and add a new schedule or disable the block number option.</p> <p>After you minted an NFT, check which NFT IDs you own under which collection. In the Polkadot-JS UI go to Developer &gt; Chain State &gt; Storage, select the <code>nfts.account</code> extrinsic, and specify the account owning the NFT and the collection ID. You can also see all your collections by selecting the <code>collectionAccount</code> extrinsic.</p> <p>When a new collection is created, a new ID will be generated and assigned to it. When a collection is destroyed, no one can pick up the collection ID again (including the owner).</p>"},{"location":"learn/learn-nft-pallets/#minting-an-nft","title":"Minting an NFT","text":"<p>You can mint an NFT using the <code>nfts.mint</code> extrinsic. You must then specify the following:</p> <ul> <li><code>collection</code>, the collection ID where you want to mint</li> <li><code>item</code>, the item ID</li> <li><code>mintTo</code>, the account</li> <li><code>witnessData</code> (toggle option), you can specify if you own an NFT in another collection</li> </ul> <p>Creating an item usually involves setting some attributes specific to that item.</p>"},{"location":"learn/learn-nft-pallets/#uploading-files-and-metadata","title":"Uploading Files and Metadata","text":""},{"location":"learn/learn-nft-pallets/#using-apillon","title":"Using Apillon","text":"<p>When you have a collection ID and an item ID you need to:</p> <ul> <li>Open an account on Apillon and create a new project.</li> <li>Navigate to the Apillon Storage service and   create a new storage bucket. Upload the file you want to mint to the bucket.</li> <li>After the file has been uploaded and pinned to IPFS, click on the file to open its details and   copy the   Content Identifier (CID).   This unique string of letters and numbers will act as a marker to link the data uploaded onto   IPFS to the collection or item ID you own.</li> <li>Prepare the JSON metadata file and add your CID (see below):</li> </ul> <pre><code>{\n    \"name\":\"Your Collection Name\",\n    \"description\":\"Collection's Description\",\n    \"image\":\"Your Collection CID\"\n}\n</code></pre> <ul> <li>Upload the metadata file to Apillon Storage and get the updated CID.</li> </ul>"},{"location":"learn/learn-nft-pallets/#alternative-using-pinata","title":"Alternative - Using Pinata","text":"<ul> <li>Open an account on Pinata.</li> <li>Follow   these steps   to upload the file you want to mint.</li> <li>After uploading your file, get the   Content Identifier (CID).   This unique string of letters and numbers will act as a marker to link the data uploaded onto   IPFS to the collection or item ID you own.</li> <li>Prepare the metadata file and add your CID (see below):</li> </ul> <pre><code>{\n    \"name\":\"Your Collection Name\",\n    \"description\":\"Collection's Description\",\n    \"image\":\"Your Collection CID\"\n}\n</code></pre> <ul> <li>Upload the metadata file to Pinata and get the updated CID.</li> </ul> <p>After minting your NFT on the Polkadot-JS UI, you can add the CID. Go to Developer &gt; Extrinsics and select the <code>nfts.setCollectionMetadata</code> (for collections) or <code>nfts.setMetadata</code> (for single NFTs) extrinsic. Under the <code>data: Bytes</code> field you can enter the CID or upload the metadata file.</p> <p>The collection can be created and its item minted before uploading the NFT file and related metadata. The minting process on-chain will assign a collection and item ID to your account. Those IDs will later be populated with NFT files, metadata, and attributes. Once you upload the NFT files and related data, the above-mentioned extrinsics can be used to update a collection or item.</p> <p>NFT/DEX/Asset Portal</p> <p>With the new NFT/DEX/Asset portal, all the above steps will be executed \"under the hood\" and the user will not have to worry about all technicalities.</p>"},{"location":"learn/learn-nft-pallets/#other-actions","title":"Other Actions","text":"<ul> <li>Buying an item up for sale.</li> <li>Burning (i.e., destroy) items or a single item (burning must be signed either by the admin of the   collection or the owner).</li> <li>Smart attributes allow an NFT owner to grant   permission to other entities (another account, an application, an oracle, etc.) to update   attributes of an NFT. An example could be that all Polkadot fellowship members have an NFT badge   that gets updated over time (sort of a rank) with a consequent upgrade in membership permissions.</li> <li>A collection is managed by the   Issuer, the Admin, and the Freezer. Those roles can   be changed anytime.</li> <li>Setting metadata for an item or collection (metadata includes all essential information about the   item or the collection). Metadata could consist of any arbitrary data like the IPFS hash.</li> <li>Setting or re-setting the price of an item.</li> <li>Clearing attributes and metadata of a collection or an item.</li> <li>Changing the owner of an item or a collection.</li> <li>Transferring an item, as well as creating and canceling transfer approvals of a specific item, or   an atomic swap.</li> <li>Transferring ownership of an item.</li> <li>Delegating accounts: Delegated accounts can approve changes to an item's attributes and transfer   an item. The item owner always has control and can decide to cancel approvals from a delegated   account.</li> <li>One can also execute pending atomic swaps created by a counterpart.</li> </ul>"},{"location":"learn/learn-nft-pallets/#work-in-progress","title":"Work in Progress","text":"<p>NFTs fractionalization will allow the user to:</p> <ul> <li>Take ownership of an NFT from the pallet-nfts</li> <li>Create a new asset in pallet-assets</li> <li>Mint the input amount to the previous owner of the NFT as the beneficiary</li> <li>Mass minting: Minting multiple items in one single transaction. This will require the user to   provide a .csv file with two columns: NFT ID and CID of metadata.</li> </ul>"},{"location":"learn/learn-nft-pallets/#uniques-pallet","title":"Uniques Pallet","text":"<p>Info</p> <p>The Uniques Pallet is deprecated. Everything related to NFTs will be covered by the NFTs Pallet.</p> <p>Uniques is a FRAME pallet deployed on the Asset Hub system parachain. It implements the most basic kind of NFT -- a data record referencing some metadata. This metadata reference is mutable until frozen, so NFTs and their classes (entities derived from) are mutable unless specifically made immutable by the issuer.</p> <p>Uniques takes a very bare-bones approach on purpose to keep the Asset Hub chain a simple balance-keeping chain for both fungible and non-fungibles.</p> <p>These NFTs can be viewed and interacted with on RMRK's Singular platform, by switching the top right menu from Kusama to the Asset Hub.</p> <p></p> <p>They can also be interacted with directly through the extrinsics tab of the Asset Hub:</p> <p></p>"},{"location":"learn/learn-nft-projects/","title":"NFT projects on Polkadot and Kusama","text":"<p>Community Page</p> <p>This page is open to contributions from the community. Please follow the Wiki contribution guidelines and add your NFT app to this page.</p>"},{"location":"learn/learn-nft-projects/#list-of-nft-projects","title":"List of NFT Projects","text":"<ul> <li>Asset Hub</li> <li>Astar</li> <li>Basilisk</li> <li>Crust</li> <li>Darwinia Network</li> <li>KodaDot</li> <li>MNet Continuum (ex BitCountry)</li> <li>Moonbeam</li> <li>Mythical</li> <li>NFTMozaic</li> <li>Nodle</li> <li>Unique Network</li> </ul>"},{"location":"learn/learn-nft-projects/#asset-hub","title":"Asset Hub","text":"<p>The Asset Hub is a system chain which provides functionality for deploying and transferring assets \u2014 both Fungible and Non-Fungible Tokens (NFTs). The Asset Hub currently hosts Uniques pallet (its use on AssetHub is not encouraged) and the NFTs pallet.</p> <p>A more in-depth overview of the Asset Hub pallets and developer resources available to the developers can be found in the dedicated section about NFT pallets.</p>"},{"location":"learn/learn-nft-projects/#astar","title":"Astar","text":"<p>Astar Network and its sister network Shiden Network are smart contract infrastructure in the Polkadot Ecosystem, i.e. they are rollups that support EVM smart contracts. Astar supports NFTs developed with EVM smart contracts and Wasm smart contracts.</p> <p>Astar has all the toolings available that every EVM NFT developer knows. The availability of those toolings makes the onboarding to Astar networks desirable to any developer looking to explore the Polkadot Ecosystem. Astar has an active community of artists and NFT enthusiasts. Besides supporting all EVM toolings, Astar also bootstrapped the Wasm smart contract environment for NFT developers writing smart contracts with ink! based on PSP34 (Polkadot Standards Proposals).</p> <p>The main advantage of having a multi-virtual machine environment for NFT developers is that it gives builders more possibilities for the use cases they are developing. With the support of Wasm smart contracts, developers can create solutions like RMRK with smart contracts.</p> <p>Developer tools and documentation links:</p> <ul> <li>General information</li> <li>Generating PSP34 NFTs via ink! contracts</li> <li>EVM NFT management example</li> </ul>"},{"location":"learn/learn-nft-projects/#basilisk","title":"Basilisk","text":"<p>Basilisk is a Kusama parachain that provides liquidity for the ecosystem. It also has a full-featured NFT platform based on the Uniques pallet. One of the key features of Basilisk is that it allows minting NFTs with a royalty fee. This royalty fee is distributed to the original creator of the NFT via the runtime pallet. Additionally Basilisk offers a feature that allows creating a buy order for a specific NFT.</p> <p>These NFTs can be viewed and interacted instantly on KodaDot.</p> <p></p>"},{"location":"learn/learn-nft-projects/#crust","title":"Crust","text":"<p>Crust is primarily a storage solution. A separate section is dedicated to NFT storage solutions.</p>"},{"location":"learn/learn-nft-projects/#darwinia-network","title":"Darwinia Network","text":"<p>Darwinia Network is a decentralized heterogeneous cross-chain bridge protocol built on Substrate. It focuses on decentralized cross-chain token swap, exchange, and market and it is an EVM-compatible blockchain.</p> <p>NFT marketplace available here.</p>"},{"location":"learn/learn-nft-projects/#kodadot","title":"KodaDot","text":"<p>KodaDot is an open-source NFT marketplace that operates on the Polkadot Ecosystem and beyond (Polkadot and Kusama Asset Hubs, Mantle, Base, and Immutable zkEVM), striving to aggregate various NFT standards and enhancing user experience.</p> <p>KodaDot's strength lies in its commitment to open-source collaboration. It has transformed into a collaborative hub where creators, developers, and community members work collectively for decision making, amassing an extensive network of over 90 open-source contributors. This robust collaboration has earned KodaDot the number one rank as a dApp in the Polkadot ecosystem on Github.</p> <p>See below a video tutorial about how to mint your NFT on the Polkadot Asset Hub using KodaDot.</p> <p> KodaDot Tutorial on Minting NFTs </p> <p>For more information about minting using KodaDot see this step-by-step tutorial.</p>"},{"location":"learn/learn-nft-projects/#history-of-kodadot","title":"History of KodaDot","text":"<p>KodaDot began as the first unofficial explorer for RMRKv0.0.1 contributing to RMRK protocol. It later received Kusama Treasury funding, which propelled the team to create great end-user experience on the Asset hub.</p> <p>In the summer of 2022, KodaDot won the first prize at the Polkadot North American event for implementing MoonBeam and MoonRiver NFT EVM smart contracts and enabling read-only access to existing components for seamless end-user interaction.</p> <p>The team successfully launched with Basilisk NFT Marketplace pallet in Fall 2022, where an increasing number of artist collections are emerging, providing artists the opportunity to receive offers on unlisted NFTs and earn on-chain royalties.</p> <p>KodaDot's upcoming integrations are based on PSP-34, leveraging smart contracts written with ink!.</p>"},{"location":"learn/learn-nft-projects/#ecosystem-tools-by-kodadot","title":"Ecosystem Tools by KodaDot","text":"<p>KodaDot has enriched the Polkadot ecosystem by offering a comprehensive API interface for builders, based on the SubSquid indexer. This platform also presents searchable items and collections, translating on-chain transactions into deep insights about collection ownership dynamics for end-users. For more info about KodaDot check out link.</p>"},{"location":"learn/learn-nft-projects/#mnet-continuum","title":"MNet Continuum","text":"<p>MNet Continuum (ex BitCountry) specializes in providing Metaverse as a Service (MaaS) to all networks. Their decentralized application (dApp) offers users the tools to create and customize a metaverse, run and reward a community through immersive quests, and mint and trade NFTs. Users can enjoy metaverse gaming, learning and networking.</p> <p>Minting And NFT Generators</p>"},{"location":"learn/learn-nft-projects/#moonbeam","title":"Moonbeam","text":"<p>Moonbeam and its Kusama counterpart Moonriver are full EVM deployments with Ethereum RPC endpoints.</p> <p>This means that the entire toolkit offered to other EVM chains (stacks like Hardhat, Remix, Truffle, Metamask, etc.) are available to Moonriver / Moonbeam users and developers, giving it a noticeable head start in attracting existing userbases.</p> <p>Several dozen high profile teams are launching their products (or re-launching) on Moonriver / Moonbeam, however, it is essential to note that Moonbeam is an EVM chain and will therefore suffer from the same limitations as any other EVM chain in regards to customization and feature-richness of NFTs.</p> <p>A notable advantage, however, is that Moonriver / Moonbeam is still a Substrate chain, meaning integration of custom pallets into the runtime is still possible, making NFT specific optimizations at the chain runtime level a reliable way to keep EVM compatibility of tools while at the same time optimizing storage and interactions for rich NFTs.</p> <p>A convenient directory of Moonbeam dApps can be found here: Moonbeam dApps</p> <p>Developer tools and documentation links:</p> <p>Minting a Cross-Chain NFT with Axelar SDK Deploying an ERC-721 Contract Example</p>"},{"location":"learn/learn-nft-projects/#mythical","title":"Mythical","text":"<p>Mythical Games is an online gaming platform that implements NFTs in its gaming ecosystem. Mythical Games has Mythos Chain, an L1 rollup in the Polkadot ecosystem that implements the Polkadot NFTs pallet to provide advanced NFT functionalities.</p> <p>Mythical offers a platform for game developers with comprehensive documentation and onboarding guides, to ensure anyone can get up and running in time. The primary integration path is REST APIs, but SDKs are also available upon request.</p> <p>Developer tools and documentation links:</p> <ul> <li>The Mythical Platform API</li> </ul>"},{"location":"learn/learn-nft-projects/#nftmozaic","title":"NFTMozaic","text":"<p>NFTMozaic is a Polkadot project created with a goal to establish Polkadot as the leading ecosystem for NFT-related applications by providing effective technology, support, business development and marketing efforts focused on this market segment.</p> <p>Its efforts are focused on strengthening the positioning of Polkadot\u2019s NFT ecosystem through strategic content, alliances, and growth programs. It aims to launch a grants program for consumer-facing MVPs, an NFT-focused website, educational journals, and more.</p> <p>NFTMozaic aims to provide a comprehensive entry-point for both business and development aspects of the NFT technology. To achieve this it brings together all interested members of the Polkadot ecosystem that provide NFT functionality in their projects to the table and strives to establish a common guidance and cooperation platform as a way to ensure that all the contributors benefit from a joint effort and the best possible solution is sought.</p> <p>NFTMozaic links:</p> <ul> <li>X link</li> <li>Telegram NFTMozaic general topics group</li> <li>Telegram NFTMozaic Tech Support group</li> </ul>"},{"location":"learn/learn-nft-projects/#nodle","title":"Nodle","text":"<p>The Nodle Network is a decentralized wireless network, composed of Nodle Edge Nodes, powered by the Nodle Chain, and the NODL token.</p> <p>Nodle NFT Minting Tool</p>"},{"location":"learn/learn-nft-projects/#unique-network","title":"Unique Network","text":"<p>Unique Network is a specialized Polkadot parachain offering advanced \u201cNFT 2.0\u201d capabilities\u2014including dynamic, nested, fractionalized and composable NFTs\u2014coupled with a hybrid environment that blends EVM and Substrate. Positioned as a front-runner for innovative NFT solutions, Unique Network streamlines creation, management, and cross-chain functionality via sophisticated developer tools and an in-house NFT SDK that substantially simplifies implementation of advanced NFT features and shortens the time-to-deployment. This approach allows dApps to harness both advanced Substrate logic, security and native speed and EVM compatibility, which aligns with Polkadot\u2019s emerging \u201cCloud + Hub\u201d framework.</p> <p>Unique Network focuses on B2B use cases, aiming to be an infrastructure provider for others to build on, rather than entering the NFT space themselves as an end-product.</p> <p>Unique Network is spearheading the effort to develop the XCM utility towards accomplishing a bridgeless and secure cross-chain interoperability and transfer mechanism for NFTs in the Polkadot ecosystem.</p> <p>The Unique Network blockchain is specifically designed to support advanced NFT features. One very successful example of how this approach resolves complexities is demonstrated in the following unique way to create NFTs. In the Unique Network blockchain implementation builds NFTs as independent addressable objects instead of enumerated entities of a contract (ERC-721, Ethereum, EVM approach.) Since they are addressable, they can explicitly become recipients of a transfer. This means that they can receive and contain another NFT just like a wallet does and in this the receiving NFT becomes a container to the contained/received NFT thus forming an object tree with a parent/child relationship. As a result the nesting mechanism stems from the nature of transferability of blockchain objects, requires no additional contracts and is intrinsically a fast operation managed by simple transfers instead of dedicated nesting operations.</p> <p>These are the additional advantages of Unique Network dedicated NFT 2.0 blockchain:</p> <ul> <li>Nested NFTs can be organised into structured bundles</li> <li>NFT bundles can contain NFTs, RFTs and fungible tokens</li> <li>The metadata format of an NFT can have arbitrary attribute structure and complexity</li> <li>An NFT is intrinsically multi-asset</li> <li>Mutability of attributes can be limited to only specific addresses or contracts providing access   control to metadata modification</li> <li>Management rights capability allows for management roles i.e. separation of application and owner   rights to metadata management</li> <li>Intrinsic mutability of metadata provides out-of-the box, contractless dynamic NFT capabilities</li> <li>NFTs can be fractionalised (RFTs - refungible tokens)</li> <li>Due to metadata format flexibility and mutability, it is possible and very simple to implement   on-chain data obfuscation for enhanced privacy</li> </ul> <p>Unique Network provides a fully featured EVM with a few perks:</p> <ul> <li>The EVM address space (0x\u2026) is mapped to the corresponding Substrate address space which   simplifies object and contract access between the EVM and Substrate objects via CrossAddressing   mechanism. This means that you can mix and match technologies. For example you can have a native   NFT call an EVM contract. This is the core mechanism for extending and customising NFTs for   specific use cases.</li> <li>This also means that a native Substrate object is addressable in EVM applications without an   intermediary address handling contract, i.e. applications like the Metamask wallet can address   Unique Network Substrate objects directly. This greatly improves efficiency.</li> <li>Unique network EVM utilities contain interfaces to the blockchain\u2019s core Substrate pallet   functions which allows Solidity contracts to directly invoke them.</li> <li>This interoperability is fully supported by the JS/TS SDK allowing rapid development even in the   mix-and-match scenario.</li> </ul> <p>The recommended and most efficient way to build on Unique Network is via the JS/TS SDK version 2.0. The SDK interacts with the blockchain via an RPC eliminating the need to build and maintain a complex development environment. It fully implements the Unique Metadata Schema 2.0. The Unique SDK allows the creation of NFT assets on the Asset Hub as well which makes it a very versatile tool for NFT management and creation on the Polkadot ecosystem.</p> <p>Developer tools and documentation links:</p> <ul> <li>General information</li> <li>Substrate native advanced NFTs (NFT 2.0)</li> <li>Building NFTs in an EVM</li> <li>Tutorials/Cookbook</li> <li>Youtube Workshops and Tutorials</li> <li>Reference Documentation</li> <li>NFT Marketplace</li> <li>Indexer/Block Explorer</li> </ul> <p>The most prominent projects that currently implement Unique Network\u2019s advanced NFT capabilities are</p> <ul> <li>TapNation</li> <li>ForeverHasFallen</li> </ul> <p>A more comprehensive list can be found on the pages of the official website.</p>"},{"location":"learn/learn-nft/","title":"NFTs","text":"<p>This page is a high-level overview of NFTs in the blockchain space and the various approaches to NFTs within the Polkadot ecosystem.</p>"},{"location":"learn/learn-nft/#fungibility","title":"Fungibility","text":"<p>NFT stands for non-fungible token. Fungibility is defined as interchangeability inside of a group. All valid issued $1 notes are a group to itself. A $1 note is always interchangeable with any other $1 note. It is not, however, interchangeable with $20, $50 or $100 dollar notes (these are separate note groups).</p> <p>A fungible item may be unique. In the currency note example, each issued note has a serial number making it a unique member of the group</p> <p></p> <p>A case where a fungible item is not unique is a simple plastic betting chip. Each chip in its pristine state is indistinguishable from any other chip and each is interchangeable within its own group.</p> <p>On the other hand, an NFT is unique and has features that allow for its uniqueness.</p>"},{"location":"learn/learn-nft/#nft-anatomy","title":"NFT Anatomy","text":"<p>Every NFT has three common components irrespective of the chain it belongs to or originates from that make it unique.</p> <ul> <li>Identity: Defined via a property, address or a contract.</li> <li>Ownership: Determined via a contract or a wallet address.</li> <li>Metadata: Can be a single reference to an off-chain object (digital asset or contract) or, in   case of advanced NFTs, an elaborate data structure containing both on-chain data and off-chain   references.</li> </ul>"},{"location":"learn/learn-nft/#nft-purpose","title":"NFT Purpose","text":"<p>What purpose does a unique digital asset provide? The answer to this question lies in the two distinct ways an NFT is utilized.</p> <p>The first is the use of NFTs as a speculative store of value derived from their uniqueness (rarity, implied, or intrinsic worth). This initial novelty aspect of NFTs initiated an era of collectibles and tradeables and instantiated the appearance of the mass markets where NFTs were traded as a commodity. This is also recognized as the era of the simple NFT, otherwise known as static NFT. The Uniques pallet was created to facilitate this implementation of the NFT.</p> <p>The second implementation is as a utility. As mentioned, when we define an NFT, it can store data on-chain. By convention, we call this NFT component the NFT\u2019s metadata. Generally, an NFT is an independent, sovereign data record. This is where the utility aspect of an NFT lies. An NFT can be a digital key, a collection of documents, an atomic data fragment, or a unique personal set of related assets and information that can be owned. An example of NFT utility is the OG WUD Burn NFT Collection where each NFT grants some benefits within the FlappyWUD game.</p> <p>These two roles are not mutually exclusive. An NFT can be a store of value only, a value-less utility token exclusively, or both at the same time if it has worth on the market as a utility token or, inversely, if it is primarily a token of worth with additional utility.</p> <p>It is the utility aspect of the NFTs that has been the driving force behind the development of and transition to the advanced NFT concept central to Polkadot\u2019s NFTs pallet development.</p>"},{"location":"learn/learn-nft/#nft-standards","title":"NFT Standards","text":"<p>Due to its heterogeneous nature, the Polkadot ecosystem supports differing implementations of NFTs. Polkadot\u2019s core blockchain technology is based on Substrate. Accordingly, NFTs created in substrate-based context are called \u201cnative\u201d NFTs. Native NFTs are created through dedicated methods available in pallets, collections of functions written as Wasm code. Polkadot Uniques and NFTs pallets and Unique Network\u2019s NFT utility pallet bundle provide a way to do this. Here a common standard for metadata may provide direct interoperability and efforts in that direction are being made through the XCM initiative (RFC-0125: XCM Asset Metadata).</p> <p>Polkadot\u2019s Ink! language for writing contracts in Substrate provides a separate mechanism for creating NFTs. Astar has been spearheading this effort and one example of this is their PSP34 (Polkadot Standards Proposals) initiative for standardizing NFTs using the Contracts pallet.</p> <p>The availability of Ethereum Virtual Machines (EVM) in the Polkadot ecosystem provides yet another way to create and manage NFTs using Solidity contracts just like on the Ethereum network. Such NFTs are built in adherence to the corresponding ERC standards adopted from the Ethereum network.</p>"},{"location":"learn/learn-nft/#birth-of-nfts-the-evm-domain","title":"Birth of NFTs - The EVM Domain","text":"<p>A general-purpose blockchain is not built to natively support the concept of NFTs. It is only natively aware and optimized for its own native fungible tokens, and implementations built on such a chain are essentially \"special case smart contracts\".</p> <p>For example, Ethereum is a general-purpose blockchain that does not have the concept of \"tokens\" at all (fungible or not) built-in. Tokens in Ethereum are essentially spreadsheets of information to be interpreted and read in a certain way by various user interfaces via an executable code named a \u201csmart contract\u201d. An agreement on the structure of such a construct is declared a standard and is designated by the Ethereum Request For Comments (ERC) document.</p> <p>The core NFT EVM standard is defined in ERC721, but there are extended implementations that introduce some aspects of advanced NFT features like ERC1155.</p> <p>This approach\u2019s significant shortcoming is its inability to combine standards implicitly. This introduces the necessity of creating custom contract implementations for specialized use cases where one might desire combined features. Each ERC that provides an advanced NFT feature is an isolated subset. As will be shown later, this is not the case for Polkadot native NFTs.</p> <p>A blockchain must provide a mechanism for overcoming these limitations to facilitate the creation of advanced NFT tokens, as we will see in the upcoming section.</p> <p>A typical NFT on Ethereum\u200b**</p> <p></p> <p>For the sake of reference, we can refer to these as static NFTs that are almost exclusively image-based collectibles of varying rarity.</p>"},{"location":"learn/learn-nft/#nfts-in-polkadot-kusama","title":"NFTs in Polkadot &amp; Kusama","text":"<p>As mentioned, standardized pallets provide a decentralized processing mechanism through Wasm contracts, specifically optimized for an NFT implementation\u2019s advanced functionality. Two examples are the Polkadot NFTs pallet and the Unique Network\u2019s collection of NFT utility pallets. This approach allows any parachain in the ecosystem to access advanced NFT features without building a contract framework from scratch.</p> <p>With the introduction of NFT capabilities to the cross-chain messaging format (XCM), a direct inter-chain NFT transfer solution is becoming a reality.</p> <p>A critical aspect of NFT interoperability hinges on the ability of differing networks to agree on a common metadata format. This greatly simplifies interoperability and removes the need for metadata conversion steps. In this regard, an effort is underway to make this a reality in this proposal RFC-0125: XCM Asset Metadata.</p> <p>The other option of building a framework of Solidity contracts as the scaffolding for advanced features within an EVM is also viable. Still, it is hampered by the necessity of using bridging mechanisms for cross-chain transfers and a lack of a derivative NFT solution. This approach exhibits much less efficient transaction processing than the native substrate solutions.</p> <p>:::info</p> <p>See this page for more information about specific NFT project on Polkadot and Kusama.</p> <p>:::</p>"},{"location":"learn/learn-nft/#cross-chain-transfers","title":"Cross-Chain Transfers","text":"<p>Transfer of NFTs across chains is one of the most engaging issues in blockchain. In terms of the mechanism through which a transfer of the NFT can occur on the Polkadot network, two distinct approaches exist:</p> <ul> <li>Asset teleportation</li> <li>Asset reservation via sovereign account mechanism - derivative NFTs</li> </ul> <p>Cross-chain transfers within the Polkadot Substrate ecosystem are exclusively executed through the XCM (Cross-Consensus Messaging) system. This system provides native, trustless security at the protocol level, eliminating the need for external bridge solutions. The XCM implementation significantly enhances security by removing the trustful aspect of the transactions, which is typically required by bridge architectures and represents potential points of failure and security risk in cross-chain communication.</p> <p>NFT transfers can be decomposed into two independently transferable components:</p> <ul> <li>core asset properties, consisting of identity and ownership data, and</li> <li>optional metadata attributes.</li> </ul> <p>In certain cross-chain operations, such as staking, complete NFT teleportation is unnecessary. This was demonstrated through a successful XCM implementation between Unique Network and Acala, where a derivative NFT was created on the Acala chain representing the original NFT from Unique Network. The derivative implementation required only core asset properties, as metadata transfer was nonessential for staking and collateral use cases where only identity and ownership verification are required.</p> <p>Teleportation, i.e., a complete transfer of identity ownership and metadata, may be the optimal solution for a complete asset migration and the only available option for bridging mechanisms.</p> <p>Bridging to and from Substrate chains and EVM chains takes much effort but is a highly desired feature in the NFT industry. Merging the collector and customer base has significant implications, so multiple projects focus on making this possible.</p>"},{"location":"learn/learn-nft/#whats-next-from-here","title":"What\u2019s Next From Here?","text":"<p>Utility NFTs are at a very early adoption stage.</p> <p>If you consider an NFT an ownable, universal digital encapsulation of data, it has a role as significant as that of a smart contract. Real-world asset tokenization, tradable digital coupons, virtual digital keys and badges, bundles of utility, resource, and accomplishment tokens, data wrappers\u2026 a likely advent of the era of discovery lays ahead.</p>"},{"location":"learn/learn-nomination-pools/","title":"Nomination Pools","text":"<p>     Nomination Pools are evolving! Soon you'll be able to participate in a pool and in OpenGov with your pooled funds! You do not need to do anything, unless you are participating in a pool and also staking solo from the same account. In this case, please check            this article          on the actions you need to take as soon as possible.    </p> \u2716 <p>Nomination Pools are live on Polkadot!</p> <p>Nomination pools are a new feature for Polkadot\u2019s staking system that allows users to pool their tokens together on-chain to nominate validators and receive rewards, significantly improving the system\u2019s scalability. Now, anyone with as little as 1 DOT can receive rewards for staking natively on Polkadot. Note that rewards are not guaranteed for those pools that do not have enough bonded funds to be included within the bags list. Only members of active pools will receive rewards.</p> <p>Note</p> <p>Learn the key differences between Staking directly vs Joining a Nomination Pool.</p> <p>For Ledger users: Joining a nomination pool is possible only with the XL version of the Polkadot Ledger App. This should be installed by default on Ledger Nano X and S Plus, but not on the Nano S.</p> <p>If you become a nomination pool member or a pool admin, you cannot participate in Governance with the bonded tokens in the pool, as they are held in a system account.</p> <p>Have questions on Nomination Pools?</p> <p>Please join the Polkadot Discord for asking general questions about Nomination Pools. If you are a developer, please join our nomination pools support channel.</p> <p></p> <p>Nomination pools are one of the key features from the roadmap of staking improvements. They are designed to permissionlessly allow members to pool their funds together and act as a single nominator account.</p> <p>Due to the current runtime constraints, the relay chain can only handle a limited number of nominators (22500 on Polkadot and 12500 on Kusama) comfortably in the electing set. As one of the objectives of the NPoS algorithm is to maximize the overall stake on the network, it can be inferred that the staking system favors nominators with a larger stake. Only the nominator accounts which back the validators in the active set are eligible for receiving staking rewards. This leaves out nomination intents from the accounts with lower token balance than the min-active nomination and places them in a waiting queue to enter electing set. Nomination pools will be handy for members who want to participate in the staking system with a stake much lower than the dynamic min-active nomination threshold on the network. All operations are constant space and time complexity relative to the number of members, eliminating any theoretical upper bound on the number of members the system can handle and thus scaling the number of accounts that can participate and earn rewards in the staking system. In summary, each nomination pool is viewed as a single nominator from the NPoS system point of view.</p> <p>Why aren't the members in the nomination pools called delegators?</p> <p>The term <code>delegator</code> is associated too much with Delegated Proof of Staking (DPoS), and since the network implements Nominated Proof of Staking (NPoS), naming them delegators would be misleading. The term <code>member</code> is our generic replacement for <code>delegator</code>. In action, members are quite similar to delegators and delegate their nomination power to the pool.</p> <p>The pool\u2019s earnings are split pro rata to a member's stake in the bonded pool (and thus, the staking rewards for members will be the same as if they were a nominator). Importantly, slashes are also applied proportionally to members who may have been actively bonded.</p>"},{"location":"learn/learn-nomination-pools/#key-components","title":"Key Components","text":"<ul> <li>Bonded Pool: Tracks the distribution of actively staked funds.</li> <li>Reward Pool: Tracks rewards earned by actively staked funds.</li> <li>Unbonding Sub Pools: Collection of pools at different phases (i.e. eras) of the unbonding   lifecycle.</li> <li>Members: Accounts that nominate to the pools.</li> <li>Point: Unit of measure for a member\u2019s portion of a pool's funds. All pools start with a point to   Planck ratio of 1. Over time, if the pool receives rewards, they increase in value, and if the   pool is slashed, it decreases in value.</li> </ul>"},{"location":"learn/learn-nomination-pools/#pool-member-lifecycle","title":"Pool Member Lifecycle","text":""},{"location":"learn/learn-nomination-pools/#join-a-pool","title":"Join a pool","text":"<p>A member delegates funds to a pool by transferring some amount to the pool\u2019s bonded account with the <code>join</code> extrinsic. The pool then increases its bond with the new funds. A member is afforded the ability to bond additional funds or re-stake rewards as long as they are already actively bonded. Note that a member may only belong to one pool at a time.</p> <p>The current minimum bond to join a pool can be seen here.</p> <p>Info</p> <p>The funds nominated to a pool will not be visible in the member's account balance on Polkadot JS Apps UI. This is because the member funds are transferred from their account to the pool's system account. This pool account is not accessible by anyone (including the pool root or depositor) and only the pool's internal logic can access the account.</p> <p>Use Proxy Accounts to join Nomination Pools</p> <p>Depending on how much control you want to give your proxy, you might choose between any &gt; non-transfer &gt; staking &gt; nomination pool proxy, with the latter being only able to sign transactions related to the <code>NominationPool</code> pallet.</p> <p>Check the \"How to join a pool\" section in this support article for guidelines.</p>"},{"location":"learn/learn-nomination-pools/#claim-rewards","title":"Claim rewards","text":"<p>The member can claim their portion of any rewards that have accumulated since the previous time they claimed (or in the case that they have never claimed, any rewards that have accumulated since the era after they joined). Rewards are split pro rata among the actively bonded members. Check the \"How to claim rewards\" section in this support article for guidelines.</p>"},{"location":"learn/learn-nomination-pools/#claim-permissions","title":"Claim Permissions","text":"<p>As a pool member, you can grant permission to any other account to claim and compound rewards on your behalf. There are four permission options:</p> <ul> <li><code>Permissioned</code> (default): you need to claim and compound your rewards.</li> <li><code>PermissionlessCompound</code>: you grant permission to any other account to compound (claim and bond)   your rewards on your behalf.</li> <li><code>PermissionlessWithdraw</code>: you grant permission to any other account to withdraw (claim and keep as   a free balance) your rewards on your behalf.</li> <li><code>PermissionlessAll</code>: you grant permission to any other account to compound or withdraw your   rewards on your behalf.</li> </ul> <p>See the Staking Dashboard page for more information about how to set your claim permissions.</p> <p>See the advanced guides to learn how to claim rewards for another pool member.</p>"},{"location":"learn/learn-nomination-pools/#unbond-and-withdraw-funds","title":"Unbond and withdraw funds","text":"<p>At any point in time after joining the pool, a member can start the process of exiting by unbonding. <code>unbond</code> will unbond part or all of the member's funds. After unbond has been called and the unbonding duration has passed a member may withdraw their funds with <code>withdrawUnbonded</code>. Withdrawing effectively ends a member's relationship with their pool, allowing them to join a different pool if desired. Check the \"Withdraw unbonded funds\" section in this support article for guidelines.</p> <p>Unbonding transaction automatically triggers withdrawal of rewards</p> <p>When there is a change in the bonded balance, the accumulated rewards in the pool thus far are automatically withdrawn to the account. The rewards are then accrued based on the updated bonded balance.</p>"},{"location":"learn/learn-nomination-pools/#limitations-of-nomination-pools","title":"Limitations of Nomination Pools","text":"<ul> <li>A member cannot vote (e.g. in Referenda or for Council members) with their nominated funds. This   may be changed in the future once accounts are afforded the ability to split votes.</li> <li>For a member to switch pools, all funds from the account must be unbonded. This process takes 28   eras.</li> <li>A member can partially unbond the staked funds in the pool (at most 16 partial unbonds).</li> </ul>"},{"location":"learn/learn-nomination-pools/#pool-administration","title":"Pool Administration","text":""},{"location":"learn/learn-nomination-pools/#states","title":"States","text":"<ul> <li>Open: The pool is open to be joined by anyone.</li> <li>Blocked: The pool is blocked; no joiners are permitted.</li> <li>Destroying: The pool is in the process of being destroyed. Once in this state, the pool may never   revert to any other state; it can only proceed to be destroyed. All members can be   permissionlessly unbonded; this allows the pool to be dismantled regardless of any member\u2019s   proactivity.</li> </ul>"},{"location":"learn/learn-nomination-pools/#roles","title":"Roles","text":"<ul> <li>Depositor: Creates the pool and is the initial member. The depositor can only leave the pool once   all other members have left. Once they leave by withdrawing, the pool is fully removed from the   system.</li> <li>Nominator: Can select the validators the pool nominates.</li> <li>Bouncer: Can change the pool\u2019s state and kick (permissionlessly unbond/withdraw) members if the   pool is blocked.</li> <li>Root: Can change the nominator, bouncer, or itself. Further, it can perform any of the actions the   nominator or bouncer can.</li> </ul>"},{"location":"learn/learn-nomination-pools/#pool-commissions","title":"Pool Commissions","text":"<p>As the pool root role, you can set pool commissions that will be applied to the staking rewards paid out to the pool's system account before rewards are allocated for the pool members. You can set pool commissions through the Polkadot Staking Dashboard.</p> <p>Three methods can be used when setting the pool commission:</p> <ul> <li>Commission Rate (<code>nominationPools.setCommission</code> extrinsic): the start or new commission rate   (<code>newCommission</code> parameter) that can be set between 0% and the   max commission parameter   (decided through governance referendum) via the   <code>globalMaxCommission</code>   parameter. You will need to specify an Input Payee Account, i.e. the account that will receive the   commission.</li> <li>Max Commission (<code>nominationPools.setCommissionMax</code> extrinsic): the maximum commission   (<code>maxCommission</code> parameter) the pool will apply to its members (between 0% and Max Commission).   Note that once set, the pool admin can only lower it.</li> <li>Change Rate (<code>nominationPools.setCommissionChangeRate</code> extrinsic): the maximum rate increase   (<code>maxIncrease</code> parameter) allowed for a single commission update. Note that once set, the pool   admin can only lower it. When setting the Change Rate, it will also be possible to set a   <code>minDelay</code> quantified as the number of blocks (since last commission update) after which it is   possible to change the commission (i.e. the minimum delay between commission updates). Note that   once set, the pool admin can only increase it.</li> </ul> <p>Max Commission and Change Rate must not be necessarily set. It is the choice of the pool admin to set those parameters and provide transparency to the pool members about the pool's commission policy.</p> <p>Max Commission and Change Rate are currently permanent</p> <p>Once the Max Commission and the Change Rate are set, the pool admin currently can only decrease those values. The minimum delay between commission updates can only be increased. The situation can change in the future and a <code>forceSetCommissionMax</code> method can be proposed through governance referendum.</p> <p>Let's take, for example, Pool A, which sets the Commission Rate to 10%, the Max Commission to 100%, and the Change Rate to 1% every 300 blocks (which equates to approximately 30 minutes). The following statements are true:</p> <ul> <li>The pool commission can be increased by 1% every 30 minutes. Bigger increases are not allowed.   Increases of less than or equal to 1% are not allowed sooner than 30 minutes since the last   commission update.</li> <li>The Max Commission can only be decreased from 100%. Once decreased, it can be decreased again but   it cannot be increased.</li> <li>The Change Rate's maximum increase can only be decreased from 1%. Once decreased, it can be   decreased again but it cannot be increased.</li> <li>The Change Rate's minimum delay between updates of 30 min can only be increased. Once increased,   it can be increased again but it cannot be decreased.</li> </ul>"},{"location":"learn/learn-nomination-pools/#pool-lifecycle","title":"Pool Lifecycle","text":"<p>Advanced How-to Guides</p> <p>See this page for more information about the lifecycle of nomination pools. The cycle includes creation, upkeep and destruction.</p>"},{"location":"learn/learn-nomination-pools/#nomination-pools-slashing","title":"Nomination Pools - Slashing","text":"<p>Suppose the staking system slashes a pool\u2019s underlying nomination account. In that case, the slash is distributed evenly across the bonded pool, and the unbonding pools from slash era+1 through the slash apply era. Thus, any member who either a) was unbonding or b) was actively bonded in the aforementioned range of eras will be affected by the slash. In other words, a member who may have been actively bonded during the offence is slashed pro rata based on its stake relative to the total slash amount.</p> <p>Unbonding pools need to be slashed to ensure all nominators who were in the bonded pool while it was backing a validator that committed an offense are punished. Without these measures a nominator could unbond right after a validator equivocated with no consequences.</p> <p>This strategy is unfair to members who joined after the slash because they get slashed as well, but it spares members who unbond. The latter is much more important for security: if a pool's validators attack the network, their members need to unbond fast! Avoiding additional slashes gives them an incentive to do that if validators get repeatedly slashed.</p>"},{"location":"learn/learn-nomination-pools/#nominating-vs-joining-a-pool","title":"Nominating vs Joining a Pool","text":"<p>Nominating is the action of choosing validators. It does not simply involve bonding tokens. Nominating is an active task, which implies that you regularly monitor that your stake is backing an active validator in all the eras and check if you are receiving your staking rewards. More importantly, ensure that the validators you chose always act in the best interests of the network protocol and have less chance of getting slashed. To nominate you need a minimum bond, while to receive rewards, you need at least a balance greater than the minimum active bond. If the validator misbehaves, It is worth noting that your stake is subject to slashing, irrespective of whether you are at the top nominators or not.</p> <p>As the minimum active bond is a dynamic value, it can make your nomination inactive when the threshold goes above your bonded balance. Hence, to be eligible to earn rewards while nominating, you would need to stake a much higher balance than the minimum active bond.</p> <p>Nomination pools are a way to participate in staking with as little as 1 DOT and earn staking rewards. Nomination pools differ from custodial solutions (like staking through central exchanges) because they are non-custodial, native to Polkadot's protocol, permissionless, transparent, and run in a decentralized way by the community. Before joining a nomination pool, you must ensure that the pool is earning rewards and nominating the validators that match your preferences. Participating in pools is more of a set-and-forget action than nominating by yourself. The pool operator maintains the list of validators nominated by the pool, and so, in a way, you are trusting the pool operator to act in your best interests. However, it is advised to check the validators nominated by the pool from time to time and change the pool if necessary.</p> <p>Minimum Active Nomination Value is Dynamic</p> <p>The minimum amount required to become an active nominator and earn rewards can be seen here. If you have less tokens than the minimum active nomination and still want to participate in staking, you can join the nomination pools with a smaller bond. For additional information, see this blog post. Check the wiki doc on nomination pools for more information.</p> Nominating Joining a Pool Minimum 250 DOT to nominate. Minimum 1 DOT to be a member. Rewards can be compounded automatically or sent to any account. Rewards can be manually claimed to the pool member's account and be bonded in the pool again to compound them. If the active validator gets slashed, all active nominators are subjected to slashing. If the active validator gets slashed, all pool members are subjected to slashing. Can bond and stake DOT indefinitely. Can bond and stake DOT until the pool exists. Unbonding period of 28 days. Can switch validators without unbonding. Unbonding period of 28 days. Need to unbond before switching to a different pool. Maximum uncapped. Maximum uncapped. Should bond more than the minimum active nomination in an era to be eligible to earn staking rewards, although it can depend on multiple other factors outlined in the linked document. A nomination pool earns rewards in an era if it satisfies all the conditions mentioned for the nominator (as the nomination pool is just a nominator from the NPoS system perspective). Staked tokens can be used for participation in Governance. Staked tokens cannot be used for participation in Governance. Rewards payout can be triggered permissionlessly by anyone (typically done by the validator). A pool member can self claim the rewards or can grant permission to any other account to claim and compound rewards on your behalf. See Claim Permissions. Bonded funds remain in your account. Bonded funds are transferred to a pool account which is administered by the network protocol and is not accessible to anyone else. See System Accounts for more information. Nominator manages the list of staked validators (up to 16). Nominations managed by the pool operator."},{"location":"learn/learn-nominator/","title":"Nominator","text":"<p>New to Staking?</p> <p>Start your staking journey or explore more information about staking on Polkadot's Home Page. You can learn how staking works by reading this dedicated page.</p> <p>Discover the new Staking Dashboard that makes staking much easier and check this extensive article list to help you get started.</p> <p>You can now stake natively with just 1 DOT and earn staking rewards.</p> <p>Stake through Nomination Pools</p> <p>The minimum amount required to become an active nominator (i.e. the minimum active bond) and earn rewards may change from era to era. If you have less tokens than the minimum active nomination and still want to participate in staking, you can join the nomination pools with a smaller amount of tokens. For additional information, see this blog post. Check the wiki doc on nomination pools for more information.</p> <p>If you landed on this page, you decided to understand how you can be a good nominator. Note, this page is not for nomination pool members, although pool members might gain essential knowledge about how to choose nomination pools.</p> <p>The information provided on this page is complementary to that on the Staking Page and Advanced Staking Page. Make sure you read those pages as well before nominating.</p>"},{"location":"learn/learn-nominator/#who-are-nominators","title":"Who are Nominators?","text":"<p>Nominators are one type of staking participant. They appoint their stake to the validators, the second type of participant. By appointing their stake, they can elect the active set of validators and share in the rewards that are paid out.</p> <p>While the validators are active participants in the network that engage in the block production and finality mechanisms, nominators take a slightly more passive role. Being a nominator does not require running a node of your own or worrying about online uptime. However, a good nominator performs due diligence on the validators that they elect. When looking for validators to nominate, a nominator should pay attention to their own reward percentage for nominating a specific validator - as well as the risk that they bear of being slashed if the validator gets slashed.</p>"},{"location":"learn/learn-nominator/#why-nominate","title":"Why Nominate?","text":"<ul> <li>You become a network participant, a group of diverse professionals and enthusiasts around the   world aspiring to build and foster the next-gen Internet, Web3: a decentralized, privacy-focused,   and trustless internet.</li> <li>You are an essential piece of the puzzle, keeping the network secure. The bonded balance can be   used to vote in Polkadot OpenGov and shape the network's future   direction.</li> <li>You will start to understand how Polkadot works at a technical-level. When you feel comfortable   with your nomination skills and knowledge, you can open your   nomination pool, help others secure the network and earn rewards,   and build your reputation as a trusted nomination pool operator. If you like to be more involved,   the next step is to become a validator.</li> <li>By getting staking rewards you keep up with or (likely) stay ahead of   network inflation.</li> </ul> <p>Nominators secure the relay chain by staking native tokens (DOT on Polkadot or KSM on Kusama) and nominating validators. You may have an account with DOT and want to earn fresh DOT. You could do so as a validator, which requires experience setting up a node and running and maintaining it 24/7.</p> <p>On Polkadot, you can also earn DOT by nominating one or more validators. Doing so makes you a nominator for the validator(s) you chose. Pick your validators carefully - if they do not behave properly, they will get slashed, and you will lose some DOT. However, if they follow the network rules, you can share the staking rewards they generate.</p> <p>While your tokens are staked for nominations, they are 'locked' (bonded). You can stop nominating at any time, but remember that the action is effective in the next era and does not automatically unbond your funds. Unbonding is a separate action, and it takes effect after the unbonding period. A staking lock will be visible on the Polkadot-JS UI during the unbonding period, and after it, the staking lock can be unlocked, and the bonded funds become free balance you can transfer.</p> <p>Fast Unstaking</p> <p>If you accidentally bonded your tokens or your bonded tokens never backed any active validator, you can now unbond them immediately.</p> <p>If your bonded balance did not back any validators in the last 28 days on Polkadot (7 days on Kusama), you are eligible to perform fast unstaking. The staking dashboard will automatically check if you qualify. For more information, visit the \"Fast Unstake\" section in this support article.</p>"},{"location":"learn/learn-nominator/#setting-up-accounts","title":"Setting-up Accounts","text":""},{"location":"learn/learn-nominator/#stash-staking-proxy","title":"Stash &amp; Staking Proxy","text":"<p>Nominators are recommended to set up separate stash and staking proxy accounts. Explanation and the reasoning for generating distinct accounts for this purpose is elaborated in the keys section.</p> <p>You can generate your stash and staking proxy account via any of the recommended methods, which are detailed on the account generation page. The first thing you need to do before becoming a nominator is to make sure you have a stash account where you can transfer funds you want to use for staking. For these accounts, it is recommended to use a \"cold wallet\" solution such as Ledger or Polkadot Vault.</p> <p>After setting up the stash account, it is recommended to have a staking proxy. Although you can be a nominator with just a stash account, having a staking proxy is good practice for security reasons.</p> <p>A staking proxy of the stash will be able to sign for all staking-related transactions as well. The stash will be fully isolated (except if the user decides to change the staking proxy of the stash or to attach different proxies to the stash).</p>"},{"location":"learn/learn-nominator/#rewards-payout-account","title":"Rewards Payout Account","text":"<p>As a nominator, you will be asked to choose an account where rewards will be paid. You can select one of the following options:</p> <ul> <li>back to staking: rewards are compounded to the bonded amount.</li> <li>to stash: rewards are sent to the stash account as a free balance.</li> <li>to another account: rewards are sent to a user-defined account (not stash).</li> </ul> <p>Starting with runtime version v23 natively included in the client version 0.8.23, payouts can go to any custom address. If you'd like to redirect payments to an account that is neither the staking proxy nor the stash account, set one up. Note that setting an exchange address as the recipient of the staking rewards is extremely unsafe.</p> <p>Info</p> <p>Being a nominator is made simpler by using the Staking Dashboard that will guide you step by step through specifying rewards destination and bonded amount, and nominating validators (more on this below). Note that staking proxies are not currently supported on the dashboard.</p>"},{"location":"learn/learn-nominator/#nominating-with-the-polkadot-js-ui","title":"Nominating with the Polkadot-JS UI","text":""},{"location":"learn/learn-nominator/#targets-page","title":"Targets Page","text":"<p>There are many factors to consider when deciding which of your nominations. One helpful tool to choose validators is the Staking Targets table in the Polkadot-JS UI. This allows sorting validators using various metrics. Below are the relevant metrics shown as an example, followed by a brief description of each.</p> validator payout nominators comm. total stake own stake return A recently 1 (<code>active</code>) 4 (<code>all</code>) 3% 1.6 MDOT 8500 DOT 17.8% <ul> <li>payout: How recently the validator made its last reward payout to nominators.</li> <li>nominators: This column consists of two number values. The active count (left number) is   the number of nominators whose stake is baking the validator in the current era. In this case   Validator A has one active nominator. The total or all count (right number) is the number of   all nominators who nominated Validator A. This includes the active count and all the other   nominators whose stake in the current era is baking other validators.</li> </ul> <p>Every nominator can select up to   a maximum number of validators,   which contributes towards maximizing the probability of having the nominator\u2019s stake applied to   the validators active set. Nominating too few validators could result in the nominators not   receiving their rewards when none of them make it to the active set or when those validators stop   validating. The election algorithm attempts to maximize the overall network stake while minimizing   the variance of the active stake across the validators. For additional information on the election   process, check out the research behind   nominated proof-of-stake.</p> <ul> <li>comm.: Total commission kept by the validator (100% means the validator will keep all rewards   , and thus nominators will not receive them). A validator's commission is the percentage of the   validator reward taken by the validator before the rewards are split among the nominators. As a   nominator, you may think that choosing validators with the lowest commission is best. However,   validators must be able to run at break-even to continue operations sustainably. Independent   validators that rely on the commission to cover their server costs help to keep the network   decentralized. Some validators, operated by central exchanges, etc., keep 100% of the commission   to payout their staking service clients and therefore do not provide any rewards to external   nominators. The commission is just one piece of the puzzle you should consider when picking   nominating validators.</li> <li>total stake: The total amount of tokens staked by nominators and the validator (i.e. own   stake, see below).</li> <li>own stake: The amount of tokens the validator has put up as a stake. A higher own stake can be   considered as having more \"skin in the game\". This can imply increased trustworthiness. However, a   validator not having a large amount of \"own stake\" is not automatically untrustworthy, as the   validator could nominate from a different address.</li> <li>return: Average annual yield paid out to nominators (i.e. number of rewards divided by the   number of bonded tokens). Note that nominating those with a higher yield may not guarantee similar   future performance.</li> </ul> <p></p> <p>On the Targets page, you can use different filters to select validators with specific traits (where a trait is a combination of the metrics above). Available filters are:</p> <ul> <li>one validator per operator: Do not show groups of validators run by a single operator. It   shows small operators only who will likely have a higher commission and higher self-stake.   Nominating only small operators might not always guarantee staking rewards, but it helps to keep   the network more resilient to attacks.</li> </ul> <p>Validator vs Operator</p> <p>A validator is the node, the physical equipment with installed software that allows to produce new blocks and earn rewards. An operator is the entity responsible for setting up, running and maintaining the node. An operator can have multiple validators under different sub-identities. For example, <code>ZUG CAPITAL/07</code> is one of the numerous validators belonging to the operator Zug Capital.</p> <ul> <li>comm. &lt; 20%: Do not show any validators with a commission of 20% or higher.</li> <li>recent payouts: Only show validators that have recently caused a   payout to be issued. Note that anyone can cause a payout to occur; it   does not have to be the operator of a validator.</li> <li>currently elected: Only show validators in the active set (i.e., they have been elected to   produce blocks in the current era).</li> <li>with an identity: Only show validators that have set an identity. Note   that this identity does not have to be verified by a registrar for the validator to appear in the   list.</li> </ul> <p>Single Operators with Multiple Validators</p> <p>Recall that slashing is an additive function; the more validators equivocating in a given session, the harsher the penalties. Since validators that are controlled by a single operator are more at risk of a \"synchronized\" failure, nominating them implies a greater risk of having a large slash of your nominated funds. Generally, it is safer to nominate validators whose behavior is independent of others in many ways (different hardware, geographic location, owner, etc.).</p>"},{"location":"learn/learn-nominator/#bags-list","title":"Bags-list","text":"<p>Info</p> <p>On Polkadot and Kusama, the instance of the pallet Bags-List is named as <code>voterList</code>.</p> <p>Nominating accounts are placed in a semi-sorted list called bags-list. This sorting functionality is extremely important for the long-term improvements of the staking/election system. Bags-list allows an unlimited number nominators to set their intention to nominate, of which only a portion of it (currently 22500) is considered for electing set that eventually determines the active validators.</p> <p>The nominator accounts in a bag are sorted based on their insertion order, not by their nomination stake. The <code>voterList.putInFrontOf</code> extrinsic can be issued to move up in the bag, which might be very useful for the accounts in the last bag eligible for receiving staking rewards. Balance changes due to staking rewards or slashing do not automatically rebag the account. Whenever applicable, Polkadot JS Apps UI prompts the nominator account to rebag or move up by calling the <code>voterList.rebag</code> extrinsic.</p> <p>For guidelines about how to rebag or move your account within a bag, see the followings:</p> <ul> <li>The \"Bags List\" Section on   this Support Page.</li> <li>The Bags List Section in Advanced Staking Concepts.</li> <li>The dedicated technical explainer video.</li> </ul>"},{"location":"learn/learn-nominator/#validator-stats","title":"Validator Stats","text":"<p>Nominators can query validator histories to see statistics such as era points, elected stake, rewards and slashes, and commission. It is good practice to do comprehensive research on validator candidates. This could include (but should not be limited to) checking the validators' identity (if they have set one) and going over the validators' websites to see who they are, what kind of infrastructure setup they are using, reputation, the vision behind the validator, and more.</p> <p>Any problematic behavior must be taken seriously. An example of problematic behavior will be if a validator is regularly offline. In this case, nominators will get fewer rewards.</p> <p></p>"},{"location":"learn/learn-nominator/#nominating-with-the-staking-dashboard","title":"Nominating with the Staking Dashboard","text":"<p>If you are a beginner, please watch the video below for detailed instructions.</p> <p></p> <p>The Polkadot Staking Dashboard allows to choose pre-selected lists of validators based on user preference, or to manually select validators similarly as in the Polkadot-JS UI.</p> <p>Pre-selected choices are:</p> <ul> <li>Optimal Selection: Selects a mix of majority active and inactive validators.</li> <li>Active Low Commission: Gets a set of active validators with low commission.</li> <li>From Favorites: Gets a set of your favorite validators.</li> </ul>"},{"location":"learn/learn-nominator/#staking-election-stages","title":"Staking Election Stages","text":"<p>The staking election system has three stages for both validators and nominators, namely \"intention\", \"electable/electing\", and \"active\".</p> <ul> <li>intention to nominate: an account that has stated the intention to nominate; also called   simply a \"nominator\".</li> <li>electing nominator: a nominator who is selected to be a part of the input to the   NPoS election algorithm. This selection is based on stake and is made using   the bags-list.</li> <li>active nominator: a nominator who came out of the NPoS election algorithm backing an active   validator. When slashing occurs, all the active nominators backing the validator get slashed.</li> </ul> <p></p>"},{"location":"learn/learn-nominator/#the-election-solution-set","title":"The Election Solution Set","text":"<p>Determining which validators are in the active set and which nominators are nominating them creates a very large graph mapping nominators to their respective validators. This \"solution set\" is computed off-chain and submitted to the chain, which means it must fit in a single block. If there are a large number of nominators, this means that some nominators must be eliminated. Currently, nominators are sorted by the amount of DOT staked, and those with more DOT are prioritized. This means that you may not receive rewards if you are staking with a small amount of DOT. This minimal amount is dynamic based on the number of validators, nominators, amount nominated, and other factors.</p>"},{"location":"learn/learn-nominator/#receiving-rewards","title":"Receiving Rewards","text":"<p>As long as you have nominated more than one validator candidate, at least one of them got elected, and you are nominating with enough stake to get into the solution set, your bonded stake will be fully distributed to one or more validators. That being said, you may not receive rewards if you nominated very few validator candidates and no one got elected, or your stake is small, and you are not part of the top 22,500 nominators, or the validator you are nominating has 100% commission. It is generally wise to choose as many trustworthy validators as you can to reduce the risk of none of your nominated validators being elected.</p> <p>Not receiving Staking Rewards?</p> <p>To explore the possible reasons for not receiving staking rewards, check out the followings: - The Staking FAQ on the Support Pages. - The \"Why am I not receiving staking rewards?\" Reddit article. - The \"Why am I not receiving staking rewards?\" section on the Staking Page.</p> <p>Rewards are lazy - somebody must trigger a payout for a validator for rewards to go to all of the validator's nominators. Any account can do this, although validator operators often do this as a service to their nominators. See the page on Simple Payouts for more information and instructions for claiming rewards.</p> <p>Explainer videos on Nominating</p> <p>These concepts have been further explained in the following videos: - Why Nominate on Polkadot &amp; Kusama - What to Consider when Nominating Validators on Polkadot and Kusama - Nominating/Staking on Polkadot and Kusama</p>"},{"location":"learn/learn-nominator/#good-nominator-practices","title":"Good Nominator Practices","text":""},{"location":"learn/learn-nominator/#required-minimum-stake","title":"Required Minimum Stake","text":"<p>Due to the way the Phragmen algorithm generates the solution set and due to the fact that the solution set must fit in a single block, a minimum number of DOT will be required to nominate with to receive staking rewards can change between the eras.</p> <ul> <li> <p>min-intention-threshold: minimum stake to declare the intention to nominate. This parameter   can be updated via on-chain governance, and the most recent and up-to-date version can be found on   chain state (select state query &gt; staking &gt;   minimumNominatorBond)</p> </li> <li> <p>min-electing: minimum stake among the electing nominators. Since this is almost always the   same as \u201cmin-active\u201d, it might not be reported.</p> </li> <li> <p>min-active: minimum stake among the active nominators. If your stake falls below this dynamic   threshold in a given era, you will not receive staking rewards for that era.</p> </li> </ul> <p>Thus, for nominator counters, we have:</p> <ul> <li>count of nominator intentions and   max possible nominator intentions</li> <li>count of electing nominators, and maximum possible electing nominators (22500 on Polkadot and   12500 on Kusama)</li> <li>count of active nominators and maximum possible active nominators (22500 on Polkadot and 12500 on   Kusama)</li> </ul>"},{"location":"learn/learn-nominator/#active-vs-inactive-nomination","title":"Active vs. Inactive Nomination","text":"<p>When you go to the Account actions under staking page, you should see your bonded accounts and nomination status. If not, you can follow this guide to configure it first. Your nominations will be effective in the next era; eras are roughly 24 hours on Polkadot (6 hours on Kusama).</p> <p></p> <p>Suppose you have nominated five validator candidates, and three out of five were elected to the active validator set; then you should see two of your nominations as \"waiting\", and most likely one as \"active\" and the rest as \"inactive\". Active or inactive nomination means your nominated validators have been elected to be in the validator set, whereas waiting means they did not get elected. Generally, you will only have a single validator have an active nomination, which means that you are directly supporting it with your stake this era and thus potentially receiving staking rewards. Inactive nominators were validators elected for this era but which you are not actively supporting. Every era, a new election will take place, and you may be assigned a different active nomination from the validators you selected.</p> <p>If you are committing a very large stake, you may have more than one active nomination. However, the election algorithm attempts to minimize this situation, and it should not occur often, so you should almost always see only a single active nomination per era. See the section on Phragm\u00e9n optimization for more details.</p>"},{"location":"learn/learn-nominator/#minimum-active-nomination-to-receive-staking-rewards","title":"Minimum Active Nomination to Receive Staking Rewards","text":"<p>Minimum DOT required to earn staking rewards</p> <p>The minimum number of tokens required to submit intent to nominate differs from the minimum active nomination required to earn staking rewards.</p> <p></p>"},{"location":"learn/learn-nominator/#guides","title":"Guides","text":"<ul> <li>Be a Nominator (Polkadot) - Guide on   nominating on the Kusama canary network.</li> <li>Stop Being a Nominator (all networks) - Guide on   stopping nominations and withdrawing tokens.</li> </ul>"},{"location":"learn/learn-offenses/","title":"Offenses & Slashes on Polkadot","text":"<p>     The material provided here is based on the changes introduced by Step 2 of the Disabling feature. See            this page          for more information.   </p> \u2716 <p>Disclaimer</p> <p>Various parachains or applications living on top of Polkadot might add various economic schemes and include slashes, but they are unrelated to the slashes described here as they only refer to the staked tokens via Nominated Proof-of-Stake.</p> <p>Polkadot is a public permissionless network. As such, it has a mechanism to disincentivize offenses and incentivize good behavior. Below, you can find a summary of punishments for specific offenses:</p> Offense Slash (%) On-chain Disabling Off-chain Disabling Reputational Changes Backing Invalid 100% Yes Yes (High Priority) No ForInvalid Vote - No Yes (Mid Priority) No AgainstValid Vote - No Yes (Low Priority) No GRANDPA / BABE / BEEFY Equivocations 0.01-100% Yes No No Seconded + Valid Equivocation - No No No Double Seconded Equivocation - No No Yes"},{"location":"learn/learn-offenses/#offenses","title":"Offenses","text":"<p>Learn more about the parachain protocol</p> <p>To better understand the terminology used for offenses, it is recommended to get familiar with the parachain protocol.</p> <p>On Polkadot, there are six main validator offenses as shown below.</p> <ul> <li>Backing Invalid: A para-validator is backing an invalid block.</li> <li>ForInvalid Vote: A validator (secondary checker) votes in favor of an invalid block.</li> <li>AgainstValid Vote: A validator (secondary checker) is voting against a valid block (and   wasting network resources).</li> <li>Equivocation: A validator produces two or more of the same block or vote.</li> <li>GRANDPA and BEEFY Equivocation: A validator signs two or more votes in the same round on     different chains.</li> <li>BABE Equivocation: A validator produces two or more blocks on the relay chain in the same time     slot.</li> <li>Double Seconded Equivocation: Within a backing group of 5 para-validators, at most 5 backed   parablocks are possible. Each parablock requires exactly one seconded and at least two more valid   votes from the five potential backers. This makes an upper bound on the number of parablocks the   system has to deal with while still allowing some choice for relay chain block authors. Backers   must decide which parablock to second, and they cannot second another. If another seconding vote   is found, they will be punished (somewhat lightly as of now, but there is little to gain from   this). All of this is made slightly more complicated with   asynchronous backing as it is no longer one candidate per relay chain   block as backers can back blocks \"into the future\" optimistically. See   this page   for more information.</li> <li>Seconded + Valid Equivocation: This happens when a malicious node first seconds something   (takes absolute responsibility for it), and then only pretends to be someone who just said it is   correct after someone else takes responsibility. That is a straight-up lie (equivocation). A node   could use that tactic to escape responsibility, but once the system notices the two conflicting   votes, the offense is reported.</li> </ul>"},{"location":"learn/learn-offenses/#equivocation-conflicting-statements","title":"Equivocation (Conflicting Statements)","text":"<p>Equivocation occurs when a validator produces statements that conflict with each other.</p> <p>For instance, as a block author appointed by BABE, only a single block should be authored for the given slot, and if two or more are authored, they are in conflict with each other. This would be a BABE Equivocation Offence.</p> <p>In BEEFY &amp; GRANDPA validators are expected to cast a single vote for the block they believe is the best, but if they are found with two or more votes for different blocks, it means they tried to confuse the network with conflicting statements and when found out this will be a BEEFY/GRANDPA Equivocation Offense.</p> <p>Equivocations usually occur when duplicate signing keys reside on the validator host. If keys are never duplicated, the probability of an honest equivocation slash decreases to near 0.</p>"},{"location":"learn/learn-offenses/#punishments","title":"Punishments","text":"<p>On Polkadot, offenses to the network can be punished depending on their severity. There are three main punishments: slashing, disabling, and reputation changes.</p>"},{"location":"learn/learn-offenses/#slashing","title":"Slashing","text":"<p>Slashing will happen if a validator misbehaves in the network. They and their nominators will get slashed by losing a percentage of their staked tokens, from as little as 0.01% up to 100%.</p> <p>Any slashed token will be added to the Treasury. The rationale for this (rather than burning or distributing them as rewards) is that slashes may be reverted by simply paying out from the Treasury. This would be useful in situations such as faulty slashes. In the case of legitimate slashing, tokens are moved away from malicious validators to those building the ecosystem through the normal Treasury process.</p> <p>Slashing only occurs for active validations for a given nominator, and slashes are not mitigated by having other inactive or waiting nominations. They are also not mitigated by the validator operator running separate nodes; each node is considered its own entity for slashing purposes.</p> <p>Multiple Active Nominations</p> <p>In rare instances, with very large bonds, a nominator may actively nominate several validators in a single era. In this case, the slash is proportionate to the amount staked to that specific validator. Note that you cannot control the percentage of stake allocated to each validator or choose who your active validator will be (except in the trivial case of nominating a single validator). Staking allocations are controlled by the Phragm\u00e9n algorithm.</p> <p>Once a validator gets slashed, it goes into the state as an \"unapplied slash\". You can check this via Polkadot-JS UI. The UI shows it per validator, followed by all the affected nominators and the amounts. While unapplied, a governance proposal can be made to reverse it during a 27-day grace period, after which the slashes are applied.</p> <p>A slash may occur under the circumstances below:</p> <ol> <li>Equivocations \u2013 A slash of 0.01% is applied with as little as a single evocation. The slashed     amount increases to 100% incrementally as more validators also equivocate.</li> <li>Disputes \u2013 This may result from a validator trying to represent the contents of a block falsely     . Slashing penalties of 100% may apply.</li> </ol>"},{"location":"learn/learn-offenses/#slash-for-equivocation","title":"Slash for Equivocation","text":"<p>The following levels of offense are defined. However, these particular levels are not implemented or referred to in the code or the system; they are meant as guidelines for different levels of severity for offenses.</p> <ul> <li>Level 1: Isolated equivocation slashes a minimal amount of the stake.</li> <li>Level 2: Misconducts unlikely to be accidental but do not harm the network's security to any large   extent. Examples include concurrent equivocation or isolated cases of unjustified voting in   GRANDPA. Slashes a moderately small amount of the stake.</li> <li>Level 3: misconduct that poses severe security or monetary risk to the system or mass collusion.   Slashes all or most of the stake behind the validator.</li> </ul> <p>The following are scenarios that build towards slashes under equivocation:</p> <ol> <li>Cloning a server, i.e., copying all contents when migrating to new hardware. This action should     be avoided. If an image is desired, it should be taken before keys are generated.</li> <li>High Availability (HA) Systems \u2013 Equivocation can occur if there are any concurrent operations,     either when a failed server restarts or if a false positive event results in both servers being     online simultaneously. HA systems are to be treated with extreme caution and are not advised.</li> <li>The keystore folder is copied when attempting to copy a database from one instance to another.     It is important to note that equivocation slashes occur with a single incident. This can happen     if duplicated keystores are used for only a few seconds. A slash can result in losing nominators     and funds, removal from the Decentralized Nodes program, and     reputational damage.</li> </ol> <p>See the next section to understand how slash amounts for equivocations are calculated. If you want to know more details about slashing, please look at our research page.</p>"},{"location":"learn/learn-offenses/#slash-calculation-for-equivocation","title":"Slash Calculation for Equivocation","text":"<p>GRANDPA, BABE, and BEEFY equivocation use the same formula for calculating the slashing penalty:</p> <pre><code>Let x = offenders, n = total number of validators in the active set\n\nmin((3 * x / n )^2, 1)\n</code></pre> <p>For example, assume that there are 100 validators in the active set, and one equivocates in a slot (for our purposes, it does not matter whether it was a BABE or GRANDPA equivocation). This is unlikely to be an attack on the network but much more likely to be a misconfiguration of a validator. The penalty would be min(3 * 1 / 100)^2, 1) = 0.0009, or a 0.09% slash for that validator (i.e., the stake held by the validator and its nominators).</p> <p>Now, assume that a group is running several validators, and they all have an issue in the same slot. The penalty would be min((3 * 5 / 100)^2, 1) = 0.0225, or a 2.25% slash. If 20 validators equivocate, this is a much more serious offense, possibly indicating a coordinated attack on the network. So, the slash will be much greater - min((3 * 20 / 100)^2, 1) = 0.36, or a 36% slash on all these validators and their nominators. All slashed validators will also be chilled.</p> <p>The example above shows the risk of nominating or running many validators in the active set. While rewards grow linearly (two validators will get you approximately twice as many staking rewards as one) slashing grows exponentially. A single validator equivocating causes a 0.09% slash, and two validators equivocating does not cause a 0.09 * 2 = 0.18% slash, but rather a 0.36% slash - 4x as much as the single validator.</p> <p>Validators may run their nodes on multiple machines to ensure they can still perform validation work if one of their nodes goes down. Still, validator operators should be cautious when setting these up. Equivocation is possible if they do not have good coordination in managing signing machines.</p>"},{"location":"learn/learn-offenses/#good-practices-to-avoid-slashing","title":"Good Practices to Avoid Slashing","text":"<p>The following are advised to node operators to ensure that they obtain pristine binaries or source code and to ensure the security of their node:</p> <ol> <li>Always download either source files or binaries from the official Parity repository</li> <li>Verify the hash of downloaded files.</li> <li>Use the W3F secure validator setup or adhere to its principles</li> <li>Ensure essential security items are checked, use a firewall, manage user access, use SSH     certificates</li> <li>Avoid using your server as a general-purpose system. Hosting a validator on your workstation or     one that hosts other services increases the risk of maleficence.</li> </ol> <p>Below are some examples of small equivocations that happened in the past.</p> Network Era Event Type Details Action Taken Polkadot 774 Small Equivocation The validator migrated servers and cloned the keystore folder. The on-chain event can be viewed here. The validator did not submit a request for the slash to be canceled. Kusama 3329 Small Equivocation The validator operated a test machine with cloned keys; the test machine was online at the same time as the primary, which resulted in a slash. Details can be found here. The validator requested a slash cancellation, but the council declined. Kusama 3995 Small Equivocation The validator noticed several errors, after which the client crashed, and a slash was applied. The validator recorded all events and opened GitHub issues to allow for technical opinions to be shared. Details can be found here. The validator requested to cancel the slash. The council approved the request as they believed the error was not operator-related."},{"location":"learn/learn-offenses/#slashing-across-eras","title":"Slashing Across Eras","text":"<p>There are three main difficulties to account for with slashing in NPoS:</p> <ul> <li>A nominator can nominate multiple validators and be slashed via any of them.</li> <li>Until slashed, the stake is reused from era to era. Nominating with N coins for E eras in a row   does not mean you have N*E coins to be slashed - you've only ever had N.</li> <li>Slashable offenses can be found after the fact and out of order.</li> </ul> <p>To balance this, the system applies only the maximum slash a participant can receive in a given time period rather than the sum. This ensures protection from overslashing.</p>"},{"location":"learn/learn-offenses/#disabling","title":"Disabling","text":"<p>Disabling stops validators from performing specific actions after they have committed an offense. Disabling is further divided into:</p> <ul> <li>On-chain disabling lasts for a whole era and stops validators from block authoring, backing, and   initiating a dispute.</li> <li>Off-chain disabling lasts for a session, is caused by losing a dispute, and stops validators from   initiating a dispute.</li> </ul> <p>Off-chain disabling is always a lower priority than on-chain disabling. Off-chain disabling prioritizes disabling first backers and then approval checkers.</p>"},{"location":"learn/learn-offenses/#reputation-changes","title":"Reputation Changes","text":"<p>Some minor offenses often connected to spamming are only punished by Networking Reputation Changes. When validators connect to each other, they use a reputation metric for each of their peers. If our peers provide valuable data and behave appropriately, the system adds reputation; if they provide us with faulty or spam data, the system reduces their reputation. A validator can lose enough reputation so that the peers will temporarily close their channels. This helps in fighting against DoS (Denial of Service) attacks. The consequences of closing channels may vary. In general, performing validator tasks under reduced reputation will be harder, resulting in lower validator rewards.</p>"},{"location":"learn/learn-parachains-faq/","title":"Parachains FAQ","text":"<p>     Parachain Slot Auctions and Crowdloans will be deprecated right after            Agile Coretime          is activated on the network. For existing parachains, the remainder of the lease will automatically be converted to coretime. See more information            here.      </p> \u2716"},{"location":"learn/learn-parachains-faq/#general","title":"General","text":""},{"location":"learn/learn-parachains-faq/#what-is-parachain-consensus","title":"What is \"parachain consensus\"?","text":"<p>\"Parachain consensus\" is special in that it will follow the relay chain. Parachains cannot use other consensus algorithms that provide their own finality. Only sovereign chains (that must bridge to the relay chain via a parachain) can control their own consensus. Parachains have control over how blocks are authored and by whom. The relay chain guarantees valid state transitions. Executing a block finality outside the context of the relay chain is outside the scope of trust that the relay chain provides.</p>"},{"location":"learn/learn-parachains-faq/#how-about-parachains-that-are-not-substrate-based","title":"How about parachains that are not Substrate-based?","text":"<p>Substrate provides FRAME Pallets as part of its framework to seamlessly build a rustic-based blockchain. Part of FRAME are pallets that can be used for consensus. Polkadot, being a Substrate-based chain, relies on BABE as the block production scheme and GRANDPA as the finality gadget as part of its consensus mechanism. Collectively, this is a Hybrid Consensus Model, where block production and block finality are separate. Parachains only need to produce blocks as they can rely on the relay chain to validate the state transitions. Thus, parachains can have their own block production where the collators act as the block producers, even if the parachain is not Substrate-based.</p>"},{"location":"learn/learn-parachains-faq/#is-100-a-hard-limit-on-the-number-of-parachains-that-can-be-supported","title":"Is 100 a hard limit on the number of Parachains that can be supported?","text":"<p>No. The network went through a significant number of optimizations, and there are several updates planned in the near future. The exact number of parachains that the relay chain can support without any degradation in performance is yet to be discovered. Also, with the blockspace over blockchains paradigm which brings on-demand parachains into the picture, there is no hard limit number on the number of blockchains that can be supported by the relay chain.</p>"},{"location":"learn/learn-parachains-faq/#what-happens-to-parachains-when-the-number-of-validators-drops-below-a-certain-threshold","title":"What happens to parachains when the number of validators drops below a certain threshold?","text":"<p>The minimal safe ratio of validators per parachain is 5:1. With a sufficiently large set of validators, the randomness of their distribution along with availability and validity will make sure security is on-par. However, should there be a big outage of a popular cloud provider or another network connectivity catastrophe, it is reasonable to expect that the number of validators per chain will drop.</p> <p>Depending on how many validators went offline, the outcome differs.</p> <p>If a few validators went offline, the parachains whose validator groups are too small to validate a block will skip those blocks. Their block production speed will slow down to an increment of six seconds until the situation is resolved and the optimal number of validators is in that parachain's validator group again.</p> <p>If anywhere from 30% to 50% of the validators go offline, availability will suffer because we need two-thirds of the validator set to back the parachain candidates. In other words, all parachains will stop until the situation is resolved. Finality will also stop, but low-value transactions on the relay chain should be safe enough to execute, despite common forks. Once the required number of validators are in the validator set again, parachains will resume block production.</p> <p>Given that collators are full nodes of the relay chain and the parachain they are running, they will be able to recognize a disruption as soon as it occurs and should stop producing block candidates. Likewise, it should be easy for them to recognize when it's safe to restart block production - perhaps based on finality delay, validator set size or some other factor that is yet to be decided within Cumulus.</p>"},{"location":"learn/learn-parachains-faq/#parachain-development-kits-pdks","title":"Parachain Development Kits (PDKs)","text":"<p>Parachain Development Kits are a set of tools that enable developers to create their own applications as parachains. For more information, see the PDK content](../build/build-parachains.md#parachain-development-kit-pdk) and Parachain Development page.</p>"},{"location":"learn/learn-parachains-faq/#security","title":"Security","text":""},{"location":"learn/learn-parachains-faq/#is-security-correlated-to-the-number-of-validators-what-about-the-number-of-parachains","title":"Is security correlated to the number of validators? What about the number of parachains?","text":"<p>Security is independent of the number of parachains that are connected to the Polkadot relay chain. The correlation of security and the number of validators exists as the higher number of validators will give the network stronger decentralization properties and make it harder to try to take down. However, the biggest indicator of the security of the network is the economic signal of the number of DOT that are bonded and staked. The greater the number of DOT staked by honest validators and nominators, the higher the minimum amount of DOT an attacker would need to acquire a validator slot.</p>"},{"location":"learn/learn-parachains-faq/#in-what-scenarios-do-parachains-need-their-own-security","title":"In what scenarios do parachains need their own security?","text":"<p>Most parachains will not need to worry about their own security, since all state transitions will be secured by the Polkadot relay chain validator set. However, in some cases (which are considered more experimental), parachains may require their own security. In general, these cases will revolve around lack of data available to relay chain validators.</p> <p>One example is if the state transition function is some succinct or zero-knowledge proof, the parachain would be responsible for keeping its data available as the relay chain won't have it. Additionally, for chains with their own consensus, like the one that enables fast payments on Blink Network, there would probably need to be a Byzantine agreement between stakers before a parachain block is valid. The agreement would be necessary because the data associated with the fast consensus would be unknown to relay chain validators.</p>"},{"location":"learn/learn-parachains-protocol/","title":"Security Protocol Overview","text":"<p>Info</p> <p>This page is a summary of the Protocol Overview chapter in The Polkadot Parachain Host Implementer's Guide and the Availability and Validity (AnV) chapter in The Polkadot Protocol Specification.</p> <p>The Parachains' Protocol aims to carry a parachain's block from authoring to inclusion through a process that can be carried out repeatedly and in parallel for each parachain connected to the Relay Chain. The protocol allows the network to be efficiently sharded among parachains while maintaining strong security guarantees. The Availability and Validity (AnV) Protocol describes the Parachain Protocol from the perspective of availability and validity. on).</p>"},{"location":"learn/learn-parachains-protocol/#main-actors","title":"Main Actors","text":""},{"location":"learn/learn-parachains-protocol/#validators","title":"Validators","text":"<p>They are responsible for validating the proposed parachain's blocks by checking the Proof-of-Validity (PoV) of the blocks and ensuring the PoV remains available for a designated period. They have \"skin in the game\", meaning they have funds bonded on-chain that can be partially or fully confiscated by the network in case of misbehavior.</p>"},{"location":"learn/learn-parachains-protocol/#collators","title":"Collators","text":"<p>They create the PoV that validators know how to check. Creating PoV requires familiarity with transaction format and block authoring rules of a specific parachain, as well as having access to its full state.</p>"},{"location":"learn/learn-parachains-protocol/#fishermen-deprecated","title":"Fishermen: Deprecated","text":"<p>Fishermen are not planned for formal implementation, despite previous proposals in the AnV protocol.</p> <p>The idea behind Fishermen is that they are full nodes of parachains, like collators, but perform a different role in relation to the network. Instead of packaging the state transitions and producing the next parachain blocks as collators do, fishermen will watch this process and ensure no invalid state transitions are included.</p> <p>To address the motivation behind the Fishermen design consideration, the current secondary backing checkers perform a similar role in relation to the network. From a security standpoint, security is based on having at least one honest validator either among parachain validators or secondary checker (more about this later on).</p>"},{"location":"learn/learn-parachains-protocol/#protocols-summary","title":"Protocols' Summary","text":""},{"location":"learn/learn-parachains-protocol/#parachain-protocol","title":"Parachain Protocol","text":"<p>The parachain protocol is divided into two main phases:</p> <ul> <li>Inclusion Pipeline: Collators send parachain blocks (parablocks) with   PoV to Validators. Validators verify if the parablocks follow the state transition rules of the   parachain and sign statements that can have a positive or negative outcome. With enough positive   statements, the block is backed and included in the relay chain, but is still pending   approval.</li> <li>Approval Process: Validators perform additional checks that, if positive,   allow the parablock to be approved.</li> </ul> <p>The figure below shows a representation of a parachain with collators and validators. The figure also shows the journey of a parachain block (white square) through the Inclusion Pipeline and the Approval Process.</p> <p></p>"},{"location":"learn/learn-parachains-protocol/#availability-and-validity-anv-protocol","title":"Availability and Validity (AnV) Protocol","text":"<p>The Availability and Validity (AnV) Protocol is a way of looking at the Parachain Protocol from another perspective, emphasizing the importance of a parablock being available and valid before being included in the finalized relay chain. It is divided into five different phases, three within the Inclusion Pipeline and two within the Approval Process:</p> <ul> <li>Inclusion Pipeline   1.  Parachain phase   2.  Relay chain submission phase   3.  Availability and unavailability phase</li> <li>Approval Process   1.  Assignments and secondary (validity) checks   2.  Chain Selection</li> </ul> <p>In the Inclusion Pipeline, a parablock is made available (or unavailable), while in the Approval Process a parablock is checked if it is valid or not.</p>"},{"location":"learn/learn-parachains-protocol/#inclusion-pipeline","title":"Inclusion Pipeline","text":""},{"location":"learn/learn-parachains-protocol/#overview","title":"Overview","text":"<p>The inclusion pipeline is the path of a parachain block (or parablock) from its creation to its inclusion into the non-finalized relay chain (i.e. in a fork of the relay chain).</p> <p></p> <p>The figure above shows the path of a candidate block through the Inclusion pipeline. The block changes its status through this path as follows:</p> <ul> <li>Candidate: A block with its PoV is put forward by a collator to a para-validator (in this case   V1). The candidate block is shown as a white square with one white tick mark at the side (PoV from   the collator). Note the candidate is not valid yet and can still fail to be included in the Relay   Chain.</li> <li>Seconded: The block is put forward by the para-validator V1 to other para-validators (in this case   V2 and V3). The seconded block is shown as a white square with a white tick mark and a yellow tick   mark on top of it. The yellow mark show the PoV from para-validator V1.</li> <li>Backable: The block validity is attested by a majority of the para-validators. The backable block   is shown as white square with a white tick mark and three yellow tick marks on top of it. The   yellow marks show the PoV from the para-validators, while the white mark the PoV from the   collator.</li> <li>Backed: The block is backed and noted in a fork on the relay chain by a relay chain block author   (in this case V4). The backed block is shown as a square with white background and yellow border   enclosing a \"B\". The backed block can still fail to be included in the relay chain. Note that for   simplicity here the backed parachain block is represented within the relay chain block, but in   reality a relay chain block does not contain the parablocks themselves (more about this later).</li> <li>Pending availability: The block is backed but not considered available yet.</li> <li>Included: The block is backed and considered available (we have a parablock). Included parablocks   are shown as square with white background and yellow border enclosing an \"I\".</li> </ul> <p>Asynchronous Backing</p> <p>Parablocks' backing and inclusion take 12 seconds to be recorded on the relay chain, i.e. backing happens in one relay chain block (6 seconds) and inclusion in another relay chain block (additional 6 seconds, see Figure above). With asynchronous backing, backing and inclusion can be recorded in just one relay chain block.</p>"},{"location":"learn/learn-parachains-protocol/#parachain-phase","title":"Parachain Phase","text":"<p>In the parachain phase, some validators are assigned to parachains by the Validator Assignment Routine (these validators are called para-validators). Para-validators establish a connection with collators, which propose candidate blocks together with Proof-of-Validity (PoV) to para-validators via the Collator Distribution Subsystem.</p> <p>Para-validators participate in the Candidate Backing Subsystem. A para-validator needs to check if the candidate block follows the state transition rules of the parachain. Because states are stored within Merkle trees, a para-validator can verify state transitions without having access to the entire state, but it needs:</p> <ul> <li>The block candidate (list of state transitions)</li> <li>The values in the parachain's database that the block modifies</li> <li>The hashes of the unaffected points in the Merkle tree</li> </ul> <p>This set of information is the proof-of-validity (PoV).</p> <p>Once a para-validator has the PoV, it gossips this information to the other para-validators, who check the candidate block against the PoV. Candidates that gather more than half of signed validity statements are considered backable (i.e. they seem to represent a valid state transition), and their backing is the set of signed statements. The para-validators can then start to construct the candidate receipt (this is what goes into the relay chain block) and an erasure coding (this is what will make the parablock available, more on this later on) that will be sent to all validators in the network.</p> <p>Polkadot guarantees valid state transitions, not valid states</p> <p>Validators do not inspect every value in a parachain's state, only those that are modified. This insures that the modification is valid.</p> <p>Previously, we said that backable blocks seem to represent valid state transitions because para-validators are a small subset of all validators. Thus, it is possible to have the majority of them dishonest. Later on, we will see that more validators with come in to help to make sure the parablock is fully valid.</p>"},{"location":"learn/learn-parachains-protocol/#relay-chain-submission-phase","title":"Relay Chain Submission Phase","text":"<p>The receipt of the backable parablock is added to the relay chain transaction queue together with other receipts from other parachains. Receipts are gossiped around, and when a relay chain block author wins BABE slot leadership, it will select a candidate receipt to include in a block on a fork of the relay chain.</p> <p>A block author can note up to 1 backable candidate for each parachain to be included in the Relay Chain block alongside its backing. Once included in a fork of the relay chain the candidate is considered backed in that fork. The candidate is considered to be in \"pending availability\" status, and it can only be considered a part of the parachain once proven available. Remember, at this stage validators of the relay chain already received the erasure coding information of that specific parablock.</p>"},{"location":"learn/learn-parachains-protocol/#availability-and-unavailability-phase","title":"Availability and Unavailability Phase","text":"<p>During the availability and unavailability phases, the validators will participate to Availability Distribution Subsystem to ensure availability of the candidate. They gossip the erasure coded pieces among the network. At least \u2153 + 1 validators must report that they possess their piece of the code word. Once this threshold of validators has been reached, the network can consider the candidate block available. The block is graduated to being a full parachain block, and its header will be included in that fork of the relay chain. The information about the candidate availability is noted in the subsequent relay chain blocks of that fork.</p> <p>The availability check by the block author ensures that the relay chain will only include blocks for which the validators distributed their erasure-coded chunks, but it does not guarantee their validity. Because the number of para-validators on each parachain is so low, collusion is a reasonable concern. By separating block production (BABE) from finality (GRANDPA), validators can perform extra validity checks after a block is produced but before it is finalized.</p> <p>Thus, once the parablock is considered available and part of the parachain, it is still \"pending approval\". The Inclusion Pipeline must conclude for a specific parachain before a new block can be accepted on that parachain. After inclusion, the Approval Process starts and it makes sure the block is valid, and it can run for many parachain blocks at once.</p> <p>Data Availability - Erasure Codes of Parachain Blocks and PoVs</p> <p>The erasure code chunks necessary for reconstructing parachain blocks and their respective Proofs-of-Validity (PoV) are stored on the relay chain validator\u2019s hardware (disk) and made available to the relay chain network for up to 24 hours. It is important to note that this data is neither stored within the relay chain blocks nor in the chain state. Only the root of those chunks is embedded within the candidate receipt and is stored in the relay chain blocks.</p>"},{"location":"learn/learn-parachains-protocol/#failure-to-inclusion","title":"Failure to Inclusion","text":"<p>The candidate can fail to be included in the parachain in any of the following ways:</p> <ul> <li>The collator cannot propagate the block to any of the assigned validators.</li> <li>The candidate is not backed by validators participating in the Candidate Backing subsystem.</li> <li>A relay chain block author does not select the candidate.</li> <li>The candidate's PoV is not considered available within a timeout, and the block is discarded from   the relay chain.</li> </ul>"},{"location":"learn/learn-parachains-protocol/#approval-process","title":"Approval Process","text":""},{"location":"learn/learn-parachains-protocol/#overview_1","title":"Overview","text":"<p>Once the parablock is considered available and part of the parachain, it is still \"pending approval\". At this stage, the parablock is tentatively included in the parachain, although more confirmation is necessary. The validators assigned to the parachain (i.e. the parachain validators) are sampled from a validator set assumed to be \u2153 dishonest in the worst-case scenario. In this case, it is likely that the majority of the random para-validators sampled for a specific parachain are dishonest and can back a candidate wrongly. To address this, the Approval Process allows detecting misbehavior after the fact without allocating more para-validators, which would ultimately reduce the system's throughput. As a parablock can accept children blocks after being considered available, failure to pass the approval process will invalidate the parablock and its descendants (children blocks). Only the validators who backed the block in question will be slashed, not those who backed the descendants.</p> <p>The approval pipeline can be divided into the following steps:</p> <ol> <li>Parablocks included by the Inclusion Pipeline are pending approval for a time window known as the    secondary checking window.</li> <li>During the secondary checking window, validators (secondary checkers) randomly self-select based    on a VRF lottery to perform secondary checks on each of the    parablock.</li> <li>Secondary checkers acquire the parablock with PoV (erasure codings are necessary to reconstruct    PoV) and re-run the validation function.</li> <li>Secondary checkers gossip about the results of their checks. Contradictory results lead to an    escalation in which all validators must check the block. The validators on the losing side will    be slashed.</li> <li>At the end of the process the parablock is either approved or rejected.</li> </ol> <p>The figure below shows the path of a parachain block when it exits the Inclusion Pipeline, and enters the Approval Process. The parablock becomes accepted when it is backed, available and undisputed. The parablock is checked a second time by a subset of validators (V5, V6 and V7), and if there are no contradictory results the block is approved and gossiped to other relay chain validators. Note the parablock after secondary checks is shown as a square with a white background a yellow border enclosing an \"I\" (stands for included), and three white ticks (one for each secondary check). Approved para-blocks are shown as yellow squares.</p> <p></p>"},{"location":"learn/learn-parachains-protocol/#assignments-secondary-checks","title":"Assignments &amp; Secondary Checks","text":"<p>Having a bad parablock on a fork of the relay chain is not catastrophic as long as the block is not approved and finalized by the finality gadget GRANDPA. If the block is not finalized, the fork on the chain containing that block can be ignored in favor of another fork containing good blocks. Dealing with a bad parablock includes the following stages:</p> <ul> <li>Detection: the bad block must be detected by honest validators.</li> <li>Escalation: the honest validators must start a dispute.</li> <li>Consequences: the backer for that parablock is slashed.</li> </ul> <p>The result of the dispute must be transplantable to all other forks so that malicious validators are slashed in all possible histories and so that honest validators will ignore any forks containing that parablock.</p> <p>Parablocks vs. relay chain Blocks</p> <p>It is important to understand that a relay chain block does not contain parablocks, but para-headers. Parachain blocks are within the parachain. Thus, it makes more sense to think of relay chain blocks as having been approved instead of parablocks that have been approved. A relay chain block containing information about approved parablocks can be considered approved as long as its parent relay chain block is also approved. Thus, the validity of a relay chain block depends on the validity of its ancestry.</p> <p>Validators perform two main actions in the Approval Process:</p> <ul> <li>Assignments   determine which validators perform approval checks on which candidates, ensuring each candidate   receives enough random checkers. This stage tracks approval votes to identify when   no-show approval   checks take suspiciously long. It also tracks relay chain   equivocations to determine when adversaries   possibly gained foreknowledge about assignments and add more checks in those cases. Assignees   determine their own assignments to check specific candidates using two or three   assignment criteria,   which are based on two possible   stories about the   relay chain block that included the candidate (i.e. declared the candidate available).   Assignment notices   are gossiped among nodes so that all validators know which validators should check which   candidates, and if any candidate requires more checkers.</li> <li>Approval checks perform the checks by obtaining the candidate, verifying its validity, sending   out the approval vote, or initiating a dispute. Approval checks have a no-show timeout window   (i.e. longer than one relay chain slot) to succeed in reconstructing the candidate block, redo its   erasure coding to check the candidate receipt, and recheck the candidate block itself. A validator   becomes tagged as a no-show if it does not approve or dispute within the no-show timeout window.   Because validators can be overloaded with assignments, they can intentionally delay sending their   assignment notice to avoid creating no-shows (see more in   Assignment postponement).</li> </ul> <p>These two steps first run as off-chain consensus protocols using messages gossiped among all validators, and then as on-chain record of those protocols' progress. The on-chain protocol is needed to provide rewards for the off-chain protocol. The on-chain verification has two phases: a) assignments notices and approval votes are recorded in a relay chain block, and b) in another relay chain block notes are fed into the approval code.</p> <p>The gossiped messages are of two types, assignment notices, and approval votes, and are signed with approval keys. Such keys are part of the session keys used by validators. Briefly, approval keys are:</p> <ul> <li>Approval assignment keys that are sr25519 keys used only for assignment criteria   VRF.</li> <li>Approval vote keys that are ed25519 and would only sign off on a candidate parablock validity.</li> </ul> <p>Info</p> <p>For detailed information about the approval process, see dedicated section in The Polkadot Parachain Host Implementers' Guide.</p> <p>Accepting a parablock is the result of having passed through the detection stage without dispute, or having passed through and escalation/dispute stage with a positive outcome.</p>"},{"location":"learn/learn-parachains-protocol/#chain-selection","title":"Chain Selection","text":"<p>After enough secondary checks have been performed on all candidate receipts within a block, validators can vote for that block (and all previous blocks) in GRANDPA. Once the block has more than \u2154 of positive votes, the block is finalized on chain.</p> <p>Chain selection is used to select blocks to build on and finalize. These processes need to consistent among nodes and resilient to a maximum proportion of malicious nodes. The parachain host uses a block authoring system and a finality gadget. The chain selection strategy involves a leaf-selection rule and a set of finality constraints.</p> <p>Info</p> <p>For detailed information about chain selection, see dedicated section in The Polkadot Parachain Host Implementers' Guide.</p>"},{"location":"learn/learn-parachains-protocol/#candidate-receipts","title":"Candidate Receipts","text":"<p>PoV are typically between 1 MB and 10 MB in size and are not included in the relay chain blocks. For Polkadot to scale to hundreds of parachains, PoV need to be represented by something smaller on the relay chain: candidate receipts. A para-validator constructs a candidate receipt for a parachain block by signing:</p> <ul> <li>The parachain ID.</li> <li>The collator's ID and signature.</li> <li>A hash of the parent block's candidate receipt.</li> <li>A Merkle root of the block's erasure-coded pieces.</li> <li>A Merkle root of any outgoing messages.</li> <li>A hash of the block.</li> <li>The state root of the parachain before block execution.</li> <li>The state root of the parachain after block execution.</li> </ul> <p>This information is of constant size, while the actual PoV block of the parachain can be variable length. It is enough information for anyone that obtains the full PoV block to verify the state transition contained inside of it.</p>"},{"location":"learn/learn-parachains-protocol/#erasure-codes","title":"Erasure Codes","text":"<p>Before sending the candidate receipt to the relay chain transaction queue, the para-validator who constructs the receipt must also construct an erasure coding of the parachain block.</p> <p>An erasure coding takes a message (in this case, the parachain block and PoV) and creates a set of smaller messages such that you can reconstruct the original message by obtaining a fraction of the smaller messages. In the case of Polkadot, the total number of smaller messages is equal to the total number of validators and the fraction is \u2153.</p> <p>The para-validator creates the erasure coding chunks, puts them into their Merkle tree, and sends out each chunk (together with the candidate receipt) to a corresponding validator on the Relay Chain. Validators who receive the receipts with an erasure coding chunk will include the receipt in the relay chain queue, where an author can include it in a block.</p> <p>The type of erasure codes used by Polkadot's availability scheme are Reed-Solomon codes, which already enjoy a battle-tested application in technology outside the blockchain industry. One example is found in the compact disk industry. CDs use Reed-Solomon codes to correct any missing data due to inconsistencies on the disk face such as dust particles or scratches.</p> <p>In Polkadot, the erasure codes are used to keep parachain state available to the system without requiring all validators to keep tabs on all the parachains. Instead, validators share smaller pieces of the data and can later reconstruct the entire data under the assumption that \u2153+1 of the validators can provide their pieces of the data.</p> <p>!!!note The \u2153+1 threshold of validators that must be responsive to construct the full parachain state data corresponds to Polkadot's security assumption about Byzantine nodes.</p>"},{"location":"learn/learn-parachains-protocol/#disputes","title":"Disputes","text":"<p>All parachain blocks that are in the finalized relay chain should be valid. This does not apply to backed blocks that are not included. To ensure nothing invalid ends up in the finalized relay chain, there are approval checks (described above) and disputes. The latter ensures that each attempt to include something invalid is caught and the offending validators are punished.</p> <p>False positives can happen; those actors responsible for it will be slashed. To detect false positives, PoV information must be available after the block has been included to the relay chain via the availability scheme.</p> <p>Disputes are independent from a particular fork, while backing and approval operate on particular forks. The approval voting stops if an alternative fork (which might not contain the currently-approved candidate) is finalized. The sole purpose of the approval process is to make sure invalid blocks are not finalized. However, even though the danger is past and the offending validators did not manage to get the invalid block approved, those validators need to get slashed for the attempt.</p> <p>A dispute stems from a disagreement between two or more validators. For this to happen, a bad actor needs to distribute an invalid block to honest validators. Scenarios leading to a dispute can be one of the followings (ordered from most to least important):</p> <ul> <li>A parablock included on a branch of the relay chain is bad</li> <li>A parablock backed on a branch of the relay chain is bad</li> <li>A parablock seconded, but not backed on any branch of the relay chain, is bad</li> </ul> <p>Checking a parachain block requires three pieces of data: the parachain validator code, the availability of data, and the candidate receipt. The validator code is available on-chain and published ahead of time. Thus, a dispute process begins with the availability to ensure the availability of the data. Such a process will conclude quickly if the data is already available, otherwise, the initiator of the dispute must make it available.</p> <p>Disputes have both off- and on-chain components. Slashing is handled on-chain, so votes by validators on either side of the dispute must be placed on-chain. Moreover, a dispute on one branch of the chain must be transposed to all active branches so that misbehavior can be punished in all possible histories. There is, thus, a distinction between local (the one we are looking at) and remote disputes relative to a particular branch of the relay chain.</p> <p>Disputes can be divided into three different phases:</p> <ul> <li>Dispute initiation:   Disputes are initiated by any validator who finds their opinion on the validity of a parablock in   opposition to another issued statement. The initiation begins off-chain by only nodes perceiving   that a parablock is bad. The validator can be one of the para-validators (i.e. one of the backers)   or one of the approval checkers. Note that if the dispute occurs during the backing phase, the   initiator must make the data available while if the dispute occurs during the approval process the   data is already available.</li> <li>Dispute participation:   Once becoming aware of the dispute, all validators must participate.</li> <li>Dispute conclusion:   Disputes conclude after a \u2154 supermajority is reached on either side. Disputes may also conclude   after a timeout. This will only happen if the majority of validators are unable to vote for some   reason.</li> </ul> <p>The on-chain component of the dispute can be initiated by providing any two conflicting votes and it also waits for a \u2154 supermajority on either side. The component also tracks which parablocks have already been disputed so that the same parablock can be disputed only once on any branch of the relay chain. Inclusion is halted for the parachain until the dispute resolves.</p> <p>Info</p> <p>For detailed information about disputes, see dedicated section in The Polkadot Parachain Host Implementers' Guide. In the Guide, there are also more details about disputes' flows.</p>"},{"location":"learn/learn-parachains-protocol/#network-asynchrony","title":"Network Asynchrony","text":"<p>We have mentioned how a relay chain block author must select the candidate and note it on the Relay Chain (we say the block is backed). The relay chain block author is selected by BABE, which is a forkful algorithm. This means that different block authors are chosen at the same time, and they may not work on the same block parent (i.e. the representations in the previous figures are simplistic). Also, the sets of validators and parachains are not fixed, and the validators' assignments to parachains is also flexible.</p> <p>We say that the network is asynchronous since there will be validators who have received a block and other validators who did not. Thus, the network is variable, and it exists in multiple states. In the figure below (left), Group 1 received block C while Group 2 did not due to network asynchrony. Validators in Group 2 can build another block on top of B, called C'. Assume that afterward, some validators become aware of both C and C' while others remain aware of one of them (right). Validators in Group 3 must be aware of the network state in each head (C and C\u2019), and they may contribute to some or full extent on both. It is possible that due to network asynchrony, two forks may grow in parallel for some time, but eventually, one fork will be chosen by the finality gadget. In the absence of an adversarial network, it is unlikely that two forks will coexist for some time as there will be validators aware of both chain heads.</p> <p></p>"},{"location":"learn/learn-parachains-protocol/#further-resources","title":"Further Resources","text":"<ul> <li>Path of a Parachain Block - Article by   Parity analyst Joe Petrowski expounds on the validity checks that a parachain block must pass in   order to progress the parachain.</li> <li>Availability and Validity -   Paper by the W3F Research Team that specifies the availability and validity protocol in detail.</li> </ul>"},{"location":"learn/learn-parachains/","title":"Parachains","text":"<p>        Agile Coretime           is activated on the network, and parachain slot auctions and crowdloans have been deprecated. For existing parachains, the remainder of the lease is automatically converted to coretime. See more information            here.          For decentralized, transparent, and regulatory-compliant fundraising within the ecosystem, check out the            Polimec parachain.      </p> \u2716 <p>Testing on Paseo</p> <p>For information on how to test coretime functionalities on Paseo, please see the Paseo Content on the parachain development guide.</p>"},{"location":"learn/learn-parachains/#definition-of-a-parachain","title":"Definition of a Parachain","text":"<p>A parachain is an application-specific data structure that is globally coherent and can be validated by the validators of the relay chain. They take their name from the concept of parallelized chains that run parallel to the relay chain. Most commonly, a parachain will take the form of a blockchain, but there is no specific need for them to be actual blockchains.</p> <p></p> <p>Due to their parallel nature, they can parallelize transaction processing and achieve scalability of the protocol. They inherit the security of the entire network and can communicate with other parachains through the XCM format.</p> <p>Parachains are maintained by a network maintainer known as a collator. The role of the collator node is to maintain a full node of the parachain, retain all necessary information about the parachain, and produce new block candidates to pass to the relay chain validators for verification and inclusion in the shared state. The incentivization of a collator node is an implementation detail of the parachain. They are not required to be staked on the relay chain or own the native token unless stipulated by the parachain implementation.</p>"},{"location":"learn/learn-parachains/#state-transitions","title":"State Transitions","text":"<p>Like other blockchains, parachains are deterministic state machines. Each parachain has a state, executes a batch of transactions grouped into a block, and achieves a new state. Joe Petrowski provided in this article a good analogy of a state with a light switch that can be either on or off, which is one of the simplest examples of how a state machine functions. Each parachain has its own state, and the Relay Chain links all those states into one state, i.e. a state of states. A multi-chain network like Polkadot can be viewed like one computer's state with many light switches where a state transition function is the logic to decide which switches should be toggled. Parachains have their own transition rule, separate economies, governance mechanisms, and users.</p> <p>A parachain's state is stored in a Merkle tree. Merkle trees have the convenient property that if some values within the tree change, this will be reflected in the Merkle root (in this case, the state root). One can verify the change by only looking at the new values and the paths that are affected within the tree.</p> <p>The Polkadot Host requires that the state transitions performed on parachains be specified as a Wasm executable. Proofs of new state transitions that occur on a parachain must be validated against the registered state transition function (STF) that is stored on the relay chain by the validators before the relay chain acknowledges a state transition has occurred on a parachain. The key constraint regarding the logic of a parachain is that it must be verifiable by the relay chain validators. Verification most commonly takes the form of a bundled proof of a state transition known as a Proof-of-Verification (PoV) block, which is submitted for checking to the validators from one or more parachain collators.</p>"},{"location":"learn/learn-parachains/#why-parachains","title":"Why Parachains?","text":"<p>Parachains are a solution to two fundamental problems in blockchains:</p> <ul> <li>Scalability: Having one blockchain for many purposes makes it difficult to scale as future   implementations and upgrades will likely advantage some purposes and disadvantage others.   Conversely, having different blockchains will allow them to implement features without affecting   other chains.</li> <li>Flexibility: It is reasonable to state a blockchain will either be really good at solving one   problem or not so good at trying to solve many problems. A blockchain specializing in solving a   specific problem has more leverage toward itself and its users. Parachains are purpose-built   blockchains are highly specialized and can take advantage of each other through cooperation.</li> </ul>"},{"location":"learn/learn-parachains/#parachain-benefits","title":"Parachain Benefits","text":"<p>Parachains contain their own runtime/STF logic and benefit from the shared security and the cross-consensus messaging provided by the relay chain. Parachains permit high flexibility and customization but require more effort to create and maintain over time. A production-grade parachain is typically more involved to create due to the complexity involved in blockchain networks' technical and economic aspects.</p> <p>Parachains grant the creators more space to build the monetary system and other chain aspects from the ground up. They will allow for a more concise and efficient execution of complex logic than a smart contract platform could offer. Parachains also provide more flexibility in the form of governance and can perform complete upgrades in a less controversial way than the current process of hard forks.</p> <p>Some examples of features you can have on a parachain or parathread:</p> <ul> <li>Custom fee structure (for example, pay a flat transaction fee or pay per byte).</li> <li>Shared security and finalization via the relay chain (Polkadot or Kusama).</li> <li>Custom monetary policy for the native token and local economy.</li> <li>Treasury to be funded through transitions in your state function.</li> <li>A governance mechanism that could manage a DAO that is responsible for allocating your on-chain   treasury.</li> </ul>"},{"location":"learn/learn-parachains/#shared-security","title":"Shared Security","text":"<p>Shared security, sometimes referred as pooled security, is one of the unique value propositions for chains considering becoming a parachain and joining the network. On a high level, shared security means that all parachains that are connected to the relay chain by accessing a core will benefit from the economic security provided by the relay chain validators.</p> <p>The notion of shared security is different from inter-chain protocols that build on an architecture of bridges. For bridge protocols, each chain is considered sovereign and must maintain its own validator set and economic security. One concern in these protocols is the point of scalability of security. For example, one suggestion to scale blockchains is that of scale by altcoins, which suggests that transaction volumes will filter down to lower market cap altcoins as the bigger ones fill their blocks. A major flaw in this idea is that the lower market cap coins will have less economic security attached and be easier to attack. A real-life example of a 51% attack occurred recently ( Ethereum Classic attack on January 10, 2019 ), in which an unknown attacker double spent 219_500 ETC (~1.1 million USD). This was followed by two more 51% attacks on ETC.</p> <p>Polkadot overcomes security scalability concerns since it gravitates all the economic incentives to the relay chain and allows the parachains to tap into stronger guarantees at genesis. Sovereign chains must expend much more effort to grow the value of their coin so that it is sufficiently secure against well-funded attackers.</p>"},{"location":"learn/learn-parachains/#pow-vs-parachain-model","title":"PoW vs Parachain Model","text":"<p>Let's compare the standard sovereign security model that exists on current proof-of-work (PoW) chains to Polkadot's shared security model. Bitcoin, Zcash, and their derivatives, must bootstrap their independent network of miners and maintain a competitive portion of honest hashing power. Since mining is becoming a larger industry that increasingly centralizes key players, it is becoming more real that a single actor may control enough hash power to attack a chain.</p> <p>This means that smaller chains that cannot maintain a secure amount of hash power on their networks could potentially be attacked by a large mining cartel at the simple whim of redirecting its hash power away from Bitcoin and toward a new and less secure chain. 51% attacks are viable today with attacks having been reported on Ethereum Classic (see above), Verge, Bitcoin Gold, and other cryptocurrencies.</p> <p>On Polkadot, this disparity between chain security will not be present. When a parachain connects to the relay chain, validators become the securers of that parachain's state transitions. The parachain will only have the overhead of running a few collator nodes to keep the validators informed with the latest state transitions and proofs/witness. Validators will then check these for the parachains to which they are assigned. In this way, new parachains instantly benefit from the overall security provided by the relay chain even if they have just been launched.</p>"},{"location":"learn/learn-parachains/#parachain-economies","title":"Parachain Economies","text":"<p>Parachains may have their economies with their native tokens. Schemes such as Proof-of-Stake are usually used to select the validator set to handle validation and finalization; parachains will not be required to do either of those things. However, since Polkadot is not overly particular about what the parachain can implement, it may be the choice of the parachain to implement a staking token, but it's not generally necessary.</p> <p>Collators may be incentivized through the inflation of a native parachain token. There may be other ways to incentivize the collator nodes that do not involve inflating the native parachain token.</p> <p>Transaction fees in a native parachain token can also be an implementation choice of parachains. Polkadot makes no hard and fast rules for how the parachains decide on the original validity of transactions. For example, a parachain may be implemented so that transactions must pay a minimum fee to collators to be valid. The relay chain will enforce this validity. Similarly, a parachain could not include that in their implementation, and the relay chain would still enforce its validity.</p> <p>Parachains are not required to have their token. If they do, it is up to the parachain (and not the relay chain) to make the economic case for their token.</p>"},{"location":"learn/learn-parachains/#coretime","title":"Coretime","text":"<p>Parachains can access the relay chain via cores.</p> <p>There are two ways to allocate relay chain cores:</p> <ul> <li>Via Governance only to system chains.</li> <li>Via coretime purchase with DOT (KSM on Kusama) for non-system chains.   Coretime is used to rent computation time on a relay chain core. This is the only way to access   Polkadot's shared security and interoperability.</li> </ul> <p>System parachains are allocated by Polkadot's on-chain governance and are part of the network's protocol, such as bridges to other networks or chains. These typically do not have an economic model and help remove transactions from the relay chain, allowing for more efficient parachain processing.</p> <p>Non-system chains can access the relay chain's cores via bulk or on-demand coretime purchased with DOT (or KSM on Kusama).</p>"},{"location":"learn/learn-parachains/#coretime-expiration","title":"Coretime Expiration","text":"<p>The DOT (or KSM on Kusama) used to purchase coretime are burned. Before the coretime expires, parachains can renew it at a fixed cost through a bulk coretime purchase. If the parachain does not purchase bulk coretime, it has an option to purchase coretime on-demand (at a variable price per block, depending on the demand and other market conditions) when they need to access the relay chain. Parachains without coretime to extend time on a relay chain core will be deprecated to the status of a parathread (i.e., a chain with a registered <code>ParaID</code> but without access to a core).</p>"},{"location":"learn/learn-parachains/#system-parachains","title":"System Parachains","text":"<p>System parachains are parachains that use execution cores allocated by the network's governance. These chains remove transactions from the relay chain, allowing network validators to allocate resources to validating parachains. System chains are Polkadot using its scaling technology to host itself.</p>"},{"location":"learn/learn-parachains/#on-demand-parachains","title":"On-demand Parachains","text":"<p>On-demand parachains were previously named parathreads</p> <p>On-demand parachains (previously called parathreads) are parachains that acquire on-demand coretime.</p> <p>On-demand parachains temporarily participate (on a block by block basis) in network security without needing to lease a dedicated relay chain core. This is done through economically sharing the scarce resource of a core among several competing resources (parachains). Chains that otherwise would not be able to acquire a full core or do not find it economically sensible to do so, can participate in shared security, as the on-demand coretime offers a graceful off-ramp to parachains that no longer require a dedicated core, but would like to continue using the relay chain.</p>"},{"location":"learn/learn-parachains/#historical-context-of-on-demand-parachains","title":"Historical Context of On-demand parachains","text":"<p>According to this talk in Chengdu back in 2019, the origin of the idea for on-demand parachains came from similar notions in the limited resource of memory on early personal computers of the late '80s and '90s. Since computers have a limited amount of physical memory, when an application needs more, the computer can create virtual memory by using swap space on a hard disk. Swap space allows the capacity of a computer's memory to expand and for more processes to run concurrently with the trade-off that some processes will take longer to progress.</p>"},{"location":"learn/learn-parachains/#parachains-vs-on-demand-parachains","title":"Parachains vs. On-demand Parachains","text":"<p>Parachains and on-demand parachains are very similar from a development perspective. One can imagine that a chain developed with Substrate can at different points in its lifetime assume one of three states:</p> <ul> <li>an independent chain with secured bridge,</li> <li>a parachain continuously connected to the relay chain,</li> <li>or a parachain intermittently connected to the relay chain (i.e. on-demand)</li> </ul> <p>It can switch between these states with relatively minimal effort since the difference is more of an economic distinction than a technological one.</p> <p>On-demand parachains have the exact same benefits for connecting to the relay chain that a full parachain has. Namely, it is able to send messages to other para-objects through XCMP and it is secured under the full economic security of the relay chain validator set.</p>"},{"location":"learn/learn-parachains/#parachains-use-cases","title":"Parachains' Use Cases","text":"<p>Note that we still have to see the true potential of parachains and what it is listed below are just a few examples.</p> <ul> <li>Encrypted Consortium Chains: These are possibly private chains that do not leak any   information to the public but still can be interacted with trustlessly due to the nature of the   XCMP protocol.</li> <li>High-Frequency Chains: These chains can compute many transactions in a short amount of time by   taking certain trade-offs or making optimizations.</li> <li>Privacy Chains: These chains do not leak any information to the public through novel   cryptography.</li> <li>Smart Contract Chains: These chains can have additional logic implemented through the   deployment of code known as smart contracts.</li> </ul>"},{"location":"learn/learn-parachains/#parachain-host","title":"Parachain Host","text":"<p>A blockchain is a Directed Acyclic Graph (DAG) of state transitions, where every added block can be viewed as the head of the chain or fork with cumulative state. All paths through the DAG terminate at the Genesis Block. A blockchain is a tree, as each block can have only one parent.</p> <p>A blockchain network is made of nodes that have a view of many forks of the chain and must decide which fork to follow. To construct the parachain host we need to answer two categories of questions addressed by two different components:</p> <ul> <li> <p>What is the state transition function of the blockchain? This is handled by the Runtime, which   defines the state transition logic of the chain. The Runtime logic is divided into:</p> </li> <li> <p>Modules encapsulate particular behavior of the protocol and consist of:</p> <ul> <li>Storage</li> <li>Routines are invoked by entry points and other modules upon block initialization or closing.   Routines can alter the storage of a module.</li> <li>The entry point defines how new information is introduced to a module and can limit the origin   from which they are called (user, root, parachain).</li> </ul> </li> <li>API provides means for the node-side behavior to extract meaningful information from the     state of a single fork.</li> </ul> <p>!!!info The Polkadot Parachain Host Implementers' Guide provides details about   Runtime Architecture and   Runtime API.</p> <ul> <li> <p>Knowing various forks of the blockchain, what behaviors should a node take? What information   should a node extract from the state of which forks, and how should that information be used? This   is handled by the Node-side behavior, which defines all activities a node undertakes given its   view of the blockchain. The node-side behavior can be divided into two categories:</p> </li> <li> <p>Networking behaviors, relate to how information is distributed between nodes but not how the     information is used afterward.</p> </li> <li>Core behaviors, relate to internal work that a specific node does. Such behavior cares about     that information is distributed and received, but not how these two are achieved.</li> </ul> <p>These two categories often interact, but they can be heavily abstracted from each other. The   node-side behavior is split into various subsystems, which perform a particular category of   work. Subsystems can communicate with each other through an   Overseer that prevents race   conditions.</p> <p>!!!info       The Polkadot Parachain Host Implementers' Guide provides details about node architecture the main subsystems:</p> <pre><code>  - [Collator subsystem](https://paritytech.github.io/polkadot/book/node/collators/index.html)\n  - [Backing subsystem](https://paritytech.github.io/polkadot/book/node/backing/index.html)\n  - [Availability subsystem](https://paritytech.github.io/polkadot/book/node/availability/index.html)\n  - [Approval subsystem](https://paritytech.github.io/polkadot/book/node/approval/index.html)\n  - [Dispute subsystem](https://paritytech.github.io/polkadot/book/node/disputes/index.html)\n  - [Utility subsystem](https://paritytech.github.io/polkadot/book/node/utility/index.html)\n</code></pre> <p>The Runtime and Node-side behavior are dependent on each other. The Runtime depends on Node-side behavior to author blocks, and to include extrinsics which trigger the correct entry points. The Node-side behavior relies on the Runtime APIs to extract information necessary to determine which action to take.</p>"},{"location":"learn/learn-parachains/#parachain-hubs","title":"Parachain Hubs","text":"<p>While the relay chain enables crosschain functionality amongst the parachains, it necessitates that there is some latency between the dispatch of a message from one parachain until the destination parachain receives the message. In the optimistic scenario, the latency for this message should be at least two blocks - one block for the message to be dispatched and one block for the receiving parachain to process and produce a block that acts upon the message. However, in some cases, we may see that the latency for messages is higher if many messages are in queue to be processed or if no nodes are running both parachain networks that can quickly gossip the message across the networks.</p> <p>Due to the necessary latency in sending crosschain messages, some parachains plan to become hubs for an entire industry (see the Asset Hub and Bridge Hub). For example, many DeFi applications could take advantage of a property known as composability which means that functions of one application can be synergistically composed with others to create new applications. One example of this includes flash loans, which borrow funds to execute some on-chain logic as long as the loan is repaid at the end of the transaction.</p> <p>An issue with crosschain latency means that composability property weakens among parachains compared to a single blockchain. This implication is common to all sharded blockchain designs, including Polkadot, Ethereum, and others. The solution to this is the introduction of parachain hubs, which maintain the stronger property of single block composability.</p>"},{"location":"learn/learn-parachains/#resources","title":"Resources","text":"<ul> <li>Polkadot: The Parachain -   Blog post by Polkadot co-founder Rob Habermeier who introduced parachains in 2017 as \"a simpler   form of blockchain, which attaches to the security provided by a relay chain rather than providing   its own. The relay chain provides security to attached parachains, but also provides a guarantee   of secure message-passing between them.\"</li> <li>The Path of a Parachain Block - A   technical walk-through of how parachains interact with the relay chain.</li> </ul>"},{"location":"learn/learn-phragmen/","title":"NPoS Election Algorithms","text":""},{"location":"learn/learn-phragmen/#npos-election-algorithms","title":"NPoS Election Algorithms","text":"<p>Since validators are paid almost equally in each era, it is important that the stake behind each validator is uniformly spread out. An election algorithm for Nominated Proof of Staking (NPoS) will try to optimize three metrics when computing a solution graph of nominators and validators:</p> <ol> <li>Maximize the total amount at stake.</li> <li>Maximize the stake behind the minimally staked validator.</li> <li>Minimize the variance of the stake in the set.</li> </ol> <p>!!!note Sequential Phragm\u00e9n, Phragmms and Star balancing are a few notable algorithms used for computing the NPoS solutions in Polkadot and Kusama.</p>"},{"location":"learn/learn-phragmen/#what-is-the-sequential-phragmen-method","title":"What is the sequential Phragm\u00e9n method?","text":"<p>The sequential Phragm\u00e9n method is a multi-winner election method introduced by Edvard Phragm\u00e9n in the 1890s. The quote below taken from the reference Phragm\u00e9n paper sums up the purpose of the sequential Phragm\u00e9n method:</p> <p>!!!note The problem that Phragm\u00e9n\u2019s methods try to solve is that of electing a set of a given numbers of persons from a larger set of candidates. Phragm\u00e9n discussed this in the context of a parliamentary election in a multi-member constituency; the same problem can, of course, also occur in local elections, but also in many other situations such as electing a board or a committee in an organization.</p>"},{"location":"learn/learn-phragmen/#validator-elections","title":"Validator Elections","text":"<p>The sequential Phragm\u00e9n is one of the methods used in the Nominated Proof-of-Stake scheme to elect validators based on their own self-stake and the stake that is voted to them from nominators. It also tries to equalize the weights between the validators after each election round.</p>"},{"location":"learn/learn-phragmen/#off-chain-phragmen","title":"Off-Chain Phragm\u00e9n","text":"<p>Given the large set of nominators and validators, Phragm\u00e9n's method is a difficult optimization problem. Polkadot uses off-chain workers to compute the result off-chain and submit a transaction to propose the set of winners. The reason for performing this computation off-chain is to keep a constant block time of six seconds and prevent long block times at the end of each era, when the validator election takes place.</p> <p>Staking Miners</p> <p>The process of computing the optimal solution for NPoS election can be delegated to Staking Miners.</p>"},{"location":"learn/learn-phragmen/#council-elections","title":"Council Elections","text":"<p>Deprecated in Polkadot OpenGov</p> <p>Phragmen was used for Council elections in Governance v1.</p> <p>The Phragm\u00e9n method was also used in the council election mechanism. When you voted for council members, you could select up to 16 different candidates and then place a reserved bond as the weight of your vote. Phragm\u00e9n would run once on every election to determine the top candidates to assume council positions and then again amongst the top candidates to equalize the weight of the votes behind them as much as possible.</p>"},{"location":"learn/learn-phragmen/#what-does-it-mean-for-node-operators","title":"What does it mean for node operators?","text":"<p>Phragm\u00e9n is something that will run in the background and requires no extra effort from you. However, it is good to understand how it works since it means that not all the stake you've been nominated will end up on your validator after an election. Nominators are likely to nominate a few different validators that they trust to do a good job operating their nodes.</p> <p>You can use this offline-phragm\u00e9n tool for predicting the outcome of a validator election ahead of a new election.</p>"},{"location":"learn/learn-phragmen/#understanding-phragmen","title":"Understanding Phragm\u00e9n","text":"<p>This section explains the sequential Phragm\u00e9n method in-depth and walks through examples.</p>"},{"location":"learn/learn-phragmen/#basic-phragmen","title":"Basic Phragm\u00e9n","text":""},{"location":"learn/learn-phragmen/#rationale","title":"Rationale","text":"<p>In order to understand the Weighted Phragm\u00e9n method, we must first understand the basic Phragm\u00e9n method. There must be some group of candidates, a group of seats they are vying for (which is less than the size of the group of candidates), and some group of voters. The voters can cast an approval vote - that is, they can signal approval for any subset of the candidates.</p> <p>The subset should be a minimum size of one (i.e., one cannot vote for no candidates) and a maximum size of one less than the number of candidates (i.e., one cannot vote for all candidates). Users are allowed to vote for all or no candidates, but this will not affect the final result, making votes of this nature meaningless.</p> <p>Note that in this example, all voters are assumed to have equal say (that is, their vote does not count more or less than any other votes). The weighted case will be considered later. However, weighting can be \"simulated\" by having multiple voters vote for the same slate of candidates. For instance, five people voting for a particular candidate is mathematically the same as a single person with weight <code>5</code> voting for that candidate.</p> <p>The particular algorithm we call here the \"Basic Phragm\u00e9n\" was first described by Brill et al. in their paper \"Phragm\u00e9n\u2019s Voting Methods and Justified Representation\".</p>"},{"location":"learn/learn-phragmen/#algorithm","title":"Algorithm","text":"<p>The Phragm\u00e9n method will iterate, selecting one seat at a time, according to the following rules:</p> <ol> <li>Voters submit their ballots, marking which candidates they approve. Ballots will not be modified    after submission.</li> <li>An initial load of 0 is set for each ballot.</li> <li>The candidate who wins the next available seat is the one where the ballots of their supporters    would have the least average (mean) cost if that candidate wins.</li> <li>The n ballots that approved that winning candidate get 1/n added to their load.</li> <li>The load of all ballots that supported the winner of this round are averaged out so that they are    equal.</li> <li>If there are any more seats, go back to step 3. Otherwise, the selection ends.</li> </ol>"},{"location":"learn/learn-phragmen/#example","title":"Example","text":"<p>Let's walk through an example with four candidates vying for three seats, and five voters.</p> <pre><code>Open Seats: 3\n\nCandidates:   A B C D  L0\n-------------------------\nVoter V1:       X      0\nVoter V2:         X X  0\nVoter V3:       X   X  0\nVoter V4:     X X      0\nVoter V5:       X X X  0\n</code></pre> <p>In this example, we can see that voter <code>V1</code> approves only of candidate <code>B</code>, voter <code>V2</code> approves of candidates <code>C</code> and <code>D</code>, etc. Voters can approve any number of candidates between 1 and <code>number_of_candidates - 1</code>. An initial \"load\" of <code>0</code> is set for each ballot (<code>L0</code> = load after round <code>0</code>, i.e., the \"round\" before the first round). We shall see shortly how this load is updated and used to select candidates.</p> <p>We will now run through an iterative algorithm, with each iteration corresponding to one \"seat\". Since there are three seats, we will walk through three rounds.</p> <p>For the first round, the winner is simply going to be the candidate with the most votes. Since all loads are equal, the lowest average load will be the candidate with the highest n, since <code>1/n</code> will get smaller as <code>n</code> increases. For this first example round, for instance, candidate <code>A</code> had only one ballot vote for them. Thus, the average load for candidate A is <code>1/1</code>, or 1. Candidate C has two ballots approving of them, so the average load is <code>1/2</code>. Candidate B has the lowest average load, at <code>1/4</code> and they get the first seat. Ballots loads are now averaged out, although for the first iteration, this will not have any effect.</p> <pre><code>Filled seats: 1 (B)\nOpen Seats: 2\n\nCandidates:   A B C D  L0 L1\n-----------------------------\nVoter V1:       X      0  1/4\nVoter V2:         X X  0  0\nVoter V3:       X   X  0  1/4\nVoter V4:     X X      0  1/4\nVoter V5:       X X X  0  1/4\n</code></pre> <p>We are now down to candidates <code>A</code>, <code>C</code>, and <code>D</code> for two open seats. There is only one voter (<code>V4</code>) for <code>A</code>, with load <code>1/4</code>. <code>C</code> has two voters, <code>V2</code> and <code>V5</code>, with loads of <code>0</code> and <code>1/4</code>. <code>D</code> has three voters approving of them, <code>V2</code>, <code>V3</code>, and <code>V5</code>, with loads of <code>0</code>, <code>1/4</code>, and <code>1/4</code>, respectively.</p> <p>If Candidate <code>A</code> wins, the average load would be <code>(1/4 + 1/1) / 1</code>, or <code>5/4</code>. If candidate <code>C</code> wins, the average load would be <code>((0 + 1/2) + (1/4 + 1/2)) / 2</code>, or <code>5/8</code>. If candidate <code>D</code> wins, the average load would be <code>((0 + 1/3) + (1/4 + 1/3) + (1/4 + 1/3)) / 3</code>, or <code>1/2</code>. Since <code>1/2</code> is the lowest average load, candidate D wins the second round.</p> <p>Now everybody who voted for Candidate <code>D</code> has their load set to the average, <code>1/2</code> of all the loads.</p> <pre><code>Filled seats: 2 (B, D)\nOpen Seats: 1\n\nCandidates:   A B C D  L0 L1  L2\n---------------------------------\nVoter V1:       X      0  1/4 1/4\nVoter V2:         X X  0  0   1/2\nVoter V3:       X   X  0  1/4 1/2\nVoter V4:     X X      0  1/4 1/4\nVoter V5:       X X X  0  1/4 1/2\n</code></pre> <p>There is now one seat open and two candidates, <code>A</code> and <code>C</code>. Voter <code>V4</code> is the only one voting for <code>A</code>, so if <code>A</code> wins then the average load would be <code>(1/4 + 1/1) / 1</code>, or <code>5/4</code>. Voters <code>V2</code> and <code>V5</code> (both with load <code>1/2</code>) support <code>C</code>, so if <code>C</code> wins the average load would be <code>((1/2 + 1/2) + (1/2 + 1/2)) / 2</code>, or <code>1</code>. Since the average load would be lower with <code>C</code>, <code>C</code> wins the final seat.</p> <pre><code>Filled seats: 3 (B, D, C)\nOpen Seats: 0\n\nCandidates:   A B C D  L0 L1  L2  L3\n------------------------------------\nVoter V1:       X      0  1/4 1/4 1/4\nVoter V2:         X X  0  0   1/2 1\nVoter V3:       X   X  0  1/4 1/2 1/2\nVoter V4:     X X      0  1/4 1/4 1/4\nVoter V5:       X X X  0  1/4 1/2 1\n</code></pre> <p>An interesting characteristic of this calculation is that the total load of all voters will always equal the number of seats filled in that round. In the zeroth round, load starts at <code>0</code> and there are no seats filled. After the first round, the total of all loads is <code>1</code>, after the second round it is <code>2</code>, etc.</p>"},{"location":"learn/learn-phragmen/#weighted-phragmen","title":"Weighted Phragm\u00e9n","text":""},{"location":"learn/learn-phragmen/#rationale_1","title":"Rationale","text":"<p>While this method works well if all voters have equal weight, this is not the case in Polkadot. Elections for both validators and candidates for the Council are weighted by the number of tokens held by the voters. This makes elections more similar to a corporate shareholder election than a traditional political election, where some members have more pull than others. Someone with a single token will have much less voting power than someone with 100. Although this may seem anti-democratic, in a pseudonymous system, it is trivial for someone with 100 tokens to create 100 different accounts and spread their wealth to all of their pseudonyms.</p> <p>Therefore, not only do we want to allow voters to have their preferences expressed in the result, but do so while keeping as equal a distribution of their stake as possible and express the wishes of minorities as much as is possible. The Weighted Phragm\u00e9n method allows us to reach these goals.</p>"},{"location":"learn/learn-phragmen/#algorithm_1","title":"Algorithm","text":"<p>Weighted Phragm\u00e9n is similar to Basic Phragm\u00e9n in that it selects candidates sequentially, one per round, until the maximum number of candidates are elected. However, it has additional features to also allocate weight (stake) behind the candidates.</p> <p>NOTE: in terms of validator selection, for the following algorithm, you can think of \"voters\" as \"nominators\" and \"candidates\" as \"validators\".</p> <ol> <li>Candidates are elected, one per round, and added to the set of successful candidates (they have    won a \"seat\"). This aspect of the algorithm is very similar to the \"basic Phragm\u00e9n\" algorithm    described above.</li> <li>However, as candidates are elected, a weighted mapping is built, defining the weights of each    selection of a validator by each nominator.</li> </ol> <p>In more depth, the algorithm operates like so:</p> <ol> <li>Create a list of all voters, their total amount of stake, and which validators they support.</li> <li>Generate an initial edge-weighted graph mapping from voters to candidates, where each edge weight    is the total potential weight (stake) given by that voter. The sum of all potential weight for    a given candidate is called their approval stake.</li> <li>Now we start electing candidates. For the list of all candidates who have not been elected, get    their score, which is equal to <code>1 / approval_stake</code>.</li> <li>For each voter, update the score of each candidate they support by adding their total budget    (stake) multiplied by the load of the voter and then dividing by that candidate's approval stake    <code>(voter_budget * voter_load / candidate_approval_stake)</code>.</li> <li>Determine the candidate with the lowest score and elect that candidate. Remove the elected    candidate from the pool of potential candidates.</li> <li>The load for each edge connecting to the winning candidate is updated, with the edge load set to    the score of the candidate minus the voter's load, and the voter's load then set to the    candidate's score.</li> <li>If there are more candidates to elect, go to Step 3. Otherwise, continue to step 8.</li> <li>Now the stake is distributed amongst each nominator who backed at least one elected candidate.    The backing stake for each candidate is calculated by taking the budget of the voter and    multiplying by the edge load then dividing by the candidate load    (<code>voter_budget * edge_load / candidate_load</code>).</li> </ol>"},{"location":"learn/learn-phragmen/#example_1","title":"Example","text":"<p>Note: All numbers in this example are rounded off to three decimal places.</p> <p>In the following example, there are five voters and five candidates vying for three potential seats. Each voter <code>V1 - V5</code> has an amount of stake equal to their number (e.g., <code>V1</code> has stake of 1, <code>V2</code> has stake of 2, etc.). Every voter is also going to have a load, which initially starts at <code>0</code>.</p> <pre><code>Filled seats: 0\nOpen Seats: 3\n\nCandidates:    A B C D E  L0\n----------------------------\nVoter V1 (1):  X X        0\nVoter V2 (2):  X X        0\nVoter V3 (3):  X          0\nVoter V4 (4):    X X X    0\nVoter V5 (5):  X     X    0\n</code></pre> <p>Let us now calculate the approval stake of each of the candidates. Recall that this is merely the amount of all support for that candidate by all voters.</p> <pre><code>Candidate A: 1 + 2 + 3 + 5 = 11\nCandidate B: 1 + 2 + 4 = 7\nCandidate C: 4 = 4\nCandidate D: 4 + 5 = 9\nCandidate E: 0\n</code></pre> <p>The first step is easy - candidate <code>E</code> has 0 approval stake and can be ignored from here on out. They will never be elected.</p> <p>We can now calculate the initial scores of the candidates, which is <code>1 / approval_stake</code>:</p> <pre><code>Candidate A: 1 / 11 = 0.091\nCandidate B: 1 / 7 = 0.143\nCandidate C: 1 / 4 = 0.25\nCandidate D: 1 / 9 = 0.111\nCandidate E: N/A\n</code></pre> <p>For every edge, we are going to calculate the score, which is current score plus the total budget * the load of the voter divided by the approval stake of the candidate. However, since the load of every voter starts at 0, and anything multiplied by 0 is 0, any addition will be <code>0 / x</code>, or 0. This means that this step can be safely ignored for the initial round.</p> <p>Thus, the best (lowest) score for Round 0 is Candidate A, with a score of <code>0.091</code>.</p> <pre><code>Candidates:    A B C D E  L0 L1\n----------------------------------\nVoter V1 (1):  X X        0  0.091\nVoter V2 (2):  X X        0  0.091\nVoter V3 (3):  X          0  0.091\nVoter V4 (4):    X X X    0  0\nVoter V5 (5):  X     X    0  0.091\n</code></pre> <pre><code>Filled seats: 1 (A)\nOpen Seats: 2\n\nCandidates:    A B C D E  L0\n----------------------------\nVoter V1 (1):  X X        0\nVoter V2 (2):  X X        0\nVoter V3 (3):  X          0\nVoter V4 (4):    X X X    0\nVoter V5 (5):  X     X    0\n</code></pre> <p>Candidate <code>A</code> is now safe; there is no way that they will lose their seat. Before moving on to the next round, we need to update the scores on the edges of our graph for any candidates who have not yet been elected.</p> <p>We elided this detail in the previous round, since it made no difference to the final scores, but we should go into depth here to see how scores are updated. We first must calculate the new loads of the voters, and then calculate the new scores of the candidates.</p> <p>Any voter who had one of their choices for candidate fill the seat in this round (i.e., voters <code>V1</code>, <code>V2</code>, <code>V3</code>, and <code>V5</code>, who all voted for <code>A</code>) will have their load increased. This load increase will blunt the impact of their vote in future rounds, and the edge (which will be used in determining stake allocation later) is set to the score of the elected candidate minus the current voter load.</p> <pre><code>edge_load = elected_candidate_score - voter_load\nvoter_load = elected_candidate_score\n</code></pre> <p>In this instance, the score of the elected candidate is <code>0.091</code> and the voter loads are all <code>0</code>. So for each voter who voted for <code>A</code>, we will calculate a new edge load <code>Voter</code> -&gt; <code>A</code> of:</p> <pre><code>Edge load: 0.091 - 0 = 0.091\n</code></pre> <p>and a new voter load of:</p> <pre><code>Voter load: 0.091\n</code></pre> <p>As a reminder, here are the current scores. Loads of the voters are all <code>0</code>.</p> <pre><code>Candidate B : 0.143\nCandidate C : 0.25\nCandidate D : 0.111\n</code></pre> <p>Now, we go through the weighted graph and update the score of the candidate and the load of the edge, using the algorithm:</p> <pre><code>candidate_score = candidate_score + ((voter_budget * voter_load) / candidate_approval_stake)\n</code></pre> <p>Without walking through each step, this gives us the following modifications to the scores of the different candidates.</p> <pre><code>V1 updates B to 0.156\nV2 updates B to 0.182\nV4 updates B to 0.182\nV4 updates C to 0.25\nV4 updates D to 0.111\nV5 updates D to 0.162\n</code></pre> <p>After scores are updated, the final scores for the candidates for this round are:</p> <pre><code>Candidate B: 0.182\nCandidate C: 0.25\nCandidate D: 0.162\n</code></pre> <p><code>D</code>, with the lowest score, is elected. You will note that even though candidate <code>B</code> had more voters supporting them, candidate <code>D</code> won the election due to their lower score. This is directly due to the fact that they had the lowest score, of course, but the root reason behind them having a lower score was both the greater amount of stake behind them and that voters who did not get one of their choices in an earlier round (in this example, voter V4) correspond to a higher likelihood of a candidate being elected.</p> <p>We then update the loads for the voters and edges as specified above for any voters who voted for candidate <code>D</code> (viz., <code>V4</code> and <code>V5</code>) using the same formula as above.</p> <pre><code>Filled seats: 2 (A, D)\nOpen Seats: 1\n\nCandidates:    A B C D E  L0 L1    L2\n-----------------------------------\nVoter V1 (1):  X X        0  0.091 0.091\nVoter V2 (2):  X X        0  0.091 0.091\nVoter V3 (3):  X          0  0.091 0.091\nVoter V4 (4):    X X X    0  0     0.162\nVoter V5 (5):  X     X    0  0.091 0.162\n</code></pre> <p>Following a similar process for Round 2, we start with initial candidate scores of:</p> <pre><code>Candidate B : 0.143\nCandidate C : 0.25\n</code></pre> <p>We can then update the scores of the remaining two candidates according to the algorithm described above.</p> <pre><code>V1 updates B to 0.156\nV2 updates B to 0.182\nV4 updates B to 0.274\nV4 updates C to 0.412\n</code></pre> <p>With the lowest score of <code>0.274</code>, Candidate <code>B</code> claims the last open seat. Candidates <code>A</code>, <code>D</code>, and <code>B</code> have been elected, and candidates <code>C</code> and <code>E</code> are not.</p> <p>Before moving on, we must perform a final load adjustment for the voters and the graph.</p> <pre><code>Filled seats: 3 (A, D, B)\nOpen Seats: 0\n\nCandidates:    A B C D E  L0 L1    L2    L3\n------------------------------------------\nVoter V1 (1):  X X        0  0.091 0.091 0.274\nVoter V2 (2):  X X        0  0.091 0.091 0.274\nVoter V3 (3):  X          0  0.091 0.091 0.091\nVoter V4 (4):    X X X    0  0     0.162 0.274\nVoter V5 (5):  X     X    0  0.091 0.162 0.162\n</code></pre> <p>Now we have to determine how much stake every voter should allocate to each candidate. This is done by taking the load of the each edge and dividing it by the voter load, then multiplying by the total budget of the voter.</p> <p>In this example, the weighted graph ended up looking like this:</p> <pre><code>Nominator: V1\n    Edge to A load= 0.091\n    Edge to B load= 0.183\nNominator: V2\n    Edge to A load= 0.091\n    Edge to B load= 0.183\nNominator: V3\n    Edge to A load= 0.091\nNominator: V4\n    Edge to B load= 0.113\n    Edge to D load= 0.162\nNominator: V5\n    Edge to A load= 0.091\n    Edge to D load= 0.071\n</code></pre> <p>For instance, the budget of <code>V1</code> is <code>1</code>, the edge load to <code>A</code> is <code>0.091</code>, and the voter load is <code>0.274</code>. Using our equation:</p> <pre><code>backing_stake (A) = voter_budget * edge_load / voter_load\n</code></pre> <p>We can fill these variables in with:</p> <pre><code>backing_stake (A) = 1 * 0.091 / 0.274 = 0.332\n</code></pre> <p>For <code>V1</code> backing stake of <code>B</code>, you can simply replace the edge load value and re-calculate.</p> <pre><code>backing_stake (B) = 1 * 0.183 / 0.274 = 0.668\n</code></pre> <p>Note that the total amount of all backing stake for a given voter will equal the total budget of the voter, unless that voter had no candidates elected, in which case it will be 0.</p> <p>The final results are:</p> <pre><code>A is elected with stake 6.807.\nD is elected with stake 4.545.\nB is elected with stake 3.647.\n\nV1 supports: A with stake: 0.332 and B with stake: 0.668.\nV2 supports: A with stake: 0.663 and B with stake: 1.337.\nV3 supports: A with stake: 3.0.\nV4 supports: B with stake: 1.642 and D with stake: 2.358.\nV5 supports: A with stake: 2.813 and D with stake: 2.187.\n</code></pre> <p>You will notice that the total amount of stake for candidates <code>A</code>, <code>D</code>, and <code>B</code> equals (aside from rounding errors) the total amount of stake of all the voters (<code>1 + 2 + 3 + 4 + 5 = 15</code>). This is because each voter had at least one of their candidates fill a seat. Any voter who had none of their candidates selected will also not have any stake in any of the elected candidates.</p>"},{"location":"learn/learn-phragmen/#optimizations","title":"Optimizations","text":"<p>The results for nominating validators are further optimized for several purposes:</p> <ol> <li>To reduce the number of edges, i.e. to minimize the number of validators any nominator selects</li> <li>To ensure, as much as possible, an even distribution of stake among the validators</li> <li>Reduce the amount of block computation time</li> </ol>"},{"location":"learn/learn-phragmen/#high-level-description","title":"High-Level Description","text":"<p>After running the weighted Phragm\u00e9n algorithm, a process is run that redistributes the vote amongst the elected set. This process will never add or remove an elected candidate from the set. Instead, it reduces the variance in the list of backing stake from the voters to the elected candidates. Perfect equalization is not always possible, but the algorithm attempts to equalize as much as possible. It then runs an edge-reducing algorithm to minimize the number of validators per nominator, ideally giving every nominator a single validator to nominate per era.</p> <p>To minimize block computation time, the staking process is run as an off-chain worker. In order to give time for this off-chain worker to run, staking commands (bond, nominate, etc.) are not allowed in the last quarter of each era.</p> <p>These optimizations will not be covered in-depth on this page. For more details, you can view the Rust implementation of elections in Substrate, the Rust implementation of staking in Substrate, or the <code>seqPhragm\u00e9nwithpostprocessing</code> method in the Python reference implementation. If you would like to dive even more deeply, you can review the W3F Research Page on Sequential Phragm\u00e9n Method.</p>"},{"location":"learn/learn-phragmen/#rationale-for-minimizing-the-number-of-validators-per-nominator","title":"Rationale for Minimizing the Number of Validators Per Nominator","text":"<p>Paying out rewards for staking from every validator to all of their nominators can cost a non-trivial amount of chain resources (in terms of space on chain and resources to compute). Assume a system with 200 validators and 1000 nominators, where each of the nominators has nominated 10 different validators. Payout would thus require <code>1_000 * 10</code>, or 10_000 transactions. In an ideal scenario, if every nominator selects a single validator, only 1_000 transactions would need to take place - an order of magnitude fewer. Empirically, network slowdown at the beginning of an era has occurred due to the large number of individual payouts by validators to nominators. In extreme cases, this could be an attack vector on the system, where nominators nominate many different validators with small amounts of stake in order to slow the system at the next era change.</p> <p>While this would reduce network and on-chain load, being able to select only a single validator incurs some diversification costs. If the single validator that a nominator has nominated acts maliciously, then the nominator incurs a risk of a significant amount of slashing. Nominators are thus allowed to nominate up to 16 different validators. However, after the weighted edge-reducing algorithm is run, the number of validators per nominator is minimized. Nominators are likely to see themselves nominating a single active validator for an era.</p> <p>At each era change, as the algorithm runs again, nominators are likely to have a different validator than they had before (assuming a significant number of selected validators). Therefore, nominators can diversify against incompetent or corrupt validators causing slashing on their accounts, even if they only nominate a single validator per era.</p>"},{"location":"learn/learn-phragmen/#rationale-for-maintaining-an-even-distribution-of-stake","title":"Rationale for Maintaining an Even Distribution of Stake","text":"<p>Another issue is that we want to ensure that as equal a distribution of votes as possible amongst the elected validators or council members. This helps us increase the security of the system by ensuring that the minimum amount of tokens in order to join the active validator set or council is as high as possible. For example, assume a result of five validators being elected, where validators have the following stake: <code>{1_000, 20, 10, 10, 10}</code>, for a total stake of 1_050. In this case, a potential attacker could join the active validator set with only 11 tokens, and could obtain a majority of validators with only 33 tokens (since the attacker only has to have enough stake to \"kick out\" the three lowest validators).</p> <p>In contrast, imagine a different result with the same amount of total stake, but with that stake perfectly equally distributed: <code>{210, 210, 210, 210, 210}</code>. With the same amount of stake, an attacker would need to stake 633 tokens in order to get a majority of validators, a much more expensive proposition. Although obtaining an equal distribution is unlikely, the more equal the distribution, the higher the threshold - and thus the higher the expense - for attackers to gain entry to the set.</p>"},{"location":"learn/learn-phragmen/#rationale-for-reducing-block-computing-time","title":"Rationale for Reducing Block Computing Time","text":"<p>Running the Phragm\u00e9n algorithm is time-consuming, and often cannot be completed within the time limits of production of a single block. Waiting for calculation to complete would jeopardize the constant block production time of the network. Therefore, as much computation as possible is moved to an off-chain worker, which validators can work on the problem without impacting block production time.</p> <p>To limit the complexity of the election and payout, any given nominator can only select a limited number of validators to nominate.</p>"},{"location":"learn/learn-phragmen/#phragmms-aka-balphragmms","title":"Phragmms (aka Balphragmms)","text":"<p><code>Phragmms</code>, formerly known as <code>Balphragmms</code>, is a new election rule inspired by Phragm\u00e9n and developed in-house for Polkadot. In general, election rules on blockchains is an active topic of research. This is due to the conflicting requirements for election rules and blockchains: elections are computationally expensive, but blockchains are computationally limited. Thus, this work constitutes state of the art in terms of optimization.</p> <p>Proportional representation is a very important property for a decentralized network to have in order to maintain a sufficient level of decentralization. While this is already provided by the currently implemented <code>seqPhragmen</code>, this new election rule provides the advantage of the added security guarantee described below. As far as we can tell, at the time of writing, Polkadot and Kusama are the only blockchain networks that implement an election rule that guarantees proportional representation.</p> <p>The security of a distributed and decentralized system such as Polkadot is directly related to the goal of avoiding overrepresentation of any minority. This is a stark contrast to traditional approaches to proportional representation axioms, which typically only seek to avoid underrepresentation.</p>"},{"location":"learn/learn-phragmen/#maximin-support-objective-and-pjr","title":"Maximin Support Objective and PJR","text":"<p>This new election rule aims to achieve a constant-factor approximation guarantee for the maximin support objective and the closely related proportional justified representation (PJR) property.</p> <p>The maximin support objective is based on maximizing the support of the least-supported elected candidate, or in the case of Polkadot and Kusama, maximizing the least amount of stake backing amongst elected validators. This security-based objective translates to a security guarantee for NPoS and makes it difficult for an adversarial whale\u2019s validator nodes to be elected. The <code>Phragmms</code> rule, and the guarantees it provides in terms of security and proportionality, have been formalized in a peer-reviewed paper).</p> <p>The PJR property considers the proportionality of the voter\u2019s decision power. The property states that a group of voters with cohesive candidate preferences and a large enough aggregate voting strength deserve to have a number of representatives proportional to the group\u2019s vote strength.</p>"},{"location":"learn/learn-phragmen/#comparing-sequential-phragmen-mms-and-phragmms","title":"Comparing Sequential Phragm\u00e9n, MMS, and Phragmms","text":"<p>Sequential Phragm\u00e9n (<code>seqPhragmen</code>) and <code>MMS</code> are two efficient election rules that both achieve PJR.</p> <p>Currently, Polkadot employs the <code>seqPhragmen</code> method for validator and council elections. Although <code>seqPhramen</code> has a very fast runtime, it does not provide constant-factor approximation for the maximin support problem. This is due to <code>seqPhramen</code> only performing an approximate rebalancing of the distribution of stake.</p> <p>In contrast, <code>MMS</code> is another standard greedy algorithm that simultaneously achieves the PJR property and provides a constant factor approximation for maximin support, although with a considerably slower runtime. This is because for a given partial solution, <code>MMS</code> computes a balanced edge weight vector for each possible augmented committee when a new candidate is added, which is computationally expensive.</p> <p>We introduce a new heuristic inspired by <code>seqPhragmen</code>, <code>PhragMMS</code>, which maintains a comparable runtime to <code>seqPhragmen</code>, offers a constant-factor approximation guarantee for the maximin support objective, and satisfies PJR. This is the fastest known algorithm to achieve a constant-factor guarantee for maximin support.</p>"},{"location":"learn/learn-phragmen/#the-new-election-rule-phragmms","title":"The New Election Rule: Phragmms","text":"<p><code>Phragmms</code> is an iterative greedy algorithm that starts with an empty committee and alternates between the <code>Phragmms</code> heuristic for inserting a new candidate and rebalancing by replacing the weight vector with a balanced one. The main differentiator between <code>Phragmms</code> and <code>seqPhragmen</code> is that the latter only perform an approximate rebalancing. Details can be found in Balanced Stake Distribution.</p> <p>The computation is executed by off-chain workers privately and separately from block production, and the validators only need to submit and verify the solutions on-chain. Relative to a committee A, the score of an unelected candidate c is an easy-to-compute rough estimate of what would be the size of the least stake backing if we added c to committee A. Observing on-chain, only one solution needs to be tracked at any given time, and a block producer can submit a new solution in the block only if the block passes the verification test, consisting of checking:</p> <ol> <li>Feasibility,</li> <li>Balance and</li> <li>Local Optimality - The least stake backing of A is higher than the highest score among    unelected candidates</li> </ol> <p>If the tentative solution passes the tests, then it replaces the current solution as the tentative winner. The official winning solution is declared at the end of the election window.</p> <p>A powerful feature of this algorithm is the fact that both its approximation guarantee for maximin support and the above checks passing can be efficiently verified in linear time. This allows for a more scalable solution for secure and proportional committee elections. While <code>seqPhragmen</code> also has a notion of score for unelected candidates, <code>Phragmms</code> can be seen as a natural complication of the <code>seqPhragmen</code> algorithm, where <code>Phragmms</code> always grants higher score values to candidates and thus inserts them with higher support values.</p> <p>To summarize, the main differences between the two rules are:</p> <ul> <li>In <code>seqPhragmen</code>, lower scores are better, whereas in <code>Phragmms</code>, higher scores are better.</li> <li>Inspired by <code>seqPhragmen</code>, the scoring system of <code>Phragmms</code> can be considered to be more intuitive   and does a better job at estimating the value of adding a candidate to the current solution, and   hence leads to a better candidate-selection heuristic.</li> <li>Unlike <code>seqPhragmen</code>, in <code>Phragmms</code>, the edge weight vector w is completely rebalanced after   each iteration of the algorithm.</li> </ul> <p>The <code>Phragmms</code> election rule is currently being implemented on Polkadot. Once completed, it will become one of the most sophisticated election rules implemented on a blockchain. For the first time, this election rule will provide both fair representation (PJR) and security (constant-factor approximation for the maximin support objection) to a blockchain network.</p>"},{"location":"learn/learn-phragmen/#algorithm_2","title":"Algorithm","text":"<p>The <code>Phragmms</code> algorithm iterates through the available seats, starting with an empty committee of size k:</p> <ol> <li> <p>Initialize an empty committee A and zero edge weight vector w = 0.</p> </li> <li> <p>Repeat k times:</p> </li> </ol> <ul> <li>Find the unelected candidate with highest score and add it to committee A.</li> <li>Re-balance the weight vector w for the new committee A.</li> </ul> <ol> <li>Return A and w.</li> </ol>"},{"location":"learn/learn-phragmen/#external-resources","title":"External Resources","text":"<ul> <li>Phragmms - W3F research paper that expands on the   sequential Phragm\u00e9n method.</li> <li>W3F Research Page on NPoS -   An overview of Nominated Proof of Stake as its applied to Polkadot.</li> <li>Python Reference Implementations - Python   implementations of Simple and Complicated Phragm\u00e9n methods.</li> <li>Substrate Implementation -   Rust implementation used in Substrate.</li> <li>Phragm\u00e9n's and Thiele's Election Methods - 95-page paper   explaining Phragm\u00e9n's election methods in detail.</li> <li>Phragm\u00e9n\u2019s Voting Methods and Justified Representation -   This paper by Brill et al. is the source for the simple Phragm\u00e9n method, along with proofs about   its properties.</li> <li>Offline Phragm\u00e9n - Script to generate the   Phragm\u00e9n validator election outcome before the start of an era.</li> </ul>"},{"location":"learn/learn-polkadot-host/","title":"Polkadot Host (PH)","text":"<p>The architecture of Polkadot can be divided into two different parts, the Polkadot runtime and the Polkadot host. The Polkadot runtime is the core state transition logic of the chain and can be upgraded over the course of time and without the need for a hard fork. In comparison, the Polkadot host is the environment in which the runtime executes and is expected to remain stable and mostly static over the lifetime of Polkadot.</p> <p>The Polkadot host interacts with the Polkadot runtime in limited, and well-specified ways. For this reason, implementation teams can build an alternative implementation of the Polkadot host while treating the Polkadot runtime as a black box. For more details of the interactions between the host and the runtime, please see the specification.</p>"},{"location":"learn/learn-polkadot-host/#components-of-the-polkadot-host","title":"Components of the Polkadot host","text":"<ul> <li>Networking components such as <code>Libp2p</code> that facilitates network interactions.</li> <li>State storage and the storage trie along with the database layer.</li> <li>Consensus engine for GRANDPA and BABE.</li> <li>Wasm interpreter and virtual machine.</li> <li>Low level primitives for a blockchain, such as cryptographic primitives like hash functions.</li> </ul> <p>A compiled Polkadot runtime, a blob of Wasm code, can be uploaded into the Polkadot host and used as the logic for the execution of state transitions. Without a runtime, the Polkadot host is unable to make state transitions or produce any blocks.</p> <p>A host node...</p> <ol> <li>must populate the state storage with the official genesis state.</li> <li>should maintain a set of around 50 active peers at any time. New peers can be found using the    discovery protocols.</li> <li>should open and maintain the various required streams with each of its active peers.</li> <li>should send block requests to these peers to receive all blocks in the chain and execute each of    them.</li> <li>should exchange neighbor packets.</li> </ol> <p>Consensus in the Polkadot Host is achieved during the execution of two different procedures, block-production and finality. The Polkadot Host must run these procedures if (and only if) it is running on a validator node.</p> <p>Additional information on each of these requirements can be found here.</p>"},{"location":"learn/learn-polkadot-host/#polkadot-runtime","title":"Polkadot Runtime","text":"<p>Below is a diagram that displays the Polkadot host surrounding the Polkadot runtime. Think of the runtime (in white) as a component that can be inserted, swapped out, or removed entirely. While the parts in grey are stable and can not change without an explicit hard fork.</p> <p></p>"},{"location":"learn/learn-polkadot-host/#code-executor","title":"Code Executor","text":"<p>The Polkadot Host executes the calls of Runtime entrypoints inside a Wasm Virtual Machine (VM), which in turn provides the Runtime with access to the Polkadot Host API. This part of the Polkadot Host is referred to as the Executor. For additional technical implementation details, check out this section of the Polkadot Spec.</p>"},{"location":"learn/learn-polkadot-host/#resources","title":"Resources","text":"<ul> <li>Polkadot Host Protocol Specification - Incubator for the   Polkadot Host spec, including tests.</li> <li>Gossamer: A Go implementation of the Polkadot Host</li> <li>Kagome - C++ implementation of Polkadot Host</li> </ul>"},{"location":"learn/learn-polkadot-js-guides/","title":"Polkadot-JS Guides","text":"<p>import DocCardList from '@theme/DocCardList';</p> <p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716 <p>Info</p> <p>We support only the use of the Polkadot-JS UI together with the Polkadot-JS browser extension, Ledger and Polkadot Vault for signing transactions. We do not provide support for third party applications.</p>"},{"location":"learn/learn-polkadot-opengov-origins/","title":"Polkadot OpenGov Origins","text":"<p>Learn more about Polkadot OpenGov</p> <p>For background information about Polkadot OpenGov, please refer to this dedicated Wiki document.</p>"},{"location":"learn/learn-polkadot-opengov-origins/#polkadot-opengov-terminology-and-parameters","title":"Polkadot OpenGov Terminology and Parameters","text":"<p>The important parameters to be aware of when voting using the Referenda module are as follows:</p> <p>Origin - Each origin has a fixed set of privileges. When making a proposal, it is important to choose the origin that has the privilege to execute the referenda.</p> <p>Track - Each track has its own dispatch origin and a preset configuration that governs the voting process and parameters.</p> <p>Submission Deposit - The minimum amount to be used as a (refundable) deposit to submit a public referendum proposal.</p> <p>Prepare Period - The minimum time the referendum needs to wait before it can progress to the next phase after submission. Voting is enabled, but the votes do not count toward the outcome of the referendum yet.</p> <p>Decision Deposit - This deposit is required for a referendum to progress to the decision phase after the end of prepare period.</p> <p>Decision Period - Amount of time a decision may take to be approved to move to the confirming period. If the proposal is not approved by the end of the decision period, it gets rejected.</p> <p>Max Deciding - The maximum number of referenda that can be in the decision period of a track all at once.</p> <p>Conviction: A multiplier to increase voting power.</p> <p>Approval: the share of the approval vote-weight after adjustments for conviction against the total number of vote-weight for both approval and rejection</p> <p>Support: The total number of votes in approval (ignoring adjustments for conviction) compared to the total possible amount of votes that could be made in the system. Support also takes into account abstained votes.</p> <p>Min Approval - The threshold of approval (along with the min support) needed for a proposal to meet the requirements of the confirm period.</p> <p>Min Support - The threshold of support (along with the min approval) needed for a proposal to meet the requirements of the confirm period.</p> <p>Confirmation Period - The total time the referenda must meet both the min approval and support criteria during the decision period in order to pass and enter the enactment period.</p> <p>Min Enactment Period - Minimum time that an approved proposal must be in the dispatch queue after approval. The proposer has the option to set the enactment period to be of any value greater than the min enactment period.</p>"},{"location":"learn/learn-polkadot-opengov-origins/#origins-and-tracks-info","title":"Origins and Tracks Info","text":"PolkadotKusama ID Origin Max Deciding Decision Deposit Prepare Period Decision Period Confirm Period Min Enactment Period Min Approval Min Support 0 Root 1 100000 DOT 2 Hours 28 Days 1 Day 1 Day Reciprocal Linear Decreasing 1 Whitelisted Caller 100 10000 DOT 30 Minutes 28 Days 10 Minutes 10 Minutes Reciprocal Reciprocal 2 Wish For Change 10 20000 DOT 2 Hours 28 Days 1 Day 10 Minutes Reciprocal Linear Decreasing 10 Staking Admin 10 5000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 11 Treasurer 10 1000 DOT 2 Hours 28 Days 7 Days 1 Day Reciprocal Linear Decreasing 12 Lease Admin 10 5000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 13 Fellowship Admin 10 5000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 14 General Admin 10 5000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Reciprocal Reciprocal 15 Auction Admin 10 5000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Reciprocal Reciprocal 20 Referendum Canceller 1,000 10000 DOT 2 Hours 7 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 21 Referendum Killer 1,000 50000 DOT 2 Hours 28 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 30 Small Tipper 200 1 DOT 1 Minutes 7 Days 10 Minutes 1 Minutes Linear Decreasing Reciprocal 31 Big Tipper 100 10 DOT 10 Minutes 7 Days 1 Hours 10 Minutes Linear Decreasing Reciprocal 32 Small Spender 50 100 DOT 4 Hours 28 Days 2 Days 1 Day Linear Decreasing Reciprocal 33 Medium Spender 50 200 DOT 4 Hours 28 Days 4 Days 1 Day Linear Decreasing Reciprocal 34 Big Spender 50 400 DOT 4 Hours 28 Days 7 Days 1 Day Linear Decreasing Reciprocal ID Origin Max Deciding Decision Deposit Prepare Period Decision Period Confirm Period Min Enactment Period Min Approval Min Support 0 Root 1 3333.333333 KSM 2 Hours 14 Days 1 Day 1 Day Reciprocal Linear Decreasing 1 Whitelisted Caller 100 333.333333 KSM 30 Minutes 14 Days 10 Minutes 10 Minutes Reciprocal Reciprocal 2 Wish For Change 10 666.666667 KSM 2 Hours 14 Days 1 Day 10 Minutes Reciprocal Linear Decreasing 10 Staking Admin 10 166.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 11 Treasurer 10 33.333333 KSM 2 Hours 14 Days 2 Days 1 Day Reciprocal Linear Decreasing 12 Lease Admin 10 166.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 13 Fellowship Admin 10 166.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 14 General Admin 10 166.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Reciprocal Reciprocal 15 Auction Admin 10 166.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Reciprocal Reciprocal 20 Referendum Canceller 1,000 333.333333 KSM 2 Hours 7 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 21 Referendum Killer 1,000 1666.666667 KSM 2 Hours 14 Days 3 Hours 10 Minutes Linear Decreasing Reciprocal 30 Small Tipper 200 0.033333 KSM 1 Minutes 7 Days 10 Minutes 1 Minutes Linear Decreasing Reciprocal 31 Big Tipper 100 0.333333 KSM 10 Minutes 7 Days 1 Hours 10 Minutes Linear Decreasing Reciprocal 32 Small Spender 50 3.333333 KSM 4 Hours 14 Days 2 Days 1 Day Linear Decreasing Reciprocal 33 Medium Spender 50 6.666667 KSM 4 Hours 14 Days 4 Days 1 Day Linear Decreasing Reciprocal 34 Big Spender 50 13.333333 KSM 4 Hours 14 Days 7 Days 1 Day Linear Decreasing Reciprocal <p>Info</p> <p>For every referendum in each of these tracks, the Polkadot-JS UI displays interactive graphs of the support and approval. </p>"},{"location":"learn/learn-polkadot-opengov-origins/#root","title":"Root","text":"PolkadotKusama <p>The origin with the highest level of privileges. This track requires extremely high levels of approval and support for early passing. The prepare and enactment periods are also large. For instance, a referendum proposed in this track needs to amass 48.2% support (total network issuance) by the end of the first day with over 93.5% approval to be considered to be part of the confirm period. The support curve drops linearly to 25% by the end of day 14 and almost to 0% by the end of day 28. This ensures that the token holders receive ample time to vote on the proposal during the decision period.</p> <p></p> <p>The origin with the highest level of privileges. This track requires extremely high levels of approval and support for early passing. The prepare and enactment periods are also large. For instance, a referendum proposed in this track needs to amass 46.8% support (total network issuance) by the end of the first day with over 88% approval to be considered to be part of the confirm period. The support curve drops linearly to 25% by the end of day 7 and almost to 0% by the end of day 14. This ensures that the token holders receive ample time to vote on the proposal during the decision period.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#whitelisted-caller","title":"Whitelisted Caller","text":"PolkadotKusama <p>Origin commanded by the Fellowship whitelist some hash of a call and allow the call to be dispatched with the root origin (after the referendum passes). This track allows for a shorter voting turnaround, safe in the knowledge through an open and transparent process for time-critical proposals. For instance, a referendum proposed in this track needs to amass 20% :polkadot support (much lesser than the root) by the end of the first day with over 93.5% approval to be considered to be part of the confirm period. Note how no referendum on the Whitelisted track can ever pass with less than 5% support.</p> <p></p> <p>Origin commanded by the Fellowship whitelist some hash of a call and allow the call to be dispatched with the root origin (after the referendum passes). This track allows for a shorter voting turnaround, safe in the knowledge through an open and transparent process for time-critical proposals. For instance, a referendum proposed in this track needs to amass 14% support (much lesser than the root) by the end of the first day with over 88% approval to be considered to be part of the confirm period. Note how no referendum on the Whitelisted track can ever pass with less than 5% support.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#wish-for-change","title":"Wish For Change","text":"<p>The Wish For Change track serves as a medium for gathering consensus through OpenGov on a proposed change to the network through an on-chain remark. This track was added to ensure the Root track, which is typically utilized for handling one referendum at a time due to the sensitive nature of Root calls, is not employed to convey network desires to various bodies within the network. These remark statements could be voted on simultaneously because they lack stateful logic impacting the network. They should not delay voting on proposals requiring Root or be obligated to its queue. The approval/support criteria resemble Root, and passing items on this track serves as a signal for a change without conferring privileges.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#staking-admin","title":"Staking Admin","text":"<p>The origin for canceling slashes. This origin has the privilege to execute calls from the staking pallet and the Election Provider Multiphase Pallet.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#treasurer","title":"Treasurer","text":"PolkadotKusama <p>The origin for spending funds from the treasury (up to 10M DOT). This origin has the privilege to execute calls from the Treasury pallet.</p> <p></p> <p>The origin for spending funds from the treasury (up to 333333.33 KSM). This origin has the privilege to execute calls from the Treasury pallet.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#lease-admin","title":"Lease Admin","text":"<p>Origin can force slot leases. This origin has the privilege to execute calls from the Slots pallet.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#fellowship-admin","title":"Fellowship Admin","text":"<p>The origin for managing the composition of the fellowship.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#general-admin","title":"General Admin","text":"<p>The origin managing the registrar and permissioned HRMP channel operations.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#referendum-canceller","title":"Referendum Canceller","text":"<p>The origin can cancel referenda. This track has a low lead time and approval/support curves with slightly sharper reductions in their thresholds for passing.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#referendum-killer","title":"Referendum Killer","text":"<p>The origin can cancel an ongoing referendum and slash the deposits. This track also has a low lead-time and approval/support curves with slightly sharper reductions in their thresholds for passing.</p> PolkadotKusama <p></p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#small-tipper","title":"Small Tipper","text":"PolkadotKusama <p>Origin able to spend up to 250 DOT from the treasury at once.</p> <p></p> <p>Origin able to spend up to 8.25 KSM from the treasury at once.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#big-tipper","title":"Big Tipper","text":"PolkadotKusama <p>Origin able to spend up to 1000 DOT from the treasury at once.</p> <p></p> <p>Origin able to spend up to 33.33 KSM from the treasury at once.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#small-spender","title":"Small Spender","text":"PolkadotKusama <p>Origin able to spend up to 10000 DOT from the treasury at once.</p> <p></p> <p>Origin able to spend up to 333.33 KSM from the treasury at once.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#medium-spender","title":"Medium Spender","text":"PolkadotKusama <p>Origin able to spend up to 100000 DOT from the treasury at once.</p> <p></p> <p>Origin able to spend up to 3333.33 KSM from the treasury at once.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-origins/#big-spender","title":"Big Spender","text":"PolkadotKusama <p>Origin able to spend up to 1000000 DOT from the treasury at once.</p> <p></p> <p>Origin able to spend up to 33333.33 KSM from the treasury at once.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-treasury/","title":"Treasury","text":"<p>The Treasury is a pot of funds collected through a portion of block production rewards, transaction fees, slashing, and staking inefficiencies. Treasury funds are held in a system account that cannot be controlled by any external account; only the system internal logic can access it.</p> <p>Creating a Treasury Proposal on Polkadot OpenGov</p> <p>If you would like to create a treasury proposal on Polkadot OpenGov, follow the instructions outlined on this how-to guide.</p>"},{"location":"learn/learn-polkadot-opengov-treasury/#treasury-inflow-and-outflow","title":"Treasury Inflow and Outflow","text":"<p>Tokens that are deposited into the Treasury (i.e. the inflow) is determined by the following mechanisms:</p> <ul> <li>Transaction fees: 80% of the transaction fees of every submitted extrinsic is diverted to the   Treasury, while 20% is given to the block producers.</li> <li>Inflation: 15% of DOT annual inflation is directed to the Treasury.</li> <li>Slashes: whenever validators and nominators are slashed, a share of the   slashed tokens are diverted to Treasury. They are typically rare and unpredictable events.</li> <li>Transfers: everyone can send funds to the Treasury directly. This is a rare event and   typically due to grantees reimbursing some of the amount they got allocated for various reasons.</li> </ul> <p>The outflow is determined by the following mechanisms:</p> <ul> <li>Burned tokens: at the end of each spend period,   a fraction of the available funds are   burned.</li> <li>Treasury proposals &amp; Bounties: they make up the largest share of outflow tokens to the   community and need to be approved by governance. Then, payouts occur at the end of a   spend period.</li> <li>Tips: smaller payouts directly to grantees that can happen within a   spend period.</li> </ul> <p>Spend Period Schedule</p> <p>On Polkadot-JS UI, navigate to Governance &gt; Treasury to view the status of current spend period.</p> <p></p>"},{"location":"learn/learn-polkadot-opengov-treasury/#treasury-tracks","title":"Treasury Tracks","text":"<p>OpenGov allows for managing funds through six tracks, each with its own origin and track parameters.</p> <ul> <li>Treasurer</li> <li>Big Spender</li> <li>Medium Spender</li> <li>Small Spender</li> <li>Big Tipper</li> <li>Small Tipper</li> </ul>"},{"location":"learn/learn-polkadot-opengov-treasury/#submit-treasury-proposal-via-polkassembly","title":"Submit Treasury Proposal via Polkassembly","text":"<p>Access to Treasury funds requires successful enactment of referendum in the respective treasury track on-chain. Learn how to submit a treasury proposal for referendum using Polkassembly.</p> <p>Go to Polkassembly and click on the FAB button in the bottom right corner. Then,</p> <ul> <li>Click on \"Create Treasury Proposal\" and choose an address for the proposer</li> <li> <p>After choosing an address, you will enter a three-stage guideline:</p> </li> <li> <p>Write a proposal: you can add a detailed description for the proposal, which will be stored on     Polkassembly. Alternatively, you can link an existing discussion post.</p> </li> </ul> <p></p> <ul> <li>Create a preimage: an existing preimage can be linked, or a new one can be created. To create a     preimage, add the beneficiary address and the token amount. The track will be auto-selected and     the user can proceed with the creation of a preimage.</li> </ul> <p></p> <ul> <li>Create a proposal: final confirmation about the proposal creation. The description of the     proposal and the preimage are automatically linked to the proposal.</li> </ul>"},{"location":"learn/learn-polkadot-opengov-treasury/#sub-treasuries","title":"Sub-treasuries","text":"<p>The treasury currently operates on a single account on-chain. The above tracks manage the outflow of the treasury on the network. With sub-treasuries, having treasury accounts that correspond to each collective is also possible.</p> <p>Rather than have many referenda through OpenGov, the treasury can allocate funds to each sub-treasury (through governance), from which each respective collective can spend funds (depending on their specific rule set).</p> <p>New treasuries could be added to respective system chains through governance by adding more instances of this pallet.</p>"},{"location":"learn/learn-polkadot-opengov-treasury/#multi-asset-treasury-support","title":"Multi-Asset Treasury Support","text":"<p>The treasuries can support multiple asset types and thus can spend assets other than DOT (or KSM on Kusama) held within the treasury, and their transfers and interactions across the chains facilitated by cross-consensus messaging. These assets have a few requirements:</p> <ol> <li>The asset is listed on the AssetHub system parachain.</li> <li>The asset is active and has sufficient liquidity to be utilized for payouts.</li> <li>The asset has a set conversion rate, as per OpenGov referenda on the Treasurer track (set via the    asset rate pallet). This conversion rate defines a fixed-point representation for converting from    that asset to the native asset (DOT or KSM).</li> <li>The asset must be approved and onboarded via OpenGov to become spendable via the treasury as a    valid spend method.</li> </ol> <p>For example, see how USDT became approved as an asset on AssetHub, which can be used in the treasury.</p>"},{"location":"learn/learn-polkadot-opengov-treasury/#bounties","title":"Bounties","text":""},{"location":"learn/learn-polkadot-opengov-treasury/#parent-bounties","title":"Parent Bounties","text":"<p>Getting treasury funding through OpenGov, depending on which treasury track you submit your referendum, can be a long and uncertain process. This is not always a suitable option, for example, for event organizers who need to pay costs upfront or close to the event's date. Bounties solve this problem by procuring access to treasury funds in a single shot and using them to fund multiple events later on through child bounties. This is why bounties are also called parent bounties.</p> <p>Parent bounty proposals aim to reserve a portion of treasury funds once, which will be used later. They save proponents the time needed to create and obtain approval for several OpenGov referenda. Bounties are managed by curators, where the curator is usually a multi-signature account. Bounties can access a large amount of funds, so managing those funds with a multisig is a good practice to enhance security. Essentially, curators are multisig addresses with agency over a portion of the treasury to promote events, fix a bug or vulnerability, develop a strategy, or monitor a set of tasks related to a specific topic, all for the benefit of the ecosystem.</p> <p>A proposer can submit a bounty proposal to OpenGov, with a curator to be defined later, whose background and expertise is such that they can determine when the task is complete.</p> <p>When submitting the value of the bounty, the proposer can specify a fee that will be paid to curators willing to invest their time and expertise in the task; this amount will be included in the total value of the bounty. In this sense, the curator's fee can be defined as the difference between the amounts paid to child bounty awardees and the total value of the bounty.</p> <p>Curators are selected through OpenGov referendum after the bounty proposal passes; and they need to pay an upfront deposit to take the position. This deposit can be used to punish curators if they act maliciously. However, if they are successful in managing the bounty to completion, they will receive their deposit back, and part of the bounty funding as a payment for their efforts.</p> <p>Curators are expected to have a decent track record in addressing the issues the bounty wants to solve. They should be very knowledgeable on the topics covered by the bounty and have proven project management skills or experience. These recommendations help ensure an effective use of the bounty mechanism. A Bounty is a reward for a specified body of work or set of objectives that needs to be executed for a predefined treasury amount designated to be paid out. The responsibility of assigning a payout address once the specified set of objectives is completed is delegated to the curator.</p> <p>The bounty has a predetermined duration, with possible extension(s) to be requested by the curator. To maintain flexibility during the tasks\u2019 curation, the curator will also be able to create child bounties for more granularity in the allocation of funds and as part of a nested iteration of the bounty mechanism.</p>"},{"location":"learn/learn-polkadot-opengov-treasury/#child-bounties","title":"Child Bounties","text":"<p>Child bounties are spawned from parent bounties. Child bounties are used to access funds directly from the parent bounty without going through an OpenGov referendum.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about bounties and treasury.</p>"},{"location":"learn/learn-polkadot-opengov/","title":"Introduction to Polkadot OpenGov","text":"<p>import VLTable from \"./../../components/Voluntary-Locking\"; import Fellowship from \"./../../components/Fellowship\";</p> <p>     Before voting or delegating in Polkadot OpenGov, get familiar with            balances and locks.      </p> \u2716 <p>The content in this document is subject to change</p> <p>The governance protocol has already undergone iterations (see Governance V1). Governance is a constantly evolving protocol at this stage in its lifecycle.</p> <p>For additional support about Polkadot OpenGov, see the dedicated support pages.</p> <p>Polkadot uses a sophisticated governance mechanism that allows it to evolve gracefully overtime at the ultimate behest of its assembled stakeholders. The goal is to ensure that most of the stake can always command the network.</p> <p>Polkadot brings together various novel mechanisms, including an amorphous (abstract) form of state-transition function stored on-chain defined in a platform-agnostic language (i.e. WebAssembly), and several on-chain voting mechanisms such as referenda and batch approval voting. All changes to the protocol must be agreed upon by stake-weighted referenda.</p>"},{"location":"learn/learn-polkadot-opengov/#premise","title":"Premise","text":"<p>Polkadot's first governance system (Governance V1) included three main components.</p> <ul> <li>The Technical Committee: A technocratic   committee to manage upgrade timelines.</li> <li>The Council: An approval-voted, elected executive   \"government\" to manage parameters, admin, and spending proposals.</li> <li>The Public: All token holders.</li> </ul> <p>Over the first few years of operation, Governance V1 ensured the appropriate usage of treasury funds and enabled timely upgrades and fixes. Like most early technologies, protocols must evolve as they mature to improve their shortcomings and keep up with modern advancements. In Governance V1, all referenda carried the same weight as only one referendum could be voted on at a time (except for emergency proposals), and the voting period could last multiple weeks. Also, an alternating voting timetable allowed to vote either for a public referendum or a council motion every 28 days (7 days on Kusama). This resulted in the system favoring careful consideration of very few proposals instead of broad consideration of many.</p> <p>Polkadot OpenGov changes how the practical means of day-to-day decisions are made, making the repercussions of referenda better scoped and agile to increase the number of collective decisions the system can make at any given time.</p> <p>The following content is focused on Polkadot OpenGov, and on the main differences with previous governance versions. We recommend learning about Governance v1 to better understand the need for and the direction of Polkadot OpenGov.</p>"},{"location":"learn/learn-polkadot-opengov/#summary","title":"Summary","text":"<p>In Governance v1, active token holders (public) and the Council administrated the network's upgrade decisions. Whether the public or the council initiated the proposal, it would eventually have to go through a referendum to let all holders (weighted by stake and conviction) make the decision.</p> <p>The Council fulfilled its role as the representative of the public, guardian of the treasury and initiator of legislation, but it was often seen as a centralized entity. To further decentralize the network, Polkadot OpenGov proposes the following main changes:</p> <ul> <li>Migrating all responsibilities of the Council to the public via a direct democracy voting system.</li> <li>Dissolving the current Council collective</li> <li>Allowing users to delegate voting power in more ways to community members</li> <li>Dissolving the Technical Committee and   establishing the broader Polkadot Technical Fellowship</li> </ul> <p>The figure below shows an overview of Polkadot OpenGov's structure.</p> <p>Info</p> <p>See this page for a comparison with the structure of Governance V1.</p> <p></p> <p>In Polkadot OpenGov, all the proposals are initiated by the public. The proposal will enter a Lead-in period (for more information, see Referenda Timeline), after which it will follow a specific Track which has a dedicated Origin. There are 15 Origins, each with a different track. The origins and tracks parameters are preset values that set the duration of a referendum as well as how many referenda can be voted on simultaneously. For example, a treasury proposal can now be submitted in different tracks depending on the amount requested. A proposal for a small tip will need to be submitted to the Small Tipper track, while a proposal requiring substantial funds will need to be submitted to the Medium or Big Spender track.</p> <p>The Polkadot Technical Fellowship can decide to whitelist a proposal that will be enacted through the Whitelist Caller origin. Those proposals will have a shorter Lead-in, Confirmation, and Enactment period when compared to the Root Origin track.</p> <p>Each track has its own preset Approval and Support curves based on the origin's privileges. When both the approval and support criteria are satisfied for a specific period (called the confirmation period), the referendum passes and will be executed after the enactment period.</p> <p>All referenda within each track and across tracks can be voted on simultaneously (assuming the track's maximum capacity is not reached).</p> <p>Polkadot OpenGov also comes with multi-role delegations where the token holder can assign voting power on different tracks to different entities who are experts in judging the referenda submitted to those tracks. For example, suppose a token holder does not have the technical background to consider the merits and vote on the referenda submitted to the Root track. In that case, they can delegate their voting power just for the Root track to a trusted expert who (according to them) acts in the best interest of the network protocol. In this way, token holders do not need to be up-to-date with governance matters and can still make their votes count through delegates.</p>"},{"location":"learn/learn-polkadot-opengov/#gov1-vs-polkadot-opengov","title":"Gov1 vs. Polkadot OpenGov","text":"Governance V1 Polkadot OpenGov Polkadot OpenGov Benefit Includes the Council, the Technical Committee, and the Public (i.e. token holders). Includes the Public and the Technical Fellowship. Simpler and more decentralized structure. Referenda executed only from one origin (Root). Referenda in this origin must be carefully scrutinized. Therefore, there is only one track (i.e., only one referendum at a time can be executed). Referenda executed from multiple origins, each with a different track that shapes proposals\u2019 timelines. Depending on the origin, multiple referenda within the same track are possible. Possibility to categorize proposals (based on importance and urgency) and execute them simultaneously within and between origin tracks. Proposals can be submitted by either the Council or the Public. The public submits proposals. More democratic. Uses Adaptive Quorum Biasing to define the approval threshold based on turnout. Given the same turnout, council-initiated referenda require fewer Aye votes to pass compared to public referenda. Uses origin-specific approval and support curves defining the amount of approval and support (i.e. turnout) needed as a function of time. The same curves are applied to all referenda within the same origin track. Referenda timeline depends on the origin and not on who submitted the proposal (i.e. Council or Public). This is a more democratic and equalitarian system. Uses alternating voting timetable allowing voters to cast votes for either council or public referenda every 28 eras. Multiple referenda can be voted at the same time. More flexible and agile governance system. Except for emergency proposals, all referenda have fixed voting and enactment periods of 28 eras. Periods' length is customizable and has pre-defined limits for each origin. The same limits apply to all tracks with the same origin. For example, the track in the origin Root will be longer than the track within the Small Tipper origin. Referenda\u2019s timeline is tailored to their importance and urgency. Flexible enactment period based on origin. Emergency proposals turned referenda can be simultaneously voted on and executed with other referenda and have shorter enactment periods. They must be proposed by the Technical Committee and approved by the Council. No emergency proposals. The Technical Fellowship can whitelist proposals that will have their origin with shorter lead-in, confirmation, and enactment periods. The Technical Fellowship is a more decentralized entity than the Technical Committee. Whitelisting a proposal requires a majority of approval from the fellowship. Only the most-endorsed proposal is able to transit from Launch to Voting period. The time for the transition is indeterminate, and (with no possibility of canceling endorsements) proposers and endorsers might wait a long time before a referendum is tabled, and getting their deposits back. All proposals will eventually be voted on (given track capacity and deposit are met and the Lead-in period has ended). It allows all proposals to get a chance to be voted on in a timely, predictive manner. Only aye or nay votes possible. Voters can have the additional voting options of abstaining or splitting votes. More ways to engage in voting and increase turnout. Voters can decide to delegate votes to another account. Voters can use multirole delegations and delegate votes to different accounts depending on origins. More agile delegations tailored by expertise."},{"location":"learn/learn-polkadot-opengov/#referenda","title":"Referenda","text":"<p>Public and Council Referenda in Governance v1</p> <p>With the Council's dissolution, council referenda are no longer present in Polkadot OpenGov.</p> <p>See this page for more information about public referenda in Governance v1.</p> <p>In Polkadot OpenGov all referenda are public. Anyone can start a referendum at any time and do so as often as they wish. Previous features were expanded and improved, most notably Origins and Tracks help facilitate the flow and processing of the submitted referenda. The Technical Fellowship has the option to whitelist referenda that can be then proposed in the track with whitelist origin.</p>"},{"location":"learn/learn-polkadot-opengov/#referenda-timeline","title":"Referenda Timeline","text":"<p>Voting timetable in Governance v1</p> <p>See this page for more information about the voting timetable in Governance v1.</p> <p></p> <p>The figure above provides a summary view of the referenda timeline for Polkadot OpenGov.</p> <p>In (1), when a referendum is initially created, the community can immediately vote on it. However, it is not immediately in a state where it can end or otherwise have its votes counted, approved, and ultimately enacted. Instead, the proposal will stay within a Lead-in Period until it fulfills three criteria:</p> <ul> <li>Proposals must stay within the lead-in period for a pre-defined minimum amount of time. This helps   mitigate against the possibility of \"decision sniping\" where an attacker controlling a substantial   amount of voting power might seek to have a proposal passed immediately after proposing, not   allowing the overall voting population adequate time to consider and participate.</li> <li>There must be enough room for the decision within the origin. Different origins have their limit   on the number of proposals that can be decided simultaneously. Tracks that have more potent   abilities will have lower limits. For example, the Root level Origin has a limit of one, implying   that only a single proposal may be decided on at once.</li> <li>A decision deposit must be submitted. Creating a referendum is cheap as the deposit value consists   of only the value required for the on-chain storage needed to track it. But, having a referendum   reviewed and decided upon carries the risk of using up the limited spots available in the   referenda queue. Having a more significant but refundable deposit requirement makes sense to help   mitigate spam. Failing to submit the decision deposit will lead to a referendum timeout.</li> </ul> <p>Decision Deposit Amounts</p> <p>In Polkadot OpenGov, someone must submit the Decision Deposit for a referendum to enter its Decision Period. The number of tokens required for the Decision Deposit depends on the track\u2019s privilege level. The higher the privilege, the higher the deposit. For example, malicious referenda posted on the Small Tipper track inflict low economic damage to the network. In contrast, malicious referenda on the Root track can inflict more significant harm, such as changing the entire network's runtime.</p> <p>Until they are in the lead-in period, proposals remain undecided. Once the criteria above are met, the referendum moves to the deciding state. The votes of the referendum are now counted towards the outcome.</p> <p>In (2), the proposal enters the Decision Period, where voting can continue. For a proposal to be approved, votes must satisfy the approval and support criteria for at least the Confirmation Period; otherwise, the proposal is automatically rejected. A rejected proposal can be resubmitted anytime and as many times as needed.</p> <p>In (3), approved proposals will enter the Enactment Period, after which proposed changes will be executed.</p> <p>Note how the length of the lead-in, decision, confirmation, and enactment periods vary depending on the track. Root origin track has more extended periods than the other tracks. Also, the number of referenda within each track differs, with the Root origin track only accepting one proposal at a time (see below).</p> <p></p> <p>This directly affects the number of proposals that can be voted on and executed simultaneously. Continuing the comparison between Root and Small Tipper, Small Tipper will allow many proposals on its track to be executed simultaneously. In contrast, Root will allow only one proposal to be on its track. Once the track capacity is filled, additional proposals in the lead-in period will queue until place is available to enter the decision period.</p>"},{"location":"learn/learn-polkadot-opengov/#origins-and-tracks","title":"Origins and Tracks","text":"<p>An Origin is a specific level of privilege that will determine the Track of all referenda executed with that origin. The track is a pipeline in which the proposal lives and proceeds, independent of other origins' tracks. The proposer of the referenda now selects an appropriate Origin for their request based on the proposal\u2019s requirements.</p> <p>Although the track structure is the same for all origins, track parameters are not. Such parameters include:</p> <ul> <li>Maximum Deciding or Capacity: the limit for the number of referenda that can be decided at   once (i.e., the number of tracks within each origin).</li> <li>Decision deposit: the amount of funds that must be placed on deposit to enter the Decision   Period (note that more requirements must be met to enter the Decision Period).</li> <li>Preparation Period: the minimum amount of voting time needed before entering the Decision   Period (given capacity and deposit are met).</li> <li>Decision Period: the time interval during which a proposal's outcome can be decided.</li> <li>Confirmation Period: the minimum amount of time the approval and support criteria must hold   before the proposal is approved and moved to the enactment period. The confirmation period should   start before the end of the decision period.</li> </ul> <p>Example Scenario of an Edge Case</p> <p>A referendum may enter the confirmation period just one block before the decision period ends. In this scenario, the referendum will pass if it satisfies approval and support thresholds for the minimum confirmation period (track-dependent).</p> <ul> <li>Voting Period: The period in which voting is allowed on a referendum, which includes   preparation, decision, and confirmation periods.</li> <li>Minimum Enactment Period: the minimum amount of waiting time before the proposed changes are   applied</li> <li>Approval Curve: the curve describing the minimum % of aye votes as a function of time within   the Decision Period. The approval % is the portion of aye votes (adjusted for conviction) over   the total votes (aye, nay, and abstained).</li> <li>Support Curve: the curve describing the minimum % of all votes in support of a proposal as a   function of time within the Decision Period. The support % is defined as the portion of all votes   (aye and abstained) without conviction over the total possible amount of votes in the system   (i.e., the total active issuance).</li> </ul> <p>For example, a runtime upgrade (requiring a <code>set_code</code> call, if approved) does not have the same implications for the ecosystem as the approval of a treasury tip (<code>reportAwesome</code> call) and therefore, different Origins for these two actions are needed in which different deposits, support, approval, and a minimum enactment periods will be predetermined on the pallet.</p> <p>For detailed information about origin and tracks, and parameter values in Kusama, see this page.</p>"},{"location":"learn/learn-polkadot-opengov/#voluntary-locking-conviction-voting","title":"Voluntary Locking (Conviction Voting)","text":"<p>Conviction Voting Locks created during Gov 1</p> <p>Conviction voting locks in Governance v1 will not be carried over to OpenGov. Voting with conviction in OpenGov will create a new lock (as this will use the <code>convictionVoting</code> pallet), while any existing lock under Governance v1 (using the deprecated <code>democracy</code> pallet) will be left to expire. Delegations under Governance v1 will need to be re-issued under OpenGov.</p> <p>Polkadot utilizes an idea called voluntary locking that allows token holders to increase their voting power by declaring how long they are willing to lock up their tokens; hence, the number of votes for each token holder will be calculated by the following formula:</p> <pre><code>votes = tokens * conviction_multiplier\n</code></pre> <p>The conviction multiplier increases the vote multiplier by one every time the number of lock periods double.</p> <p></p> <p>The maximum number of \"doublings\" of the lock period is set to 6 (and thus 32 lock periods in total). For additional information regarding the timeline of governance events, check out the governance section on the Polkadot Parameters page.</p> <p>Votes are always \"counted\" at the same time (at the end of the voting period), no matter how long the tokens are locked.</p> <p>See below an example that shows how voluntary locking works.</p> <p>Peter: Votes <code>No</code> with 10 DOT for a 32-week lock period =&gt; 10 x 6 = 60 Votes</p> <p>Logan: Votes <code>Yes</code> with 20 DOT for one week lock period =&gt; 20 x 1 = 20 Votes</p> <p>Kevin: Votes <code>Yes</code> with 15 DOT for a 2-week lock period =&gt; 15 x 2 = 30 Votes</p> <p>Even though both Logan and Kevin vote with more DOT than Peter, the lock period for both of them is less than Peter\u2019s, leading to their voting power counting as less.</p> <p>Staked tokens can be used in governance</p> <p>While the tokens are locked, you can still use them for voting and staking. You are only prohibited from transferring these tokens to another account. See the section about OpenGov locks, and learn more about locks on the Balances page.</p>"},{"location":"learn/learn-polkadot-opengov/#approval-and-support","title":"Approval and Support","text":"<p>Adaptive Quorum Biasing is deprecated</p> <p>In Polkadot OpenGov, Adaptive quorum biasing used in Governance V1 has been replaced with the Approval and Support system.</p> <p></p> <p>The figure above provides a summary view of how the approval and support system works during the Decision Period.</p> <p>Once the proposal exits the Lead-in Period and enters the Voting Period, to be approved, it must satisfy the approval and support criteria for the Confirmation Period.</p> <ul> <li>Approval is defined as the share of conviction-weighted aye votes   against the conviction-weighted total of aye and nay votes. The code implementation can be   viewed   here</li> <li>Support is the total number of aye and abstain votes (ignoring any adjustment for   conviction) compared to the total possible votes (active issuance)   that could be made in the system. In case of split votes, only aye and abstain will count.</li> </ul> <p>For example, let us consider a hypothetical example where the total active issuance is 100 DOT.</p> <ul> <li>An account A votes \"Aye\" with 10 DOT with 4x conviction</li> <li>An account B votes \"Nay\" with 5 DOT with 2x conviction</li> <li>An account C votes \"Abstain\" with 20 DOT. (no conviction can be applied to \"Abstain\" votes)</li> </ul> <p>In this scenario, only 35 DOT from the total active issuance participated in voting on the referendum. Now, let us calculate the Approval and Support values for that referendum.</p> <ul> <li>Approval is calculated as (Aye') / (Aye' + Nay\u2019), where Aye' and Nay' are the votes after applying   the conviction multiplier. Hence, Approval = (10 x 4) / (10 x 4 + 5 x 2) = 40/50 which is 80%.</li> <li>Support is calculated as (Aye + Abstain) / (total active issuance), where \"Aye\" and \"Abstain\" are   the votes without the conviction multiplier. Hence, Support = (10 + 20) / 100 which is 30%.</li> </ul> <p>Nay votes are not counted towards Support</p> <p>Support is a measure of voters who turned out either in favor of the referenda or consciously abstained from it. Support does not include nay votes. This avoids edge situations where nay votes could push a referendum into a confirming state. For example, imagine current approval is high (near 100%, way above the approval curve), and current support is just below the support curve. A nay could bump support above the support curve but not reduce approval below the approval curve. Therefore, someone voting against a proposal would make it pass. Hence, a decrease in % of current approval through new votes does not directly translate into increasing support because Support needs to consider nay votes.</p> <p>The figure above shows the following:</p> <ul> <li>Even if the approval threshold is reached (i.e., % of current approval is greater than the   approval curve), the proposal only enters the confirmation period once the support threshold is   also reached (i.e., % current support is greater than the underlying support curve).</li> <li>If the referendum meets the approval and support thresholds for the duration of the confirmation   period, the proposal will be approved and will be scheduled for enactment. Each track has a   default minimum Enactment Period, and the approved referendum needs to wait till the end of it to   be executed. Powerful Tracks like <code>Root</code> enforce a larger Enactment Period to ensure the network   has ample time to prepare for any changes the proposal may bring. The referendum proposers can   also set the enactment period higher than its default value.</li> <li>A referendum may exit the confirmation period when the thresholds are no longer met due to new   Nay votes or a change of existing Aye or Abstain votes to Nay . Each time it exits, the   confirmation period clock is reset. For example, suppose the confirmation period is 20 minutes,   and a referendum enters it just for 5 min before exiting. The next time it enters, it must be   confirmed for 20 minutes (not 15 minutes).</li> <li>It is possible that a referendum meets the approval and support thresholds almost at the end of   the decision period. In this case, even though the decision period elapses, the referendum can   pass if it stays confirming for the duration of the track-specific confirmation period. It is   rejected immediately if it exits the confirmation period after the decision period elapses.</li> <li>The approval curve starts at 100% and gradually decreases to 50%, but never below 50%. Assuming   all the active token supply has voted on a proposal, the conviction vote-weighted support should   always be above 50% to pass.</li> </ul> <p></p> <p>Note that support may not increase monotonically, as shown in the figure, as people might switch votes.</p> <p>Different Origins' tracks have different Confirmation Periods and requirements for approval and support. For additional details on the various origins and tracks, check out this table. With proposals that use less privileged origins, it is far more reasonable to drop the required support to a more realistic amount earlier than those which use highly privileged classes such as <code>Root</code>.</p>"},{"location":"learn/learn-polkadot-opengov/#enactment","title":"Enactment","text":"<p>Enactment in Governance v1</p> <p>See this page for more information about enactment in Governance v1.</p> <p>In Polkadot OpenGov, the proposer suggests the enactment period, but there is also a minimum set for each Origin Track. For example, <code>root</code> Origin approvals require an extended period because of the importance of the changes they bring to the network.</p>"},{"location":"learn/learn-polkadot-opengov/#cancelling-killing-blacklisting","title":"Cancelling, Killing &amp; Blacklisting","text":"<p>Cancelling Referenda in Governance v1</p> <p>See this page for more information about cancelling referenda in Governance v1.</p> <p>Polkadot OpenGov has two origins dedicated to rejecting ongoing referenda: Referendum Canceller and Referendum Killer.</p> <p>Referendum Canceller aims to cancel an already ongoing referendum. When this origin cancels a referendum, the Submission and Decision Deposit are refunded to their originators. An example of when a referendum might be considered to be canceled is if the originator has made some errors in creating the preimage and did not necessarily do anything malicious. Cancellation has a lower Decision Period, and Approval and Support criteria are much easier to meet over time than most other Origins. This is because the cancellation of a referendum usually comes with a sense of urgency.</p> <p>Referendum Killer aims to instantly kill an ongoing referendum, slashing submission and decision deposit (the account(s) that posted these deposits will lose those funds). This origin can be engaged if, for example, a malicious actor submits a referendum on the Root Track to set the code of the chains' runtime to stop block production.</p> <p>The Decision Deposit for the Referendum Killer track itself is high to prevent malicious actors from attempting to slash deposits of good referenda. A subsequent Referendum Killer can kill an existing Referendum Killer.</p> <p>For more information about how to cancel or kill a referendum, see the advanced how-to guides.</p> <p>Blacklisting</p> <p>Blacklisting referenda in Polkadot OpenGov is the same as in Governance v1.</p>"},{"location":"learn/learn-polkadot-opengov/#voting-on-a-referendum","title":"Voting on a Referendum","text":"<p>If you are a voter, it means that you will vote with your tokens on each single referendum.</p> <p>In Governance V1, voters could cast only an aye or nay vote. In Polkadot OpenGov, voters can additionally cast a abstain and split votes. Vote splitting allows voters to allocate different votes for aye, nay, and abstain. Voting with conviction is not possible when abstaining or splitting the votes.</p> <p>Only the last vote counts</p> <p>Voting a second time replaces your original vote, e.g. voting with 10 DOT, then a second extrinsic to vote with 5 DOT, means that you are voting with 5 DOT, not 10 DOT.</p> <p>Note that to successfully cast votes you need to have the existential deposit and some additional funds to pay for transaction fees.</p> <p>In general, you can remove your vote:</p> <ul> <li>While a referendum is ongoing (your vote does not count)</li> <li>After a referendum ended (your vote counts)</li> </ul> <p>If you voted without conviction, there's no conviction lock in either case. If you voted with conviction, you only get a conviction lock if the referendum ended and you voted with the winning side.</p> <p></p> <p>Revoke your delegation on a track if you like to vote on your own</p> <p>If you want to vote on a referendum on a specific track on your own, you will need to revoke any existing delegation on that track (i.e. undelegate). You can have a conviction lock on the track, but you cannot have an active delegation.</p>"},{"location":"learn/learn-polkadot-opengov/#voting-without-conviction","title":"Voting Without Conviction","text":"<p>If you vote without conviction, the referendum is ongoing, and you remove the vote, you can unlock your tokens immediately. If the referendum ended, you can remove your vote and unlock your tokens immediately, regardless of whether you are on the winning or losing side of the referendum. The governance app or interface you used for participating in Polkadot OpenGov should show an option to unlock your tokens.</p>"},{"location":"learn/learn-polkadot-opengov/#voting-with-conviction","title":"Voting with Conviction","text":"<p>If you voted with conviction, the referendum is ongoing, and you removed the vote, you can unlock your tokens immediately. If the referendum ended and you are on the losing side, you can remove your vote and unlock the tokens immediately. However, if you are on the winning side of the referendum, you will get a conviction lock.</p> <p>Conviction locks are calculated from the time the referendum ended but are applied when you remove the vote.</p> <p>For example, if you voted with conviction 1x with 10 DOT, those 10 DOT will be locked for 7 days after the referendum ends (assuming you are on the winning side). If you remove the vote 3 days after the referendum ended, your tokens will be locked for 4 more days. If you remove it on the 8<sup>th</sup> day after the end of the referendum, the tokens can be unlocked right away (after you remove the vote). When you remove the vote, the lock expiration block is calculated and added to the chain state.</p> <p>If you voted on multiple referenda, and you are on the winning side of all those referenda, you will get multiple conviction voting locks for all those referenda. Locks do not stack; the length and size of the lock decides. This means that - assuming you used the same conviction on the same number of tokens - when the conviction lock on the latest referendum (see below, Ref 4) expires, you will be able to unlock your tokens. In the meantime, the previous locks (1 to 3) might have expired, and you can remove those locks (after removing the votes).</p> <p></p> <p>When you delegate your votes, the locking mechanism differs slightly. Please check the next section on Multirole Delegation for more information.</p>"},{"location":"learn/learn-polkadot-opengov/#multirole-delegation","title":"Multirole Delegation","text":"<p>Polkadot OpenGov builds on the vote delegation feature from Governance v1 where a voter can delegate their voting power to another voter. It does so by introducing a feature known as multirole delegation, where voters can specify a different delegate for every class of referendum in the system. Delegation can be done per track, and accounts can choose to select different delegates (or no delegation) for each track.</p> <p>For example, a voter could delegate one entity for managing a less potent referenda class, choose a different delegate for another class with more powerful consequences and still retain full voting power over any remaining classes.</p> <p>Contrary to solo voting, with delegations, any conviction locks are applied as soon as you undelegate, regardless of whether your delegated votes were used for voting during that time. If your delegated votes were used in any ongoing referenda, they would be removed from those referenda when you undelegate. Alternatively, after undelegating, you can delegate to another person or modify your delegation. The only way to modify the delegation is to undelegate and delegate again. You do not have to do this yourself; wallets and extensions should have implemented UI to modify delegation without you knowing this.</p> <p>If you delegate without conviction and you undelegate, you can unlock your tokens immediately. Alternatively, after undelegating, you can always delegate to another person or modify your delegation.</p> <p></p> <p>In the case you delegated with 1x conviction, you undelegate and re-delegate with 2x conviction; the time you undelegate again, you will have created two conviction locks: one for the 1x and one for the 2x conviction. If you re-delegate immediately with 1x conviction and undelegate, you will get a second 1x conviction lock, but the 2x conviction lock will be the one deciding when your token can be unlocked.</p> <p></p> <p>Info</p> <p>If the account delegated votes to different delegates using different convictions, then after undelegating those delegates, there will be different unlocking periods with lengths dependent on the conviction multipliers.</p> <p>Before delegating a specific track, you must remove any vote on that track.</p> <p>It is worth noting that a user delegating their voting power does not imply that the delegate will have control over the funds of the delegating user's account. That delegate's account can vote with a user's voting power but won't be able to transfer balances, nominate a different set of validators, or execute any call other than voting on the tracks defined by the user.</p> <p>The goal of delegations is to ensure the required support for proposals to be enacted is reached while keeping the overall design censorship-free. Also, voters might not have the technical knowledge to judge some referenda or might not have the time to read all referenda. Delegations allow voters to participate in OpenGov hands-free by delegating their voting power to trusted entities.</p>"},{"location":"learn/learn-polkadot-opengov/#resources","title":"Resources","text":"<ul> <li>Democracy Pallet</li> <li>Governance v2</li> <li>Polkadot Direction</li> <li>Kusama Direction</li> <li>PolkAssembly</li> </ul> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about OpenGov.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/","title":"Polkadot Technical Fellowship","text":"<p>The Technical Fellowship is a self-governing body of experts and developers of Polkadot and Kusama networks protocols. It operates on-chain through the Polkadot Collectives system chain and off-chain through the Polkadot Fellows repository.</p> <p>Historical Context</p> <p>The Polkadot Technical Fellowship was established in 2022 and plays an important role in the Polkadot OpenGov. This fellowship replaced the Technical Committee from Polkadot's first iteration of governance, and will be serving both the Polkadot and Kusama networks. This Fellowship is designed to be far broader in membership (i.e. to work well with even tens of thousands of members) and with far lower barriers to entry both in terms of administrative process flow and levels of expertise. For more information, read through the Fellowship Manifesto.</p> <p>Apart from the collectives system chain and the GitHub repository, the Polkadot Technical Fellowship also uses multiple public avenues to discuss updates related to the Polkadot protocol. Their public discussions can be viewed on this chatroom and their monthly meetings are posted to this OpenDev - Polkadot Fellowship Core Dev Call YouTube playlist.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/#technical-fellowship-referenda","title":"Technical Fellowship Referenda","text":"<p>The fellowship's governance model has multiple tracks with their own approval and support parameters, where the votes are weighted by the rank of the member. Members of the Fellowship can vote on any given Fellowship proposal and the aggregated opinion of the members (weighted by their rank) constitutes the Fellowship's collective opinion. The list of current and historic fellowship referenda can be viewed on Polkassembly or Subsquare. The fellowship governance is primarily used for its membership management, approving RFCs and whitelisting Polkadot OpenGov proposals created on the whitelist track.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/#whitelisting","title":"Whitelisting","text":"<p>Polkadot OpenGov allows the Technical Fellowship to authorize an origin known as \"Whitelisted-Caller\" to execute with Root-level privileges for calls approved by the Fellowship (currently only level-three fellows and above can vote for whitelist calls). Note that the fellowship cannot unanimously change the network parameters, conduct rescues or move assets. The whitelisted proposals still have to go through the whole life cycle of an OpenGov referendum and can only be enacted when the referendum passes successfully.</p> <p>The whitelisting process starts as a fellowship referenda with embedded XCM call from the collectives system chain to the Polkadot relay chain. For instance, the Polkadot Fellowship referenda 68 was used to whitelist the Polkadot OpenGov referenda 440.</p> <p></p> <p>Submitting Whitelisted Proposals</p> <p>For more information about how to submit a whitelisted proposal see the dedicated advanced how-to guides.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/#technical-fellowship-ranking-and-salary","title":"Technical Fellowship Ranking and Salary","text":"<p>The Fellowship manifesto outlines the requirements and expectations for individuals to attain and retain any given rank, ranging between 0 to 9. By default, an active account on the collectives system chain has no assigned rank and can be inducted into the Polkadot Technical Fellowship starting with rank 0. The Fellowship Manifesto states that members should receive a monthly allowance on par with gross income in OECD countries. A fellowship RFC was proposed with concrete amounts for each ranked members.</p> Dan Title Annual Salary I Member $10,000 II Proficient $20,000 III Fellow $80,000 IV Architect $120,000 V Architect Adept $160,000 VI Grand Architect $200,000 VII Free Master $200,000 VIII Master Constant $200,000 IX Grand Master $200,000"},{"location":"learn/learn-polkadot-technical-fellowship/#membership-management","title":"Membership Management","text":"<p>The Polkadot technical Fellowship was initially seeded with its members and their corresponding ranks, and got added on to Polkadot's Collectives system chain. All new membership requests will go through the fellowship governance and the procedure is outlined in the section below.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/#becoming-a-member","title":"Becoming a Member","text":"<p>As a member of the Polkadot Technical Fellowship, you are expected to faithfully uphold the below tenets:</p> <ul> <li>Sincerely uphold the interests of Polkadot and avoid actions which clearly work against it.</li> <li>Respect the philosophy and principles of Polkadot.</li> <li>Respect the operational procedures, norms and voting conventions of the Fellowship.</li> <li>Respect fellow Members and the wider community.</li> </ul> <p>Register your interest</p> <p>For new fellowship inductions, Polkassembly has created an interface (still in beta) to apply for the Polkadot Technical Fellowship. This initiative is funded by Polkadot treasury through OpenGov referendum 373</p> <p>The full set of instructions to be inducted to the Polkadot Technical Fellowship are available on the fellowship dasboard.</p>"},{"location":"learn/learn-polkadot-technical-fellowship/#rank-updates","title":"Rank Updates","text":"<p>The Polkadot Technical Fellowship members are expected to provide a periodic evidence to request for retaining their rank or to get promoted to a higher rank. Any fellowship member upto rank 4 can be promoted to the next rank through a fellowship referenda that can be voted by the members who are 2 ranks higher. For instance, the fellowship referenda 64 which promotes a member from rank 1 to rank 2 can only be voted by members whose ranks are greater than or equal to 3. Promotion of the Polkadot Fellowship members from rank 5 needs to be done through an OpenGov referendum. For more information, check the rank updates section on the fellowship dashboard.</p>"},{"location":"learn/learn-polkadotjs/","title":"Polkadot-JS","text":"<p>     Polkadot-JS is for developers and power users only. If you need help using the Polkadot-JS UI, you can contact the            Polkadot Support Team.      </p> \u2716"},{"location":"learn/learn-proxies-pure/","title":"Pure Proxy Accounts","text":"<p>Pure proxies are very different from other proxy types. The proxies we described so far are existing accounts assigned as proxies by a primary account. These proxies act on behalf of the primary account, reducing the exposure of the primary account's private key. Remember, the more often we use an account's private key to sign transactions, the more we expose that key to the internet, increasing the visibility of that account. The purpose of a proxy is thus to draw the attention of potential attackers away from the primary account, as proxies' private keys will be used most of the time to perform actions on behalf of the primary account.</p> <p></p> <p>Pure proxies are new accounts that are created (not assigned) by a primary account. That primary account then acts as any proxy on behalf of the pure proxy. Pure proxies are keyless non-deterministic accounts as they do not have a private key but they have an address that is randomly generated. Also, in some sense, nobody owns a pure proxy as nobody has a private key to control them.</p> <p>Pure proxies were called anonymous proxies</p> <p>Pure proxies are not anonymous because they have an address that is spawned by a primary account acting as any proxy. Even if any proxy changes, it is still possible to find who generated the anonymous proxy by going backward using a block explorer. There was thus the need to change the name of anonymous proxy. People suggested keyless accounts since they do not have a private key and are proxied accounts. However, multisig accounts are also keyless (but deterministic). Moreover, even if anonymous proxies are proxied accounts, they can still act as proxies and control other accounts via proxy calls (see multisig example below). Thus, the name that has been chosen is pure proxy. If you want to know more about the reasoning behind renaming of pure proxies, see the discussion in this PR or the discussion on Polkadot forum.</p>"},{"location":"learn/learn-proxies-pure/#use-of-pure-proxy","title":"Use of Pure Proxy","text":"<p>The use of the pure proxy is strictly bound to the relationship between the pure proxy and the any proxy. Note that the any proxy does not necessarily be the one who created the pure proxy in the first place. Hence, pure proxies are not really owned by somebody, but they can be controlled. Once that relationship between the pure proxy and its any proxy is broken, the pure proxy will be inaccessible (even if visible on the Polkadot-JS UI). Also, pure proxies are non-deterministic, meaning that if we lose one pure proxy, the next one we create from the same primary account will have a different address.</p> <p>Pure proxies cannot sign anything because they do not have private keys. However, although they do not have private keys and cannot sign any transaction directly, they can act as proxies (or better, proxy channels) within <code>proxy.proxy</code> calls (proxy calls). For example, it is possible to have pure proxies within a multisig. Using proxy calls, it is possible to use the any proxy to call the pure proxy, which in turn will do a multisig call. More about this later on.</p> <p>Danger</p> <p>Once you remove the relationship with any proxy, the pure proxy will be inaccessible. Also, pure proxies cannot sign for anything.</p>"},{"location":"learn/learn-proxies-pure/#why-pure-proxy","title":"Why Pure Proxy?","text":"<p>Pure proxies have important benefits that we discuss below:</p> <ul> <li>Enhanced Security: Pure proxies cannot be stolen because they do not have private keys. The   only accounts that have full access to the pure proxies are any proxies. Security can be   further increased if the any proxy is a multi-signature account.</li> <li>Simplified and Secure Account Management: Pure proxies can simplify the management of complex   account relationships at a corporate level.</li> <li>Multi-signature Account Management: Pure proxies are useful to efficiently manage   multi-signature (multisig) accounts. In fact, multi-signature accounts are deterministic, which   means that once a multisig is created the signatories cannot be changed. If one of the signatories   wants to leave the multisig, a new multisig must be created. This is inconvenient, especially at   corporate-level management where the chance of replacing someone within a multisig can be high.   Pure proxies allow keeping the same multisig when the signatories change.</li> </ul> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about pure proxy accounts.</p>"},{"location":"learn/learn-proxies/","title":"Proxy Accounts","text":"<p>Proxies are helpful because they let you delegate efficiently and add a layer of security. Rather than using funds in a single account, smaller accounts with unique roles can complete tasks on behalf of the main stash account. Proxies can be hotter than the initial account, which can be kept cold, but the weight of the tokens in the colder account can be used by the hotter accounts. This increases the security of your accounts by minimizing the number of transactions the cold account has to make. This also drives attention away from the stash account, although it is possible to determine the relationship between the proxy and the proxied account.</p> <p>From the security perspective, we can imagine proxies as bodyguards of a VIP, loyal and ready to risk their lives to ensure the VIP's protection. But proxies are also useful in other contexts such as efficient account management at the corporate level. They also provide an elegant solution to change signatories within multi-signature accounts, and they can be used within proxy calls and nested proxy calls. In this page we will explore all these interesting use cases of proxies within the Polkadot ecosystem.</p> <p>Shown below is an example of how you might use these accounts. Imagine you have one stash account as your primary token-holding account and don't want to access it very often, but you want to participate in staking to earn staking rewards. You could set one of your existing accounts as a staking proxy for that stash account, and use your staking proxy to sign all staking-related transactions.</p> <p></p> <p>Having a staking proxy will make the stash account isolated within the staking context. In other words, the account assigned as a staking proxy can participate in staking on behalf of that stash. Without the proxy you will need to sign all the staking-related transactions with the stash. If the proxy is compromised, it doesn't have access to transfer-related transactions, so the stash account could just set a new proxy to replace it. You can also monitor proxies by setting a time-delay.</p> <p>Creating multiple proxy accounts that act for a single account, lets you come up with more granular security practices around how you protect private keys while still being able to actively participate in the network.</p>"},{"location":"learn/learn-proxies/#proxy-types","title":"Proxy Types","text":"<p>When a proxy account makes a transaction, Polkadot filters the desired transaction to ensure that the proxy account has the appropriate permission to make that transaction on behalf of the proxied account. For example, staking proxies have permission to do only staking-related transactions.</p> <p>When you set a proxy, you must choose a type of proxy for the relationship with the proxied account.</p> <ul> <li>Any: allow any transaction, including balance transfers. In most cases, this should be avoided   as the proxy account is used more frequently than the cold account and is therefore less secure.</li> <li>Non-transfer: allow any type of transaction except   balance transfers (including   vested transfers). Hence, this proxy does not have   permission to access calls in the Balances and XCM pallet.</li> <li>Governance: allow to make transactions related to governance.</li> <li>Nomination pool: allow transactions pertaining to   Nomination Pools.</li> <li>Staking: allow all staking-related transactions. The stash account is meant to stay in cold   storage, while the staking proxy account makes day-to-day transactions like setting session keys   or deciding which validators to nominate. Visit the   Advanced Staking Concepts page for more detailed   information about staking proxies.</li> <li>Identity Judgement: allow registrars to make judgments on an account's identity. If you are   unfamiliar with judgment and identities on chain, please refer to   this page. This proxy can only access <code>provide_judgement</code> call   from the Identity pallet along with the calls from the Utility pallet.</li> <li>Cancel: allow to reject and remove any time-delay proxy announcements. This proxy can only   access <code>reject_announcement</code> call from the Proxy pallet.</li> <li>Spokesperson: Kusama-specific proxy type that only allows <code>remark</code> or <code>remark_with_event</code>   calls.</li> <li>Society: Kusama-specific proxy type that only allows   society-related calls.</li> </ul>"},{"location":"learn/learn-proxies/#proxy-deposits","title":"Proxy Deposits","text":"<p>Proxies require deposits in the native currency to be created. The deposit is required because adding a proxy requires some storage space on-chain, which must be replicated across every peer in the network. Due to the costly nature of this, these functions could open up the network to a Denial-of-Service attack. To defend against this attack, proxies require a deposit to be reserved while the storage space is consumed over the lifetime of the proxy. When the proxy is removed, so is the storage space, and therefore the deposit is returned.</p> <p>The required deposit amount for <code>n</code> proxies is equal to:</p> <p><code>ProxyDepositBase</code> + <code>ProxyDepositFactor</code> * <code>n</code></p> <p>where the <code>ProxyDepositBase</code> is the required amount to be reserved for an account to have a proxy list (creates one new item in storage). For every proxy the account has, an additional amount defined by the <code>ProxyDepositFactor</code> is reserved as well (appends 33 bytes to storage location).</p>"},{"location":"learn/learn-proxies/#time-delayed-proxy","title":"Time-delayed Proxy","text":"<p>We can add a layer of security to proxies by giving them a delay time. The delay will be quantified in blocks. Polkadot has approximately 6 seconds of block time. A delay value of 10 will mean ten blocks, which equals about one minute delay.</p> <p>The proxy will announce its intended action and will wait for the number of blocks defined in the delay time before executing it. Within this time window, the intended action may be canceled by accounts that control the proxy.</p> <p>Announcing <code>n</code> calls using a time-delayed proxy also requires a deposit of the form:</p> <p><code>announcementDepositBase</code> + <code>announcementDepositFactor</code> * <code>n</code></p> <p>where the <code>announcementDepositBase</code> is the required amount to be reserved for an account to announce a proxy call. For every proxy call the account has, an additional amount defined by the <code>announcementDepositFactor</code> is reserved as well.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about proxy accounts. You can find information about creating and removing proxies, and more.</p>"},{"location":"learn/learn-runtime-upgrades/","title":"Runtime Upgrades","text":"<p>Runtime upgrades allow the relay chain, parachains, and solo blockchains built with the Polkadot SDK to change their core business logic (referred to as the runtime) without the need for a hard fork.</p>"},{"location":"learn/learn-runtime-upgrades/#forkless-upgrades","title":"Forkless Upgrades","text":"<p>You may have encountered the term \"hard fork\" before in the blockchain space. A hard fork occurs when a blockchain's logic changes such that nodes that do not include the new changes cannot remain in consensus with nodes that do. Such changes are backward incompatible. Hard forks can be political due to the nature of the upgrades and logistically demanding due to the number (potentially thousands) of nodes in the network that need to upgrade their software. Thus, hard forking is slow, inefficient, and error-prone due to the levels of offline coordination required and, therefore, the propensity to bundle many upgrades into one large-scale event.</p> <p>The usage of WebAssembly in the Polkadot SDK (the framework powering Polkadot, Kusama and their respective parachains), give the relay chain, its parachains, as well as any other standalone solo chains built with the Polkadot SDK the ability to upgrade their runtime (the chain's \"business logic\") without a hard fork of the respective network.</p> <p>Rather than encoding the runtime in the nodes, Polkadot nodes contain a WebAssembly execution host. They maintain consensus on a very low-level and well-established instruction set. Upgrades can be small, isolated, and very specific by deploying WebAssembly on-chain and having nodes auto-enact the new logic at a particular block height.</p> <p>The runtime is stored on the blockchain itself. Polkadot can upgrade its runtime by upgrading the logic stored on-chain and removes the coordination challenge of requiring thousands of node operators to upgrade in advance of a given block number. Polkadot stakeholders propose and approve upgrades through the on-chain governance system, which also enacts them autonomously once the runtime upgrade referendum is approved through on-chain voting.</p> <p>As a result of storing the runtime as part of the state, the runtime code itself becomes state sensitive, and calls to runtime can change the runtime code itself. Therefore, the Polkadot Host must always ensure it provides the runtime corresponding to the state in which the entry point has been called.</p>"},{"location":"learn/learn-runtime-upgrades/#forkless-upgrades-parachains-solo-chains","title":"Forkless Upgrades - Parachains &amp; Solo Chains","text":"<p>The node architectural design for parachains and solo chains is similar to that of the relay chain, with the runtime code being a Wasm blob that is stored in chain state. Solo chains built with Polkadot SDK, which are blockchains that have a native consensus mechanism that is independent of the relay chain's consensus, can be updated through an on-chain governance system like OpenGov or a simple sudo/multisig setup.</p> <p>Parachains must notify the relay chain whenever a new upgrade is to be enacted. This is done using two key extrinsics:</p> <ul> <li><code>system.authorizeUpgrade</code> -   notifies the relay chain that an upgrade is to take place, and thus a new state transition   function is going to be introduced for that parachain to be validated with.</li> <li><code>system.applyAuthorizedUpgrade</code> -   enacts the upgrade, assuming it has been approved.</li> </ul>"},{"location":"learn/learn-runtime-upgrades/#client-releases","title":"Client Releases","text":"<p>The existing runtime logic is followed to update the Wasm runtime stored on the blockchain to a new version. The upgrade is then included in the blockchain itself, meaning that all the nodes on the network execute it. Generally, there is no need to upgrade your nodes manually before the runtime upgrade, as they will automatically start to follow the new logic of the chain. Nodes only need to be updated when the runtime requires new host functions, or there is a change in networking or consensus.</p> <p>Transactions constructed for a given runtime version will not work on later versions. Therefore, a transaction constructed based on a runtime version will not be valid in later runtime versions. If you can\u2019t submit a transaction before the upgrade, it is better to wait and construct it afterward.</p> <p>Although upgrading your nodes is generally not necessary to follow an upgrade, we recommend following the Polkadot releases and upgrading promptly, especially for high-priority or critical releases.</p> <p>New Client Releases</p> <p>The details about the latest client releases can be found in the releases section on the Polkadot repository. A detailed analysis for client releases can be viewed on the Polkadot Forum.</p>"},{"location":"learn/learn-runtime-upgrades/#runtime-vs-client-versions","title":"Runtime vs Client versions","text":"<p>The runtime and client versions are distinct from each other. The runtime versioning typically looks like <code>network-xxxx</code>, whereas the client versioning looks like <code>vx.x.xx</code>. For instance, the runtime version shown on the top left section of Polkadot-JS UI below is <code>kusama-9370</code>, and the client (node) version shown on the top right section is <code>v0.9.36</code>.</p> <p></p> <p>Querying runtime and client versions</p> <p>The runtime version can be queried on-chain through Polkadot-JS UI by navigating to the Developer tab &gt; Chain State &gt; Storage &gt; system and query <code>lastRuntimeUpgrade()</code>.</p> <p>The node version can be queried by navigating to the Developer tab &gt; RPC calls &gt; system and query <code>version()</code>.</p>"},{"location":"learn/learn-runtime-upgrades/#runtime-upgrades-for-various-users","title":"Runtime Upgrades for Various Users","text":""},{"location":"learn/learn-runtime-upgrades/#for-infrastructure-providers","title":"For Infrastructure Providers","text":"<p>Infrastructure services include but are not limited to the following:</p> <ul> <li>Validators</li> <li>API services</li> <li>Node-as-a-Service (NaaS)</li> <li>General infrastructure management (e.g. block explorers, custodians)</li> <li>Wallets</li> </ul> <p>For validators, keeping in sync with the network is key. At times, upgrades will require validators to upgrade their clients within a specific time frame, for example, if a release includes breaking changes to networking. It is essential to check the release notes, starting with the upgrade priority and acting accordingly.</p> <p>General infrastructure providers, aside from following the runtime releases and upgrading in a timely manner, should monitor changes to runtime events and auxiliary tooling, such as the Substrate API Sidecar.</p> <p>Transactions constructed for runtime <code>n</code> will not work for any other runtime <code>&gt;n</code>. If a runtime upgrade occurs before broadcasting a previously constructed transaction, you will need to reconstruct it with the appropriate runtime version and corresponding metadata.</p>"},{"location":"learn/learn-runtime-upgrades/#for-nominators","title":"For Nominators","text":"<p>Runtime upgrades don't require any actions by a nominator, though it is always encouraged to keep up-to-date and participate with the latest runtime upgrade motions and releases while keeping an eye on how the nodes on the network are reacting to a new upgrade.</p>"},{"location":"learn/learn-runtime-upgrades/#monitoring-runtime-changes","title":"Monitoring Runtime Changes","text":"<p>You can monitor the chain for upcoming upgrades. The client release notes include the hashes of any proposals related to any on-chain upgrades for easy matching. We recommend keeping track of the Polkadot Fellowship's runtime upgrades to be aware of changes in the runtime logic.</p> <p>Runtime upgrades are voted on and executed via Polkadot OpenGov. You should monitor the relay chain as follows to know when the next runtime upgrade will be enacted:</p> <ol> <li>Check each block for <code>referenda (Submitted)</code> events and check if the <code>track</code> is <code>0</code> or <code>1</code>, which    correspond to the <code>Root</code> and <code>whitelistedCaller</code> tracks, respectively. These are the only tracks    that can enact runtime upgrdes. Log the referendum's <code>index</code>; this will help you keep track of    the its progress. With the index you can look up the details of the proposal in    Polkassembly.io to    see if it corresponds with a runtime upgrade.</li> <li>Ongoing referenda will have an <code>enactment</code> field under <code>referenda.ReferendumInfoFor</code> storage.    This is the block number that, if passed, the system will attempt to schedule the inner    proposal's execution for. Note that there are some constraints like a minimum enactment period    that could result in the proposal's execution occurring later. It is not possible for the    proposal to enact before this block number.</li> <li>Check also for <code>referenda (DecisionDepositPlaced)</code> events where <code>index</code> matches the one    previously found. This means that the required deposit has been placed.</li> <li><code>referenda (DecisionStarted)</code> indicates that the decision period has started for the referendum    of that <code>index</code>.</li> <li><code>referenda (ConfirmStarted)</code> indicates that <code>index</code>'s referendum has entered the confirmation    period.</li> <li><code>referenda (Confirmed)</code> indicates that <code>index</code>'s referendum has been confirmed and will enter       the enactment period. With this and <code>enactment_moment</code>, you can calculate when the proposal       will be enacted.</li> <li><code>referenda (Rejected)</code> indicates that <code>index</code>'s referendum has been rejected and will not be       enacted.</li> <li>When the runtime upgrades, there will be a <code>system(CodeUpdated)</code> event confirming the execution    of the runtime upgrade.</li> </ol>"},{"location":"learn/learn-safrole/","title":"Polkadot Block Production: SAFROLE","text":"<p>SAFROLE (formerly known as SASSAFRAS) is a SNARK-based block production algorithm that provides anonymity in the validator selection process. SAFROLE also aims to deliver (nearly) fork-free, constant time block production. SAFROLE is an upgrade to BABE, the block production portion of the hybrid consensus model that Polkadot uses (and later JAM).</p> <p>zkSNARKs, in conjunction with a RingVRF, are used to ensure that slots are not preassigned to malicious actors that are not part of the active validator set. Using a zkSNARK would allow anonymity to be preserved when a validator submits a ticket, proving they are in the active set without revealing their identity. This solution enables a validator to prove they are part of an eligible group (via the RingVRF) while preserving anonymity within the block production mechanism and preventing the likelihood of spam.</p> <p>Part of how SAFROLE minimizes the possibility of forks is by limiting the possibility of multiple valid authors per six-second timeslot (the time to produce a block) where a valid, possible author must only be a single key-holder from within a pre-specified group of validators. In other words, it limits the possibility of two heads of the chain (built on the same parent) forming. More on how SAFROLE prevents forks can be found in Section 4.3, 4.8, and 6 of the JAM Graypaper.</p>"},{"location":"learn/learn-safrole/#resources","title":"Resources","text":"<ul> <li>The JAM Graypaper (see: Block Production and Chain Growth)</li> <li>Web3 Foundation Research Page (SASSAFRAS)   about SASSAFRAS.</li> </ul>"},{"location":"learn/learn-snowbridge/","title":"Snowbridge","text":"<p>Using Snowbridge</p> <p>Snowbridge can be accessed through the web app, where you may track processing times of transactions, recent transfers, and other information about the bridge's overall status.</p> <p>Snowbridge by Snowfork is a general-purpose, trustless bridge between Polkadot and Ethereum. It utilizes the Bridge Hub system parachain to establish a connection to its relayers, allowing for permissionless and trustless messaging between Ethereum and Polkadot.</p> <p>With Snowbridge, a sender can (but does not need to) run a relayer to ensure that their cross-chain transaction is successful. A sender is a user using relayers provided by others.</p> <p>Snowbridge currently supports two-way token transfers between Ethereum and Polkadot parachain.</p>"},{"location":"learn/learn-snowbridge/#random-sampling-beefy","title":"Random-sampling BEEFY","text":"<p>A trustless bridge always has a prover (needs to compute the proof), a verifier (asks the prover to compute the proof and verifies it), and relayers to relay messages. Snowbridge prover uses BEEFY, a novel bridge protocol drastically reducing operational costs without compromising security.</p> <p>Even with simplifications ushered in by BEEFY, a smart contract updating Polkadot's state on Ethereum has to perform 201 signature checks for every update since there are ~300 validators on Polkadot. This remains expensive (gas costs), especially as the validator set grows. The solution is random-sampling BEEFY that leverages the RANDAO randomness beacon as follows:</p> <ul> <li>Commit: Relayer submits a state commitment of a recently finalized block on Polkadot and   claims to have a super-majority of validator\u2019s signatures to the light client deployed on   Ethereum. It also provides one validator signature backing the commitment, which can be slashed if   needed.</li> <li>Challenge: Light client queries on-chain randomness (RANDAO) to subsample <code>m</code> (~25) signatures   from the list Relayer\u2019s claimed list.</li> <li>Response: Relayer responds by sharing exactly those <code>m</code> signatures that were randomly sampled   which the light client then verifies. If everything checks out, the finalized block is accepted.</li> </ul> <p>The number of signature checks needed is significantly reduced and independent of the validator set size, making the protocol more efficient. The number of subsampled signatures, <code>m,</code> is the parameter that trades off security and efficiency (i.e., security parameter). The value of this parameter is derived using crypto-economic arguments.</p>"},{"location":"learn/learn-snowbridge/#snowbridge-crypto-economic-security","title":"Snowbridge Crypto-economic Security","text":"<p>If up to a third of the validators are malicious, the chance that all <code>m</code> signatures subsampled are from these bad actors is <code>(1/2)^m</code> (exponentially low). Any validator who supports a malicious commitment faces severe penalties. The expected value of an attack <code>E(A)</code> is:</p> <pre><code>E(A) = p * V + (1 - p)*(-S)\n</code></pre> <p>Where <code>V</code> is the value of attack (bounded by market capitalization), <code>S</code> is the validator slashable stake, and <code>p</code> is the probability of a successful attack.</p>"},{"location":"learn/learn-snowbridge/#snowbridge-assumptions","title":"Snowbridge Assumptions","text":"<p>Snowbridge relies on two major assumptions:</p> <ul> <li> <p>The crypto-economic assumption that an adversary is rational, i.e., an attack is launched only if   the expected value of an attack is positive. Hence, we derive our security parameter <code>m</code> by   ensuring the expected value of an attack is negative, i.e., <code>E(A) &lt; 0</code>.</p> </li> <li> <p>RANDAO unpredictability. The Web3 Foundation research team performed a thorough analysis of RANDAO   bias and extended the state-of-the-art in analysing the last-revealer attack on RANDAO. Assuming   \u2153rd of Ethereum validators are malicious, the effect of such bias is mitigated by proportionally   increasing the security parameter.</p> </li> </ul>"},{"location":"learn/learn-snowbridge/#resources","title":"Resources","text":"<ul> <li>Medium article   \"Random Sampling BEEFY: Pillaring the trust-less Snowbridge\"   by Bhargav Bhatt at Web3 Foundation</li> <li>Snowbridge GitHub repository</li> <li>Web3 Foundation Research Repository</li> </ul>"},{"location":"learn/learn-spree/","title":"SPREE","text":"<p>Shared Protected Runtime Execution Enclaves (SPREE) sometimes referred to as \"trust wormholes,\" are fragments of logic comparable to runtime modules in Substrate, but live on the relay chain and maybe opted into by parachains.</p> <p>SPREE in brief was described with the following properties and functions:</p> <ul> <li>Parachains can opt-in to special runtime logic fragments (like smart contracts).</li> <li>These fragments have their own storage and own XCM endpoint.</li> <li>All instances across parachains have identical logic.</li> <li>It executes alongside parachain logic.</li> <li>Protected: storage can not be altered by parachain logic; messages can not be faked from them by   parachains.</li> </ul>"},{"location":"learn/learn-spree/#origin","title":"Origin","text":"<p>On 28 March, 2019 u/Tawaren, a member of the Polkadot community, made a post on r/dot called \"SmartProtocols Idea\" and laid out a proposal for Smart Protocols. The core insight of the post was that XCMP had a complication in that it was difficult to verify and prove code was executed on a parachain without trust. A solution was to install the SmartProtocols in the relay chain that would be isolated blobs of code with their own storage per instance that could only be changed through an interface with each parachain. SmartProtocols are the precursor to SPREE.</p>"},{"location":"learn/learn-spree/#what-is-a-spree-module","title":"What is a SPREE module?","text":"<p>SPREE modules are fragments of logic (in concrete terms they are blobs of WebAssembly code) that are uploaded onto Polkadot through a governance mechanism or by parachains. Once the blob is uploaded to the relay chain, all other parachains can decide to opt-in to the logic. The SPREE module would retain its own storage independent of the parachain, but would be callable through an interface with the parachain. Parachains will send messages to the SPREE module synchronously.</p> <p>SPREE modules are important to the overall XCMP architecture because they give a guarantee to the code that will be executed on destination parachains. While XCMP guarantees the delivery of a message, it does not guarantee what code will be executed, i.e. how the receiving parachain will interpret the message. While XCMP accomplishes trustless message passing, SPREE is the trustless interpretation of the message and a key part of the usefulness of XCMP.</p> <p>SPREE modules are like recipes in cookbooks. For example, if we give an order to a cook to make a souffl\u00e9, and we\u2019re decently confident in the ability of the cook, we have a vague idea of what will be made but no actual surety of how it will be made. However, let\u2019s say that a cook has the \u201cSouffl\u00e9 Maker\u2019s Manual\u201d on their bookshelf and has committed themselves to only make souffles from this book. Now we can also consult the same book that the cook has, and we have a precise understanding of what will happen when we tell the cook to make a souffl\u00e9. In this example, \u201cmake a souffl\u00e9\u201d was the message in XCMP and the cookbook was the SPREE module.</p> <p>In concrete terms, SPREE modules could be useful for various functionality on Polkadot. One suggested use case of SPREE modules is for a trustless decentralized exchange that is offered as functionality to any parachain without any extra effort from parachain developers. One can imagine this working by having a SPREE module that exposes the interface for the incrementing and decrementing of balances of various assets based on a unique identifier.</p>"},{"location":"learn/learn-spree/#why","title":"Why?","text":"<p>Sending messages across parachains in XCMP only ensures that the message will be delivered but does not specify the code that will be executed, or how the message will be interpreted by the receiving parachain. There would be ways around this such as requesting a verifiable receipt of the execution from the receiving parachain, but in the naked case, the other parachain would have to be trusted. Having shared code that exists in appendices that the parachain can opt-in to resolves the need for trust and makes the execution of the appendices completely trustless.</p> <p>SPREE would be helpful to ensure that the same logic is shared between parachains in the SPREE modules. An especially relevant use case would revolve around the use of token transfers across parachains in which it is important that the sending and receiving parachains agree about how to change the total supply of tokens and a basic interface.</p>"},{"location":"learn/learn-spree/#example","title":"Example","text":"<p>The diagram above is a simplification of the Polkadot system.</p> <p>In this diagram, we see that the Wasm code for SPREE module \"X\" has been uploaded to the relay chain. The two cylinders \"A\" and \"B\" represent two distinct parachains that have both opted-in to this SPREE module creating two distinct instances of it with their own XCMP endpoints \"A.X\" and \"B.X\".</p> <p>In the example, we assume that this SPREE module \"X\" contains the functionality for incrementing or decrementing the balance of a particular asset that is unique to this module.</p> <p>By initiating a transaction at A.X to decrease a particular balance by 1, a message over XCMP can be trustlessly sent to B.X to increase a balance by 1.</p> <p>Collators, represented as the green triangle are responsible for relaying this message from parachain A to parachain B, as well as maintaining the storage for each particular instance of A.X and B.X for their respective parachains. They provide proofs of valid state transitions to the Relay Chain validators represented as blue diamonds.</p> <p>Validators can validate the correct state transitions of SPREE modules A.X and B.X by being provided with the previous state root of the SPREE module instances, the data of the XCMP message between the instances, and the next state root of the instance. They do this validation by checking it against the <code>validate</code> function as provided by the SPREE module API. Collators are expected to be able to provide this information to progress their parachains.</p>"},{"location":"learn/learn-staking-advanced/","title":"Advanced Staking Concepts","text":"<p>New to Staking?</p> <p>Start your staking journey or explore more information about staking on Polkadot's Home Page. Discover the new Staking Dashboard that makes staking much easier and check this extensive article list to help you get started. You can now stake natively with a small number of tokens and earn staking rewards. For additional information, check out this blog post.</p> <p>This page is meant to be an advanced guide to staking with the relay chain. For a more general introduction, checkout the Introduction to Staking page.</p>"},{"location":"learn/learn-staking-advanced/#staking-proxies","title":"Staking Proxies","text":"<p>Polkadot makes it possible to create accounts having special permissions also called proxy accounts. For more details about proxy accounts visit the dedicated page on this wiki.</p> <p>Proxy accounts are special accounts which can sign extrinsic calls made to specific pallets on behalf of the proxied account. There is thus the possibility to create staking proxy accounts that can be used to sign extrinsic calls specific to the staking, session and utility pallets.</p> <p>Staking is not a set-and-forget action, as a nominator you will need to monitor the performance of your validators and make changes if needed. There will be this transactions such as nominating that will be needed to regularly signed. Each time you sign with an account, in the case of hot accounts, you expose the private key of that account to the internet with consequent risk of attack. A hot stash will be exposed all the time a transaction is signed. Even in the case of a cold stash created with a Ledger device, signing with the stash will build a transaction history that might tell something about your habits and preferences, or even your location.</p> <p>Ideally, accounts with high economic power like the stash must be and remain as isolated as possible. With a staking proxy, the stash account is fully isolated when signing for staking-related transactions. The proxy private key will be used to sign staking-related transactions, the stash private key will stay isolated and the staking transaction history will be built by the proxy.</p> <p></p> <p>For a practical perspective we need to use only one account and remember one password to sign for all staking-related transactions. From a security perspective who controls the staking proxy controls our staking actions.</p> <p>It is important to remember that actions that can be performed by the proxy accounts are limited, and in the case of staking proxy, extrinsic calls to the balances pallet cannot be signed. This means it is not possible to do balance transfers on the proxied account through a staking proxy.</p> <p>Note that to change the staking proxy you will need to sign with the stash or an any proxy.</p>"},{"location":"learn/learn-staking-advanced/#bags-list","title":"Bags List","text":"<p>Info</p> <p>On Polkadot and Kusama, the instance of the pallet Bags-List is named as 'voterList'.</p> <p>For a demo about bags list see this video tutorial.</p> <p>In Polkadot's NPoS nomination intents are placed in a semi-sorted list called bags-list. The Bags-List substrate pallet is designed to be self-maintaining, with minimal effort from the blockchain, making it extremely scalable. The bags list has two primary components, bags and nodes (or nominators' accounts), with bags containing the nodes with bonded balance within a specific range. In the figure below the 1<sup>st</sup> empty bag will contain nominators whose bonded balance is in the range of 21 - 30 DOT, the 2<sup>nd</sup> bag 11 - 20 DOT, and the 3<sup>rd</sup> bag 0-10 DOT. The nomination intents are the nominators' accounts with bonded tokens (in the example shown below, there are eight nomination intents) that will be put inside each of those three bags depending on their stake.</p> <p></p> <p>The bags list is semi-sorted, meaning that sorting is only partially done. When the nomination intents are submitted to the network, they are automatically put into each bag based on the number of bonded tokens, but within each bag, those nodes are arranged based on the time they are inserted and not based on their stake (see figure below). When the nomination intent of 19 DOT is submitted, it gets placed at the last spot in the 2<sup>nd</sup> bag (shown in the green circle). The same scenario applies for the node with 8 DOT (yellow circle) in the 3<sup>rd</sup> bag. Placing the node above all nodes with a lesser stake requires an additional step (more on this later).</p> <p></p> <p>The mentioned two nodes (19 DOT and 8 DOT) have the option to move up in their respective bags, which can put them in front of the nodes with less stake than them (see figure below). This action must be done manually by submitting the <code>putInFrontOf</code> extrinsic within the <code>voterList</code> pallet instance. Moreover, if the node with 19 DOT bonds an additional 2 DOT, that node will be put automatically in the 1<sup>st</sup> bag (i.e. automatic <code>rebag</code>) because the total number of bonded tokens will now be within the range of the 1<sup>st</sup> bag. That node with now 21 DOT will be put at the tail end of the 1<sup>st</sup> bag with the possibility to manually put itself in front of \"older\" nodes with less than 21 DOT (if there are any).</p> <p></p> <p>If one decides to send staking rewards to the stash account and automatically bond them (i.e. compounding the staking rewards), the position within a bag does not change automatically. The same scenario applies to a slashing event, i.e., when a nominator gets slashed, their position within a bag does not change. This might result in a scenario where the node is in the wrong bag and needs to be placed in the right bag. To address this issue, any account on-chain can submit the permissionless extrinsic <code>rebag</code> within the <code>voterList</code> pallet instance to update the positions of the nodes that do not belong to their bag and place them in the correct one. To reiterate, actions like bonding/unbonding tokens automatically rebag the nominator node, but events like staking rewards/slashing do not. See the bags-list section for more information.</p> <p>The bags-list is capable of including an unlimited number of nodes, subject to the chain's runtime storage. In the current staking system configuration, at most 22500 nominators in the bags-list (12500 on Kusama) come out as the electing nominators. See Staking Election Stages section for more info.</p> <p>This means that only a portion of the nomination intents is kept. Once the nomination period ends, the NPoS election system takes all nomination intents and their associated votes as input, and it outputs a set of validators. The bags are iterated from the most staked to the least staked. If the accounts are not appropriately sorted, this could leave the last touched bag to only be partially iterated. Thus, in some edge cases, the order of the members within a bag is important. Continuing with the example used in the previous figures, there are 8 nomination intents of which only 7 will be kept. If the bags list stays semi-sorted (i.e. no accounts call the <code>putInFrontOf</code> and <code>rebag</code> extrinsics), the nomination of the node with 8 DOT in the 3<sup>rd</sup> bag will not be considered while that of the preceding node with 5 DOT will be. Nomination of the node with 8 DOT will be kept only if it puts itself in front of the one with 5 DOT. Note how the nomination of the node with 19 DOT in the 2<sup>nd</sup> bag will be considered regardless of changing its position inside the bag. The sorting functionality of nomination intents using bags is extremely important for the long-term improvements of the staking/election system.</p> <p></p> <p>Minimum active nomination threshold to earn rewards is dynamic</p> <p>Submitting a nomination intent does not guarantee staking rewards. The stake of the top 22500 nominators (12500 on Kusama) is applied to the validators in the active set. To avail of staking rewards, ensure that the number of tokens bonded is higher than the minimum active bond. For more information, see the nominator guide.</p> <p>The \"election solution\" which is a connected graph between nominators and validators with the stake as edge weights, has to meet certain requirements, such as maximizing the amount of stake to nominate validators and distributing the stake backing validators as evenly as possible. The objectives of this election mechanism are to maximize the security of the network, and achieve fair representation of the nominators. If you want to know more about how NPoS works (e.g. election, running time complexity, etc.), please read here.</p>"},{"location":"learn/learn-staking-advanced/#rewards-distribution","title":"Rewards Distribution","text":"<p>Info</p> <p>The general rule for rewards across validators is that two validators get paid essentially the same amount of tokens for equal work, i.e. they are not paid proportional to their total stakes. There is a probabilistic component to staking rewards in the form of era points and tips but these should average out over time.</p> <p>Validators are paid the same regardless of stake backing them. Validators with less stake will generally pay more to nominators per-token than the ones with more stake. This gives nominators an economic incentive to gradually shift their preferences to lower-staked validators that gain a sufficient amount of reputation. A consequence of this is that the stake across validators will be as evenly distributed as possible which avoids concentration of power among a few validators. In the long term, validators will have similar levels of stake, with the stake being higher for validators with higher reputation. A nominator who is willing to risk more by backing a validator with a lower reputation will get paid more, provided there are no slashing events.</p> <p>Before distributing rewards to nominators, validators can create a cut of the reward (a commission) that is not shared with the nominators. This cut is a percentage of the block reward, not an absolute value. After the commission gets deducted, the remaining portion is distributed pro-rata based on their staked value and split between the validator and all of the nominators whose stake has backed this validator.</p> <p>For example, assume the block reward for a validator is 10 DOT. A validator may specify <code>validator_commission = 50%</code>, in which case the validator would receive 5 DOT. The remaining 5 DOT would then be split between the validator and their nominators based on the proportion of stake each nominator had. Note that for this calculation, validator's self-stake acts just as if they were another nominator.</p> <p>Thus, a percentage of the reward goes thus to pay the validator's commission fees and the remainder is paid pro-rata (i.e. proportional to stake) to the nominators and validator. If a validator's commission is set to 100%, no tokens will be paid out to any of the nominators. Notice in particular that the validator is rewarded twice: once in commission fees for validating (if their commission rate is above 0%), and once for nominating itself with own stake.</p> <p>The following example should clarify the above. For simplicity, we have the following assumptions:</p> <ul> <li>These validators do not have a stake of their own.</li> <li>They each receive the same number of era points.</li> <li>There are no tips for any transactions processed.</li> <li>They do NOT charge any commission fees.</li> <li>Total reward amount is 100 DOT tokens.</li> <li>The current minimum amount of DOT to be a validator is 350 (note that this is not the actual   value, which fluctuates, but merely an assumption for purposes of this example; to understand how   the actual minimal stake is calculated, see   here).</li> </ul> Validator A Nominator (4) Stake (600) Fraction of the Total Stake Rewards Jin 100 0.167 16.7 Sam 50 0.083 8.3 Anson 250 0.417 41.7 Bobby 200 0.333 33.3 Validator B Nominator (4) Stake (400) Fraction of the Total Stake Rewards Alice 100 0.25 25 Peter 100 0.25 25 John 150 0.375 37.5 Kitty 50 0.125 12.5 <p>Both validators A &amp; B have 4 nominators with a total stake 600 and 400 respectively.</p> <p>Based on the above rewards distribution, nominators of validator B get more rewards per DOT than those of validator A because A has more overall stake. Sam has staked 50 DOT with validator A, but he only gets 8.3 in return, whereas Kitty gets 12.5 with the same amount of stake.</p> <p>To estimate how many tokens you can get each month as a nominator or validator, you can use this tool as a reference and play around with it by changing some parameters (e.g. how many days you would like to stake with your DOT, provider fees, compound rewards, etc.) to have a better estimate. Even though it may not be entirely accurate since staking participation is changing dynamically, it works well as an indicator.</p>"},{"location":"learn/learn-staking-advanced/#commission-fees-slashes","title":"Commission Fees &amp; Slashes","text":"<p>The network slashes a validator for a misbehavior. The slashed amount is a fixed percentage (and not a fixed amount), which means that validators with more stake get slashed more DOT. Again, this is done to provide nominators with an economic incentive to shift their preferences and back less popular validators whom they consider to be trustworthy.</p> <p>Also, note that each validator candidate is free to name their desired commission fee (as a percentage of rewards) to cover operational costs. Since validators are paid the same, validators with lower commission fees pay more to nominators than validators with higher fees. Thus, each validator can choose between increasing their fees to earn more, or decreasing their fees to attract more nominators and increase their chances of being elected. In the long term, we expect that all validators will need to be cost-efficient to remain competitive, and that validators with higher reputation will be able to charge slightly higher commission fees (which is fair).</p>"},{"location":"learn/learn-staking-advanced/#simple-payouts","title":"Simple Payouts","text":"<p>Polkadot makes stakers claim their rewards for past eras by submitting a transaction. This naturally leads to spreading out reward distribution, as people make transactions at disparate times, rather than updating the accounts of all stakers in a single block.</p> <p>Even if everyone submitted a reward claim at the same time, the fact that they are individual transactions would allow the block construction algorithm to process only a limited number per block and ensure that the network maintains a constant block time. If all rewards were sent out in one block, this could cause serious issues with the stability of the network.</p> <p>Simple payouts require one transaction per validator, per era, to claim rewards. The reason Polkadot requires this is to avoid an attack where someone has several thousand accounts nominating a single validator. The major cost in reward distribution is mutating the accounts in storage, and Polkadot cannot pay out several thousand accounts in a single transaction.</p>"},{"location":"learn/learn-staking-advanced/#claiming-rewards","title":"Claiming Rewards","text":"<p>The relay chain stores the last 84 eras of reward information (e.g. maps of era number to validator points, staking rewards, nomination exposure, etc.). Rewards will not be claimable more than 84 eras after they were earned. This means that all rewards must be claimed within a maximum of 84 eras, although under certain circumstances (described below) this may be as low as 28 eras.</p> <p>If a validator kills their stash, any remaining rewards will no longer be claimable. Before doing this, however, they would need to first stop validating and then unbond the funds in their stash, which takes 28 eras. If a validator were to immediately chill and start unbonding after rewards are calculated, and nobody issued a payout for that era from that validator in the next 28 eras, the reward would no longer be claimable.</p> <p>Advanced How-to Guides</p> <p>In order to be absolutely sure that staking rewards can be claimed, users should trigger a payout before 28 eras have passed. See this page for more information about how to claim rewards using the Polkadot-JS UI.</p>"},{"location":"learn/learn-staking-advanced/#faq-and-cautionary-notes","title":"FAQ and Cautionary Notes","text":"<ol> <li>Rewards expire after 84 eras. On Polkadot, that's about 84 days. On Kusama, it is approximately    21 days. Validators should claim all pending rewards before killing their stash in the event the    validator decides to <code>chill</code> -&gt; <code>unbonds all</code> -&gt; <code>withdraws unbonded</code>. Nominators will not miss    out on rewards if they claim the pending rewards for a validator within 28 days. Essentially, the    deadline to ensure you get staking rewards is 28 eras. If the validator verifies its intent and    does not unbond and withdraw, the 84 era timeline holds.</li> <li>Claiming rewards (or neglecting to claim rewards) does not affect nominations in any way.    Nominations will persist after claiming rewards or after the rewards expire.</li> <li>Rewards are not minted until they are claimed. Therefore, if your reward destination is \"stash,    increasing amount at stake\", then your staked amount does not reflect your rewards until you    claim them. If you want to maximize compounding, then you will need to claim often or nominate    validators which regularly claim for you.</li> <li>Staking operations at the end of an era are closed to allow the off-chain validator election to    take place. See Off-chain Phragm\u00e9n for more information.</li> </ol>"},{"location":"learn/learn-staking-advanced/#staking-miner","title":"Staking Miner","text":"<p>Caution</p> <p>The staking-miner code is experimental and it is still in the development phase. Use is at your own discretion, as there is a risk of losing some funds.</p> <p>At the end of each era on Polkadot and Kusama, using NPoS, a new set of validators must be elected based on the nominator preferences. This is a computationally intensive process, hence the usage of the term \"mining\" for computing the solution. The validators use off-chain workers to compute the result and submit a transaction to propose the set of winners. This can also be delegated to stand-alone programs, whose task is to mine the optimal solution. Staking miners compete with each other to produce election solutions which consist of a validator set, stake distribution across that set, and a score indicating how optimal the solution is. Staking miners run any given staking algorithms (as of now, sequential Phragm\u00e9n or PhragMMS, subject to change if improved algorithms are introduced) to produce results, which are then sent as a transaction to the relay chain via a normal signed extrinsic. The transaction requires a bond and a transaction fee. The best solution is rewarded, which the least covers the transaction fee, and the bond is returned to the account. The bond and the fee are lost if the solution is invalid.</p> <p>Staking miner uses a pallet called <code>pallet_election_provider_multi_phase</code> and can only produce solutions during the <code>SignedPhase</code> of the pallet's life cycle. Once the <code>SignedPhase</code> is over and the <code>UnsignedPhase</code> starts, only the off-chain workers can provide election results.</p> <p>Running the staking miner requires passing the seed of a funded account in order to pay the fees for the transactions that will be sent. The same account's balance is used to reserve deposits as well. The best solution in each round is rewarded. All correct solutions will get their deposit back and the ones that submit invalid solutions will lose their deposit.</p>"},{"location":"learn/learn-staking-advanced/#npos-election-optimization","title":"NPoS election optimization","text":"<p>A basic election solution is a simple distribution of stake across validators, but this can be optimized for better distribution equaling a higher security score. The staking miner does not act as a validator and focuses solely on the election result and optimization of the solution. It connects to a specified chain and keeps listening to new signed phase of the election pallet in order to submit solutions to the NPoS election. When the correct time comes, it computes its solution and submits it to the chain. The default miner algorithm is sequential Phragm\u00e9n with a configurable number of balancing iterations that improve the score.</p>"},{"location":"learn/learn-staking-advanced/#signed-phase-of-the-election-pallet","title":"Signed Phase of the election pallet","text":"<p>The election provider pallet <code>pallet_election_provider_multi_phase</code> is divided into two phases, signed and unsigned. At the end of the pallet's timeline, the function <code>elect()</code> is called.</p> <pre><code>                                                                   elect()\n                +   &lt;--T::SignedPhase--&gt;  +  &lt;--T::UnsignedPhase--&gt;   +\n  +-------------------------------------------------------------------+\n   Phase::Off   +       Phase::Signed     +      Phase::Unsigned      +\n</code></pre> <p>Solutions provided by the staking miner can only be submitted during the signed phase. Solutions are submitted and queued on the chain as a <code>RawSolution</code>. Once submitted, a solution cannot be retracted by the originating account.</p> <p><code>RawSolution</code> struct definition:</p> <pre><code>pub struct RawSolution&lt;S&gt; {\n    pub solution: S, // The solution itself\n    pub score: ElectionScore, // The claimed score of the solution.\n    pub round: u32, // The round at which this solution should be submitted.\n}\n</code></pre> <p>A maximum of <code>pallet::Config::SignedMaxSubmissions</code> will be stored on-chain and they will be sorted based on score. Higher the score the more optimal the election solution is. The <code>SignedMaxSubmissions</code> variable can be modified through governance.</p> <p>Upon arrival of a new solution:</p> <ol> <li>If the queue is not full, it is stored in the appropriate sorted index.</li> <li>If the queue is full but the submitted solution is better than one of the queued ones, the worse    solution is discarded, the deposit of the outgoing solution is returned, and the new solution is    stored in the correct index.</li> <li>If the queue is full and the solution is not an improvement compared to any of the queued ones,    it is instantly rejected and no deposit is reserved.</li> </ol> <p>Upon the end of the <code>SignedPhase</code>, no more solutions can be submitted and the solutions in the queue will be checked using <code>Pallet::feasibility_check</code> which ensures the score is indeed correct, and marks them as valid or invalid. By checking each solution in the queue, the queue will be reorganized by score. The highest valid score will be rewarded. Invalid solutions with higher score than the winning solution will be slashed. The rest of the solutions will be discarded and their deposit will be returned. Once the staking miner with a winning solution is ready to be rewarded the runtime will automatically execute <code>finalize_signed_phase_accept_solution</code> which reward account associated with the winning solution.</p> <pre><code>Queue\n+-------------------------------+\n|Solution(score=20, valid=false)| +--&gt;  Slashed\n+-------------------------------+\n|Solution(score=15, valid=true )| +--&gt;  Rewarded, Saved\n+-------------------------------+\n|Solution(score=10, valid=true )| +--&gt;  Discarded\n+-------------------------------+\n|Solution(score=05, valid=false)| +--&gt;  Discarded\n+-------------------------------+\n|             None              |\n+-------------------------------+\n</code></pre>"},{"location":"learn/learn-staking-advanced/#deposit-and-reward-mechanics","title":"Deposit and reward mechanics","text":"<p>The staking miners are required to pay a deposit to post their solutions. Deposit amount is the sum of <code>SignedDepositBase</code> +<code>SignedDepositByte</code> + <code>SignedDepositWeight</code>. All good solutions are subject to receiving a <code>SignedRewardBase</code>. For more information about deposit values see the Chain State Values page.</p>"},{"location":"learn/learn-staking-advanced/#further-resources","title":"Further Resources","text":"<p>If you want to run a staking miner on your validator, refer to the repository provided in the resources section below.</p> <ul> <li>Staking Miner repository</li> <li>Election Pallet definition</li> <li>Signed phase parameter configuration on Polkadot</li> </ul>"},{"location":"learn/learn-staking/","title":"Introduction to Staking","text":"<p>     Nomination Pools are evolving! Soon you'll be able to participate in a pool and in OpenGov with your pooled funds! You do not need to do anything, unless you are participating in a pool and also staking solo from the same account. In this case, please check            this article          on the actions you need to take as soon as possible.    </p> \u2716 <p>New to Staking?</p> <p>Explore Polkadot with a secure and user-friendly wallets listed on the Polkadot website and start your staking journey or explore more information about staking on Polkadot's Staking Page. Discover the new Staking Dashboard that makes staking much easier and check this extensive article list to help you get started. The dashboard supports Ledger devices natively and does not require an extension or wallet as an interface.</p> <p>Stake through Nomination Pools</p> <p>The minimum amount required to become an active nominator (i.e. the minimum active bond) and earn rewards may change from era to era. If you have less tokens than the minimum active nomination and still want to participate in staking, you can join the nomination pools with a minimal bond and earn staking rewards. For additional information, check out this blog post. Check the wiki doc on nomination pools for more information.</p> <p>Here you will learn about what staking is, why it is important, and how it works.</p>"},{"location":"learn/learn-staking/#proof-of-stake-pos","title":"Proof-of-Stake (PoS)","text":"<p>Blockchain networks use consensus mechanisms to finalize blocks on the chain. Consensus is the process of agreeing on something, in this case, the progression of the blockchain or how blocks are added to the chain. Consensus consists of two actions:</p> <ul> <li>Block production, i.e. the way multiple blocks candidates are produced, and</li> <li>Block finality, i.e. the way only one block out of many candidates is selected and added to   the canonical chain (see this article   for more information about finality).</li> </ul> <p>Proof-of-Work (PoW) and Proof-of-Stake (PoS) are well-known mechanisms used to reach consensus in a secure and trustless way on public blockchains, where there are many participants who do not know each other (and probably never will). In PoW, network security relies on the fact that the miners who are responsible for adding blocks to the chain must compete to solve difficult mathematic puzzles to add blocks - a solution that has been criticized for the wastage of energy. For doing this work, miners are typically rewarded with tokens.</p> <p>In PoS networks like Polkadot, the security of the network depends on the amount of capital locked on the chain: the more the capital locked, the lower the chance of an attack on the network, as the attacker needs to incur a heavy loss to orchestrate a successful attack (more on this later on). The process of locking tokens on the chain is called staking.</p> <p>Similar to the miners in PoW networks, PoS networks have validators, but they do not have to compete with each other to solve mathematical puzzles. They are instead pre-selected to produce the blocks based on the stake backing them. Token holders can lock funds on the chain and for doing so, they are getting staking rewards. There is thus an economic incentive for token holders to become active participants who contribute to the economic security and stability of the network. PoS networks in general are therefore more inclusive than PoW networks, as participants do not need to have either technical knowledge about blockchain technology or experience in running mining equipment.</p> <p>PoS ensures that everybody participating in the staking process has \"skin in the game\" and thus can be held accountable. In case of misbehavior, participants in the staking process can be punished or slashed, and depending on the gravity of the situation, their stake can be partly or fully confiscated by the network. It is not in a staker's economic interest to orchestrate an attack and risk losing tokens. Any rational actor staking on the network would want to get rewarded, and the PoS network rewards good behavior and punishes bad behavior.</p>"},{"location":"learn/learn-staking/#nominated-proof-of-stake-npos","title":"Nominated Proof-of-Stake (NPoS)","text":"<p>Polkadot implements Nominated Proof-of-Stake (NPoS), a relatively novel and sophisticated mechanism to select the validators who are allowed to participate in its consensus protocol. NPoS encourages token holders to participate as nominators.</p> <p>Any potential validators can indicate their intention to be a validator candidate. Their candidacies are made public to all nominators, and a nominator, in turn, submits a capped list of candidates that it supports, and the network will automatically distribute the stake among validators in an even manner so that the economic security is maximized. In the next era, a certain number of validators having the highest backing get elected and become active. For more information about the election algorithm go to this page on the wiki or this research article. As a nominator, a minimum bond is required to submit an intention to nominate, which can be thought of as registering to be a nominator. Note that in NPoS the stake of both nominators and validators can be slashed. For an in-depth review of NPoS see this research article.</p> <p>Minimum Nomination to Receive Staking Rewards</p> <p>The minimum nomination intent does not guarantee staking rewards. The nominated amount has to be greater than minimum active nomination, which is a dynamic value that can be much higher than the minimum nomination intent. This dynamic value depends on the amount of tokens being staked, in addition to the selected nominations.</p>"},{"location":"learn/learn-staking/#nominating-validators","title":"Nominating Validators","text":"<p>Nominating requires 2 actions:</p> <ul> <li>Locking tokens on-chain.</li> <li>Selecting a set of validators, to whom these locked tokens will automatically be allocated to.</li> </ul> <p>How many tokens you lock up is completely up to you - as are the validators you wish to select. The action of locking tokens is also known as bonding. You can also refer to your locked tokens as your bonded tokens, or staked tokens. Likewise, selecting validators is also known as backing or nominating validators. These terms are used interchangeably by the community. From now on locked tokens will be referred to as bonded tokens.</p> <p>Once the previous 2 steps are completed and you are nominating, your bonded tokens could be allocated to one or more of your selected validators, and this happens every time the active validator set changes. This validator set is updated every era.</p> <p>Unlike other staking systems, Polkadot automatically chooses which of your selected validators will be backed by your bonded tokens. Selecting a group of validators increases your chances of consistently backing at least one who is active. This results in your bonded tokens being allocated to validators more often, which means more network security and more rewards. This is in strong contrast to other staking systems that only allow you to back one validator; if that validator is not active, you as a staker will also not be.</p> <p>Polkadot's nomination model solves this. It uses tools ranging from election theory to game theory to discrete optimization, to develop an efficient validator selection process that offers fair representation and security, thus avoiding uneven power and influence among validators. The election algorithms are based on the Proportional Justified Representation (PJR) methods like Phragmen. For more information about PJR methods visit this research article.</p>"},{"location":"learn/learn-staking/#eras-and-sessions","title":"Eras and Sessions","text":"<p>The stake from nominators is used to increase the number of tokens held by such candidates, increasing their chance of being selected by the election algorithm for block production during a specific era. An era is a period of 24 hours (6 hours on Kusama) during which an active set of validators is producing blocks and performing other actions on the chain. This means that not all validators are in the active set and such set changes between eras. Each era is divided into 6 epochs or sessions during which validators are assigned as block producers to specific time frames or slots. This means that validators know the slots when they will be required to produce a block within a specific session, but they do not know all the slots within a specific era. Having sessions adds a layer of security because it decreases the chance of having multiple validators assigned to a slot colluding to harm the network.</p>"},{"location":"learn/learn-staking/#staking-rewards","title":"Staking Rewards","text":"<p>Validators who produce a block are rewarded with tokens, and they can share rewards with their nominators. Both validators and nominators can stake their tokens on chain and receive staking rewards at the end of each era. The staking system pays out rewards equally to all validators regardless of stake. Thus, having more stake in a validator does not influence the amount of block rewards it receives. This avoids the centralization of power to a few validators. There is a probabilistic component in the calculation of rewards, so they may not be exactly equal for all validators. In fact, during each era validators can earn era points by doing different tasks on chain. The more the points, the higher the reward for a specific era. This promotes validators' activity on chain. To know more about era points, and how and on which basis they are distributed visit the dedicated page. Distribution of the rewards is pro-rata to all stakers after the validator's commission is deducted.</p>"},{"location":"learn/learn-staking/#skin-in-the-game-when-staking","title":"Skin in the game when Staking","text":"<p>The security of PoS networks depends on the amount of staked tokens. To successfully attack the network, a malicious actor would need to accrue a large number of tokens or would need different participants to collude and act maliciously. If there is an attack in the case of NPoS, both the validator(s) and nominators will be slashed resulting in their stake being partially or fully confiscated by the network and then deposited to the treasury. There is little interest for a rational network participant to act in a harmful way because NPoS ensures that all participants can be held accountable for their bad actions. In NPoS, validators are paid equal rewards regardless of the amount of stake backing them, thus avoiding large payouts to few large validators which might lead to centralization.</p>"},{"location":"learn/learn-staking/#being-a-nominator","title":"Being a Nominator","text":""},{"location":"learn/learn-staking/#tasks-and-responsibilities-of-a-nominator","title":"Tasks and Responsibilities of a Nominator","text":"<p>Validators. Since validator slots are limited, most of those who wish to stake their tokens and contribute to the economic security of the network will be nominators, thus here we focus on the role of nominators. However, it is worth mentioning that validators do most of the heavy lifting: they run the validator nodes and manage session keys, produce new block candidates in BABE, vote and come to consensus in GRANDPA, validate the state transition function of parachains, and possibly some other responsibilities regarding data availability and XCM. For more information, you can take a look at the validator docs to understand what you need to do as a validator. If you want to become a validator you can consult this guide.</p> <p>Nominators. Nominators have far fewer responsibilities than validators. These include selecting validators and monitoring their performance, keeping an eye on changing commission rates (a validator can change commission at any time), and general health monitoring of their validators' accounts. Thus, while not being completely set-it-and-forget-it, a nominator's experience is relatively hands-off compared to that of a validator, and even more with nomination pools. For more information, you can take a look at the nominator guide to understanding your responsibilities as a nominator.</p> <p>If you want to become a nominator, see this guide. If you are a beginner and would like to securely stake your tokens using the Polkadot-JS UI, refer to this support article. The tutorial presented in the support article is demonstrated on Polkadot, but the procedure is the same for Kusama.</p> <p>Polkadot Staking Dashboard</p> <p>The Staking Dashboard provides a more user-friendly alternative to staking. See the instructions in this support article to learn how to stake with the dashboard.</p> <p>Pools. Pools are \"built\" on top of NPoS to provide a very low barrier to entry to staking, without sacrificing Polkadot's strict security model.</p>"},{"location":"learn/learn-staking/#selection-of-validators","title":"Selection of Validators","text":"<p>The task of choosing validators is not simple, as it should take into account nominator reward and risk preferences. Ideally one aims to maximize the reward-to-risk ratio by maximizing rewards and minimizing risks, with sometimes having to compromise between the two, as minimizing risks might decrease rewards as well. Nominators should pay attention, especially to six criteria when nominating validators (not in order of importance):</p> <ul> <li>recent history of the era points earned across eras</li> <li>validator's self stake (shows skin in the game)</li> <li>total stake backing the validator (which is the sum of self stake and the stake coming from   nominators)</li> <li>commission fees (i.e. how much validators charge nominators)</li> <li>verified identity</li> <li>previous slashes</li> </ul> <p>The diagram below shows how the selection of those criteria affects the reward-to-risk ratio.</p> <p></p>"},{"location":"learn/learn-staking/#validator-selection-criteria","title":"Validator Selection Criteria","text":"<p>To maximize rewards and minimize risk, one could select those validators that:</p> <ul> <li>have era points above average (because they will get more rewards for being active),</li> <li>have the total stake backing the validator below the average active validator stake (because they   will pay out more rewards per staked token),</li> <li>have high own stake (because if slashed they have something to lose),</li> <li>have low commission fees but not 0% (because it makes sense that for doing the heavy lifting,   validators ask for a small commission),</li> <li>have on-chain registered identity (because it adds a layer of trust and possibly provides access   to their website and contact details),</li> <li>and have not been slashed (meaning that their on-chain behavior is genuine).</li> </ul>"},{"location":"learn/learn-staking/#network-providers","title":"Network Providers","text":"<p>For successful operation, a Validator node should always be ensured to meet the required software, hardware, and network bandwidth specifications. Understandably, most of the validator nodes run on cloud service providers that guarantee high hardware specifications and high levels of availability and connectivity. Keep in mind that a validator in the active set is supposed to be fully online and available for producing blocks. If the active validator node goes offline due to network interruptions or a power outage, that validator will get fewer rewards.</p> <p>Checking Validators using Network Providers</p> <p>You can connect your stash account to the Polkawatch app. The app will show your rewards earned in the past 60 eras divided by network provider and country. You will be able to see networks used by each validator and verify if your validators are using providers who support PoS. This is also a great tool to explore how decentralized your nominations are and act accordingly.</p>"},{"location":"learn/learn-staking/#keeping-track-of-nominated-validators","title":"Keeping Track of Nominated Validators","text":"<p>Nominators must periodically check their validators</p> <p>Nominating is not a \"set and forget\" operation. The whole NPoS system is dynamic and nominators should periodically monitor the performance and reputation of their validators. Failing to do so could result in applied slashes and/or rewards not being paid out, possibly for a prolonged period.</p> <p>Although the theory can be used as a general guideline, in practice it is more complicated and following the theory might not necessarily lead to the desired result. Validators might have the total stake backing them below average, low commission and above average era points in one era and then have a different profile in the next one. Selection based on the criteria like on-chain identity, slash history and low commission make the staking rewards deterministic. But some criteria vary more than others, with era points being the most variable and thus one of the key probabilistic components of staking rewards. Part of this probability is directly related to the fact that a validator can produce blocks for a parachain (i.e. para-validators) or the relay chain, with para-validators earning more era points per unit time (see this page for more information). The role can switch between sessions, and you can look at the staking tab on the Polkadot-JS UI to know which validator is producing blocks for the relay chain or parachains.</p> <p>It is not recommended to change nominations because of the low era points of a validator in a single era. Variability in rewards due to the era points should level out over time. If a validator consistently gets era points below average, it makes sense to nominate a better-performing validator for the health of the network and increased staking rewards. See this support article to understand in detail how to select the set of validators to nominate.</p>"},{"location":"learn/learn-staking/#stash-account-and-staking-proxy","title":"Stash Account and Staking Proxy","text":"<p>Two different accounts can be used to securely manage your funds while staking.</p> <ul> <li> <p>Stash: This account holds funds bonded for staking, but delegates all staking functions to a   staking proxy account. You may actively participate in staking with a stash private key kept in a   cold wallet like Ledger, meaning it stays offline all the time. Having a staking proxy will allow   you to sign all staking-related transactions with the proxy instead of using your Ledger device.   This will allow you:</p> </li> <li> <p>to avoid carrying around your Ledger device just to sign staking-related transactions, and</p> </li> <li> <p>to keep the transaction history of your stash clean</p> </li> <li> <p>Staking Proxy: This account acts on behalf of the stash account, signalling decisions about   nominating and validating. It can set preferences like commission (for validators) and the staking   rewards payout account. The earned rewards can be bonded (locked) immediately for bonding on your   stash account, which would effectively compound the rewards you receive over time. You could also   choose to have them deposited to a different account as a free (transferable) balance. If you are   a validator, it can also be used to set your session keys. Staking   proxies only need sufficient funds to pay for the transaction fees.</p> </li> </ul> <p>Warning</p> <p>Never leave a high balance on a proxy account which are usually \"hot\" as their private key is stored on the device (PC, phone) and it is always exposed to the internet for potential hacks and scams. It is good practice to deposit rewards on the stash account or to send them to another account on a cold wallet.</p> <p></p> <p>This hierarchy of separate keys for stash and staking accounts was designed to add a layer of protection to nominators and validator operators. The more often one exposes and uses a private key, the higher its vulnerability for hacks or scams. So, if one uses a key for multiple roles on a blockchain network, it is likely that the account can get compromised. Note that the damage linked to stolen private keys is different depending on the type of account derivation. In the case of soft derivation, all derived accounts are compromised. More information about account derivation can be found here.</p> <p>Info</p> <p>For Ledger users staking directly on Ledger Live, currently, there is no option to use separate stash and staking proxy accounts.</p> <p>Ledger devices are now supported in SubWallet, Talisman, and PolkaGate extension. Users can import their Ledger accounts in the extension and use them as a stash in staking. You can find more information about, SubWallet, Talisman, PolkaGate and other wallets that officially secured funding from the treasury here.</p>"},{"location":"learn/learn-staking/#claiming-staking-rewards","title":"Claiming Staking Rewards","text":"<p>Note that Kusama runs approximately 4x as fast as Polkadot, except for block production times. Polkadot will also produce blocks at approximately six-second intervals.</p> <p>Rewards are calculated per era (approximately six hours on Kusama and twenty-four hours on Polkadot). These rewards are calculated based on era points, which have a probabilistic component. In other words, there may be slight differences in your rewards from era to era, and even amongst validators in the active set at the same time. These variations should cancel out over a long enough timeline. See the page on Validator Payout Guide.</p> <p>The distribution of staking rewards to the nominators is not automatic and needs to be triggered by someone. Typically the validators take care of this, but anyone can permissionlessly trigger rewards payout for all the nominators whose stake has backed a specific validator in the active set of that era. Staking rewards are kept available for a limited amount of time.</p> <p>For more information on why this is so, see the page on simple payouts.</p> <p>Payouts</p> <p>Payouts are unclaimed rewards waiting to be paid out to both validators and nominators. If you go to the Staking payouts page on Polkadot-JS, you will see a list of all validators that you have nominated in the past 84 eras and for which you have not yet received a payout. The payout page is visible only to stakers.</p> <p>Each validator as well as their nominators have the option to trigger the payout for all unclaimed eras. Note that this will pay everyone who was nominating that validator during those eras. Therefore, you may not see anything in this tab, yet still have received a payout if somebody (generally, but not necessarily, another nominator or the validator operator) has triggered the payout for that validator for that era.</p> <p>Time limit to claim staking rewards</p> <p>If nobody claims your staking rewards within 84 eras, then you will not be able to claim them and they will be lost. Additionally, if the validator unbonds all their own stake, any pending payouts will also be lost.</p> <p>Rewards can be directed to the same account used to sign the payout or to a completely unrelated account. It is also possible to top-up / withdraw some bonded tokens without having to un-stake all staked tokens.</p> <p>If you wish to know if you received a payout, you will have to check via a block explorer. See the relevant Support page for details. For specific details about validator payouts, please see this guide.</p>"},{"location":"learn/learn-staking/#chilling","title":"Chilling","text":"<p>Chilling is the act of stepping back from any nominating or validating. It can be done by a validator or nominator at any time, taking effect in the next era.</p> <p>Chilling can be validator-initiated, e.g. if there is a planned outage in the validator's surroundings or hosting provider, and the validator wants to exit to protect themselves against slashing. Chilling will keep the validator active in the current era, but will move them to the inactive set in the next. The validator will not lose their nominators.</p> <p>For more on chilling, see the \"How to Chill\" page on this wiki.</p>"},{"location":"learn/learn-staking/#fast-unstake","title":"Fast Unstake","text":"<p>Fast Unstaking feature is live!</p> <p>If you accidentally bonded your tokens or your bonded tokens never backed any active validator, you can now unbond them immediately.</p> <p>If your bonded balance did not back any validators for a pre-determined period, you are eligible to perform fast unstaking. The staking dashboard will automatically check if you qualify. For more information, visit the \"Fast Unstake\" section in this support article.</p>"},{"location":"learn/learn-staking/#why-and-why-not-to-stake","title":"Why and Why not to Stake?","text":""},{"location":"learn/learn-staking/#pros-of-staking","title":"Pros of Staking","text":"<ul> <li>Earn rewards for contributing to the network's security through staking.</li> <li>Low barrier of entry through Nomination Pools.</li> <li>Can choose multiple validators   which can help to decentralize the network through the sophisticated   NPoS system</li> <li>85% of inflation/year of the tokens is primarily intended for staking rewards. Check the   inflation section on the Wiki for more information.</li> </ul>"},{"location":"learn/learn-staking/#cons-of-staking","title":"Cons of Staking","text":"<ul> <li>Tokens will be locked during the   unbonding period and no rewards will be   earned if you unbond.</li> <li>Possible punishment in case of the active validator found to be misbehaving (see   slashing).</li> <li>Lack of liquidity i.e. You would not be able to use the tokens for participating in crowdloans or   transfer them to different account etc.</li> </ul>"},{"location":"learn/learn-staking/#unbonding-period-length","title":"Unbonding Period Length","text":"<p>The unbonding period provides a safety net for slashing offenses identified in past eras, which can hold the respective validators and their nominators accountable. The unbonding period is crucial in mitigating ex post facto slashing, particularly in guarding against long-range attacks. When a client encounters a chain finalized by GRANDPA that originates more than one unbonding period in the past, it lacks the security of slashing protection.</p> <p>Essentially, this period establishes a cadence for synchronizing with the chain or acquiring a checkpoint within a timeframe that engenders trust. It's worth noting that while the choice of unbonding period length is somewhat arbitrary, it unquestionably provides a higher level of security compared to a shorter period.</p>"},{"location":"learn/learn-staking/#how-many-validators","title":"How many Validators?","text":"<p>The top bound on the number of validators has not been determined yet, but should only be limited by the bandwidth strain of the network due to peer-to-peer message passing.</p> <p>The estimate of the number of validators that Polkadot will have at maturity is around 1000, while Kusama is already operating at this threshold.</p>"},{"location":"learn/learn-staking/#why-am-i-not-receiving-rewards","title":"Why am I not receiving rewards?","text":"<p>Nominating is not a set-and-forget action. Nominators need to monitor their nominations and ensure they are eligible to receive staking rewards. Otherwise, they would be risking their funds to secure the chain with no reward. If you are bonding significantly more than the Minimum Active Bond and yet not receiving rewards, your nominations are all waiting, or your active validator has 100% commission. However, if you bond funds close to the Minimum Active Bond, there could be several possibilities for not receiving staking rewards. The table below can be used to troubleshoot why you might not be receiving staking rewards using Polkadot-JS UI.</p> Nomination Status What's happening? Causes What to do? Nominated validators are all in waiting status. Your stake has not been assigned to any of the nominated validators. You cannot earn rewards, nor be slashed in that era. Waiting validators are not in the active set in the current era and the stake backing them is not used to secure the network. In simple words, NPoS \"does not see them\". Change your nominations. Try to select validators (with reasonable commission) that have high chances to end up in the active set. You have some inactive, and some waiting nominations. Validators shown as \"Inactive\" in your staking dashboard are still in the active set and are producing blocks in the current era, but your stake has not been assigned to any of them. You will not earn rewards if your stake is not backing an active validator. In this case, you cannot be slashed either. Scenario 1: You have bonded less than the Minimum Active Bond. Scenario 2: You have more than the Minimum Active Bond, but your account is at the tail end of the bags list and within your bag there are accounts with less stake than you, in front of you. Scenario 1: Try bonding more funds. Scenario 2: Try to put your account in front of the accounts with less stake than you. Instructions available here <p>Join a Nomination Pool</p> <p>By joining a nomination pool that is active and earning rewards, you can start earning staking rewards with as low as 1 DOT. The nomination pools typically have a dedicated pool operator who ensures that the pool's stake is always backing an active validator and is receiving rewards.</p> <p>Bags List &amp; Minimum Active Bond</p> <p>You can find information about why you might not receive staking rewards on this support page and this video tutorial.</p>"},{"location":"learn/learn-staking/#staking-faq","title":"Staking FAQ","text":"<p>Info</p> <p>See this support page for the FAQs about staking.</p>"},{"location":"learn/learn-staking/#resources","title":"Resources","text":"<ul> <li>How Nominated Proof of Stake will work in Polkadot -   Blog post by Web3 Foundation researcher Alfonso Cevallos covering NPoS in Polkadot.</li> <li>Validator setup</li> <li>Polkadot validator selector tool - A tool   that helps nominators find reliable validators that meet quality-control criteria, including   commission rates, verified identity, etc.</li> </ul> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about staking.</p>"},{"location":"learn/learn-system-chains/","title":"System Chains","text":"<p>The primary functionality of the relay chain is to secure the parachains and facilitate secure communication between them. All other functionalities like asset transfers, governance, identities and bridging (a potentially resource intensive task) can benefit from operating separately on system chains. System chains are responsible for delegating functionality away from the relay chain for peformance reasons, taking advantage of the inherent parallelization the architecture of Polkadot provides.</p>"},{"location":"learn/learn-system-chains/#overview","title":"Overview","text":"<p>System parachains are those that contain core Polkadot protocol features, but in parachains rather than the relay chain. Rather than purchasing coretime on a marketplace, execution cores for system chains are allocated through the network governance.</p> <p>By hosting core protocol logic in parachains instead of the relay chain, Polkadot uses its own scaling technology -- namely, parallel execution -- to host itself. System parachains remove transactions from the relay chain, allowing more relay chain blockspace to be used for Polkadot's primary purpose: validating parachains.</p> <p>System parachains always defer to on-chain governance to manage their upgrades and other sensitive actions. That is, they do not have their own native tokens or governance systems separate from DOT KSM. In fact, there will likely be a system parachain specifically for network governance.</p> <p>Note</p> <p>In the past, these were often called \"Common Good Parachains\", so you may come across articles and discussions using that term. As the network has evolved, that term has been confusing in many cases, so \"System Parachains\" is preferred now. A discussion on this evolution can be found in this forum thread.</p>"},{"location":"learn/learn-system-chains/#existing-system-chains","title":"Existing System Chains","text":"PolkadotKusama <p>Compared to Polkadot, Kusama does not have the Collectives system chain, and it has the Encointer system chain.</p>"},{"location":"learn/learn-system-chains/#asset-hub","title":"Asset Hub","text":"<p>The Asset Hub on both Polkadot and Kusama are the first system parachains.</p> <p>The Asset Hub is an asset portal for the entire network. It helps asset creators (e.g. reserve backed stablecoin issuers) to track the total issuance of their asset in the network, including amounts that have been transferred to other parachains. It is also the point where they can transact, to mint and burn, to manage the on-chain asset.</p> <p>The Asset Hub also supports non-fungible assets (NFTs) via the Uniques pallet and the new nfts pallet. For more information about NFTs see the dedicated wiki page.</p> <p>This logic for asset management is not encoded in smart contracts, but rather directly in the runtime of the chain. Because of the efficiency of executing logic in a parachain, fees and deposits are about 1/10<sup>th</sup> of their respective value on the relay chain.</p> <p>These low fee levels mean that the Asset Hub is well suited for handling balances and transfers as well as managing on-chain assets.</p>"},{"location":"learn/learn-system-chains/#collectives","title":"Collectives","text":"<p>The Polkadot Collectives parachain was added in Referendum 81 and exists only on Polkadot (i.e., there is no Kusama equivalent). The Collectives chain hosts on-chain collectives that serve the Polkadot network.</p> <p>Some of these collectives are the Polkadot Alliance and the Polkadot Technical Fellowship. These on-chain collectives will play important roles in the future of network stewardship and decentralized governance.</p> <p>Networks themselves can act as collectives and express their legislative voices as single opinions within other networks. This is achieved with the assistance from a bridge hub.</p>"},{"location":"learn/learn-system-chains/#bridge-hub","title":"Bridge Hub","text":"<p>Before Polkadot and Kusama supported their first parachains, the only way to design a bridge was to put the logic onto the relay chain itself. Since both networks now support parachains, it makes sense to have a parachain on each network dedicated to bridges. This is because of the execution isolation provided by parachains.</p> <p>The Bridge Hub system parachain operates on the relay chain, and is responsible for faciliating bridges to the wider Web3 space. It contains the required bridge pallets in its runtime, which enable trustless bridging with other blockchain networks like Polkadot, Kusama and Ethereum. The Bridge Hub uses the native token of the relay chain.</p> <p>See the Bridges page for information on the latest bridge projects.</p>"},{"location":"learn/learn-system-chains/#people-chain","title":"People Chain","text":"<p>The People Chain allows users to mange their account identity.</p>"},{"location":"learn/learn-system-chains/#coretime-chain","title":"Coretime Chain","text":"<p>The Coretime system chain allows users to buy coretime to access Polkadot's computation. Coretime marketplaces run on top of the Coretime chain. For more information about agile coretime, see here.</p>"},{"location":"learn/learn-system-chains/#encointer","title":"Encointer","text":"<p>Encointer is a blockchain platform for self-sovereign ID and a global universal basic income. With referendum 158 Encointer was registered as the second system parachain on Kusama's network. The functionality of Encointer adds logic to the Relay Chain that aims to bring financial inclusivity to Web3 and mitigate Sybil attacks with a novel Proof of Personhood (PoP) system for unique identity.</p> <p>Encointer offers a framework that, in principle, allows for any group of real people to create, distribute, and use their own digital community tokens. Referendum 187 introduced a runtime upgrade bringing governance and full functionality for communities to be able to use the protocol.</p> <p>Encointer aims to invert the Cantillon Effect, where money is issued at the bottom, and not as credit to businesses or creditworthy individuals. This way, every individual gets a universal basic income (UBI).</p> <p>To resist Sybil attacks, the Encointer protocol uses a PoP mechanism to foster a unique identity system. The notion is that a person can only be present at one place at a given time. Participants are requested to attend physical key-signing ceremonies with small groups of random people at randomized locations, where these local meetings are part of one global ceremony that co-occur. Participants use the Encointer wallet app to participate in these ceremonies, and the wallet enables the management of local community currencies. Watch an Encointer ceremony in action in this video.</p> <p>The protocol involves other mechanisms to protect the privacy of users in addition to the physical key-signing ceremonies.</p> <p>Encointer was accepted as a system chain based on its offer of a Sybil defense mechanism as a basis for digital democracy. This can also be adapted by other chains, which can use the unique identity system to prevent Sybil attacks and use PoP for token airdrops or faucets.</p> <p>Tip</p> <p>To learn more about Encointer, check out the official Encointer book.</p>"},{"location":"learn/learn-teleport/","title":"Teleporting Assets","text":"<p>One of the main properties that Polkadot brings to the blockchain industry is secure interoperability. This interoperability allows for asset teleportation, i.e., the process of moving assets (such as fungible and non-fungible tokens) between chains (parachains) to use them as any other asset native to that chain. Interoperability is possible through XCM and SPREE modules, which together ensure that assets are not lost or duplicated across multiple chains.</p> <p>Walk-through video tutorial about teleporting assets</p> <p>See this technical explainer video to learn how to teleport assets from Kusama to the Asset Hub. The same procedure applies to teleporting between Polkadot and the Polkadot Asset Hub, or any other parachain.</p>"},{"location":"learn/learn-teleport/#how-teleports-work","title":"How Teleports work","text":"<p>As you can see from the diagram above, there are only two actors within this model: the source and the destination. How we transfer assets between the source and the destination is briefly summarized in the numbered labels on the diagram and explained in more detail below.</p>"},{"location":"learn/learn-teleport/#initiate-teleport","title":"Initiate Teleport","text":"<p>The source gathers the assets to be teleported from the sending account and takes them out from the circulating supply, taking note of the total amount of assets that was taken out.</p>"},{"location":"learn/learn-teleport/#receive-teleported-assets","title":"Receive Teleported Assets","text":"<p>The source chain then creates an XCM instruction called <code>ReceiveTeleportedAssets</code> containing the receiving account and the amount of assets taken out from circulation as parameters.</p> <p>It then sends this instruction over to the destination chain, where it gets processed, and new assets are put back into the circulating supply.</p>"},{"location":"learn/learn-teleport/#deposit-asset","title":"Deposit Asset","text":"<p>The destination deposits the assets to the receiving account. The actions of taking out from the circulating supply and putting back into the circulating supply show the great flexibility that an XCM executor has in regulating the flow of an asset without changing its circulating supply. Assets are transferred to an inaccessible account to remove them from circulation. Likewise, for putting assets back into circulation, assets are released from a pre-filled and inaccessible treasury, or perform a mint of the assets. This process requires mutual trust between the source and destination. The destination must trust the source of having appropriately removed the sent assets from the circulating supply, and the source must trust the destination of having put the received assets back into circulation. The result of an asset teleportation should result in the same circulating supply of the asset, and failing to uphold this condition will result in a change in the asset's total issuance (in the case of fungible tokens) or a complete loss/duplication of an NFT.</p>"},{"location":"learn/learn-transactions/","title":"Types of Transactions (a.k.a. Extrinsics)","text":""},{"location":"learn/learn-transactions/#pallets-and-extrinsics","title":"Pallets and Extrinsics","text":"<p>Polkadot is built using Substrate, a modular framework to efficiently build blockchains. Substrate's FRAME development environment provides modules called pallets and support libraries that you can use, modify, and extend to build the runtime logic to suit the needs of your blockchain. You can explore Substrate's FRAME pallets on this dedicated page.</p> <p>Within each functional pallet on the blockchain, one can call its functions and execute them successfully, provided they have the permission to do so. Because these calls originate outside of the blockchain runtime, such transactions are referred to as extrinsics. Extrinsics normally contain a signature, some data to describe if the extrinsic has passed some validity checks and a reference to the pallet and call that it is intended for. For example, the Staking pallet contains all functions related to staking. A nominator can bond funds and nominate validators by issuing the respective extrinsics. Some extrinsics might also trigger an event on the chain such as a reward payout to the nominators.</p>"},{"location":"learn/learn-transactions/#types-of-extrinsics","title":"Types of Extrinsics","text":"<p>Now that we introduced the term extrinsic, let us dive deeper and understand what extrinsics really are. Extrinsics can be one of 3 distinct types:</p> <ul> <li>Signed transactions: these must contain the signature of the account sending the inbound   request to the runtime. With signed transactions, the account used to submit the request typically   pays the transaction fee and must sign it using the account's private key.</li> <li>Unsigned transactions: these don't carry any information about who submitted the transaction,   since the format of this type of transaction doesn't require a signature. You can define what   conditions must be met for such a transaction to be valid.</li> <li>Inherents: are a special type of unsigned transaction made by block authors which carry   information required to build a block such as timestamps, storage proofs and uncle blocks.</li> </ul> <p>Signed transactions is the way that most users will interact with Polkadot. Signed transactions come from an account that has funds, and therefore Polkadot can charge a transaction fee as a way to prevent spam.</p> <p>Unsigned transactions are for special cases where a user needs to submit an extrinsic from a key pair that does not control funds. For example, validator's session keys never control funds. Unsigned transactions are only used in special cases because, since Polkadot cannot charge a fee for them, each one needs its own, custom validation logic.</p> <p>Inherents are pieces of information that are not signed or included in the transaction queue. As such, only the block author can add inherents to a block. Inherents are assumed to be \"true\" simply because a sufficiently large number of validators have agreed on them being reasonable. For example, the relay chain blocks include a timestamp inherent. There is no way to prove that a timestamp is true the way one proves the desire to send funds with a signature. Rather, validators accept or reject the block based on how reasonable they find the timestamp. In Polkadot, it must be within some acceptable range of their own system clocks.</p> <p>Here are some key differences between the different types of extrinsics:</p> <ul> <li>Contrary to signed transactions, unsigned transaction types require implementing custom validation   logic which can consume more resources for checking validity compared to signed transactions.</li> <li>Unsigned transactions have no economic deterrent to prevent spam or replay attacks, so custom   logic must account for protecting the network from these types of transactions being misused.</li> <li>Inherents exist to address the need of adding some data to a block, whereas signed or unsigned   transactions exist to potentially change the state of the blockchain.</li> </ul>"},{"location":"learn/learn-transactions/#mortal-and-immortal-extrinsics","title":"Mortal and Immortal Extrinsics","text":"<p>Transactions are generally irreversible once confirmed and added to the blockchain, an immutable ledger of all transactions. This means users must exercise caution, as mistakes such as sending DOT to the wrong address cannot be reverted. The permanence of transactions highlights the importance of careful verification before signing any transaction on a blockchain network. It is usually a good practice not to blind sign transactions to avoid being victim of an attack.</p> <p>In blockchain terms, transactions can be mortal extrinsics (i.e. valid within a defined block interval, usually short), or immortal extrinsics (i.e. always valid). It is possible to make immortal transactions on Polkadot. However, for security reasons, it is highly recommended not to do so and most wallet software will not allow you to make an immortal extrinsic.</p>"},{"location":"learn/learn-transactions/#balance-transfers","title":"Balance Transfers","text":"<p>Balance transfers are transfers of token balances between accounts. This is the most well-known type of transfer.</p>"},{"location":"learn/learn-transactions/#vested-transfers","title":"Vested Transfers","text":"<p>DOT may have a lock to account for vesting funds. Like other types of locks, these funds cannot be transferred but can be used in other parts of the protocol such as voting in governance or being staked as a validator or nominator.</p> <p>Vesting funds are on a release schedule that unlocks a constant number of tokens at each block (linear vesting) or the full amount after a specific block number (cliff vesting). In all vesting cases, the lock decreases over time until all the funds are transferable.</p>"},{"location":"learn/learn-transactions/#verifying-extrinsics","title":"Verifying Extrinsics","text":"<p>Danger</p> <p>Do not sign a transaction if you can't verify what you are signing or you suspect you might be signing a different extrinsic than the one intended.</p> <p>Verifying the extrinsic you are signing can take some more time before signing for a transaction but it allows you to add an extra security step. There are a multitude of possible attacks that will prevent you to send funds to the desired destination account.</p>"},{"location":"learn/learn-transactions/#transaction-fees","title":"Transaction Fees","text":"<p>Storage and computation are limited resources in a blockchain network. Transaction fees prevent individual users from consuming too many resources. Polkadot uses a weight-based fee model as opposed to a gas-metering model. As such, fees are charged before transaction execution. Once the fee is paid, nodes will execute the transaction.</p> <p>Polkadot fees consist of three parts:</p> <ul> <li><code>Base fee</code>: a fixed fee applied to every transaction and set by the runtime.</li> <li><code>Length fee</code>: a fee that gets multiplied by the length of the transaction in bytes.</li> <li><code>Weight fee</code>: a fee for each varying runtime function. Runtime implementers must implement a   conversion mechanism that determines the corresponding currency amount for the calculated weight.</li> </ul> <p>The final fee can be summarized as:</p> <pre><code>fee = base_fee + length_of_transaction_in_bytes * length_fee + weight_fee\n</code></pre> <p>where:</p> <p>Base fee: 1 milliDOT</p> <p>Length fee: 0.1 DOT per byte</p> <p>The weight-to-fee conversion is calculated as follows:</p> <pre><code>weight_fee = weight/1.26 * (10\u22128)\n</code></pre> <p>A weight of 126,000 nS is mapped to 1 mDOT. This fee will always be, at most, the max size of an unsigned 128-bit integer.</p> <p>See the Polkadot specification and the Substrate documentation for more details.</p>"},{"location":"learn/learn-transactions/#fee-multiplier","title":"Fee Multiplier","text":"<p>Polkadot can add an additional fee to transactions if the network becomes too busy and starts to decelerate the system. This additional fee is known as the <code>Fee Multiplier</code> and its value is defined by the runtime. The multiplier compares the saturation of blocks; if the previous block is less saturated than the current block (implying an uptrend in usage), the fee is slightly increased. Similarly, the fee is decreased if the previous block is more saturated than the current block (implying a downtrend in usage).</p> <p>The multiplier can create an incentive to avoid the production of low-priority or insignificant transactions. In contrast, those additional fees will decrease if the network calms down and transactions can be executed without overheads.</p> <p>The final fee is calculated as follows:</p> <pre><code>final_fee = fee * fee_multiplier\n</code></pre> <p>See the documentation about the Polkadot specifications for more details.</p>"},{"location":"learn/learn-transactions/#other-resource-limitation-strategies","title":"Other Resource Limitation Strategies","text":"<p>Transaction weight must be computable before execution and can only represent fixed logic. Some transactions warrant limiting resources with other strategies. For example:</p> <ul> <li>Bonds: Some transactions, like voting, may require a bond that will be returned or   slashed after an on-chain event. In the voting example, returned at the end   of the election or slashed if the voter tried anything malicious.</li> <li>Deposits: Some transactions, like setting an identity or claiming an index,   use storage space indefinitely. These require a deposit to be returned if the user decides to   clear their identity and free the storage.</li> <li>Burns: A transaction may burn funds internally based on its logic. For example, a transaction may   burn funds from the sender if it creates new storage entries, thus increasing the state size.</li> <li>Limits: Some limits are part of the protocol. For example, nominators can only nominate 16   validators. This limits the complexity of Phragm\u00e9n.</li> </ul>"},{"location":"learn/learn-transactions/#parachain-transactions","title":"Parachain Transactions","text":"<p>The transactions that take place within parachains do not incur relay chain transaction fees. Users of shard applications do not even need to hold DOT tokens, as each shard has its own economic model and may or may not have a token. There are, however, situations where shards themselves make transactions on the relay chain.</p> <p>Parachains have a dedicated core on the relay chain for execution, so their collators do not need to own DOT in order to include blocks. The parachain will make some transactions itself, for example, opening or closing an XCM channel, renew its time on a core, or upgrading its runtime. Parachains have their own accounts on the relay chain and will need to use those funds to issue transactions on the parachain's behalf.</p>"},{"location":"learn/learn-transactions/#block-limits-and-transaction-priority","title":"Block Limits and Transaction Priority","text":"<p>Relay chain blocks have both a maximum length (in bytes) and a maximum weight. Block producers will fill blocks with transactions up to these limits. A portion of each block - currently 25% - is reserved for critical transactions that are related to the chain's operation. Block producers will only fill up to 75% of a block with normal transactions. Some examples of operational transactions:</p> <ul> <li>Misbehavior reports</li> <li>Council operations</li> <li>Member operations in an election (e.g. renouncing candidacy)</li> </ul> <p>Block producers prioritize transactions based on each transaction's total fee. Since a portion of the fee will go to the block producer, producers will include the transactions with the highest fees to maximize their reward.</p> <p>Polkadot-JS Guides</p> <p>If you are an advanced user, see the Polkadot-JS guides about transfers.</p>"},{"location":"learn/learn-validator/","title":"Validator","text":"<p>Info</p> <p>This page provides a general overview of the role of validators in the Polkadot network. For more detailed information you can read the Parachain Protocol Overview.</p> <p>Validators secure the relay chain by staking native tokens, validating proofs from collators and participating in consensus with other validators.</p> <p>Validators play a crucial role in adding new blocks to the relay chain and, by extension, to all parachains. This allows parties to complete cross-chain transactions via the relay chain. They guarantee that each parachain follows its unique rules and can pass messages between shards in a trust-free environment.</p>"},{"location":"learn/learn-validator/#para-validators","title":"Para-validators","text":"<p>Parachain validators (i.e. para-validators) participate to the Parachain Phase of the AnV Protocol, and submit candidate receipts to the relay chain transaction queue so that a block author can include information on the parablock in a fork of the relay chain.</p> <p>Para-validators work in groups and are selected by the runtime in every epoch to validate parachain blocks for all parachains connected to the relay chain. The selected para-validators are part of the active validators randomly selected (per epoch) to participate in the validation, creating a validator pool of 200 para-validators.</p> <p>Para-validators verify that the information contained in an assigned set of parachain blocks is valid. They receive parachain block candidates from the collators together with a Proof-of-Validity (PoV). The para-validators perform the first round of validity checks on the block candidates. Candidates that gather enough signed validity statements are considered backable.</p>"},{"location":"learn/learn-validator/#block-authors","title":"Block Authors","text":"<p>There are validators on the relay chain who participate in the consensus mechanism to produce the relay chain blocks based on validity statements from other validators. These validators are called block authors, they are selected by BABE and can note up to one backable candidate for each parachain to include in the relay chain. A backable candidate included in the relay chain is considered backed in that fork of the chain.</p> <p>In a relay chain block, block authors will only include candidate receipts that have a parent candidate receipt in an earlier relay chain block. This ensures the parachain follows a valid chain. Also, the block authors will only include a receipt for which they have an erasure coding chunk, ensuring that the system can perform the next round of availability and validity checks.</p>"},{"location":"learn/learn-validator/#other-validators","title":"Other Validators","text":"<p>Validators also contribute to the so-called availability distribution. In fact, once the candidate is backed in a fork of the relay chain, it is still pending availability, i.e. it is not fully included (only tentative included) as part of the parachain until it is proven available (together with the PoV). Information regarding the availability of the candidate will be noted in the following relay chain blocks. Only when there is enough information, the candidate is considered a full parachain block or parablock.</p> <p>Validators also participate in the so-called approval process. Once the parablock is considered available and part of the parachain, it is still pending approval. Because para-validators are a small subset of all validators, there is a risk that by chance the majority of para-validators assigned to a parachain might be dishonest. It is thus necessary to run a secondary verification of the parablock before it can be considered approved. Having a secondary verification step avoids the allocation of more para-validators that will ultimately reduce the throughput of the system.</p> <p>Any instances of non-compliance with the consensus algorithms result in disputes with the punishment of the validators on the wrong side by removing some or all their staked tokens, thereby discouraging bad actors. Good performance, however, will be rewarded, with validators receiving block rewards (including transaction fees) in the form of native tokens (DOT or KSM on Kusama) in exchange for their activities.</p> <p>Finally, validators participate in the chain selection process within GRANDPA, ensuring that only available and valid blocks end within the finalized relay chain.</p> <p>Within an era roles can change</p> <p>Within the same era, a Validator can be a para-validator, block author, and participate in the availability distribution or the approval process. Those roles can change between sessions.</p>"},{"location":"learn/learn-validator/#further-readings","title":"Further Readings","text":""},{"location":"learn/learn-validator/#guides","title":"Guides","text":"<ul> <li>How to Validate on Polkadot - Guide on   how to set up a validator on the Polkadot live network.</li> <li>Validator Payout Overview - A short overview on   how the validator payout mechanism works.</li> <li>How to run your validator as a systemd process -   Guide on running your validator as a <code>systemd</code> process so that it will run in the background and   start automatically on reboots.</li> <li>How to Upgrade your Validator - Guide for   securely upgrading your validator when you want to switch to a different machine or begin running   the latest version of client code.</li> <li>How to Use Validator Setup - Guide on   how to use Polkadot / Kusama validator setup.</li> </ul>"},{"location":"learn/learn-validator/#other-references","title":"Other References","text":"<ul> <li>How to run a Polkadot node (Docker)</li> <li>A Serverless Failover Solution for Web3.0 Validator Nodes -   Blog that details how to create a robust failover solution for running validators.</li> <li>VPS list</li> <li>Polkadot Validator Lounge -   A place to chat about being a validator.</li> <li>Slashing Consequences - Learn more about slashing consequences for running   a validator node.</li> <li>Why You Should be A Validator on Polkadot and Kusama</li> <li>Roles and Responsibilities of a Validator</li> <li>Validating on Polkadot - An explanation of   how to validate on Polkadot, with Joe Petrowski and David Dorgan of Parity Technologies, along   with Tim Ogilvie from Staked.</li> </ul>"},{"location":"learn/learn-validator/#security-key-management","title":"Security / Key Management","text":"<ul> <li>Validator Security Overview</li> </ul>"},{"location":"learn/learn-validator/#monitoring-tools","title":"Monitoring Tools","text":"<ul> <li>PANIC for Polkadot - A monitoring and alerting   solution for Polkadot / Kusama node</li> <li>Polkadot Telemetry Service - Network   information, including what nodes are running on a given chain, what software versions they are   running, and sync status.</li> </ul>"},{"location":"learn/learn-validator/#validator-stats","title":"Validator Stats","text":"<ul> <li>Polkastats - Polkastats is a cleanly designed dashboard for validator   statistics.</li> <li>Subscan Validators Page - Displays information on the   current validators - not as tailored for validators as the other sites.</li> </ul>"},{"location":"learn/learn-video-tutorials/","title":"Videos about Polkadot","text":"<p>Technical Explainers</p> <p>Info</p> <p>For more videos see all playlists on the Polkadot YouTube channel.</p>"},{"location":"learn/learn-wasm/","title":"WebAssembly (Wasm)","text":"<p>WebAssembly is used in Polkadot and Substrate as the compilation target for the runtime.</p>"},{"location":"learn/learn-wasm/#what-is-webassembly","title":"What is WebAssembly?","text":"<p>WebAssembly, shortened to Wasm, is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable target for the compilation of high-level languages like C/C++/Rust, enabling deployment on the web for client and server applications.</p>"},{"location":"learn/learn-wasm/#why-webassembly","title":"Why WebAssembly?","text":"<p>WebAssembly is a platform-agnostic binary format, meaning it will run the exact instructions across whatever machine it operates on. Blockchains need determinacy to have reliable state transition updates across all nodes in the peer-to-peer network without forcing every peer to run the same hardware. Wasm is an excellent fit for reliability among the diverse set of machines. Wasm is both efficient and fast. The efficiency means that it can be uploaded onto the chain as a blob of code without causing too much state bloat while keeping its ability to execute at near-native speeds.</p>"},{"location":"learn/learn-wasm/#resources","title":"Resources","text":"<ul> <li>WebAssembly.org - WebAssembly homepage that contains a link to the   spec.</li> <li>Wasmi - WebAssembly interpreter written in Rust.</li> <li>Parity Wasm - WebAssembly   serialization/deserialization in Rust.</li> <li>Wasm utils - Collection of Wasm utilities used in   Parity and Wasm contract development.</li> </ul>"},{"location":"learn/learn-xcm-instructions/","title":"XCM Instructions & Register Specification","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>This page can also be viewed at the <code>xcm-format</code> repository, where each instruction and register is explained in-depth.</p>"},{"location":"learn/learn-xcm-instructions/#xcvm-registers","title":"XCVM Registers","text":"<ul> <li>Programme</li> <li>Programme Counter</li> <li>Error</li> <li>Error Handler</li> <li>Appendix</li> <li>Origin</li> <li>Holding</li> <li>Surplus Weight</li> <li>Refunded Weight</li> <li>Transact Status</li> <li>Topic</li> <li>Transact Status Register</li> <li>Topic Register</li> </ul>"},{"location":"learn/learn-xcm-instructions/#xcvm-instruction-set","title":"XCVM Instruction Set","text":"<ul> <li><code>WithdrawAsset</code></li> <li><code>ReserveAssetDeposited</code></li> <li><code>ReceiveTeleportedAsset</code></li> <li><code>QueryResponse</code></li> <li><code>TransferAsset</code></li> <li><code>TransferReserveAsset</code></li> <li><code>Transact</code></li> <li><code>HrmpNewChannelOpenRequest</code></li> <li><code>HrmpChannelAccepted</code></li> <li><code>HrmpChannelClosing</code></li> <li><code>ClearOrigin</code></li> <li><code>DescendOrigin</code></li> <li><code>ReportError</code></li> <li><code>DepositAsset</code></li> <li><code>DepositReserveAsset</code></li> <li><code>ExchangeAsset</code></li> <li><code>InitiateReserveWithdraw</code></li> <li><code>InitiateTeleport</code></li> <li><code>QueryHolding</code></li> <li><code>BuyExecution</code></li> <li><code>RefundSurplus</code></li> <li><code>SetErrorHandler</code></li> <li><code>SetAppendix</code></li> <li><code>ClearError</code></li> <li><code>ClaimAsset</code></li> <li><code>Trap</code></li> <li><code>SubscribeVersion</code></li> <li><code>UnsubscribeVersion</code></li> <li><code>BurnAsset</code></li> <li><code>ExpectAsset</code></li> <li><code>ExpectError</code></li> <li><code>ExpectOrigin</code></li> <li><code>QueryPallet</code></li> <li><code>ExpectPallet</code></li> <li><code>ReportTransactStatus</code></li> <li><code>ClearTransactStatus</code></li> <li><code>LockAsset</code></li> <li><code>UnlockAsset</code></li> <li><code>NoteUnlockable</code></li> <li><code>RequestUnlock</code></li> </ul>"},{"location":"learn/learn-xcm-instructions/#instructions-application-example","title":"Instructions Application Example","text":"<p>The following presents the practical mapping of instructions to some core functionality in XCM.</p> Programfmd <p>These are the primary instructions that enable programmability and branching to be possible. Branching in this context is the ability for errors and logic to be handled as needed when dealing with a message.</p> <ul> <li><code>ExpectAsset(MultiAssets)</code> -   Checks if the Holding register has a specific amount of assets, throws an error if it doesn't.</li> <li><code>ExpectError(Option&lt;(u32, Error)&gt;)</code> -   Ensures the Error register contains the given error, and throws an error if it doesn't.</li> <li><code>ExpectOrigin(MultiLocation)</code> -   Ensures the Origin register contains the expected origin, and throws an error if it doesn't.</li> <li> <p><code>QueryPallet</code> - Queries the existence of a particular pallet type.</p> </li> <li> <p><code>ExpectPallet</code> - Ensure that a particular pallet with a particular version exists.</p> </li> <li> <p><code>ReportTransactStatus(QueryResponseInfo)</code> - Send a <code>QueryResponse</code> message containing the value of   the Transact Status Register to some destination.</p> </li> <li> <p><code>ClearTransactStatus</code> - Set the Transact Status Register to its default, cleared, value.</p> </li> </ul> <p>These instructions highlight the key instructions focused on Functional Multichain Decomposition.</p> <ul> <li> <p><code>LockAsset(MultiAsset, MultiLocation)</code> - Lock the locally held asset and prevent further transfer   or withdrawal.</p> </li> <li> <p><code>UnlockAsset(MultiAsset, MultiLocation)</code> - Remove the lock over <code>asset</code> on this chain and (if   nothing else is preventing it) allow the asset to be transferred.</p> </li> <li> <p><code>NoteUnlockable(MultiAsset, MultiLocation)</code> - Asset (<code>asset</code>) has been locked on the <code>origin</code>   system and may not be transferred. It may only be unlocked with the receipt of the <code>UnlockAsset</code>   instruction from this chain.</p> </li> <li> <p><code>RequestUnlock(MultiAsset, MultiLocation)</code> - Send an <code>UnlockAsset</code> instruction to the <code>locker</code> for   the given <code>asset</code>.</p> </li> </ul>"},{"location":"learn/learn-xcm-pallet/","title":"XCM FRAME Pallet Overview","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>The XCM pallet (<code>pallet-xcm</code>) provides a set of pre-defined, commonly used XCVM programs in the form of a set of extrinsics using FRAME.</p> <p>This pallet provides some default implementations for traits required by <code>XcmConfig</code>. The XCM executor is also included as an associated type within the pallet's configuration.</p> <p>Where the XCM format defines a set of instructions used to construct XCVM programs, <code>pallet-xcm</code> defines a set of extrinsics that can be utilized to build XCVM programs, either to target the local or external chains. <code>pallet-xcm</code>'s functionality is separated into three categories:</p> <p>Note</p> <p>Remember, all XCMs are XCVM programs that follow the XCM format. It is the job of the XCM executor is to handle and execute these programs.</p> <ol> <li>Primitive, dispatchable functions to locally execute an XCM.</li> <li>High-level, dispatchable functions for asset transfers.</li> <li>Version negotiation-specific dispatchable functions.</li> </ol>"},{"location":"learn/learn-xcm-pallet/#primitive-extrinsics","title":"Primitive Extrinsics","text":"<p>There are two primary primitive extrinsics. These extrinsics handle sending and executing XCVM programs as dispatchable functions within the pallet.</p> <ol> <li><code>execute</code> -    This call contains direct access to the XCM executor. It is the job of the executor to check the    message and ensure that no barrier/filter will block the execution of the XCM. Once it is deemed    valid, the message will then be locally executed, therein returning the outcome as an event.    This operation is executed on behalf of whichever account has signed the extrinsic. It's possible    for only a partial execution to occur.</li> <li><code>send</code> -    This call specifies where a message should be sent    (via a transport method) externally to a particular destination, i.e.    a parachain, smart contract, or any system which is governed by consensus. In contrast to    <code>execute</code>, the executor is not called locally, as the execution will occur on the destination    chain.</li> </ol> <p>Info</p> <p>The XCM pallet needs the <code>XcmRouter</code> to send XCMs. It is used to dictate where XCMs are allowed to be sent, and which XCM transport protocol to use. For example, Kusama, the canary network, uses the <code>ChildParachainRouter</code> which only allows for Downward Message Passing from the relay to parachains to occur.</p> <p>You can read more about XCM transport protocols here.</p>"},{"location":"learn/learn-xcm-pallet/#asset-transfer-extrinsics","title":"Asset Transfer Extrinsics","text":"<p>Several extrinsics within the pallet handle asset transfer logic. They define a predetermined set of instructions for sending and executing XCMs. Two variants of these functions are prefixed with <code>limited_</code>. They have the same functionality but can specify a weight to pay for the XCM fee.</p> <p>Otherwise, the fee is taken as needed from the asset being transferred.</p> <ol> <li> <p><code>reserve_transfer_assets</code> -    Transfer some assets from the local chain to the sovereign account of a destination chain and    forward an XCM containing a    <code>ReserveAssetDeposited</code>    instruction, which serves as a notification.</p> </li> <li> <p><code>teleport_assets</code> -    Teleport some assets from the local chain to some destination chain.</p> </li> </ol>"},{"location":"learn/learn-xcm-pallet/#transfer-reserve-vs-teleport","title":"Transfer Reserve vs. Teleport","text":"<p>While both extrinsics deal with transferring assets, they exhibit fundamentally different behavior.</p> <ul> <li>Teleporting an asset implies a two-step process: the assets are taken out of circulating   supply (typically by burning/destroying) in the origin chain and re-minted to whatever account is   specified at the destination. Teleporting should only occur if there is an inherent and bilateral   trust between the two chains, as the tokens destroyed at the origin could not necessarily be   guaranteed to have the same properties when minted at the destination. There has to be trust   that the a particular chain burned, or re-minted the assets.</li> <li>Transferring or reserving an asset implies that equivalent assets (i.e, native   currency, like <code>DOT</code> or <code>KSM</code>) are withdrawn from sovereign account of the origin chain and   deposited into the sovereign account on the destination chain. Unlike teleporting an asset, it is   not destroyed and re-minted, rather a trusted, third entity is used (i.e., Asset Hub) to   reserve the assets, wherein the sovereign account of the destination chain on the reserve   chain obtains ownership of these assets.</li> </ul> <p>It's worth noting that this means that some other mechanism is needed to ensure that the balance   on the destination does not exceed the amount being held in reserve chain.</p> <p>Info</p> <p>A sovereign account refers to an account within a particular consensus system. Even though accounts may be different in terms of factors such as an address format, XCM agnostic nature enables communication between these sovereign accounts that are in other consensus systems.</p>"},{"location":"learn/learn-xcm-pallet/#version-negotiation-extrinsics","title":"Version Negotiation Extrinsics","text":"<p>The following extrinsics require root, as they are only used when bypassing XCM version negotiation. They change any relevant storage aspects that enforce anything to do with XCM version negotiations.</p> <ol> <li><code>force_xcm_version</code> -    Modifies the <code>SupportedVersion</code> storage to change a particular destination's stated XCM version.</li> <li><code>force_default_xcm_version</code> -    Modifies the <code>SafeXcmVersion</code> storage, which stores the default XCM version to use when the    destination's version is unknown.</li> <li><code>force_subscribe_version_notify</code> -    Sends an XCM with a    <code>SubscribeVersion</code> instruction to a    destination.</li> <li><code>force_unsubscribe_version_notify</code> -    Sends an XCM with a    <code>UnsubscribeVersion</code> instruction    to a destination.</li> </ol>"},{"location":"learn/learn-xcm-pallet/#fees-in-the-xcm-pallet","title":"Fees in the XCM Pallet","text":"<p>Message fees are only paid if the interior location does not equal the interpreting consensus system (known as Here in the context of an XCM <code>Multilocation</code>). Otherwise, the chain bears the fees. If applicable, fees are withdrawn from the assets from the specified <code>MultiLocation</code> and used as payment to execute any subsequent instructions within the XCM.</p> <p>Fees are generally dependent on several factors within the <code>XcmConfig</code>. For example, the barrier may negate any fees to be paid at all.</p> <p>Before any XCM is sent, and if the destination chain\u2019s barrier requires it, a <code>BuyExecution</code> instruction is used to buy the necessary weight for the XCM. XCM fee calculation is handled by the Trader, which iteratively calculates the total fee based on the number of instructions.</p> <p>The Trader used to calculate the weight (time for computation in consensus) to include in the message. Fee calculation in XCM is highly configurable and, for this reason, subjective to whichever configuration is in place.</p>"},{"location":"learn/learn-xcm-transport/","title":"XCM Transport Methods (XCMP, HRMP, VMP)","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>With the XCM format established, common patterns for protocols of these messages are needed. Polkadot implements two message passing protocols for acting on XCM messages between its constituent parachains.</p> <p>There are three primary methods for message passing, one of which is under development:</p> <ol> <li>XCMP (Cross-Consensus Message Passing)</li> <li>Horizontal Relay-routed Message Passing (HRMP/XCMP-lite)</li> <li>VMP (Vertical Message Passing)</li> </ol>"},{"location":"learn/learn-xcm-transport/#xcmp-cross-chain-message-passing","title":"XCMP (Cross-Chain Message Passing)","text":"<p>Caution</p> <p>XCMP is currently under development, and most of the cross-chain messages pass through HRMP channels for the time being.</p> <p>XCM is related to XCMP in the same way that REST is related to RESTful.</p> <p>Cross-Consensus Message Passing secure message passing between parachains. There are two variants: Direct and Relayed.</p> <ul> <li>With Direct, message data goes direct between parachains and is O(1) on the side of the relay   chain and is very scalable.</li> <li>With Relayed, message data is passed via the relay chain, and piggy-backs over VMP. It is much   less scalable, and on-demand parachains in particular may not receive messages due to excessive   queue growth.</li> </ul> <p>Cross-chain transactions are resolved using a simple queuing mechanism based around a Merkle tree to ensure fidelity. It is the task of the relay chain validators to move transactions on the output queue of one parachain into the input queue of the destination parachain. However, only the associated metadata is stored as a hash in the relay chain storage.</p> <p>The input and output queue are sometimes referred to in the Polkadot codebase and associated documentation as <code>ingress</code> and <code>egress</code> messages, respectively.</p> <p>Info</p> <p>For detailed information about VMP see dedicated section in The Polkadot Parachain Host Implementers' Guide.</p>"},{"location":"learn/learn-xcm-transport/#vmp-vertical-message-passing","title":"VMP (Vertical Message Passing)","text":"<p>Vertical Message Passing message passing between the relay chain itself and a parachain. Message data in both cases exists on the relay chain and are interpreted by the relay chain according to XCM standards. This includes:</p> <p>Upward Message Passing message passing from a parachain to the relay chain.</p> <p>Info</p> <p>For detailed information about VMP see dedicated section in The Polkadot Parachain Host Implementers' Guide.</p>"},{"location":"learn/learn-xcm-transport/#ump-upward-message-passing","title":"UMP (Upward Message Passing)","text":""},{"location":"learn/learn-xcm-transport/#dmp-downward-message-passing","title":"DMP (Downward Message Passing)","text":"Downward Message Passing message passing from the relay chain to a parachain."},{"location":"learn/learn-xcm-transport/#hrmp-xcmp-lite","title":"HRMP (XCMP-Lite)","text":"<p>While XCMP is still being implemented, a stop-gap protocol (see definition below) known as Horizontal Relay-routed Message Passing (HRMP) exists in its place. HRMP has the same interface and functionality as XCMP but is much more demanding on resources since it stores all messages in the relay chain storage. When XCMP has been implemented, HRMP is planned to be deprecated and phased out in favor of it.</p> <p></p> <p>Note</p> <p>A stop-gap protocol is a temporary substitute for the functionality that is not fully complete. While XCMP proper is still in development, HRMP is a working replacement.</p> <p>A tutorial on how to open an HRMP channel on a parachain can be found here.</p>"},{"location":"learn/learn-xcm-transport/#xcmp-cross-consensus-message-passing-design-summary","title":"XCMP (Cross Consensus Message Passing) Design Summary","text":"<p> XCMP Explained </p> <p>Note</p> <p>XCMP is not yet implemented. The following illustrates the overall design goals and expectations for XCMP.</p> <ul> <li>Cross-chain messages will not be delivered to the relay chain.</li> <li>Cross-chain messages will be constrained to a maximum size specified in bytes.</li> <li>Parachains are allowed to block messages from other parachains, in which case the dispatching   parachain would be aware of this block.</li> <li>Collator nodes are responsible for routing messages between chains.</li> <li>Collators produce a list of <code>egress</code> messages and will receive the <code>ingress</code> messages from other   parachains.</li> <li>On each block, parachains are expected to route messages from some subset of all other parachains.</li> <li>When a collator produces a new block to hand off to a validator, it will collect the latest   ingress queue information and process it.</li> <li>Validators will check the proof that the new candidate for the next parachain block includes the   processing of the expected ingress messages to that parachain.</li> </ul> <p>XCMP queues must be initiated by first opening a channel between two parachains. The channel is identified by both the sender and recipient parachains, meaning that it's a one-way channel. A pair of parachains can have at most establish two channels between them, one for sending messages to the other chain and another for receiving messages. The channel will require a deposit in DOT to be opened, which will get returned when the channel is closed.</p>"},{"location":"learn/learn-xcm-transport/#the-anatomy-of-an-xcmp-interaction","title":"The Anatomy of an XCMP Interaction","text":"<p>A smart contract that exists on parachain <code>A</code> will route a message to parachain <code>B</code> in which another smart contract is called that makes a transfer of some assets within that chain.</p> <p>Charlie executes the smart contract on parachain <code>A</code>, which initiates a new cross-chain message for the destination of a smart contract on parachain <code>B</code>.</p> <p>The collator node of parachain <code>A</code> will place this new cross-chain message into its outbound messages queue, along with a <code>destination</code> and a <code>timestamp</code>.</p> <p>The collator node of parachain <code>B</code> routinely pings all other collator nodes asking for new messages (filtering by the <code>destination</code> field). When the collator of parachain <code>B</code> makes its next ping, it will see this new message on parachain <code>A</code> and add it into its own inbound queue for processing into the next block.</p> <p>Validators for parachain <code>A</code> will also read the outbound queue and know the message. Validators for parachain <code>B</code> will do the same. This is so that they will be able to verify the message transmission happened.</p> <p>When the collator of parachain <code>B</code> is building the next block in its chain, it will process the new message in its inbound queue as well as any other messages it may have found/received.</p> <p>During processing, the message will execute the smart contract on parachain <code>B</code> and complete the asset transfer as intended.</p> <p>The collator now hands this block to the validator, which itself will verify that this message was processed. If the message was processed and all other aspects of the block are valid, the validator will include this block for parachain <code>B</code> into the relay chain.</p>"},{"location":"learn/learn-xcm-usecases/","title":"XCM Use-cases & Examples","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>XCM has a multitude of use cases. While the wiki covers some of the key commonplace interactions, the XCM format can be used to construct many more combinations to suit the use case at hand.</p>"},{"location":"learn/learn-xcm-usecases/#example-use-cases","title":"Example Use-Cases","text":"<ul> <li>Request for specific operations to occur on the recipient system such as governance voting.</li> <li>Enables single use-case chains e.g. the Asset Hub as asset   parachains</li> <li>Optionally include payment of fees on a target network for requested operation.</li> <li>Provide methods for various asset transfer models:</li> <li>Remote Transfers: control an account on a remote chain, allowing the local chain to have an     address on the remote chain for receiving funds and to eventually transfer those funds it     controls into other accounts on that remote chain.</li> <li>Asset Teleportation: movement of an asset happens by destroying it on one side and creating     a clone on the other side.</li> <li>Reserve Asset Transfer: there may be two chains that want to nominate a third chain, where     one includes a native asset that can be used as a reserve for that asset. Then, the derivative     form of the asset on each of those chains would be fully backed, allowing the derivative asset     to be exchanged for the underlying asset on the reserve chain backing it.</li> </ul> <p>Let's review two of these example asset transfer use cases: Asset Teleportation and Reserve Asset Transfer.</p>"},{"location":"learn/learn-xcm-usecases/#asset-teleportation","title":"Asset Teleportation","text":"<p>An asset teleport operation from a single source to a single destination.</p> <p></p> <ol> <li>InitiateTeleport</li> </ol> <p>The source gathers the assets to be teleported from the sending account and takes them out of the circulating supply, taking note of the total amount of assets that was taken out.</p> <ol> <li>ReceiveTeleportedAsset</li> </ol> <p>The source then creates an XCM instruction called <code>ReceiveTeleportedAssets</code> and puts the amount of assets taken out of circulation and the receiving account as parameters to this instruction. It then sends this instruction over to the destination, where it gets processed and new assets gets put back into circulating supply accordingly.</p> <ol> <li>DepositAsset</li> </ol> <p>The destination then deposits the assets to the receiving account of the asset.</p>"},{"location":"learn/learn-xcm-usecases/#reserve-asset-transfer","title":"Reserve Asset Transfer","text":"<p>When consensus systems do not have a established layer of trust over which they can transfer assets, they can opt for a trusted 3<sup>rd</sup> entity to store the assets.</p> <p></p> <ol> <li>InitiateReserveWithdraw</li> </ol> <p>The source gathers the derivative assets to be transferred from the sending account and burns them, taking note of the amount of derivatives that were burned.</p> <ol> <li>WithdrawAsset</li> </ol> <p>The source sends a WithdrawAsset instruction to the reserve, instructing the reserve to withdraw assets equivalent to the amount of derivatives burned from the source's sovereign account.</p> <ol> <li>DepositReserveAsset</li> </ol> <p>The reserve deposits the assets withdrawn from the previous step to the destination's sovereign account, taking note of the amount of assets deposited.</p> <ol> <li>ReserveAssetDeposited</li> </ol> <p>The reserve creates a ReserveAssetDeposited instruction with the amount of assets deposited to the destination's sovereign account, and sends this instruction onwards to the destination. The destination receives the instruction and processes it, minting the derivative assets as a result of the process.</p> <ol> <li>DepositAsset</li> </ol> <p>The destination deposits the derivative assets minted to the receiving account.</p>"},{"location":"learn/learn-xcm/","title":"Introduction to Cross-Consensus Message Format (XCM)","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>The Cross-Consensus Message Format, or XCM, is a messaging format and language used to communicate between consensus systems.</p> <p>One of Polkadot's main functionalities is interoperability amongst parachains and any other participating consensus-driven systems. XCM is the language through which complex, cross-consensus interactions can occur. Two blockchains can \"speak\" XCM to seamlessly interact with each other using a standard messaging format.</p> <p>Info</p> <p>We typically discuss XCM in the context of parachains, but please bear this in mind that it expands to the domain of all consensus systems! Remember, a consensus system here means any system or protocol that achieves finality to agree on the latest and correct state, whether it's a Polkadot parachain, an EVM smart contract, or other bridged consensus systems.</p> <p>XCM is not meant to be only specific to Polkadot, but rather its primary intention is to define a generic and common format amongst different consensus systems to communicate.</p> <p>It's important to note that XCM does not define how messages are delivered but rather define how they should look, act, and contain relative instructions to the on-chain actions the message intends to perform.</p> <p>XCMP, or Cross Chain Message Passing, is the actual network-layer protocol to deliver XCM-formatted messages to other participating parachains. There are other ways to define transport layer protocols for delivering XCM messages(see: HRMP and VMP).</p> <p>XCM has four high-level core design principles which it stands to follow:</p> <ol> <li>Asynchronous: XCM messages in no way assume that the sender will be blocking on its    completion.</li> <li>Absolute: XCM messages are guaranteed to be delivered and interpreted accurately, in order    and in a timely fashion. Once a message is sent, one can be sure it will be processed as it was    intended to be.</li> <li>Asymmetric: XCM messages, by default, do not have results that let the sender know that the    message was received - they follow the 'fire and forget' paradigm. Any results must be separately    communicated to the sender with an additional message back to the origin.</li> <li>Agnostic: XCM makes no assumptions about the nature of the consensus systems between which    the messages are being passed. XCM as a message format should be usable in any system that    derives finality through consensus.</li> </ol> <p>These four crucial design decisions allow for XCM messages to be a reliable yet convenient way to properly convey the intentions from one consensus system to another without any compatibility issues.</p> <p>Note</p> <p>XCM is constantly in development - meaning the format is expected to change over time. XCM v3 is the latest version, and is deployed on Polkadot. To view updates on the XCM format, visit the xcm-format repository to view any RFCs that have been submitted that would contribute to the next release.</p>"},{"location":"learn/learn-xcm/#a-format-not-a-protocol","title":"A Format, Not a Protocol","text":"<p>What started as an approach to cross-chain communication, has evolved into a format for Cross-Consensus Communication that is not only conducted between chains, but also between smart contracts, pallets, bridges, and even sharded enclaves like SPREE.</p> <p>XCM cannot actually send messages between systems. It is a format for how message transfer should be performed, similar to how RESTful services use REST as an architectural style of development, where HTTP requests contain specific parameters to perform some action.</p> <p>Similar to UDP, out of the box XCM is a \"fire and forget\" model, unless there is a separate XCM message designed to be a response message which can be sent from the recipient to the sender. All error handling should also be done on the recipient side.</p> <p>Info</p> <p>XCM is not designed in a way where every system supporting the format is expected to be able to interpret any possible XCM message. Practically speaking, one can imagine that some messages will not have reasonable interpretations under some systems or will be intentionally unsupported.</p> <p>Furthermore, it's essential to realize that XCM messages by themselves are not considered transactions. XCM describes how to change the state of the target network, but the message by itself doesn't perform the state change.</p> <p>This partly ties to what is called asynchronous composability, which allows XCM messages to bypass the concept of time-constrained mechanisms, like on-chain scheduling and execution over time in the correct order in which it was intended.</p>"},{"location":"learn/learn-xcm/#xcm-tech-stack","title":"XCM Tech Stack","text":"<p>XCM can be used to express the meaning of the messages over each of these three communication channels.</p>"},{"location":"learn/learn-xcm/#core-functionality-of-xcm","title":"Core Functionality of XCM","text":"<p>XCM opens the doors to a multi-hop, multi-network communications.</p> <p>XCM introduces some key features and additions to cross-consensus messaging, including:</p> <ol> <li> <p>Programmability - the ability to have expectations for messages, which allow for more    comprehensive use cases, safe dispatches for version checking, branching, and NFT/Asset support.</p> </li> <li> <p>Functional Multichain Decomposition - the ability to define mechanisms to cross-reference and    perform actions on other chains on behalf of the origin chain (remote locking), context/id for    these messages, and asset namespacing.</p> </li> <li> <p>Bridging - introduces the concept of a universal location, which allows for a base reference    for global consensus systems for multi-hop setups. This location is above the parent relay chain    or other consensus systems like Ethereum or Bitcoin.</p> </li> </ol> <p>A core part of the vision that XCM provides is improving communication between the chains to make system parachains a reality. For example, the Polkadot relay chain handles more than just parachain management and shared security - it handles user balances/assets, governance, and staking. Ideally, the relay chain should be for what it's intended to be - a place for shared security. System parachains can alleviate these core responsibilities from the relay chain but only by using a standard format like XCM.</p> <p>This is where system parachains come in, where each of these core responsibilities can be delegated to a system parachain respectively.</p> <p>Info</p> <p>XCM bridging, functional multichain decomposition, and programmability upgrades are crucial to bringing ecosystems together using a common communication abstraction.</p> <p>For more information on the specific instructions used for these key features, head over to the instructions and registers page.</p>"},{"location":"learn/learn-xcm/#cross-consensus-message-format-xcm-format","title":"Cross-Consensus Message Format (XCM Format)","text":"<p>For an updated and complete description of the cross-consensus message format please see the xcm-format repository on GitHub.</p>"},{"location":"learn/learn-xcm/#resources","title":"Resources","text":"<ul> <li> <p>Shawn Tabrizi: XCM - The Backbone Of A Multichain Future | Polkadot Decoded 2022 -   High level overview which should answer \u201cWhat is XCM?</p> </li> <li> <p>XCM: The Cross-Consensus Message Format -   Detailed blog post by Dr. Gavin Wood about the XCM Format.</p> </li> <li> <p>XCM Format specification - The best starting point for   understanding the XCM API at a technical level.</p> </li> <li> <p>Gavin Wood, Polkadot founder: XCM v3 | Polkadot Decoded 2022 -   High level overview of XCM and specifically the new features available in XCM v3.</p> </li> <li> <p>XCMP Scheme - An   overall overview of XCMP describing a number of design decisions.</p> </li> <li> <p>Messaging Overview - An overview   of the messaging schemes from the Polkadot Parachain Host Implementor's guide.</p> </li> <li> <p>Sub0 Online: Getting Started with XCM - Your First Cross Chain Messages -   Code focused workshop on how XCM v1 works, and the core concepts of XCM.</p> </li> <li> <p>XCM: Cross-Consensus Messaging Audit -   Technical audit report by Quarkslab prepared for Parity.</p> </li> <li> <p>XCM pallet code -   The pallet that contains XCM logic from the Polkadot code repository</p> </li> <li> <p>XCM Config &amp; Pallet-XCM | Polkadot Deep Dives - A   technical deep dive into <code>pallet-xcm</code> and the XCM configuration.</p> </li> </ul>"},{"location":"learn/learn-xcvm/","title":"XCM Virtual Machine (XCVM) & XCM Executor","text":"<p>XCM Documentation</p> <p>For a more practical approach to utilizing XCM, refer to the XCM Docs. Please keep in mind that XCM is under active development.</p> <p>At the core of XCM lies the Cross-Consensus Virtual Machine (XCVM). A \u201cmessage\u201d in XCM is an XCVM program, referred to as an \"XCM\" or \"XCMs\" for multiple messages. The XCVM is a register-based state machine. The state is tracked in domain-specific registers that hold information that is used and mutated along the execution of a particular message. Most of the XCM format comprises these registers and the instructions used to compose XCVM programs.</p> <p>The XCVM is an ultra-high-level non-Turing-complete computer whose instructions are designed to be roughly at the same level as transactions in terms of definition. Messages are one or more XCM instructions executed in order by the XCVM. An XCM is executed until it either runs to the end or hits an error, at which point it finishes up and halts.</p> <p>The first implementation of the XCVM is the <code>xcm-executor</code>. It follows the XCVM specification provided by Parity. It's engineered to be extendable, providing maximum customizability when configuring XCM. Because the <code>xcm-executor</code> is just an implementation of XCVM, it's entirely possible to create another implementation if desired.</p>"},{"location":"learn/learn-xcvm/#xcms-are-xcvm-programs","title":"XCMs are XCVM Programs","text":"<p>A cross consensus message (XCM) is just a program that runs on the <code>XCVM</code>: in other words, one or more XCM instructions that are executed by an XCVM implementation, such as the <code>xcm-executor</code>. To learn more about the XCVM and the XCM format, see the latest blog post on XCM by Dr. Gavin Wood.</p> <p>XCM instructions might change a register, the state of the consensus system, or both. Depending on the program's goal, whether it is to teleport assets from one chain to another or call a smart contract on another chain, XCMs usually require changes to the registers before any changes to the consensus system can be made.</p>"},{"location":"learn/learn-xcvm/#xcm-executor-configuration","title":"XCM Executor &amp; Configuration","text":"<p>The XCM Executor's implementation centers around a core piece: the XCM configuration. Each instance of the Executor must have a valid configuration, which specifies a multitude of options on how a chain may treat incoming messages via Barriers, calculate weight for a message via the Weigher, how much weight to purchase via the Trader, configure fees, how to convert origins, and more.</p>"},{"location":"learn/learn-xcvm/#cross-consensus-message-xcm-anatomy-flow","title":"Cross Consensus Message (XCM) Anatomy &amp; Flow","text":"<p>An XCM is made up of a list of instructions that are executed in order. There are four different kinds of XCM instructions:</p> <ol> <li>Instruction - Results in a state change in the local consensus system or some state change.</li> <li>Trusted Indication - Tells the XCVM, or the Executor, that some action has been done before    already - meaning, this action is now trusted and can be acted on, i.e., in a teleport scenario.</li> <li>Information - Provides additional information about a particular origin, usually the result    of a query, i.e., a <code>QueryResponse</code> instruction.</li> <li>System Notification - Typically used in the context of when an HRMP channel is being opened,    closed, or accepted.</li> </ol> <p>Typically, an XCM takes the following path through the XCVM:</p> <ol> <li>Instructions within an XCM are read one-by-one by the XCVM. An XCM may contain one or more     instructions.</li> <li>The instruction is executed. This means that the current values of the XCVM registers, the     instruction type, and the instruction operands are all used to execute some operation, which     might result in some registers changing their value, or in an error being thrown, which would     halt execution.</li> <li>Each subsequent instruction within the XCM is read until the end of the message has been     reached.</li> </ol>"},{"location":"learn/learn-xcvm/#example-register-the-holding-register","title":"Example Register: The Holding Register","text":"<p>There are many instructions that depend on the Holding register. The Holding register is an XCVM register that provides a place for any assets that are in an intermediary state to be held until they are taken out of the Holding register. It requires an instruction to place assets within it and another to withdraw them. The simplest example of this occurring is the <code>DepositAsset</code> instruction, which in its Rust form looks like this:</p> <pre><code>enum Instruction {\n    DepositAsset {\n        assets: MultiAssetFilter,\n        beneficiary: MultiLocation,\n    },\n    /* snip */\n}\n</code></pre> <p>This instruction specifies which assets (asset type and amount), already present in the Holding register, are going to be taken from it and deposited to the specified beneficiary (recipient). It is very common for instructions to remove and place assets into the Holding register when transacting between chains.</p>"},{"location":"learn/learn-xcvm/#example-transferasset","title":"Example: TransferAsset","text":"<p>An example below illustrates how a chain may transfer assets locally, or locally on a remote chain (as part of another instruction) using an XCM. In this message, the <code>TransferAsset</code> instruction is defined with two parameters: <code>assets</code>, which are the assets to be transferred, and the <code>beneficiary</code>, whoever will be the sole beneficiary of these assets. More complex instructions, especially those which perform actions that target a location other than the interpreting consensus system may make use of XCVM registers.</p> <pre><code>enum Instruction {\n    TransferAsset {\n        assets: MultiAssets,\n        beneficiary: MultiLocation,\n    }\n    /* snip */\n}\n</code></pre> <ul> <li> <p>A <code>MultiAsset</code> is a general identifier for an asset. It may represent both fungible and   non-fungible assets, and in the case of a fungible asset, it represents some defined amount of the   asset.</p> </li> <li> <p>A <code>MultiLocation</code> is a relative identifier, meaning that it can only be used to define the   relative path between two locations, and cannot generally be used to refer to a location   universally.</p> </li> </ul> <p><code>TransferAsset</code> is one of the many instructions that can be contained within an XCM. For more information, please read XCM Instructions in the wiki.</p>"},{"location":"learn/learn-xcvm/#locations-in-xcm","title":"Locations in XCM","text":"<p>XCM's generic nature involves specifying a wide array of \"locations\", or any body that is governed by consensus (parachains, solochains, smart contracts, accounts, etc). These are relatively abstract notions that point to where but also to who a particular action may affect. The <code>MulitLocation</code> type is what XCM uses to define these locations.</p> <p>A <code>MultiLocation</code> is a relative identifier that defines a relative path into some state-bearing consensus system.</p> <p>It is used to define the relative path between two locations, and cannot generally be used to refer to a location universally. It is very much akin to how a relative filesystem path works and is dependent on which consensus system the location expression is being evaluated.</p> <p></p> <p><code>MultiLocation</code> has two primary fields:</p> <ul> <li>A series of paths, called <code>Junctions</code>, which define an interior portion of state to descend into   it (sometimes called a \"sub-consensus\" system, such as a smart contract or pallet). An interior   location may also be used to refer to a Junction, used in the context of \"a parachain is an   interior location of the relay chain\", or how a UTXO is interior to Bitcoin's consensus.</li> <li>The number of parent junctions at the beginning of a <code>MultiLocation</code>'s formation - in other words,   the number of parent consensus systems above it.</li> </ul> <p>There are a number of various <code>Junction</code> variants that may be used to describe a particular location - whether it's a 32 byte account, a Substrate pallet, or a pluralistic body.</p>"},{"location":"learn/learn-xcvm/#multilocation-scenario-example","title":"MultiLocation Scenario Example","text":"<p>In this scenario, assume an XCM is to be sent from our parachain to the Asset Hub (<code>Parachain 1000</code>). This XCM references an account on the Asset Hub. As a general path, the <code>MultiLocation</code> would look like this:</p> <pre><code>../Parachain(1000)/AccountId32(&lt;some_account_id&gt;)\n</code></pre> <p>Or, as a Rust enum:</p> <pre><code>MultiLocation {\n  parents: 1,\n  interior: X2(Parachain(1000), &lt;some_account_id&gt;.into())\n}\n</code></pre> <ul> <li> <p>In the first field, <code>parents</code>, there is a parent of <code>1</code>. This is because our parachain has the   relay chain as a parent - in other words, it will go up by one consensus system to the relay   chain. This is also illustrated by the <code>../</code> of the \"file path\" representation.</p> </li> <li> <p>The second field, <code>interior</code>, defines where to go after the relay chain. In this case, from the   relay chain this message will go to the Asset Hub (<code>Parachain 1000</code>), then reference the account   (<code>some_account_id</code>) located within.</p> </li> </ul> <p>Keep in mind that this location is specific to this interaction. The identities may need to change if this location was defined on another consensus system, such as Kusama. On other consensus systems, such as Ethereum, it won't be able to interpret it.</p>"},{"location":"learn/learn-xcvm/#universallocation-in-xcm","title":"UniversalLocation in XCM","text":"<p>A <code>UniversalLocation</code> refers to any global consensus system. A global consensus system is an entity that provides its top-level consensus through some non-derivative consensus algorithm that can exist without reference to any other singleton data system. Such global consensus systems include Polkadot (or other relay chains), Bitcoin, or Ethereum. It provides a point of reference for overarching consensus systems.</p> <p>The <code>GlobalConsensus</code> junction refers to a global consensus system and takes a <code>NetworkId</code> that specifies a particular remote network. A <code>UniversalLocation</code> allows overarching consensus systems to communicate using this junction. Sub-consensus systems (i.e., a parachain on Polkadot) may refer to other remote sub-consensus systems (i.e., a parachain on Kusama) using a relative path defined via a <code>MultiLocation</code>.</p>"},{"location":"learn/learn-xcvm/#simulating-xcvm-using-the-xcm-simulator","title":"Simulating XCVM using the xcm-simulator","text":"<p>Within the Polkadot repository exists the <code>xcm-simulator</code>, which allows developers to experiment with building, executing, and simulating various XCM use scenarios.</p>"},{"location":"learn/advanced/","title":"Advanced","text":"<p>Welcome to the Advanced. Here you will find advanced information about Polkadot.</p>"},{"location":"learn/advanced/#advanced_1","title":"Advanced","text":"<ul> <li>Consensus - Information on consensus.</li> <li>Parachains Protocol - Details on the parachains protocol.</li> <li>Async Backing - Information on async backing.</li> <li>Coretime Marketplaces - Guide on coretime marketplaces.</li> <li>Coretime Parachains - Guide on coretime parachains.</li> <li>Elastic Scaling - Information on elastic scaling.</li> <li>Parachains - Details on parachains.</li> <li>System Chains - Information on system chains.</li> <li>Parachains FAQ - Frequently asked questions about parachains.</li> <li>Snowbridge - Information on Snowbridge.</li> <li>Hyperbridge - Details on Hyperbridge.</li> <li>DOT-KSM Bridge - Information on the DOT-KSM bridge.</li> <li>Account (Advanced) - Advanced account information.</li> <li>Staking (Advanced) - Advanced staking information.</li> <li>NFT Pallets - Information on NFT pallets.</li> <li>Cryptography - Details on cryptography.</li> <li>Phragmen - Information on Phragmen.</li> </ul>"},{"location":"learn/archive/","title":"Archive","text":"<ul> <li>Governance - Archived governance information.</li> <li>Treasury - Archived treasury information.</li> <li>Launch - Archived launch information.</li> <li>Redenomination - Archived redenomination information.</li> <li>Controller - Archived controller information.</li> <li>Auction - Archived auction information.</li> <li>Crowdloans - Archived crowdloans information.</li> <li>Thousand Validators - Archived thousand validators information.</li> </ul>"},{"location":"learn/archive/learn-auction/","title":"Parachain Slot Auctions","text":"<p>     The content on this page is archived.            Agile Coretime          is activated on the network, and parachain slot auctions have been deprecated. For existing parachains, the remainder of the lease is automatically converted to coretime. See more information             here.      </p> \u2716 <p>For a parachain to be added to the relay chain it must inhabit one of the available parachain slots. The number of parachain slots is not unbounded, as only a limited number are available. A limited number of slots are unlocked every few months through on-chain governance. If a parachain wants to have guaranteed block inclusion at every relay chain block, it must acquire a parachain slot. The development of on-demand parachains is complete, and they can be deployed after Agile Coretime is live on the network.</p> <p>The parachain slots will be leased according to an unpermissioned candle auction, with several alterations related to improving security while operating on a blockchain. See Rationale for additional details.</p> <p>A Beginner's guide to Parachain Slot Auctions</p>"},{"location":"learn/archive/learn-auction/#mechanics-of-a-candle-auction","title":"Mechanics of a Candle Auction","text":"<p>Candle auctions are a variant of open auctions where bidders submit bids that are increasingly higher. The highest bidder at the conclusion of the auction is considered the winner.</p> <p>Candle auctions were originally employed in the 16<sup>th</sup> century for the sale of ships. The name is derived from the system by which the auction length was determined. The phrase \"inch of a candle\" refers to the length of time required for a candle to burn down 1 inch. When the flame extinguishes and the candle goes out, the auction terminates and the standing bid at that point in time prevails the winner.</p> <p>When candle auctions are used online, they require a random number to decide the moment of termination. Parachain slot auctions differ slightly from a normal candle auction in that they do not randomly terminate the auction. Instead, they run for an entire fixed duration and the winner is randomly chosen retroactively.</p> <p>The candle auction is split into two parts:</p> <ol> <li> <p>The opening period which is in effect immediately after the auction starts. This period lasts    for one day and eighteen hours and serves as a buffer time for parachain candidates to setup    their initial bids, and likely start executing their strategy on how to win the slot auction.    During the opening phase, bids will continue to be accepted, but they do not have any effect on    the outcome of the auction.</p> </li> <li> <p>The ending period follows the opening period for five additional days, where the auction is    subject to end based on the candle auction mechanism.</p> </li> </ol> <p>The auction\u2019s ending time can occur any time within the ending period. This time is automatically and randomly chosen by the Verifiable Random Function (VRF). The probability of winning the auction is equal to the number of blocks that contain a winning bid, divided by the total number of blocks in the ending period. The random ending is managed by propagating through the entire ending period, where a snapshot is taken at each block within the ending period to capture the winners for that given block. At the end of the period, one of the snapshots is randomly selected to determine the winner of the auction.</p> <p>Info</p> <p>The parachain candidate with the highest bid at the ending time chosen by the Verifiable Random Function wins the slot auction.</p> <p>A parachain auction lasts exactly one week from the starting period (1 day and 18 hours) to ending period (candle auction phase) and finally 6 hours for determining the auction winner.</p> <p>Info</p> <p>Crowdloan contributions cannot be made during these six hours when the winning block for the auction is being determined on-chain.</p> <p>More details on this are available in the Network Implementation section.</p>"},{"location":"learn/archive/learn-auction/#randomness-in-action","title":"Randomness in action","text":"<p>The following example will showcase the randomness mechanics of the candle auction for the ninth auction on Kusama. Keep in mind that the candle phase has a uniform termination profile and has an equal probability of ending at any given block, and the termination block cannot be predicted before or during the auction.</p> <ul> <li>The ending period of auction 9 starts at <code>block 9362014</code>.</li> </ul> <p>!!!note \"The auction has a full duration equal to <code>block 9362014</code> + <code>72000</code>\"       Here, <code>block 72000</code> is the \"ending period\", which is divided into 3600 samples of 20 blocks. Figuratively, the candle is lit, and the candle phase lasts for 72,000 blocks.</p> <ul> <li>The winning sample during the ending period had the <code>index 1078</code>.</li> </ul> <p>!!!note \"Sample 1078 is the winner\"       Sample 1078 refers to the winner as of <code>block 9362014 + 21560</code>, which equals <code>block 9383574</code>.</p> <ul> <li>The parent block was a new BABE session in the <code>Logs</code>, which updated the randomness that was used   to select that sample index.</li> </ul> <p>!!!note \"Inspecting the block state\"       You can inspect the state at the end of <code>block 9434277</code> to see the sample indices with an archive node. The digest in the <code>Logs</code> of <code>9434277</code> is decodable and contains the random value as well as the BABE authorities.</p> <ul> <li>As a result, the winner of this auction was not the highest bid during the full duration.</li> </ul>"},{"location":"learn/archive/learn-auction/#rationale","title":"Rationale","text":"<p>The open and transparent nature of blockchain systems opens attack vectors that are non-existent in traditional auction formats. Normal open auctions in particular can be vulnerable to auction sniping when implemented over the internet or on a blockchain.</p> <p>Auction sniping takes place when the end of an auction is known and bidders are hesitant to bid their true price early, in hopes of paying less than they actually value the item.</p> <p>For example, Alice may value an item at auction for 30 USD. She submits an initial bid of 10 USD in hopes of acquiring the items at a lower price. Alice's strategy is to place incrementally higher bids until her true value of 30 USD is exceeded. Another bidder Eve values the same item at 11 USD. Eve's strategy is to watch the auction and submit a bid of 11 USD at the last second. Alice will have no time to respond to this bid before the close of the auction and will lose the item. The auction mechanism is sub-optimal because it has not discovered the true price of the item and the item has not gone to the actor who valued it the most.</p> <p>On blockchains this problem may be even worse, since it potentially gives the producer of the block an opportunity to snipe any auction at the last concluding block by adding it themselves while ignoring other bids. There is also the possibility of a malicious bidder or a block producer trying to grief honest bidders by sniping auctions.</p> <p>For this reason, Vickrey auctions, a type of sealed-bid auction where bids are hidden and only revealed at a later phase, have emerged as a well-regarded mechanic. For example, this mechanism is leveraged to auction human readable names on the ENS. The Candle auction is another solution that does not require a two-step commit and reveal schemes (a main component of Vickrey auctions), which allows smart contracts to participate.</p> <p>Candle auctions allow everyone to always know the states of the bid, but they do not reveal when the auction has officially ended. This helps to ensure that bidders are willing to make their true bids early. Otherwise, they may find themselves in a situation where the auction was determined to have ended before having an opportunity to bid.</p>"},{"location":"learn/archive/learn-auction/#network-implementation","title":"Network Implementation","text":"<p>The relay chain will use a random beacon based on the Verifiable Random Function (VRF). The VRF will provide the base of the randomness, which will retroactively determine the end-time of the auction.</p> <p>Polkadot's slot durations are capped to 2 years and are divided into 3-month periods (1 year divided into 6-week periods for Kusama). Parachains may lease a slot for any combination of periods of the slot duration. Parachains may lease more than one slot over time, meaning that they could extend their lease to the network past the maximum duration by leasing a contiguous slot.</p> <p>Individual parachain slots are fungible</p> <p>This means that parachains do not need to always inhabit the same slot, however they always must maintain a slot to remain a parachain.</p>"},{"location":"learn/archive/learn-auction/#bidding","title":"Bidding","text":"<p>Parachains or parachain teams, bid in the auction by specifying the slot range that they want to lease and the number of tokens they are willing to reserve. Bidders can be either ordinary accounts, or use the crowdloan functionality to source tokens from the community. For a more in-depth comparison between both of these options for gaining a parachain slot, check out this section on Crowdloan Campaigns vs Parachain Auctions.</p> <pre><code>Parachain slots at genesis\n\n       --3 months--\n       v          v\nSlot A |     1    |     2     |     3     |     4     |     5     |     6    |     7     |     8     |     9     |...\nSlot B |     1    |     2     |     3     |     4     |     5     |     6    |     7     |     8     |     9     |...\nSlot C |__________|     1     |     2     |     3     |     4     |     5    |     6     |     7     |     8     |     9     |...\nSlot D |__________|     1     |     2     |     3     |     4     |     5    |     6     |     7     |     8     |     9     |...\nSlot E |__________|___________|     1     |     2     |     3     |     4    |     5     |     6     |     7     |     8     |     9     |...\n       ^                                                                                             ^\n       ---------------------------------------------max lease-----------------------------------------\n</code></pre> <p>Each period of the range 1 - 4 represents a 3-month duration for a total of 2 years for Polkadot (or 6-week duration for a total of 1 year for Kusama).</p> <p>Bidders will submit a configuration of bids specifying the token amount they are willing to bond and for which periods. The slot ranges may be any of the periods 1 - <code>n</code>, where <code>n</code> is the number of periods available for a slot.</p> <p>!!!note If you bond tokens with a parachain slot, you cannot stake with those tokens. In this way, you pay for the parachain slot by forfeiting the opportunity to earn staking rewards.</p> <p>A bidder configuration for a single bidder may look like the following pseudocode example:</p> <pre><code>const bids = [\n  {\n    range: [1, 2, 3, 4, 5, 6, 7, 8],\n    bond_amount: 300,\n  },\n  {\n    range: [1, 2, 3, 4],\n    bond_amount: 777,\n  },\n  {\n    range: [2, 3, 4, 5, 6, 7],\n    bond_amount: 450,\n  },\n];\n</code></pre> <p>The important concept to understand from this example is that bidders may submit different configurations at different prices (<code>bond_amount</code>). However, only one of these bids would be eligible to win exclusive of the others.</p> <p>The winner selection algorithm will pick bids that may be non-overlapping in order to maximize the amount of tokens held over the entire lease duration of the parachain slot. This means that the highest bidder for any given slot lease period might not always win (see the example below).</p> <p>A random number, which is based on the VRF used by the relay chain, is determined at each block. Additionally, each auction will have a threshold that starts at 0 and increases to 1. The random number produced by the VRF is examined next to the threshold to determine if that block is the end of the auction within the so-called ending period. Additionally, the VRF will pick a block from the last epoch to access the state of bids which can help aid in mitigating some types of attacks from malicious validators.</p>"},{"location":"learn/archive/learn-auction/#examples","title":"Examples","text":"<p>There is one parachain slot available.</p> <p>Charlie bids <code>75</code> for the range 1 - 8.</p> <p>Dave bids <code>100</code> for the range 5 - 8.</p> <p>Emily bids <code>40</code> for the range 1 - 4.</p> <p>Let's calculate each bidder's valuation according to the algorithm. We do this by multiplying the bond amount by the number of periods in the specified range of the bid.</p> <p>Charlie - 75 * 8 = 600 for range 1 - 8</p> <p>Dave - 100 * 4 = 400 for range 5 - 8</p> <p>Emily - 40 * 4 = 160 for range 1 - 4</p> <p>Although Dave had the highest bid in accordance to token amount per period, when we do the calculations we see that since he only bid for a range of 4, he would need to share the slot with Emily who bid much less. Together Dave and Emily's bids only equals a valuation of <code>560</code>. Charlie's valuation for the entire range is <code>600</code>. Therefore Charlie is awarded the complete range of the parachain slot.</p>"},{"location":"learn/archive/learn-auction/#parachain-lease-extension","title":"Parachain Lease Extension","text":"<p>Before the slot lease expires, parachains have to bid and win another auction for continuity of the lease. To avoid any downtime in connectivity and minimize the risk of losing a subsequent auction, parachain teams need to plan ahead to bid for the lease extension before their current lease period ends. Explained in the section above, each auction lets you bid for 8 LPs (Lease Periods) which enables two scenarios for the parachain's lease extension.</p>"},{"location":"learn/archive/learn-auction/#lease-extension-with-overlapping-slots","title":"Lease Extension with Overlapping Slots","text":"<p>Acquire a slot where the first lease period is before the last lease period of the current slot.</p> <ul> <li>Register a new <code>paraId</code></li> <li>Win a slot auction with the new <code>paraId</code></li> </ul> <p>The parachain team has access to two slots:</p> <ul> <li>one that will end soon</li> <li>one that just started</li> </ul> <p>Both slots have at least one LP in common. When the old slot transitions to their last LP, the parachain can swap the slots. This can be done via on-chain governance. The <code>swap</code> call is available in the <code>registrar</code> pallet.</p> <p></p> <p>Any two parachains can swap their slots via XCM</p> <p>The slot swap via XCM requires two live parachains to send an XCM message to the relay chain to approve the swap. A parachain team with access to two overlapping slots can start a shell parachain on the new slot and swap it with their actual parachain on the old slot, thus ensuring continuity of the lease.</p>"},{"location":"learn/archive/learn-auction/#lease-extension-with-non-overlapping-slots","title":"Lease Extension with Non-Overlapping Slots","text":"<p>Acquire a slot where the first LP starts right after the end of the last LP of the current slot. In this case, the parachain can bid directly with their current <code>paraId</code>, and it will be automatically extended without the need of swapping. This method has the advantage of not having superfluous LP's on different slots owned by the same team, however it has the disadvantage of losing flexibility on when to win a new slot: if the team does not win the exact slot, then it will suffer some downtime until it wins a new slot.</p>"},{"location":"learn/archive/learn-auction/#slot-auctions-faq","title":"Slot Auctions FAQ","text":""},{"location":"learn/archive/learn-auction/#why-doesnt-everyone-bid-for-the-max-length","title":"Why doesn't everyone bid for the max length?","text":"<p>For the duration of the slot, the tokens used for bidding in the auction are locked up. This suggests there is an opportunity cost associated with bidding, as the tokens could have been leveraged for something else.</p>"},{"location":"learn/archive/learn-auction/#how-does-this-mechanism-help-ensure-parachain-diversity","title":"How does this mechanism help ensure parachain diversity?","text":"<p>The method for dividing the parachain slots into intervals was partly inspired by the desire to allow for a greater amount of parachain diversity, while preventing particularly large and well-funded parachains from hoarding slots. By making each period a three-month duration but the overall slot a 2-year duration (and 6-week duration but the overall slot a 1-year duration on Kusama), the mechanism can cope with well-funded parachains, ensuring they secure a slot at the end of their lease, while gradually allowing other parachains to enter the ecosystem to occupy the durations that are not filled. For example, if a large, well-funded parachain has already acquired a slot for range 1 - 8, they would be very interested in getting the next slot that would open for 2 - 9. Under this mechanism, that parachain could acquire just period 9 (since that is the only one required) and allow the 2 - 8 range of the second parachain slot to be occupied by another party.</p>"},{"location":"learn/archive/learn-auction/#why-is-randomness-difficult-on-blockchains","title":"Why is randomness difficult on blockchains?","text":"<p>Generating a random number trustlessly on a transparent and open network opens up the possibility for bad actors to attempt to alter or manipulate the randomness. There have been a few solutions that have been proposed, including hash-onions like RANDAO and verifiable random functions (VRFs). The latter is what the relay chain uses as a base for its randomness.</p>"},{"location":"learn/archive/learn-auction/#are-there-other-ways-of-acquiring-a-slot-besides-the-candle-auction","title":"Are there other ways of acquiring a slot besides the candle auction?","text":"<p>Aa parachain slot can also be acquired through a secondary market where a 3<sup>rd</sup> party has already won a parachain slot and has the ability to resell the slot along with the associated deposit of tokens that are locked up to another buyer. This would allow the seller to get liquid tokens in exchange for the parachain slot and the buyer to acquire the slot as well as the deposited tokens.</p> <p>A number of system or common-good parachains may be granted slots by the governance of the relay chain. System parachains can be recognized by a parachain ID lower than 1_000, and common-good parachains by a parachain ID between 1_000 and 1_999. Other parachains will have IDs 2_000 or higher. Such parachains would not have to bid for or renew their slots as they would be considered essential to the ecosystem's future.</p>"},{"location":"learn/archive/learn-auction/#how-are-auctions-scheduled","title":"How are auctions scheduled?","text":"<p>The parachain slot auctions are scheduled through the governance. At least \u2154 of the Council can initiate an auction, however, Root origin (via referendum) is needed to cancel an auction. Here is a proposal that gives a glimpse of what goes into planning auctions schedule - Proposed Polkadot Auction Schedule 2022.</p>"},{"location":"learn/archive/learn-auction/#resources","title":"Resources","text":"<ul> <li>How do Parachain Slot Auctions Work</li> <li>Parachain Allocation -   W3F research page on parachain allocation that goes more in depth to the mechanism</li> <li>Research Update: The Case for Candle Auctions -   W3F breakdown and research update about candle auctions</li> <li>Front-Running, Smart Contracts, and Candle Auctions   W3F Research team discusses how to remedy current blockchain auction setbacks with candle auctions</li> </ul>"},{"location":"learn/archive/learn-controller/","title":"Controller Accounts","text":"<p>     The content on this page is archived. Controller accounts are deprecated. For more information, see            this discussion.      </p> \u2716 <p>Controller accounts were used for staking and were a \"less-powerful\" version of staking proxies. Controllers could only sign for unbonding and rebonding funds, nominating and changing the reward destination. The stash account was still used to bond more funds and change the controller. Controller accounts became redundant and added unnecessary complexity to the staking mechanics.</p> <p></p> <p>With the setup shown above, the stash account was not entirely isolated. More complicated designs to fully isolate the stash account included having both controller and staking proxies (see below).</p>"},{"location":"learn/archive/learn-controller/#stash-as-controller","title":"Stash as Controller","text":"<p>It was unnecessary to have a controller if you had a staking proxy. In this case the stash was also set to be the controller, and the account security would not have been compromised. The staking proxy was used to sign all staking-relate transactions. Note that you needed to sign with the stash to change the staking proxy.</p> <p></p> <p>This past situation was similar to the present setup, except that now there is no option to set the stash as controller and that the action of \"changing the controller\" is missing. From a practical perspective, we need to use only one account and remember one password to sign for all staking-related transactions. From a security perspective, who controls the staking proxy controls our staking actions.</p>"},{"location":"learn/archive/learn-controller/#stash-not-as-controller","title":"Stash not as Controller","text":"<p>If the stash and controller were different accounts, the staking proxy was used to bond more funds and change the controller. Thus the staking proxy was used to sign for those transactions that were used less often and usually signed by the stash.</p> <p></p> <p>From a practical perspective, there were two accounts, and we needed to remember two passwords. From a security perspective, the party who wanted to control our staking actions was required to control two accounts.</p>"},{"location":"learn/archive/learn-crowdloans/","title":"Parachain Crowdloans","text":"<p>     The content on this page is archived.            Agile Coretime          is activated on the network, and crowdloans have been deprecated. For decentralized, transparent, and regulatory-compliant fundraising within the ecosystem, check out the            Polimec parachain.      </p> \u2716 <p>Polkadot allows parachains to source tokens for their parachain bids in a decentralized crowdloan.</p> <p>Contributing to a crowdloan</p> <p>If you are here for guidance on how to contribute to a crowdloan, watch the video below or read this support article on crowdloans.</p> <p>Crowdloans on Polkadot-JS</p>"},{"location":"learn/archive/learn-crowdloans/#crowdloan-campaigns-vs-parachain-auctions","title":"Crowdloan Campaigns vs Parachain Auctions","text":"<p>It is important to recognize that starting a crowdloan campaign is optional for participating in a parachain slot auction. The parachain slot auction can also be won directly through self-funding without community involvement. To reiterate, crowdloan campaigns are just one of the means to win auctions, which allow the community to participate in a trustless and permissionless way.</p> <p>Let's look at a scenario where Project A is bidding for a parachain slot, but they don't have enough tokens to bid directly to win the parachain auction. Project A could benefit from starting a new crowdloan campaign to help secure a parachain slot. Crowdloans are trustless and are supported natively on the relay chain, allowing the community to bond their tokens on Project A's behalf for the entire parachain lease duration. This will allow Project A to compete with projects that may have access to greater capital, given the project has sufficient community support. In return, the community contributors are rewarded by the projects that win the parachain slot, which would compensate for the opportunity cost of bonding their tokens for the lease duration.</p> <p>On the other hand, let's say Project B, which is more established and has access to capital, is hoping to secure a parachain slot through self-funding. Project B is not relying on community funding (at least via the crowdloan mechanism), so they must determine how much funding they can allocate towards winning a slot.</p> <p>Project B fully controls how much they are willing to contribute to gaining a parachain slot. Project B need not work on creating a reward model for community contributors like Project A. In contrast, crowdloan campaigns benefit projects with access to limited capital but have strong community support. They are also beneficial for projects that can successfully bid to win the auction with self-funding but are looking for a mechanism to bootstrap their community and get noticed by the key actors in the ecosystem.</p> <p>It is publicly visible on-chain whether or not a project is bidding directly or through a crowdloan campaign. More details regarding creating and executing a crowdloan campaign are provided below.</p>"},{"location":"learn/archive/learn-crowdloans/#starting-a-crowdloan-campaign","title":"Starting a Crowdloan Campaign","text":"<p>Anyone who has registered a parachain can create a new crowdloan campaign for a slot by depositing a specified number of tokens. A campaign is configured as a range of slots (i.e. the duration of the parachain will bid for), a cap, and a duration. The duration can last over several auctions as long as the range of slots matches those of the auction (i.e. the first lease period of the crowdloan is the same or bigger than that of the auction). This means a team will not need to restart the campaign just because they do not secure a slot on their first attempt.</p> <p>Crowdloan Submission Deposit Required</p> <p>To create a new crowdloan campaign, your account must have 500 DOT (or 100 KSM on Kusama) transferrable which will be reserved for the duration of the crowdloan.</p> <p>When setting the parameters of a crowdloan campaign, consider the following:</p> <ul> <li>A crowdloan campaign can start well before the auction slot is opened.</li> <li>The campaign creation form requires setting a crowdloan cap \u2014 the maximum amount a campaign   can collect. A team can still win an auction if the cap is not reached.</li> <li>Set the desired end of the crowdloan in the \"Ending block\" field. This helps ensure that the   crowdloan is live during the entire auction. For example, if an auction starts in three days and   lasts five days, you should set your crowdloan to end in 10 days or a similar timescale.</li> <li> <p>One way of calculating the ending block number is adding: <code>(10 * 60 * 24 * 7) * (x * 6) + y</code></p> </li> <li> <p><code>x</code> is the number of auction periods you want the crowdloan to continue for</p> </li> <li> <p><code>y</code> is the current block number</p> </li> <li> <p><code>(Blocks/Min * Min/Hour * Hour/Day * Day/Week) * (x[Period] * Week/Period) + y[BlockNumber]</code></p> </li> <li> <p>\"First period\" field refers to the first period you want to bid for. If the current auction     encompasses periods <code>(3, 4, 5, 6)</code>, your first period can be at least <code>3</code>. The last slot must     also be within that range.</p> </li> <li>You can only cancel an ongoing crowdloan if no contributions have been made. Your deposit will     be returned to you.</li> </ul> <p>Before the start of the crowdloan campaign, the owner will upload the parachain data. Once the crowdloan is live, the parachain configuration will be locked and will be deployed as the parachain's runtime. Of course, once the parachain is running, it can always change via runtime upgrades (as determined through its local governance).</p>"},{"location":"learn/archive/learn-crowdloans/#supporting-a-crowdloan-campaign","title":"Supporting a Crowdloan Campaign","text":""},{"location":"learn/archive/learn-crowdloans/#contributing-to-crowdloans","title":"Contributing to Crowdloans","text":"<p>Minimum Crowdloan Contribution</p> <p>There is a minimum balance for contributions for a crowdloan campaign. This is to make crowdloans as accessible as possible while maintaining a balance to justify using the network's resources.</p> <p>Each created campaign will have an index. Once a crowdloan campaign is open, anyone can participate by sending a transaction referencing the campaign's index. Tokens used to participate must be transferable \u2014 that is, not locked for any reason, including staking, vesting, and governance \u2014 because they will be moved into a module-controlled account that was generated uniquely for this campaign. See system accounts for more information.</p> <p>Do not send Crowdloan contributions directly to the Parachain address</p> <p>All crowdloan contributions are handled by the Crowdloan module\u2019s logic, where a campaign is identified by an index, not by address. Never transfer tokens to an address in support of a campaign.</p> <p>It is up to individual parachain teams to decide if and how they want to reward participants who forgo staking and choose to lock their tokens in support of the parachain\u2019s campaign. As one can imagine, rewards will take many forms and may vary widely among projects.</p> <p>If a crowdloan campaign is successful, that parachain will be on-boarded to the relay chain. The collective tokens will be locked in that parachain's account for the entire duration that it is active.</p>"},{"location":"learn/archive/learn-crowdloans/#withdraw-crowdloaned-tokens","title":"Withdraw Crowdloaned Tokens","text":"<p>Participants will be able to reclaim their tokens in one of two ways:</p> <ul> <li>If the campaign succeeds, the parachain will enter a retirement phase at the end of its lease.   During this phase, participants can withdraw the tokens with which they participated.</li> <li>If the campaign is unsuccessful, this retirement phase will begin at its configured end, and   participants can likewise withdraw their tokens.</li> </ul> <p><code>crowdloan.contribute</code> extrinsic is trustless</p> <p>Contributing to a crowdloan through Polkadot JS Apps (which uses <code>crowdloan.contribute</code> extrinsic) guarantees that you receive your tokens after the campaign ends. If you intend to contribute through other websites and custodial service providers like central exchanges, review their terms and conditions thoroughly and assess the associated risks.</p> <p>Note: When the lease periods won by the crowdloan have finished, or the crowdloan has ended without winning a slot, anyone can trigger the refund of crowdloan contributions back to their original owners. This can be done through the permissionless <code>crowdloan.refund</code> extrinsic available on Polkadot JS Apps &gt; Developer &gt; Extrinsics page, by specifying the parachain ID. This extrinsic may need to be issued multiple times if the list of contributors is too long. All contributions must be returned before the crowdloan is entirely deleted.</p> <p></p> <p>Many projects will have dashboards that allow users to participate in their crowdloans. PolkadotJS apps also offer a breakdown of ongoing crowdloans on the Apps page.</p> <p>Here is an example of the crowdloans in play during the very first Kusama auction.</p> <p></p> <p>Furthermore, check out this video on How to Participate in Crowdloans for steps on how to access available crowdloans on PolkadotJS apps.</p>"},{"location":"learn/archive/learn-governance/","title":"Governance V1","text":"<p>     The content on this page is archived. For up-to-date information about governance, see the            Polkadot OpenGov page.      </p> \u2716 <p>Polkadot uses a sophisticated governance mechanism that allows it to evolve gracefully overtime at the ultimate behest of its assembled stakeholders. The stated goal is to ensure that the majority of the stake can always command the network.</p> <p>Polkadot brings together various novel mechanisms, including an amorphous (abstract) form of state-transition function stored on-chain defined in a platform-agnostic language (i.e. WebAssembly). It also allows for several on-chain voting mechanisms, such as referenda with the novel concept of Adaptive Quorum Biasing and batch approval voting. All changes to the protocol must be agreed upon by stake-weighted referenda.</p> <p>To make any changes to the network, the idea is to compose active token holders and the council together to administrate a network upgrade decision. No matter whether the proposal is proposed by the public (token holders) or the Council, it finally will have to go through a vote on a referendum to let all holders, weighted by stake, make the decision.</p>"},{"location":"learn/archive/learn-governance/#governance-summary","title":"Governance Summary","text":"<p>The figure below shows an overview of Governance V1 with the key actors and different paths for submitting a proposal that can potentially be voted on as a referendum.</p> <p></p> <p>The public (i.e. token holders) can submit a proposal that gets added to the proposal queue. Here, proposals are endorsed, and the one that gets the most support will climb to the top of the queue. When it is time, the proposal at the top of the queue will become a Public Referendum. For instance, the proposal with 11 endorsements is shown at the top of the queue in the figure, which is ready to become a referendum.</p> <p>The public can also submit a treasury proposal, which must be evaluated by the Council through a motion. If the Council motion passes, the treasury proposal can be directly executed or go to the external queue, which will be voted on through a Council Referendum. See the figure's green horizontal path from the Public (green) to the Council (yellow). Treasury proposals and Council proposals can be directly executed (horizontal yellow arrows) or go to the external queue, where they will become a referendum</p> <p>Note that the external queue always consists of a single proposal. A proposal in the external queue can be fast-tracked by the Technical Committee (light blue). The fast track can contain as many proposals as possible (also called emergency proposals) that can be voted on simultaneously with with the referenda introduced either by the Council or the Public. See in the figure the yellow circle (i.e. Council Proposal) exiting the external queue, and the yellow circle with a light-blue border also leaving the queue and being fast-tracked by the Technical Committee (TC). Once empty, the external queue can be filled with another Council proposal.</p> <p>The Council can also submit proposals that will end up in the external queue. Voting on Council and Public proposals subject to an alternating timetable, shown in the figure as the \"on\" and \"off\" toggles on the external and proposal queues. In this example, the Public proposal will be voted on together with the fast-tracked Council Proposal. Voting on non-fast-tracked Council Proposals will be blocked until the alternating timetable switches the toggles, which stops Public proposals from becoming a referenda.</p> <p>Referenda will follow an adaptive quorum biasing mechanism for deciding whether they get enacted, and if they do, they will be executed after an enactment period.</p> <p>Token holders can delegate their votes (with a conviction multiplier) to another account belonging to a trusted entity voting on their behalf.</p>"},{"location":"learn/archive/learn-governance/#proposals","title":"Proposals","text":"<p>Referenda can be started in different ways:</p> <ul> <li>Publicly submitted proposals</li> <li>Proposals submitted by the council, either through a majority or unanimously</li> <li>Proposals submitted as part of the enactment of a prior referendum (i.e. making a   referendum to start a new referendum)</li> <li>Emergency proposals submitted by the Technical Committee and approved by   the Council</li> </ul> <p>Starting a proposal in Governance V1</p> <p>For more information about how to start a proposal, see the dedicated page.</p>"},{"location":"learn/archive/learn-governance/#endorsing-proposals","title":"Endorsing Proposals","text":"<p>Anyone can submit a proposal by depositing the minimum amount of tokens for a certain period (number of blocks). If someone agrees with the proposal, they may deposit the same amount of tokens to support it - this action is called endorsing. The proposal with the highest amount of bonded support will be selected to be a referendum in the next voting cycle based on an alternating voting timetable.</p>"},{"location":"learn/archive/learn-governance/#cancelling-proposals","title":"Cancelling Proposals","text":"<p>A proposal can be canceled if the Technical Committee unanimously agrees to do so or if Root Origin (e.g. sudo) triggers this functionality. A canceled proposal's deposit is burned.</p> <p>Additionally, a two-thirds majority of the council can cancel a referendum. This may function as a last-resort if there is an issue found late in a referendum's proposal, such as a bug in the code of the runtime that the proposal would institute.</p> <p>If the cancellation is controversial enough that the council cannot get a two-thirds majority, then it will be left to the stakeholders en masse to determine the proposal\u2019s fate.</p>"},{"location":"learn/archive/learn-governance/#blacklisting-proposals","title":"Blacklisting Proposals","text":"<p>A proposal can be blacklisted by Root Origin (e.g. sudo). A blacklisted proposal and its related referendum (if any) are immediately canceled. Additionally, a blacklisted proposal's hash cannot re-appear in the proposal queue. Blacklisting is useful when removing erroneous proposals that could be submitted with the same hash.</p> <p>Upon seeing their proposal removed, a submitter who is not properly introduced to the democracy system of Polkadot might be tempted to re-submit the same proposal. That said, this is far from a fool-proof method of preventing invalid proposals from being submitted - a single changed character in a proposal's text will also change the hash of the proposal, rendering the per-hash blacklist invalid.</p>"},{"location":"learn/archive/learn-governance/#referenda","title":"Referenda","text":"<p>Referenda are simple, inclusive, stake-based voting schemes. Each referendum has a specific proposal that takes the form of a privileged function call in the runtime. That function includes the most powerful call: <code>set_code</code>, which can switch out the entire runtime code, achieving what would otherwise require a \"hard fork\".</p> <p>Referenda are discrete events, have a fixed period where voting happens, and then are tallied, and the function call is executed if the vote is approved. Referenda are always binary: your only options in voting are \"aye\", \"nay\", or abstaining entirely.</p>"},{"location":"learn/archive/learn-governance/#referenda-timeline","title":"Referenda Timeline","text":"<p>The structure of the timeline for all referenda is the same regardless of who initiates the proposal, although the timeline length can vary (see below).</p> <p></p> <p>The figure above provides a summary view of the referenda timeline for Governance V1.</p> <p>In (1), the proposal is submitted, and the Launch Period starts. During this period of indefinite length the voters can endorse proposals by bonding the same amount of tokens used by the depositor. Deposited tokens for endorsement will be returned once the proposal becomes a referendum. During the launch period, the proposal will compete with other proposals, and the one that gets to the top will be selected for a referendum when the next voting period starts.</p> <p>The figure shows that the launch period is shown with a fixed length. Still, it varies depending on who initiated the proposal and how many proposals there are in the pipeline. Council motions will likely have a short launch period when compared to the public referenda which might take longer unless they are the only ones in the pipeline.</p> <p>In (2), the proposal is selected for a referendum. Proposals initiated by the public will become a public referendum, while those initiated by the council will become council referenda. The voting period lasts 28 days (7 days on Kusama), after which, if the proposal is approved, it will go through an enactment period. Rejected proposals will need to start from (1). Note that Governance V1 uses an alternating voting timeline where voters can vote either for a public proposal or a council motion every 28 days (7 days on Kusama).</p> <p>In (3), the proposal is approved and moves through the enactment period that can be of different lengths depending on who initiated the proposal in the first place, with emergency proposals being the fastest ones and the only ones that can be voted simultaneously with other referenda.</p>"},{"location":"learn/archive/learn-governance/#public-referenda","title":"Public Referenda","text":"<p>Public referenda will have a positive turnout bias, meaning that they will require a heavy supermajority of aye votes to pass at low turnouts but as turnout increases towards 100%, it will require a simple majority of aye votes to pass (i.e. 51% wins).</p> <p>Note that the bonded tokens will be released once the proposal is tabled (that is, brought to a vote), and a maximum of 100 public proposals can be in the proposal queue.</p> <p>turnout</p> <p>The total number of voting tokens excluding conviction or voluntary locking.</p>"},{"location":"learn/archive/learn-governance/#council-referenda","title":"Council Referenda","text":"<p>Unanimous Council - When all council members agree on a proposal, it can be moved to a referendum with a negative turnout bias. Briefly, it will require a heavy supermajority of nay votes to reject at low turnouts, but as turnout increases towards 100%, it will require a simple majority of nay votes to fail (i.e. 51% wins).</p> <p>Majority Council - When agreement from only a simple majority of council members occurs, the referendum will need simple majority to pass.</p> <p>Public- vs. Council-initiated Referenda</p> <p>Public referenda must be agreed upon using a positive bias to mitigate attacks by malicious or ill-conceived proposals. Conversely, when a proposal is unanimously voted in favor by the council, it benefits from using the negative bias. We assume low turnout is less problematic if the council proposes a referendum. Also, the council members are elected by the community and have strong technical as well as functional knowledge about the system, and we assume solid justifications back changes proposed by the council.</p>"},{"location":"learn/archive/learn-governance/#alternating-voting-timetable","title":"Alternating Voting Timetable","text":"<p>All referenda are executed by Root Origin. It follows that multiple referenda cannot be voted upon in the same period, excluding emergency referenda. An emergency referendum occurring at the same time as a regular referendum (either public- or council-proposed) is the only time multiple referenda can be voted on.</p> <p>Every 28 days (7 days on Kusama), a new referendum will come up for a vote, assuming there is at least one proposal in one of the queues. There is a queue for Council-approved proposals and a queue for publicly-submitted proposals. The referendum to be voted upon alternates between the top proposal in the two queues, where the proposals' rank is based on endorsement (i.e. bonded tokens).</p>"},{"location":"learn/archive/learn-governance/#adaptive-quorum-biasing","title":"Adaptive Quorum Biasing","text":"<p>Polkadot introduces the concept of Adaptive Quorum Biasing, which is used to alter the effective super-majority required to make it easier or more difficult for a proposal to pass depending on voting power (turnout) and origin (Council or public).</p> <p>Adaptive Quorum Biasing creates three tallying mechanisms: majority carry, super-majority approve, and super-majority against. They all equate to a simple majority-carry system at 100% turnout. Their selection depends on which entity proposed the proposal and whether all Council members voted yes (in the case of Council Referenda).</p> Entity Metric Public Positive Turnout Bias (Super-Majority Approve) Council (Complete agreement) Negative Turnout Bias (Super-Majority Against) Council (Majority agreement) Simple Majority <p>Let's use the image below as an example.</p> <p></p> <p>If a publicly submitted referendum only has a 25% turnout, the tally of aye votes has to reach 66% for it to pass since we applied Positive Turnout Bias. In contrast, when it has a 75% turnout, the tally of aye votes has to reach 54%, which means that the super-majority required decreases as the turnout increases. A positive turnout bias, whereby a heavy super-majority of aye votes is required to carry at low turnouts. However, as turnout increases towards 100%, it becomes a simple majority carry as below.</p> <p></p> <p>Where <code>approve</code> is the number of aye votes, <code>against</code> is the number of nay votes, <code>turnout</code> is the total number of voting tokens excluding voluntary locking, and <code>electorate</code> is the total number of tokens issued in the network.</p> <p>When the council proposes a new proposal through unanimous consent, the referendum would be put to the vote using Negative Turnout Bias. Referring to the above image, when a Council referendum only has a 25% turnout, the tally of aye votes has to reach 34% for it to pass, while if the turnout increases to 75%, the tally of aye votes has to reach 46%. A negative turnout bias requires a heavy super-majority of nay votes to reject at low turnouts. However, as turnout increases towards 100%, it becomes a simple majority carry as below.</p> <p></p> <p>In short, when the turnout rate is low, a super-majority is required to reject the proposal, which means a lower threshold of aye votes must be reached. As turnout increases toward 100%, it becomes a simple majority, a simple comparison of votes. If there are more aye votes than nay, then the proposal is carried, no matter how much stake votes on the proposal.</p> <p></p> <p>To know more about where these above formulas come from, please read the democracy pallet.</p>"},{"location":"learn/archive/learn-governance/#example-of-adaptive-quorum-biasing","title":"Example of Adaptive Quorum Biasing","text":"<p>Let's assume we only have 1,500 DOT tokens in total and that this is a public proposal.</p> <ul> <li>John: 500 DOT</li> <li>Peter: 100 DOT</li> <li>Lilly: 150 DOT</li> <li>JJ: 150 DOT</li> <li>Ken: 600 DOT</li> </ul> <p>John: Votes <code>Yes</code> for a 4 week lock period =&gt; 500 x 1 = 500 Votes</p> <p>Peter: Votes <code>Yes</code> for a 4 week lock period =&gt; 100 x 1 = 100 Votes</p> <p>JJ: Votes <code>No</code> for a 16 week lock period =&gt; 150 x 3 = 450 Votes</p> <ul> <li>approve = 600 Votes</li> <li>against = 450 Votes</li> <li>turnout = 750 Votes</li> <li>electorate = 1500 Votes</li> </ul> <p></p> <p></p> <p>Since the above example is a public referendum, Super-Majority Approve would be used to calculate the result. Super-Majority Approve requires more aye votes to pass the referendum when turnout is low; therefore, based on the above result, the referendum will be rejected.</p> <p>only the winning voter's tokens are locked.</p> <p>If the voters on the losing side of the referendum believe that the outcome will have adverse effects, their tokens are transferrable, so they will not be locked into the decision. Winning proposals are autonomously enacted after the enactment period.</p>"},{"location":"learn/archive/learn-governance/#enactment","title":"Enactment","text":"<p>Referenda are considered baked if they are closed and tallied. Assuming a referendum is approved, it will be scheduled for enactment. Referenda are considered unbaked if they are pending an outcome, i.e. being voted on.</p> <p>All referenda are associated with an enactment delay or enactment period. This is the period between a referendum ending and (assuming it was approved) the changes being enacted.</p> <p>For public and Council referenda, the enactment period is a fixed time of 28 days (8 days on Kusama). For proposals submitted as part of the enactment of a prior referendum, it can be set as desired. Emergency proposals deal with major problems with the network and need to be \"fast-tracked\". These will have a shorter enactment period.</p>"},{"location":"learn/archive/learn-governance/#voting-on-a-referendum","title":"Voting on a Referendum","text":"<p>To vote, a voter generally must lock their tokens up for at least the enactment period beyond the end of the referendum. This is to ensure that some minimal economic buy-in to the result is needed and to dissuade vote selling.</p> <p>Referenda explainer video</p> <p>To learn more about voting on referenda, please check out our technical explainer video.</p> <p>It is possible to vote without locking, but your vote is worth a small fraction of a normal vote, given your stake. At the same time, holding only a small amount of tokens does not mean that the holder cannot influence the referendum result, thanks to time-locking or voluntary locking (see below).</p>"},{"location":"learn/archive/learn-governance/#voluntary-locking","title":"Voluntary Locking","text":"<p>Voluntary Locking</p> <p>For more information about voluntary locking or conviction voting see Polkadot OpenGov.</p>"},{"location":"learn/archive/learn-governance/#delegations","title":"Delegations","text":"<p>In Polkadot, you can delegate your voting power to another account you trust if you are not willing to stay up-to-date with all referenda.</p> <p>You can also use a governance proxy to vote on behalf of your stash account. The proxy can be yours, or you can authorize a third-party governance proxy to vote with your stash. Learn more from the dedicated page on Proxy Accounts.</p>"},{"location":"learn/archive/learn-governance/#council","title":"Council","text":"<p>To represent passive stakeholders, Polkadot introduces the idea of a \"council\". The council is an on-chain entity comprising several actors, each represented as an on-chain account. The Polkadot council consists of 13 members (19 on Kusama).</p> <p>Along with controlling the treasury, the council is called upon primarily for three tasks of governance:</p> <ul> <li>Proposing sensible referenda</li> <li>Cancelling uncontroversially dangerous or malicious referenda</li> <li>Electing the Technical Committee.</li> </ul> <p>For a referendum to be proposed by the council, a strict majority of members must be in favor, with no member exercising a veto. Vetoes may be exercised only once by a member for any single proposal. If the proposal is resubmitted after a cool-down period, they may not veto it a second time.</p> <p>Council motion that pass with a \u2157 (60%) super-majority - but without reaching unanimous support - will move to a public referendum under a neutral, majority-carries voting scheme. In the case that all members of the council that voted are in favor of a motion, the vote is considered unanimous and becomes a referendum with negative turnout bias.</p> <p>Explainer video on the Council</p> <p>For more information, check out our video explainer on Council</p>"},{"location":"learn/archive/learn-governance/#prime-members","title":"Prime Members","text":"<p>The council, being an instantiation of Substrate's Collective pallet, implements what's called a prime member whose vote acts as the default for other members that fail to vote before the timeout.</p> <p>The prime member is chosen based on a Borda count.</p> <p>The purpose of having a prime council member is to ensure a quorum, even when several members abstain from a vote. Council members might be tempted to vote a \"soft rejection\" or a \"soft approval\" by not voting and letting the others vote. The existence of a prime member forces councilors to be explicit in their votes or have their vote counted for whatever is voted on by the prime.</p>"},{"location":"learn/archive/learn-governance/#technical-committee","title":"Technical Committee","text":"<p>The Technical Committee(TC) was introduced in the Kusama rollout and governance post as one of the three chambers of Kusama governance (along with the Council and the Referendum chamber). The TC is composed of the teams that have successfully implemented or specified either a Polkadot runtime or Polkadot Host. Teams are added or removed from the TC via a simple majority vote of the Council.</p> <p>The TC aims to safeguard against malicious referenda, implement bug fixes, reverse faulty runtime updates, or add new but battle-tested features. The TC can fast-track proposals using the Democracy pallet and is the only origin that can trigger the fast-tracking functionality. We can think of the TC as a \"unique origin\" that cannot generate proposals but fast-track existing ones.</p> <p>Fast-tracked referenda are the only referenda that can be active alongside another active referendum. Thus, with fast-tracked referenda, it is possible to have two active referendums simultaneously. Voting on one does not prevent a user from voting on the other.</p>"},{"location":"learn/archive/learn-governance/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"learn/archive/learn-governance/#how-to-be-a-council-member","title":"How to be a council member?","text":"<p>All stakeholders can signal their approval of any of the registered candidates.</p> <p>Council elections are handled by the same Phragm\u00e9n election process that selects validators from the available pool based on nominations. However, token holders' votes for councilors are isolated from any nominations they may have on validators. Council terms last for one week on Polkadot and one day day on Kusama.</p> <p>At the end of each term, Phragm\u00e9n election algorithm runs and the result will choose the new councilors based on the vote configurations of all voters. The election also chooses a set number of runners-up, which is 20 on Polkadot (12 on Kusama), that will remain in the queue with their votes intact.</p> <p>As opposed to a \"first-past-the-post\" electoral system, where voters can only vote for a single candidate from a list, a Phragm\u00e9n election is a more expressive way to include each voter\u2019s views. Token holders can treat it as a way to support as many candidates as they want. The election algorithm will find a fair subset of the candidates that most closely matches the expressed indications of the electorate as a whole.</p> <p>Let's take a look at the example below.</p> Round 1 Token Holders Candidates A B C D E Peter X X X X Alice X Bob X X X Kelvin X X Total 2 1 3 2 2 <p>The above example shows that candidate C wins the election in round 1, while candidates A, B, D &amp; E keep remaining on the candidates' list for the next round.</p> Round 2 Token Holders Candidates A B D E Peter X X Alice X X Bob X X X X Kelvin X X Total 4 4 1 1 <p>The top-N (say 4 in this example) runners-up can remain, and their votes persist until the next election. After round 2, even though candidates A &amp; B get the same number of votes in this round, candidate A gets elected because after adding the older unused approvals, it is higher than B.</p>"},{"location":"learn/archive/learn-governance/#how-can-i-appeal-to-the-council-to-enact-a-change-on-my-behalf","title":"How can I appeal to the council to enact a change on my behalf?","text":"<p>In some circumstances, you may want to appeal to the on-chain council to enact a change on your behalf. One example of this circumstance is the case of lost or locked funds when the funds were lost due to a human interface error (such as inputting an address for another network). Another example is if you participated in the 2017 Polkadot ICO with a multi-sig address which now does not let you sign a message easily. When these circumstances can be proven beyond a reasonable doubt to be an error, the council may consider a governance motion to correct it.</p> <p>The first step to appeal to the council is to contact the councilors. There is no singular place where you are guaranteed to grab every councilor\u2019s ear with your message. However, there are a handful of good places to start where you can get the attention of some of them. After creating an account and joining this room, you can post a well-thought-through message here that lays down your case and justifies why you think the council should consider enacting a change to the protocol on your behalf.</p> <p>At some point, you will likely need a place for a longer-form discussion. For this, making a post on Polkassembly is the recommended place to do so. When you write a post on Polkassembly, present all the evidence for your circumstances and state clearly what kind of change you would suggest to the councilors to enact.</p> <p>Info</p> <p>Remember, the councilors do not need to make the change, it is your responsibility to make a strong case for why the change should be made.</p>"},{"location":"learn/archive/learn-governance/#gov1-runtime-upgrade-monitoring","title":"Gov1 Runtime Upgrade Monitoring","text":"<p>Monitor the chain for:</p> <ol> <li><code>democracy(Started)</code> events and log <code>index</code> and <code>blockNumber</code>. This event indicates that a    referendum has started (although it does not mean it is a runtime upgrade). Get the referendum    info*; it should have a status of <code>Ongoing</code>. Find the ending block number (<code>end</code>) and the    enactment <code>delay</code> (delay). If the referendum passes, it will execute on block number    <code>end + delay</code>.</li> <li><code>democracy(Passed)</code>, <code>democracy(NotPassed)</code>, or, <code>democracy(Cancelled)</code> events citing the index.    If <code>Passed</code>, you need to look at the <code>scheduler(Scheduled)</code> event in the same block for the    enactment block.</li> <li><code>democracy(PreimageNoted)</code> events with the same hash as the <code>ReferendumInfoOf(index)</code> item. This    may be up to the last block before execution, but it will not work if this is missing.</li> <li><code>democracy(Executed)</code> events for actual execution. In the case of a runtime upgrade, there will    also be a <code>system(CodeUpdated)</code> event.</li> </ol> <p>You can also monitor Polkassembly for discussions on on-chain proposals and referenda.</p> <p>* E.g. via <code>pallets/democracy/storage/ReferendumInfoOf?key1=index&amp;at=blockNumber</code> on Sidecar.</p>"},{"location":"learn/archive/learn-governance/#resources","title":"Resources","text":"<ul> <li>Initial Governance Description</li> <li>Democracy Pallet</li> <li>Governance Demo - Dr.   Gavin Wood presents the initial governance structure for Polkadot. (Video)</li> <li>Governance on Polkadot - A webinar   explaining how governance works in Polkadot and Kusama.</li> </ul>"},{"location":"learn/archive/learn-launch/","title":"Polkadot Launch Phases","text":"<p>     The content on this page is archived.   </p> \u2716 <p>The Polkadot network has a phased roll-out plan, with important milestones toward decentralization marking each phase. Keep up-to-date with the Polkadot's phased roll-out plan at by viewing the roadmap</p> <p>Current Phase: Post-launch Upgrades</p> <p>Claims</p> <p>For the most update-to-date information on DOT claims (if you bought your DOTs before Polkadot went live), check out the following claiming resources and tutorials:</p> <ul> <li>Why do I need to claim my DOT tokens, and is there a deadline?</li> <li>I claimed my DOT before Polkadot went live, but still see zero balance!</li> <li>How to claim your DOT - Tutorial</li> <li>How do I know my claim worked?</li> </ul>"},{"location":"learn/archive/learn-launch/#the-poa-launch","title":"The PoA Launch","text":"<p>The Genesis block of the Polkadot network was launched on May 26, 2020, as a Proof of Authority (PoA) network. Governance was restricted to the single Sudo (super-user) key, which was held by Web3 Foundation to issue the commands and upgrades necessary to complete the launch process. During this time, validators started joining the network and signaling their intention to participate in consensus.</p>"},{"location":"learn/archive/learn-launch/#nominated-proof-of-stake","title":"Nominated Proof of Stake","text":"<p>Once Web3 Foundation was confident in the stability of the network and there was a sufficient number of validator intentions, Web3 Foundation used Sudo \u2014 a superuser account with access to governance functions \u2014 to initiate the first validator election. Following this election, the network transitioned from PoA into its second phase, Nominated Proof of Stake (NPoS), on June 18, 2020.</p>"},{"location":"learn/archive/learn-launch/#governance","title":"Governance","text":"<p>After the chain had been running well with the validator set, the Sudo key issued a runtime upgrade that enabled the suite of governance modules in Polkadot; namely, the modules to enable a Council, a Technical Committee, and public referenda.</p>"},{"location":"learn/archive/learn-launch/#removal-of-sudo","title":"Removal of Sudo","text":"<p>The Sudo module was removed by a runtime upgrade on July 20, 2020, transitioning the governance of the chain into the hands of the token (DOT) holders.</p> <p>From this point, the network has been entirely in the hands of the token holders and is no longer under control of any centralized authority.</p>"},{"location":"learn/archive/learn-launch/#balance-transfers","title":"Balance Transfers","text":"<p>To enable balance transfers, the community made a public proposal for a runtime upgrade that lifted the restriction on balance transfers. Transfer functionality was subsequently enabled on Polkadot at block number 1_205_128 on August 18, 2020, at 16:39 UTC.</p>"},{"location":"learn/archive/learn-launch/#core-functionality","title":"Core Functionality","text":"<p>After five years of research and development and a multi-stage launch that began in May 2020, Polkadot launch was completed on December 18, 2021, with all auction-winning parachains producing blocks on the network.</p> <p>Check out these resources for further information:</p> <ul> <li>Polkadot Network blog.</li> <li>Polkadot A to Z: L for Polkadot Launch.</li> </ul>"},{"location":"learn/archive/learn-redenomination/","title":"Redenomination of DOT","text":"<p>     The content on this page is archived.   </p> \u2716 <p>On August 21, 2020, the redenomination of DOT, the native token on Polkadot, occurred. From this date, one DOT (old) equals 100 new DOT.</p> <p>Denomination Day</p> <p>The DOT redenomination took place on 21 August 2020, known as Denomination Day, at block number 1_248_328.</p> <p>While DOT is the unit of currency on Polkadot that most people use when interacting with the system, the smallest unit of account is the Planck. A Planck's relation to DOT is like the relation of a Satoshi to Bitcoin. Before 21 August, the DOT was denominated as 1e12 Plancks, that is, twelve decimal places. After Denomination Day, DOT is denominated as 1e10 Plancks, as in, ten decimal places. DOT denominated to twelve decimal places is referred to as \"DOT (old)\" and DOT denominated to ten decimal places is generally referred to as \"DOT\". When the difference must be made explicit, the current ten-decimal-denominated DOT is referred to as \"New DOT\".</p> <p>Redenomination Explainer</p> <p>Check out our technical explainer video that explains more of Redenomination.</p> <p>The change in denomination, henceforth referred to as the redenomination, was voted on by the community of DOT holders. The community decided between four options, to change the DOT denomination by a factor of ten, one hundred, one thousand, or not at all. The end result was to change the denomination by a factor of one hundred.</p> <p>The overall effect of this change was that the number of Polkadot's smallest unit, the Planck, remained constant, while the DOT balance for all holders was increased by a factor of one hundred. As one can see from the example below, the number of Plancks a user has does not change, only the number of Plancks that constitute a single DOT. A user with 1_000_000_000_000 Plancks still has the same number of Plancks but will have 100 DOT under the new denomination, as opposed to one DOT under the old denomination.</p> <pre><code>   Before the change the decimal was here\n   v\n  1.000000000000 DOT\n\n  100.0000000000 DOT\n     ^\n     After the change the decimal is here\n</code></pre> <p>Note</p> <p>There are no state changes with redenomination. There are no transfers. The real change regards the social consensus around where to put the decimal place when we talk about what constitutes a DOT.</p>"},{"location":"learn/archive/learn-redenomination/#origins","title":"Origins","text":"<p>The initial vote for redenomination occurred as a referendum on the Kusama blockchain. The referendum was summarized as having four effects if approved by KSM holders.</p> <p>Referendum Summary</p> <ul> <li>The total allocations of DOT will increase one hundred times from 10 million to 1 billion.</li> <li>DOT allocation balances will increase by a factor of one hundred, such that 1 DOT will be 100 DOT.</li> <li>The distribution of DOT does not change, and holders of DOT still own an equal share of the network as before the change.</li> <li>The precision of DOT will change from 12 decimal places to 10 decimal places.</li> <li>The main benefit of this change is to avoid using small decimals when dealing with DOT and to achieve an easier calculation system.</li> </ul> <p>The initial referendum was proposed before the Polkadot genesis block, assuming that making a redenomination would be simpler before the Polkadot chain was live. However, many in the community pointed out the disconnect between the two networks and how it was unfair for holders of DOT to be impacted by a vote by a different token holder set. For this reason, Web3 Foundation decided to make a new vote on Polkadot when it went live, although the Kusama vote ended with a majority in favor of the redenomination change.</p> <p>Web3 Foundation summarized the decision not to change:</p> <p>Note</p> <p>However, given the non-negligible amount of opposition, including from some within the ranks of Web3 Foundation and Parity, the Foundation decided that we cannot, in good faith, sponsor the redenomination.</p>"},{"location":"learn/archive/learn-redenomination/#the-vote","title":"The Vote","text":"<p>After the genesis block of Polkadot was created and the network was running with a decentralized community of validators securing the network, Web3 Foundation decided to put the redenomination topic up for a vote again. This time, the vote was explicitly binding \u2014 meaning that it would be executed if voted through. In comparison, the vote on Kusama was non-binding to capture a signal without a direct way to affect the Polkadot chain.</p> <p>Based on the feedback received during the Kusama referendum, the Polkadot vote was held as an approval vote, with four available options. DOT holders could issue votes for any configuration of the four options: no change, a change of 10x, a change of 100x, or a change of 1000x. The voting logic was contained in a specially-built Substrate pallet included in Polkadot's runtime for this poll.</p> <p>Summary of the Vote</p> <ul> <li>Any combination of the four options may have been approved by the voter. There was no need to select only one option.</li> <li>Approving all or none of the options was equivalent and did not affect the outcome.</li> <li>All voters could alter their votes any number of times before the close of the poll.</li> <li>No discretionary lock-voting was in place; all DOT used to vote counts the same.</li> <li>Voting was made on a per-account basis; a single account must have voted the same way and could not split its vote.</li> <li>This vote did not affect any economics of the Polkadot platform. As in, staking rewards inflation, effective market capitalization, and the underlying balances of every account remained completely unchanged. It was \u201cmerely\u201d about what units the network uses to denominate the balances into \u201cDOT\u201d.</li> </ul> <p>With a voting period of two weeks set, the redenomination was now in the hands of the Polkadot community for a final, binding decision.</p>"},{"location":"learn/archive/learn-redenomination/#the-outcome","title":"The Outcome","text":"<p>After two weeks of voting, the results of the redenomination vote were tallied. About one-third of the total DOT in the network participated in the vote. The redenomination proposal passed with 86% of the voters favoring a 100x factor increase (or two decimal places of precision loss).</p> <p>Polkadot's redenomination then took place on 21 August, now known as Denomination Day, at block <code>1_248_328</code>.</p>"},{"location":"learn/archive/learn-redenomination/#what-this-means-for-the-community","title":"What This Means for the Community","text":"<p>If you are a DOT holder or user of the network, then you do not need to take any action. The DOT redenomination was a purely front-end change. You still hold the same amount of Plancks after the change, but now it will appear that you hold 100x more DOT. This change applies proportionally to every account.</p>"},{"location":"learn/archive/learn-redenomination/#what-this-means-for-builders-of-tools","title":"What This Means for Builders of Tools","text":"<p>If you are the builder of a tool that consumes the <code>@polkadot/api</code> package \u2014 then there should be no real changes to be made in your application. The denomination is technically a cosmetic change, and every value remains a constant amount of Plancks.</p> <p>However \u2014 if you are a builder of a tool that displays DOT balances to users (e.g. a wallet) or handles DOT balances in an off-chain or custodial way, then you will need to ensure that you display the correct denomination of DOT to users.</p> <p>Please see our Ecosystem Redenomination Guide for recommendations.</p> <p>Please reach out to support@polkadot.network if you need any assistance in making sure your software is compatible with the redenomination.</p>"},{"location":"learn/archive/learn-treasury/","title":"Governance v1 Treasury","text":"<p>     The content on this page is archived. For up-to-date information, see the            Polkadot OpenGov Treasury page.      </p> \u2716 <p>The Treasury is a pot of funds collected through a portion of block production rewards, transaction fees, slashing, staking inefficiencies, etc.</p> <p>The Treasury funds are held in a system account not accessible by anyone; only the system internal logic can access it. Funds can be spent by making a spending proposal that, if approved by the Council, will enter a waiting period before distribution. This waiting period is known as the spend period, and its duration is subject to governance. The Treasury attempts to spend as many proposals in the queue as it can without running out of funds.</p> <p>Treasury payout is an automatic process:</p> <ul> <li>If the Treasury funds run out with approved proposals left to fund, those proposals are kept in   the approved queue, and will receive funding in the following spend period.</li> <li>If the Treasury ends a spend period without spending all of its funds, it suffers a burn of   a percentage of its funds - thereby   causing deflationary pressure. This encourages the spending of the funds in the Treasury by   Polkadot's governance system.</li> </ul> <p>When a stakeholder wishes to propose a spend from the Treasury, they must reserve a deposit of at least 5% of the proposed spend (see below for variations). This deposit will be slashed if the proposal is rejected, and returned if it is accepted.</p> <p>Proposals may consist of (but are not limited to):</p> <ul> <li>Infrastructure deployment and continued operation.</li> <li>Network security operations (monitoring services, continuous auditing).</li> <li>Ecosystem provisions (collaborations with friendly chains).</li> <li>Marketing activities (advertising, paid features, collaborations).</li> <li>Community events and outreach (meetups, pizza parties, hackerspaces).</li> <li>Software development (wallets and wallet integration, clients and client upgrades).</li> </ul> <p>The Council governs the Treasury and how the funds are spent is up to their judgment.</p> <p>Caution</p> <p>The Council does not approve or deny Treasury Proposals based on the available funds. Proposals are not approved just because there are funds ready to spend but are subject to a burn.</p>"},{"location":"learn/archive/learn-treasury/#funding-the-treasury","title":"Funding the Treasury","text":"<p>For more information about how the Polkadot Treasury is funded, see the treasury page.</p>"},{"location":"learn/archive/learn-treasury/#tipping","title":"Tipping","text":"<p>Next to the proposals process, a separate system for making tips exists for the Treasury. Tips can be suggested by anyone and are supported by members of the Council. Tips do not have any definite value, and the final value of the tip is decided based on the median of all tips issued by the tippers.</p> <p>Currently, the tippers are the same as the members of the Council. However, being a tipper is not the direct responsibility of the Council, and at some point the Council and the tippers may be different groups of accounts.</p> <p>A tip will enter a closing phase when more than a half plus one of the tipping group have endorsed a tip. During that time frame, the other members of the tipping group can still issue their tips, but do not have to. Once the window closes, anyone can call the <code>close_tip</code> extrinsic, and the tip will be paid out.</p> <p>There are two types of tips:</p> <ul> <li>public: A small bond is required to place them. This bond depends on the tip message length, and a   fixed bond constant defined on chain, currently 1 DOT (0.166 KSM on Kusama). Public tips carry a   finder's fee of 20% (same on Polkadot and Kusama) which is paid out from the total amount.</li> <li>tipper-initiated: Tips that a Council member published, do not have a finder's fee or a bond.</li> </ul> <p>Info</p> <p>For information about how to submit a tip from the Treasury you can read this support article.</p> <p>To better understand the process a tip goes through until it is paid out, let's consider the example below.</p>"},{"location":"learn/archive/learn-treasury/#example","title":"Example","text":"<p>Bob has done something great for Polkadot. Alice has noticed this and decides to report Bob as deserving a tip from the Treasury. The Council is composed of three members Charlie, Dave, and Eve.</p> <p>Alice begins the process by issuing the <code>report_awesome</code> extrinsic. This extrinsic requires two arguments, a reason and the beneficiary. Alice submits Bob's address with the reason being a UTF-8 encoded URL to a post on Polkassembly that explains her reasoning for why Bob deserves the tip.</p> <p>As mentioned above, Alice must also lock up a deposit for making this report. The deposit is the base deposit as set in the chain's parameter list, plus the additional deposit per byte contained in the reason. This is why Alice submitted a URL as the reason instead of the explanation directly: it was cheaper for her to do so. For her trouble, Alice is able to claim the eventual finder's fee if the tip is approved by the tippers.</p> <p>Since the tipper group is the same as the Council, the Council must now collectively (but also independently) decide on the value of the tip that Bob deserves. Charlie, Dave, and Eve all review the report and make tips according to their personal valuation of the benefit Bob has provided to the network. Charlie tips 10 DOT, Dave tips 30 DOT, and Eve tips 100 DOT.</p> <p>The tip could have been closed out with only two of the three tippers. Once more than half of the tippers group have issued tip valuations, the countdown to close the tip will begin. In this case, the third tipper issued their tip before the end of the closing period, so all three were able to make their tip valuations known.</p> <p>The actual tip that will be paid out to Bob is the median of these tips, so Bob will be paid out 30 DOT from the Treasury. In order for Bob to be paid his tip, some account must call the <code>close_tip</code> extrinsic at the end of the closing period for the tip. This extrinsic may be called by anyone.</p>"},{"location":"learn/archive/learn-treasury/#bounties-spending","title":"Bounties Spending","text":"<p>There are practical limits to Council Members curation capabilities when it comes to treasury proposals: Council members likely do not have the expertise to make a proper assessment of the activities described in all proposals. Even if individual Councillors have that expertise, it is highly unlikely that a majority of members are capable in such diverse topics.</p> <p>Bounties Spending proposals aim to delegate the curation activity of spending proposals to experts called Curators: They can be defined as addresses with agency over a portion of the Treasury with the goal of fixing a bug or vulnerability, developing a strategy, or monitoring a set of tasks related to a specific topic: all for the benefit of the Polkadot ecosystem.</p> <p>A proposer can submit a bounty proposal for the Council to pass, with a curator to be defined later, whose background and expertise is such that they are capable of determining when the task is complete. Curators are selected by the Council after the bounty proposal passes, and need to add an upfront payment to take the position. This deposit can be used to punish them if they act maliciously. However, if they are successful in their task of getting someone to complete the bounty work, they will receive their deposit back and part of the bounty reward.</p> <p>When submitting the value of the bounty, the proposer includes a reward for curators willing to invest their time and expertise in the task: this amount is included in the total value of the bounty. In this sense, the curator's fee can be defined as the result of subtracting the value paid to the bounty rewardee from the total value of the bounty.</p> <p>In general terms, curators are expected to have a well-balanced track record related to the issues the bounty tries to resolve: they should be at least knowledgeable on the topics the bounty touches, and show project management skills or experience. These recommendations ensure an effective use of the mechanism. A Bounty Spending is a reward for a specified body of work - or specified set of objectives - that needs to be executed for a predefined treasury amount to be paid out. The responsibility of assigning a payout address once the specified set of objectives is completed is delegated to the curator.</p> <p>After the Council has activated a bounty, it delegates the work that requires expertise to the curator who gets to close the active bounty. Closing the active bounty enacts a delayed payout to the payout address and a payout of the curator fee. The delay phase allows the Council to act if any issues arise.</p> <p>To minimize storage on chain in the same way as any proposal, bounties don't contain contextual information. When a user submits a bounty spending proposal, they will probably need to find an off-chain way to explain the proposal (any of the available community forums serve this purpose). This template can help as a checklist of all needed information for the Council to make an informed decision.</p> <p>The bounty has a predetermined duration of 90 days with the possibility of being extended by the curator. Aiming to maintain flexibility on the tasks\u2019 curation, the curator will be able to create sub-bounties for more granularity and allocation in the next iteration of the mechanism.</p>"},{"location":"learn/archive/learn-treasury/#creating-a-bounty-proposal","title":"Creating a Bounty Proposal","text":"<p>Anyone can create a Bounty proposal using Polkadot-JS Apps: Users are able to submit a proposal on the dedicated Bounty section under Governance. The development of a robust user interface to view and manage bounties in the Polkadot Apps is still under development and it will serve Council members, Curators and Beneficiaries of the bounties, as well as all users observing the on-chain treasury governance. For now, the help of a Councillor is needed to open a bounty proposal as a motion to be voted.</p> <p>To submit a bounty, please visit Polkadot-JS Apps and click on the governance tab in the options bar on the top of the site. After, click on 'Bounties' and find the button '+ Add Bounty' on the upper-right side of the interface. Complete the bounty title, the requested allocation (including curator's fee) and confirm the call.</p> <p>After this, a Council member will need to assist you to pass the bounty proposal for vote as a motion. You can contact the Council by joining the main Direction Element Channel and Discord server and publishing a short description of your bounty, with a link to one of the forums for contextual information.</p> <p>A bounty can be cancelled by deleting the earmark for a specific treasury amount or be closed if the tasks have been completed. On the opposite side, the 90 days life of a bounty can be extended by amending the expiry block number of the bounty to stay active.</p>"},{"location":"learn/archive/learn-treasury/#closing-a-bounty","title":"Closing a bounty","text":"<p>The curator can close the bounty once they approve the completion of its tasks. The curator should make sure to set up the payout address on the active bounty beforehand. Closing the Active bounty enacts a delayed payout to the payout address and a payout of the curator fee.</p> <p>A bounty can be closed by using the extrinsics tab and selecting the Treasury pallet, then <code>Award_bounty</code>, making sure the right bounty is to be closed and finally sign the transaction. It is important to note that those who received a reward after the bounty is completed, must claim the specific amount of the payout from the payout address, by calling <code>Claim_bounty</code> after the curator closed the allocation.</p> <p>To understand more about Bounties and how this new mechanism works, read this Polkadot Blog post.</p>"},{"location":"learn/archive/learn-treasury/#faq","title":"FAQ","text":""},{"location":"learn/archive/learn-treasury/#what-prevents-the-treasury-from-being-captured-by-a-majority-of-the-council","title":"What prevents the Treasury from being captured by a majority of the Council?","text":"<p>The majority of the Council can decide the outcome of a treasury spend proposal. In an adversarial mindset, we may consider the possibility that the Council may at some point go rogue and attempt to steal all of the treasury funds. It is a possibility that the treasury pot becomes so great, that a large financial incentive would present itself.</p> <p>For one, the Treasury has deflationary pressure due to the burn that is suffered every spend period. The burn aims to incentivize the complete spend of all treasury funds at every burn period, so ideally the treasury pot doesn't have time to accumulate mass amounts of wealth. However, it is the case that the burn on the Treasury could be so little that it does not matter - as is the case currently on Kusama with a 0.2% burn.</p> <p>However, it is the case on Kusama that the Council is composed of mainly well-known members of the community. Remember, the Council is voted in by the token holders, so they must do some campaigning or otherwise be recognized to earn votes. In the scenario of an attack, the Council members would lose their social credibility. Furthermore, members of the Council are usually externally motivated by the proper operation of the chain. This external motivation is either because they run businesses that depend on the chain, or they have direct financial gain (through their holdings) of the token value remaining steady.</p> <p>Concretely, there are a couple on-chain methods that resist this kind of attack. One, the Council majority may not be the token majority of the chain. This means that the token majority could vote to replace the Council if they attempted this attack - or even reverse the treasury spend. They would do this through a normal referendum. Two, there are time delays to treasury spends. They are only enacted every spend period. This means that there will be some time to observe this attack is taking place. The time delay then allows chain participants time to respond. The response may take the form of governance measures or - in the most extreme cases a liquidation of their holdings and a migration to a minority fork. However, the possibility of this scenario is quite low.</p>"},{"location":"learn/archive/learn-treasury/#further-reading","title":"Further Reading","text":"<ul> <li> <p>Substrate's Treasury Pallet</p> </li> <li> <p>Documentation of the Rust implementation of the Treasury</p> </li> </ul>"},{"location":"learn/archive/thousand-validators/","title":"Thousand Validators Programme","text":"<p>     The content on this page is archived. For up-to-date information, see the            Decentralized Nodes web page.      </p> \u2716 <p>The Thousand Validators Programme is an initiative by Web3 Foundation and Parity Technologies to use the funds held by both organizations to nominate validators in the community.</p> <p>It serves two major purposes:</p> <ol> <li>Give validators a structured on-ramp to join the active set of validators on Kusama and Polkadot</li> <li>Further decentralize the validator active set.</li> </ol>"},{"location":"learn/archive/thousand-validators/#how-it-works","title":"How it Works","text":"<p>The nominating backend will routinely change its nominations at every era (four eras on Kusama). The backend does this by short-listing candidates by validity and then sorts validators by their weighted score in descending order.</p> <ul> <li> <p>Validators with a higher weighted score are selected for any possible slots. As validators are   nominated and actively validate, their weighted scores decrease allowing other validators to be   selected in subsequent rounds of assessment.</p> </li> <li> <p>If a validator is active during a single nomination period (the time after a new nomination and   before the next one) and does not break any of the requirements, it will have its rank increased   by 1. Validators with higher rank have performed well within the program for a longer period of   time.</p> </li> </ul> <p>The backend nominates as many validators as it reasonably can in such a manner to allow each nominee an opportunity to be elected into the active set.</p>"},{"location":"learn/archive/thousand-validators/#setting-up-a-validator","title":"Setting up a Validator","text":"<p>Please see the guide on how to set up a validator as well as additional information on how to secure a validator.</p>"},{"location":"learn/archive/thousand-validators/#how-to-apply","title":"How to Apply","text":"<p>Entrance to the Polkadot program requires a rank of 100 or higher in the Kusama program. Attaining a rank of 100 usually takes around two months. In order to apply to the Polkadot 1KV programme, set up your Polkadot node to adhere to the requirements below.</p> <p>1KV on Kusama</p> <p>In order to apply to the Kusama 1KV programme, set up your node to adhere to the requirements below. The process of review and addition is a manual one; you'll be invited to the 1KV Kusama channel and added to the leaderboard, if accepted.</p>"},{"location":"learn/archive/thousand-validators/#requirements","title":"Requirements","text":"<ul> <li>Verified identity (see here for instructions)</li> <li>Connect to dedicated telemetry (use   <code>--telemetry-url 'wss://telemetry-backend.w3f.community/submit 1'</code> when starting the node)</li> <li>Minimum of 5_000 DOTs self stake on Polkadot and 10 KSM on Kusama</li> <li>No more than 5% commission on Polkadot and 15% commission on Kusama</li> <li>Have a staking proxy set up</li> <li>Must be on the latest release</li> <li>Maximum one node per applicant on Polkadot and two nodes (under same sub/super identity) on Kusama</li> <li>Validators must operate nodes themselves. They may not be operated by third parties or staking   providers.</li> </ul>"},{"location":"learn/archive/thousand-validators/#nominators","title":"Nominators","text":"<p>The below addresses are the stash / staking proxy pairs for the primary nominators involved in the Thousand Validators programme. They are formatted like \"<code>stash</code> / <code>staking proxy</code>\".</p> PolkadotKusama <ul> <li><code>14Ns6kKbCoka3MS4Hn6b7oRw9fFejG8RH5rq5j63cWUfpPDJ</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> <li><code>12RYJb5gG4hfoWPK3owEYtmWoko8G6zwYpvDYTyXFVSfJr8Y</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> <li><code>16GMHo9HZv8CcJy4WLoMaU9qusgzx2wxKDLbXStEBvt5274B</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> <li><code>13yk62yQYctYsRPXDFvC5WzBtanAsHDasenooLAxKvf5bNkK</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> <li><code>13SkL2uACPqBzpKBh3d2n5msYNFB2QapA5vEDeKeLjG2LS3Y</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> <li><code>12WLDL2AXoH3MHr1xj8K4m9rCcRKSWKTUz8A4mX3ah5khJBn</code> /   <code>12iz6aJ75KdqVZLGyvFJmgc5k74Pdokgy9UGTgWtnt67RNTg</code></li> </ul> <ul> <li><code>G1rrUNQSk7CjjEmLSGcpNu72tVtyzbWdUvgmSer9eBitXWf</code> /   <code>Edyfdyoi4KJVdXUJ3SU3nuZYMpg13HHa1SWYtPDCV8UPdxy</code></li> <li><code>HgTtJusFEn2gmMmB5wmJDnMRXKD6dzqCpNR7a99kkQ7BNvX</code> /   <code>Edyfdyoi4KJVdXUJ3SU3nuZYMpg13HHa1SWYtPDCV8UPdxy</code></li> <li><code>EX9uchmfeSqKTM7cMMg8DkH49XV8i4R7a7rqCn8btpZBHDP</code> /   <code>Edyfdyoi4KJVdXUJ3SU3nuZYMpg13HHa1SWYtPDCV8UPdxy</code></li> <li><code>JLENz97TFT2kYaQmyCSEnBsK8VhaDZNmYATfsLCHyLF6Gzu</code> /   <code>Edyfdyoi4KJVdXUJ3SU3nuZYMpg13HHa1SWYtPDCV8UPdxy</code></li> </ul> <p>A time delay proxy is used as the interaction method for some of these accounts.</p> <p>Within the Kusama program, there are several other nominator accounts that can exhaustively be determined by parsing data found here.</p> <p>Since approximately early January 2021, the nominators will select an automatic number of validators to nominate based on the lowest amount staked for a validator and the amount of funds it holds. This can be anywhere from a few validators receiving nomination from a single nominator, to the max of nominators.</p>"},{"location":"learn/archive/thousand-validators/#selection","title":"Selection","text":"<p>On-chain parameters assess each candidate to produce a weighted score. It is a changing system in which new endpoints or scores are sometimes introduced. Below are some of the original weights.</p>"},{"location":"learn/archive/thousand-validators/#weights","title":"Weights","text":""},{"location":"learn/archive/thousand-validators/#inclusion","title":"Inclusion","text":"<p>The inclusion weight accounts for 40 points. It is assessed by an evaluation of the validator's inclusion in the active set over the past 84 eras. A candidate can be assured of full score if there were no stints of active validation in 84 eras.</p>"},{"location":"learn/archive/thousand-validators/#span-inclusion","title":"Span Inclusion *","text":"<p>The span inclusion weight accounts for 40 points. It is assessed by an evaluation of the validator's inclusion in the active set over the past 28 eras. A candidate can be assured of full score if there were no stints of active validation in 28 eras.</p>"},{"location":"learn/archive/thousand-validators/#discovered","title":"Discovered *","text":"<p>The discovered weight accounts for 5 points. It is determined by comparing the candidates tenure in the program relative to other candidates. A candidate that is in the program for a longer duration relative to the entire group of validators allows for a higher score.</p>"},{"location":"learn/archive/thousand-validators/#nominated","title":"Nominated *","text":"<p>The nominated weight accounts for 10 points, and it is assessed based on when the candidate was last nominated relative to the other candidates in the program.</p>"},{"location":"learn/archive/thousand-validators/#rank","title":"Rank *","text":"<p>The rank weight accounts for 5 points and is assessed relative to the ranks of other candidates within the program.</p>"},{"location":"learn/archive/thousand-validators/#unclaimed","title":"Unclaimed","text":"<p>The unclaimed weight relates to the number of payouts outstanding for greater than four eras on Polkadot and sixteen on Kusama. Each payout that exceeds this threshold would attribute a negative score of 10 points.</p>"},{"location":"learn/archive/thousand-validators/#bonded","title":"Bonded *","text":"<p>Candidates with a bond size that is relatively higher than others would receive a score of 50 points.</p>"},{"location":"learn/archive/thousand-validators/#faults","title":"Faults *","text":"<p>A fault is attained when a candidate has an offline event when actively validating. A legitimate fault is irrevocable. Faults account for 5 points in the system and are relative to others in the program.</p>"},{"location":"learn/archive/thousand-validators/#offline-time","title":"Offline time","text":"<p>Candidates who have accumulated &lt; 200 minutes offline time during the weekly period will receive 2 points in the system. Offline time is judged by a candidate's connection to the W3F Telemetry and is reset on Sundays.</p>"},{"location":"learn/archive/thousand-validators/#location","title":"Location *","text":"<p>The system allocates a score of 40 points for candidates who host their validators in uniquely located data centres. A candidate's location is determined from Telemetry and is relative to the number of other candidates located at the same data centre.</p>"},{"location":"learn/archive/thousand-validators/#council","title":"Council","text":"<p>Candidates will receive a score of up to 50 points for voting for council members. Candidates may back as few as one candidate; to attain a full score of 50 points, the 1KV candidate should allocate &gt; 75% of their bond to the respective council members.</p>"},{"location":"learn/archive/thousand-validators/#democracy","title":"Democracy","text":"<p>Candidates will receive 10 * 1KV points for each referendum they have voted on (Aye/Nay) to a limit of 100 points. Scores are based on votes for referendum 49 on Polkadot (163 on Kusama) and beyond.</p> <p>* Scores that are based on their relative position against others are assessed as follows:</p> <ul> <li>The respective weight is assigned high and low percentiles. Any scores lower than the score at the   low percentile and higher than the score at the high percentile are removed.</li> <li> <p>The weighted score is then obtained by ((candidate_value - low_threshold) / (high_threshold -   low_threshold)) * weight.</p> </li> <li> <p>The default low and high percentiles are 10 and 90%, respectively.</p> </li> <li>Inclusion and Span Inclusions are measured against low and high percentiles of 20 and 75%,   respectively.</li> <li>Bonded is measured against low and high percentiles of 5 and 85%, respectively.</li> <li>Finally, location is measured against low and high percentiles of 10 and 95%, respectively.</li> </ul>"},{"location":"learn/archive/thousand-validators/#frequently-asked-questions","title":"Frequently asked questions","text":"<ul> <li>How do I apply? See here.</li> <li>How long does it take for the application to process? Usually a few weeks. Sometimes a little   longer. You can inspect the candidate files   here and see if your info shows   up. Also, you will get invited to a dedicated matrix room after being accepted.</li> <li>I'm in the program and am getting nominated but don't get active? The system optimizes the   nominations to maximize the stake on active validators and minimize the stake variance across   them. Also keep in mind that getting nominated does not mean all the nominations are with you.   Nominators can choose up to 16 validators.</li> <li>My scoring doesn't update, I haven't been elected for a while? Sometimes it\u2019s best to give   things time to resolve; if they don't, leave a message in the dedicated matrix room or open an   issue on GitHub.</li> <li>The 1000 validators website is not up to date? See these resources for more   up-to-date information.</li> </ul>"},{"location":"learn/archive/thousand-validators/#resources","title":"Resources","text":"<p>To extract and display the 1KV Programme scores there are various tools listed below.</p> Resource Github source Info SubVT telegram bot for polkadot and kusama github Telegram bot with overviews and alerts for various polkadot and kusama related events, including 1KV events. SubVT ios and android app github SubVT app version for mobile phones. Validator earnings overview github Overview of validators' earnings. Math Crypto's Insights github 1KV-oriented scoring overview of Kusama and Polkadot. One-T for polkadot and kusama github A performance report bot for the Polkadot and Kusama network with special focus on the 1KV programme. One-T parachains overview github One-T's parachain overview. Metaspan's 1KV overview github Overview of 1KV programme, including the newly introduced endpoints, see here for available endpoints. Decentradot's 1KV overview github Overview of the 1KV programme, including the newly introduced endpoints. Hirish 1KV overview github? Overview of the 1KV Programme."},{"location":"learn/assets/","title":"Assets Index","text":"<p>Welcome to the Assets Index. Here you will find information about assets on Polkadot.</p> <ul> <li>DOT - Information about the DOT token.</li> <li>Inflation - Details on inflation.</li> <li>Asset Conversion (Asset Hub) - Guide on asset conversion.</li> <li>Teleport - Information on teleporting assets.</li> <li>NFT - Details on NFTs.</li> </ul>"},{"location":"learn/basics/","title":"Basics Index","text":"<p>Welcome to the Basics Index. Here you will find basic information about Polkadot.</p> <ul> <li>Account Balances - Information on account balances.</li> <li>Account Abstraction - Details on account abstraction.</li> <li>Identity - Guide on identity.</li> <li>Account Multisig - Information on multisig accounts.</li> <li>Proxies - Details on proxies.</li> <li>Proxies Pure - Information on pure proxies.</li> <li>Transactions - Guide on transactions.</li> <li>Staking - Information on staking.</li> <li>Nomination Pools - Details on nomination pools.</li> <li>Polkadot OpenGov - Information on Polkadot OpenGov.</li> <li>Polkadot OpenGov Origins - Details on OpenGov origins.</li> <li>Polkadot Technical Fellowship - Information on the technical fellowship.</li> <li>DOT - Information about the DOT token.</li> <li>Inflation - Details on inflation.</li> <li>Asset Conversion (Asset Hub) - Guide on asset conversion.</li> <li>Teleport - Information on teleporting assets.</li> <li>NFT - Details on NFTs.</li> <li>Collator - Information on collators.</li> <li>Nominator - Details on nominators.</li> <li>Validator - Information on validators.</li> <li>Offenses - Guide on offenses.</li> <li>Polkadot Host - Information on Polkadot Host.</li> <li>WASM - Details on WASM.</li> <li>Runtime Upgrades - Guide on runtime upgrades.</li> </ul>"},{"location":"learn/comparisons/","title":"Comparisons","text":"<ul> <li>Kusama - Comparison with Kusama.</li> <li>Ethereum - Comparison with Ethereum.</li> <li>Cosmos - Comparison with Cosmos.</li> <li>Avalanche - Comparison with Avalanche.</li> </ul>"},{"location":"learn/components/","title":"Components","text":"<p>Welcome to the Components Index. Here you will find information about the components of the Polkadot network.</p> <ul> <li>Polkadot Host - Information on Polkadot Host.</li> <li>WASM - Details on WASM.</li> <li>Runtime Upgrades - Guide on runtime upgrades.</li> </ul>"},{"location":"learn/future-implementations/","title":"Future Implementations Index","text":"<p>Welcome to the Future Implementations Index. Here you will find information about future implementations on Polkadot.</p> <ul> <li>Spree - Information on Spree.</li> <li>Safrole - Details on Safrole.</li> <li>JAM Chain - Information on JAM Chain.</li> <li>JAM FAQ - Frequently asked questions about JAM.</li> </ul>"},{"location":"learn/general/","title":"General","text":"<p>Here you will find general information about Polkadot.</p> <ul> <li>Web3 and Polkadot - Information about Web3 and Polkadot.</li> <li>Polkadot Vision - Vision of Polkadot.</li> <li>Polkadot V1 - Polkadot Version 1.</li> <li>Polkadot Direction - Direction of Polkadot.</li> <li>Stay Safe - Stay safe in the Polkadot ecosystem.</li> <li>How to DYOR - How to Do Your Own Research.</li> <li>Scams - Information about scams.</li> <li>Transaction Attacks - Information about transaction attacks.</li> <li>Web3 Foundation Research - Research by Web3 Foundation.</li> <li>Start Building - Start building on Polkadot.</li> <li>Glossary - Glossary of terms.</li> </ul>"},{"location":"learn/participants/","title":"Network Participants","text":"<p>Here you will find information about participants in the Polkadot network.</p> <ul> <li>Collator - Information about Collators.</li> <li>Nominator - Information about Nominators.</li> <li>Validator - Information about Validators.</li> </ul>"},{"location":"learn/polkadot-opengov/","title":"Polkadot OpenGov","text":"<p>Here you will find information about Polkadot's governance.</p> <ul> <li>Polkadot OpenGov Origins - Information about Polkadot OpenGov Origins.</li> <li>Polkadot Technical Fellowship - Information about Polkadot Technical Fellowship.</li> <li>OpenGov.Watch - OpenGov Watch website.</li> <li>OpenGov Tracker - OpenGov Tracker website.</li> <li>OpenGov Portal - OpenGov Portal on Notion.</li> </ul>"},{"location":"learn/staking/","title":"Staking","text":"<p>Here you will find information about staking on Polkadot.</p> <ul> <li>Staking - Detailed information about Staking.</li> <li>Nomination Pools - Information about Nomination Pools.</li> </ul>"},{"location":"learn/xcm/learn-xcm-docs-intro/","title":"XCM: Cross-Consensus Messaging","text":"<p>Welcome to the Cross-Consensus Messaging (XCM) documentation! XCM is a language for communicating intentions between consensus systems. Whether you're a developer, a blockchain enthusiast, or just interested in Polkadot, this guide aims to provide you with an easy-to-understand and comprehensive introduction to XCM.</p>"},{"location":"learn/xcm/learn-xcm-docs-intro/#getting-started","title":"Getting started","text":"<p>Head over to the overview to begin your journey with XCM.</p>"},{"location":"learn/xcm/learn-xcm-docs-intro/#configuration","title":"Configuration","text":"<p>Head over to the configuration section if you want to learn how to configure your project to use XCM.</p>"},{"location":"learn/xcm/learn-xcm-docs-intro/#glossary","title":"Glossary","text":"<p>Go to the glossary section for a quick explanation of all the terms used when dealing with XCM.</p>"},{"location":"learn/xcm/learn-xcm-docs-intro/#contribute","title":"Contribute","text":"<p>Both the format and this documentation are open for anyone to contribute. If there's anything you'd like to see in the documentation, feel free to open an issue. If you want to contribute to the format, check out the RFC process.</p>"},{"location":"learn/xcm/testing/","title":"Testing","text":"<p>Before deploying your XCM-powered solution to production, it's paramount to test it thoroughly. There are different levels for testing, which should be tackled sequentially:</p> <ul> <li>Message: Making sure your message works properly, according to the XCVM spec.</li> <li>Configuration: Making sure your executor's configuration is as expected.</li> <li>End-to-end: Making sure the whole flow works, in an environment as similar to production as   possible.</li> </ul> <p>We'll discuss tools and best practices for each of these levels.</p>"},{"location":"learn/xcm/testing/#xcm-simulator","title":"XCM Simulator","text":"<p>The xcm-simulator is a tool to quickly test the execution of various XCM instructions against the <code>xcm-executor</code>. The examples in this documentation use the xcm-simulator. The simulator mocks the Downward Message Passing pallet, enabling us to get the XCMs that a parachain receives from the relay chain using the <code>received_dmp</code> getter. The simulator should be used as a XCM playground. For testing the XCM configuration of your parachain and the integration with other chains, you can use the xcm-emulator.</p>"},{"location":"learn/xcm/testing/#xcm-emulator","title":"XCM Emulator","text":"<p>The xcm-emulator is a tool to emulate XCM program execution using pre-configured runtimes, including those used to run on live networks, such as Kusama, Polkadot, Statemine, etc. This allows for testing cross-chain message passing and verifying outcomes, weights, and side-effects.</p> <p>An example of how the emulator is used for testing common good parachains can be found here.</p> <p>The xcm-emulator uses the transport layer pallets. However, the messages do not utilize the same messaging infrastructure as live networks, as the transport mechanism is being mocked out. Also, consensus related events are not tested, like disputes and staking. To test for these events, parachains can use E2E tests.</p>"},{"location":"learn/xcm/testing/#end-to-end-testing","title":"End-to-End testing","text":"<p>There are two frameworks being used in the ecosystem to do e2e testing:</p> <ul> <li>Zombienet.</li> <li>Chopsticks.</li> </ul>"},{"location":"learn/xcm/executor_config/config/","title":"Executor Config","text":"<p>As previously mentioned, the xcm-executor is a Cross-Consensus Virtual Machine (XCVM) implementation. It provides an opinionated interpretation and execution of XCMs. Each chain that uses the xcm-executor, can configure it for their use case. In this chapter we will go over this configuration, explain each config item and give some examples of the tools and types that can be used to configure these items.</p>"},{"location":"learn/xcm/executor_config/config/#xcm-executor-configuration","title":"XCM Executor Configuration","text":"<p>Below we list the Config trait of the xcm-executor. The Config trait expects multiple associated types. Each type has a trait bound which the concrete type must implement. Some of these types will use a default implementation in most situations (e.g. RuntimeCall). Other types have a default implementation specified by the unit type <code>()</code>. Most types you'll want to carefully choose which implementation they get. For most of these types there are pre-defined solutions and building blocks you can use and adapt to your scenario. These solutions are listed in the xcm-builder folder.</p> <p>We will now explain each type and go over some of the implementations of the type:</p> <p><code>``rust, noplayground /// The trait to parameterize the</code>XcmExecutor`. pub trait Config {     type RuntimeCall: Parameter + Dispatchable + GetDispatchInfo;     type XcmSender: SendXcm;     type AssetTransactor: TransactAsset;     type OriginConverter: ConvertOrigin&lt;::RuntimeOrigin&gt;;     type IsReserve: ContainsPair;     type IsTeleporter: ContainsPair;     type UniversalLocation: Get;     type Barrier: ShouldExecute;     type Weigher: WeightBounds;     type Trader: WeightTrader;     type ResponseHandler: OnResponse;     type AssetTrap: DropAssets;     type AssetClaims: ClaimAssets;     type AssetLocker: AssetLock;     type AssetExchanger: AssetExchange;     type SubscriptionService: VersionChangeNotifier;     type PalletInstancesInfo: PalletsInfoAccess;     type MaxAssetsIntoHolding: Get;     type FeeManager: FeeManager;     type MessageExporter: ExportXcm;     type UniversalAliases: Contains&lt;(MultiLocation, Junction)&gt;;     type CallDispatcher: CallDispatcher;     type SafeCallFilter: Contains; } <pre><code>## How to use multiple implementations.\n\nSome associated types in the Config trait are highly configurable and in certain cases will have\nmultiple implementations (e.g. Barrier). These implementations are then grouped using a tuple\n`(impl_1, impl_2, ..., impl_n)`. The execution of the tuple type is sequential, meaning that each\nitem is executed one after another. Each item is checked to see whether it fails to pass, then the\nnext item is checked, and so on. The execution is halted when one of these items returns positive\n(Ok or true, etc.). The next example of the Barrier type shows how the grouping works (understanding\neach item in the tuple is not necessary).\n\n```rust\npub type Barrier = (\n    TakeWeightCredit,\n    AllowTopLevelPaidExecutionFrom&lt;Everything&gt;,\n    AllowKnownQueryResponses&lt;XcmPallet&gt;,\n    AllowSubscriptionsFrom&lt;Everything&gt;,\n);\n\npub struct XcmConfig;\nimpl xcm_executor::Config for XcmConfig {\n    ...\n    type Barrier = Barrier;\n    ...\n}\n</code></pre> <p>In the above example, when checking the barrier, we'll first check the TakeWeightCredit type. If it fails, we'll go on to check the <code>AllowTopLevelPaidExecutionFrom&lt;Everything&gt;</code> and so on until one of them gives a positive. If they all fail, a <code>Barrier</code> error is thrown.</p>"},{"location":"learn/xcm/executor_config/config/#config-items","title":"Config Items","text":"<p>We now go over each config item to explain what the associate type does and how it is used in the xcm-executor. Many of these types have pre-defined solutions that can be found in the xcm-builder and a good way to understand these configurations is to look at example configurations. On the bottom of this page we listed some examples.</p>"},{"location":"learn/xcm/executor_config/config/#runtimecall","title":"RuntimeCall","text":"<p>The <code>RuntimeCall</code> type is equal to the RuntimeCall created in the <code>construct_runtime!</code> macro. It is an enum of all the callable functions of each of the implemented pallets.</p>"},{"location":"learn/xcm/executor_config/config/#xcmsender","title":"XcmSender","text":"<p>The <code>XcmSender</code> type implements the <code>SendXcm</code> trait, and defines how the xcm_executor can send XCMs (which transport layer it can use for the XCMs). This type normally implements a tuple for one or more transport layer(s). For example a parachain can implement the XcmSender as:</p> <pre><code> (\n    // Two routers - use UMP to communicate with the relay chain:\n    cumulus_primitives_utility::ParentAsUmp&lt;ParachainSystem, PolkadotXcm, ()&gt;,\n    // ..and XCMP to communicate with the sibling chains.\n    XcmpQueue,\n);\n</code></pre> <p>If a runtime does not contain the XcmpQueue pallet as a config item for XcmSender, it will not be able to send messages to other parachains. This can be useful for controlling the destinations that an XCM can be sent to.</p>"},{"location":"learn/xcm/executor_config/config/#assettransactor","title":"AssetTransactor","text":"<p>The <code>AssetTransactor</code> type implements the <code>TransactAsset</code> trait and defines how the xcm-executor can convert <code>MultiAsset</code>s from and to on chain assets and how to transfer these assets between accounts, or from and to the holding register. As chains can support different types of currencies (native tokens), fungibles and non-fungibles, we can configure the AssetTransactor in different ways, depending on the chains implementation fo these types. Three default implementations are provided in the xcm-builder, namely the <code>CurrencyAdapter</code>, <code>FungiblesAdapter</code> and <code>NonFungiblesAdapter</code>.</p>"},{"location":"learn/xcm/executor_config/config/#originconverter","title":"OriginConverter","text":"<p>The <code>OriginConverter</code> type implements the <code>ConvertOrigin</code> trait and defines how the xcm-executor can convert a <code>MultiLocation</code> into a <code>RuntimeOrigin</code>. Most xcm-executors take multiple implementations in a tuple for this configuration as there are many different MLs we would like to convert. When multiple <code>OriginConverter</code>s conflict, the OriginKind that is passed to the <code>convert_origin</code> function is used to distingues which <code>OriginConverter</code> to use. There are four different <code>OriginKind</code>s :</p> <pre><code>pub enum OriginKind {\n    Native,\n    SovereignAccount,\n    Superuser,\n    Xcm,\n}\n</code></pre> <p>An example of the use of <code>OriginKind</code>s are the <code>SovereignSignedViaLocation</code> and <code>SignedAccountId32AsNative</code> OriginConverters (defined in xcm-builder). The first converts an sovereign account into a <code>Signed</code> RuntimeOrigin (uses <code>SovereignAccount</code> OriginKind) while the second converts a local native account into a <code>Signed</code> RuntimeOrigin (uses <code>Native</code> OriginKind).</p> <pre><code>pub type SovereignAccountOf = AccountId32Aliases&lt;ThisNetwork, AccountId&gt;;\n(\n    // A `Signed` origin of the sovereign account that the original location controls.\n    SovereignSignedViaLocation&lt;SovereignAccountOf, RuntimeOrigin&gt;,\n    // The AccountId32 location type can be expressed natively as a `Signed` origin.\n    SignedAccountId32AsNative&lt;ThisNetwork, RuntimeOrigin&gt;,\n);\n</code></pre>"},{"location":"learn/xcm/executor_config/config/#isreserve","title":"IsReserve","text":"<p>The <code>IsReserve</code> type must be set to specify which <code>&lt;MultiAsset, MultiLocation&gt;</code> pair we trust to deposit reserve assets on our chain. We can also use the unit type <code>()</code> to block <code>ReserveAssetDeposited</code> instructions. An example implementation is the <code>NativeAsset</code> struct, that accepts an asset iff it is a native asset.</p>"},{"location":"learn/xcm/executor_config/config/#isteleporter","title":"IsTeleporter","text":"<p>The <code>IsTeleporter</code> type must be set to specify which <code>&lt;MultiAsset, MultiLocation&gt;</code> pair we trust to teleport assets to our chain. We can also use the unit type <code>()</code> to block <code>ReceiveTeleportedAssets</code> instruction. An example implementation is the <code>NativeAsset</code> struct, that accepts an asset iff it is a native asset.</p>"},{"location":"learn/xcm/executor_config/config/#universallocation","title":"UniversalLocation","text":"<p>The <code>UniversalLocation</code> type describes the location of the runtime implementing the xcm-executor in the consensus universe. Below we give some examples of <code>UniversalLocation</code> implementations.</p> <pre><code>//Polkadot\nX1(GlobalConsensus(NetworkId::Polkadot))\n//Kusama\nX1(GlobalConsensus(NetworkId::Kusama))\n//Statemint\nX2(GlobalConsensus(NetworkId::Polkadot), Parachain(1000))\n</code></pre>"},{"location":"learn/xcm/executor_config/config/#barrier","title":"Barrier","text":"<p>Before any XCMs are executed in the XCM executor, they need to pass the <code>Barrier</code>. The <code>Barrier</code> type implements the <code>ShouldExecute</code> trait and can be seen as the firewall of the xcm-executor. Each time the xcm-executor receives an XCM, it check with the barrier if the XCM should be executed. We can also define multiple barriers for our <code>Barrier</code> type by using a tuple. During execution, each barrier is checks, and if one of them succeed, the XCM is executed. Example of a <code>Barrier</code> implementations is <code>AllowTopLevelPaidExecutionFrom&lt;T&gt;</code> that accepts the XCM if the <code>T</code> contains the origin of the XCM and the XCM contains the <code>BuyExecution</code> instruction. To accept all XCMs that pay for execution we could set the barrier to <code>AllowTopLevelPaidExecutionFrom&lt;Everything&gt;</code>. There are multiple pre-defined barrier implementations in the xcm-builder.</p>"},{"location":"learn/xcm/executor_config/config/#weigher","title":"Weigher","text":"<p>The <code>Weigher</code> is responsible for weighing full XCMs and individual instructions. This weight is calculated before the XCM execution, and this calculated weight is checked against the weight_limit. If the weight is more than weight_limit, the xcm will not be executed. The weight is also passed to each <code>Barrier</code>, as certain barriers execute weight-based checks. After the execution of the XCM, unused weight is refunded (if possible). There are pre-defined <code>Weigher</code> solutions in the xcm-builder. The most used is the <code>FixedWeightBounds</code>:</p> <pre><code>// BaseXcmWeight is a const weight.\nFixedWeightBounds&lt;BaseXcmWeight, RuntimeCall, MaxInstructions&gt;;\n</code></pre> <p>Note: More information about weight.</p>"},{"location":"learn/xcm/executor_config/config/#trader","title":"Trader","text":"<p>The <code>Trader</code> type is responsible for buying weight in the <code>BuyExecution</code> instruction using assets in the holding register and to refund unspend weight. One of the first implementations of the <code>Trader</code> is defined in the xcm-builder, namely the <code>UsingComponents</code> trader.</p>"},{"location":"learn/xcm/executor_config/config/#responsehandler","title":"ResponseHandler","text":"<p>The <code>ResponseHandler</code> type is responsible for handling the <code>QueryResponse</code> instructions. A <code>ResponseHandler</code> implementation has to implement the <code>OnResponse</code> trait. One of the implementations of the <code>ResponseHandler</code> is the <code>pallet-xcm</code>. This will be the main implementation for most FRAME-based systems that implement the XCM-executor. Another option is to use the unit type <code>()</code> if you do not want to support <code>QueryResponse</code>.</p>"},{"location":"learn/xcm/executor_config/config/#assettrap","title":"AssetTrap","text":"<p>The <code>AssetTrap</code> type is responsible for handling the funds left over in holding after the execution of the XCM. The assets are stored in the AssetTrap and can be claimed using the ClaimAsset instruction. One of the implementations of the <code>AssetTrap</code> type is the <code>pallet-xcm</code>. Another option is to use the unit type <code>()</code> if you do not want to support asset trapping. In this case, the assets that are left in holding are burned.</p>"},{"location":"learn/xcm/executor_config/config/#assetclaims","title":"AssetClaims","text":"<p>The <code>AssetClaims</code> type is responsible for claiming trapped assets. It is during execution of the <code>ClaimAsset</code> instruction. One of the implementations of the <code>AssetClaims</code> type is the <code>pallet-xcm</code>. Another option is to use the unit type <code>()</code> if you do not want to support asset claiming.</p>"},{"location":"learn/xcm/executor_config/config/#assetlocker","title":"AssetLocker","text":"<p>The <code>AssetLocker</code> type is responsible with handling locking and unlocking assets. One of the implementations of the <code>AssetLocker</code> type is the <code>pallet-xcm</code>. Another option is to use the unit type <code>()</code> if you do not want to support asset locking.</p>"},{"location":"learn/xcm/executor_config/config/#assetexchanger","title":"AssetExchanger","text":"<p>The <code>AssetExchanger</code> type implements the <code>AssetExchange</code> trait and handles the exchange of assets for the ExchangeAsset instruction. An option is to use the unit type <code>()</code> if you do not want to support asset exchanging.</p>"},{"location":"learn/xcm/executor_config/config/#subscriptionservice","title":"SubscriptionService","text":"<p>The <code>SubscriptionService</code> type implements the <code>VersionChangeNotifier</code> trait and is used for the execution of the (Un)SubscribeVersion instructions. When a chain receives the <code>SubscribeVersion</code> instruction, the <code>SubscriptionService</code> should send back a <code>QueryResponse</code> with the XCM version that the chain uses. One of the implementations of the <code>SubscriptionService</code> is the <code>pallet-xcm</code>. This will be the main implementation for most FRAME-based systems that implement the XCM-executor.</p>"},{"location":"learn/xcm/executor_config/config/#palletinstancesinfo","title":"PalletInstancesInfo","text":"<p>The <code>PalletInstancesInfo</code> type implements the <code>PalletsInfoAccess</code> trait and is used in the <code>QueryPallet</code> and <code>ExpectPallet</code> instructions. It supplies the information of all the pallets in the Runtime, and is therefore FRAME specific. The unit type <code>()</code> can be used if you do not want to support pallet information.</p>"},{"location":"learn/xcm/executor_config/config/#maxassetsintoholding","title":"MaxAssetsIntoHolding","text":"<p>The <code>MaxAssetsIntoHolding</code> type is used to set a limit on the number of assets in the Holding Register. In the worse case, the Holding Register may contain up to twice as many assets as this limit.</p>"},{"location":"learn/xcm/executor_config/config/#feemanager","title":"FeeManager","text":"<p>The <code>FeeManager</code> type is used to manage what happens with the fees that need to be paid for certain XCM instructions. A <code>FeeManager</code> implementation implements the <code>FeeManager</code> trait. The FeeManager determines if fees should be paid (or if they are waived) and what to do with the paid fees. The unit type <code>()</code> can be used if you want to waive every fee.</p>"},{"location":"learn/xcm/executor_config/config/#messageexporter","title":"MessageExporter","text":"<p>The <code>MessageExporter</code> type implements the <code>ExportXcm</code> trait and is used to export a message to another consensus system. The <code>MessageExporter</code> is different from the <code>XcmSender</code>. The <code>MessageExporter</code> is able to spoof the origin of the message, meaning it can represent a different origin then the local (i.e. the caller chain's) location. The MessageExporter will mainly be used to send XCMs over bridges. For a more in depth explanation, see the ExportXcm trait. The unit type <code>()</code> can be used if you do not want to support XCM exporting.</p>"},{"location":"learn/xcm/executor_config/config/#universalaliases","title":"UniversalAliases","text":"<p>The <code>UniversalAliases</code> type is used to list the origin locations and specific universal junctions to which they are allowed to elevate themselves. <code>UniversalAliases</code> is used in the <code>UniversalOrigin</code> instruction. To not allow any alliasing of origins, <code>Nothing</code> can be used.</p>"},{"location":"learn/xcm/executor_config/config/#calldispatcher","title":"CallDispatcher","text":"<p>The <code>CallDispatcher</code> type is used by xcm-executor to dispatch calls that are passed in the <code>Transact</code> instruction with the given origin. When no special call dispatcher is required, this can be set to the same type as <code>RuntimeCall</code>. However, <code>CallDispatcher</code> can be used to customize call dispatch, such as adapting the origin based on the call or modifying the call.</p>"},{"location":"learn/xcm/executor_config/config/#safecallfilter","title":"SafeCallFilter","text":"<p>The <code>SafeCallFilter</code> type is used by the xcm-executor to whitelist calls that can be made in the <code>Transact</code> instruction. This is a temporary measure until proof size weights for XCM instructions are properly account for. If you want to allow all calls in <code>Tansact</code>, use <code>Everything</code>.</p>"},{"location":"learn/xcm/executor_config/config/#what-next","title":"What Next","text":"<p>Check out the Kusama, Statemine, or Trappist for examples of how to implement the xcm-executor config.</p>"},{"location":"learn/xcm/fundamentals/multiasset/","title":"MultiAsset","text":"<p>When working with XCM, it is often needed to represent an asset of some sort. This is because practically all public blockchains in existence rely on some native digital asset to provide the backbone for its internal economy and security mechanism. For example, the native asset for the Polkadot relay chain is DOT.</p> <p>Some blockchains manage multiple assets, e.g. Ethereum\u2019s ERC-20 framework allows for many different assets to be managed on-chain. Some manage assets that are not fungible, such as Ethereum\u2019s Crypto-kitties \u2014 each kitty is a one-of-a-kind instance. It was an early example of such non-fungible tokens or NFTs.</p> <p>XCM is designed to be able to describe all such assets without breaking a sweat. For this purpose, there is the <code>MultiAsset</code> datatype, along with its related types <code>MultiAssets</code>, <code>WildMultiAsset</code>, and <code>MultiAssetFilter</code>.</p>"},{"location":"learn/xcm/fundamentals/multiasset/#multiasset-breakdown","title":"MultiAsset Breakdown","text":"<p>Let's take a look at the MultiAsset struct:</p> <pre><code>pub struct MultiAsset {\n    pub id: AssetId,\n    pub fun: Fungibility,\n}\n</code></pre> <p>So two fields define our asset: id and fun. These fields are indicative of how XCM approaches assets. Firstly, an overall asset identity must be provided. For fungible assets, this is simply a symbol that identifies the asset. For NFTs this identifies the overall asset \u201cclass\u201d \u2014 different asset instances may be within this class.</p> <pre><code>enum AssetId {\n   Concrete(MultiLocation),\n   Abstract([u8; 32]),\n}\n</code></pre> <p>The asset identity is expressed in one of two ways; either Concrete or Abstract. Abstract identities allow assets to be specified by a 32-byte blob. This is convenient, but it relies on the receiver to interpret the blob in the way that the sender expects, which will require a common definition between the sender and the receiver, and may not be simple to achieve. Concrete identities use a <code>MultiLocation</code> to identify an asset unambiguously. For native assets (such as DOT), the asset is identified as the chain which mints the asset (the Polkadot relay chain in this case, which would be the location <code>..</code> from one of its parachains). Other assets (e.g. non-native assets or NFTs) can be identified by a <code>GeneralIndex</code> junction. Depending on the implementation of the encapsulating consensus system, the exact location may differ (e.g. <code>GeneralIndex(AssetID)</code> or <code>PalletInstance(PalletID)/GeneralIndex(AssetID)</code> can both be valid asset identities).</p> <pre><code>enum Fungibility {\n   // Fungible cannot be 0\n   Fungible(u128),\n   NonFungible(AssetInstance),\n}\n</code></pre> <p>Secondly, they must be either fungible or non-fungible. If they\u2019re fungible, then there should be some associated non-zero amount of assets specified. If they\u2019re not fungible, then instead of an amount, there should be some indication of which AssetInstance they are. (This is commonly expressed with an index, but XCM also allows arrays.)</p>"},{"location":"learn/xcm/fundamentals/multiasset/#how-to-use-multiple-assets-together","title":"How to use Multiple Assets Together?","text":"<p>There are multiple ways to group Assets. In this section, we go over these methods.</p>"},{"location":"learn/xcm/fundamentals/multiasset/#multiassets","title":"MultiAssets","text":"<p>One way to group a set of <code>MultiAsset</code> items is the MultiAssets type.</p> <pre><code>struct MultiAssets(Vec&lt;MultiAsset&gt;);\n</code></pre> <p>This structure must uphold some rules:</p> <ul> <li>It may not contain duplicate <code>MultiAsset</code>s (<code>Fungible</code> assets are considered the same if their IDs   match. However, <code>NonFungible</code> assets are different if the <code>AssetInstance</code> is different);</li> <li>All items must be ordered;</li> <li>The number of items should grow no larger than MAX_ITEMS_IN_MULTIASSETS (currently set to 20).</li> </ul>"},{"location":"learn/xcm/fundamentals/multiasset/#wildmultiasset","title":"WildMultiAsset","text":"<p>Then we have WildMultiAsset; this is a wildcard that can be used to match against one or more MultiAsset items. All the WildMultiAsset wildcards can be used to select/filter assets in the Holding register.</p> <pre><code>pub enum WildMultiAsset {\n    /// All assets in Holding.\n    All,\n    /// All assets in Holding of a given fungibility and ID.\n    AllOf { id: AssetId, fun: WildFungibility },\n    /// All assets in Holding, up to `u32` individual assets (different instances of non-fungibles\n    /// are separate assets).\n    AllCounted(#[codec(compact)] u32),\n    /// All assets in Holding of a given fungibility and ID up to `count` individual assets\n    /// (different instances of non-fungibles are separate assets).\n    AllOfCounted {\n        id: AssetId,\n        fun: WildFungibility,\n        #[codec(compact)]\n        count: u32,\n    },\n}\n</code></pre>"},{"location":"learn/xcm/fundamentals/multiasset/#multiassetfilter","title":"MultiAssetFilter","text":"<p>Finally, there is <code>MultiAssetFilter</code>. This is used most often and is just a combination of MultiAssets and WildMultiAsset allowing either a wildcard or a list of definite (i.e. not wildcard) assets to be specified.</p> <pre><code>pub enum MultiAssetFilter {\n    /// Specify the filter as being everything contained by the given `MultiAssets` inner.\n    Definite(MultiAssets),\n    /// Specify the filter as the given `WildMultiAsset` wildcard.\n    Wild(WildMultiAsset),\n}\n</code></pre>"},{"location":"learn/xcm/fundamentals/multiasset/#examples","title":"Examples","text":""},{"location":"learn/xcm/fundamentals/multiasset/#multiasset_1","title":"MultiAsset","text":"<p>For more information about the MultiLocations used to define concrete assets, see MultiLocation and Junction.</p> <pre><code>// Location relay chain\n// 100 Native Asset (three ways)\nMultiAsset {id: Concrete(MultiLocation {parents: 0, interior: Here}), fun: Fungible(100u128)};\nMultiAsset {id: Here.into(), fun: 100.into()};\nlet _: MultiAsset = (Here, 100u128).into();\n\n// 100 Parachain's Native Asset\nlet _: MultiAsset = (X1(Parachain(1000)), 100u128).into();\n// 100 Fungible assets in Parachain 1000 with id 1234\nlet _: MultiAsset = (X2(Parachain(1000), GeneralIndex(1234)), 100u128).into();\n// Non Fungible asset with asset class 1234 containing only one nft instance in Parachain 1000\nlet _: MultiAsset = (X2(Parachain(1000), GeneralIndex(1234)), Undefined).into();\n// Non Fungible asset with asset class 1234 and AssetInstance 1 in Parachain 1000\nlet _: MultiAsset = (X2(Parachain(1000), GeneralIndex(1234)), Index(1)).into();\n</code></pre>"},{"location":"learn/xcm/fundamentals/multiasset/#multiassetfilter_1","title":"MultiAssetFilter","text":"<pre><code>let a1: MultiAssets = MultiAssets::from(vec![MultiAsset {id: Here.into(), fun: 100u128.into()}]);\nlet b1: MultiAssets = (Here, 100u128).into();\nassert_eq!(a1, b1);\n\nlet a2: MultiAssetFilter = a1.into();\nlet b2 = MultiAssetFilter::Definite((Here, 100u128).into());\nassert_eq!(a2, b2);\n\nlet a3 = MultiAssetFilter::Wild(WildMultiAsset::All);\nlet b3: MultiAssetFilter = All.into();\nassert_eq!(a3, b3);\n</code></pre>"},{"location":"learn/xcm/fundamentals/summary/","title":"Fundamentals","text":"<p>In this chapter we explore all the fundamentals that you should understand before diving deeper into XCM.</p>"},{"location":"learn/xcm/fundamentals/weight_and_fees/","title":"Weight and fees","text":"<p>The resources available to a blockchain are limited, so it's important to manage how operations on-chain use them. Not managing how resources are used can open an attack vector, known as DoS (Denial of Service), where an attacker floods the chain with operations in order to get it to stop producing blocks. In order to manage how resources are used and to protect against DoS attacks, XCM uses a concept of weight. This concept, which has the purpose of quantifying usage of blockchain resources, comes from the Substrate world.</p> <p>Weight is two-dimensional, it tracks both time (execution time) and space (state accesses). Weight determines how much fees need to be paid in order to perform some operation. The logic for turning it into fees is configurable.</p> <p>Some systems have the concept of gas metering, which is calculated during execution and only measures execution time. Weight, however, is static, defined beforehand, which makes XCM execution lighter by not including gas metering.</p> <p>The principle behind weight payment is to pay for what you use, so the two stages of XCM where fees are paid are sending the message and actually executing it. The fees for sending are paid on the local system, usually by the origin of the message, because we are using the message delivery mechanism maintained by the origin. Similarly, the execution fees are paid on the destination system, via the <code>BuyExecution</code> instruction. In other words, XCMs are paid for via their own instructions. We'll talk more about <code>BuyExecution</code> in the fee handling chapter.</p> <p>XCM is agnostic, which means it doesn't assume fees need to be paid. It's entirely possible to not pay for the effects of an XCM on the destination system. Even in systems where fees have to be paid, special cases of free execution can be made. There are security measures systems can put in place (see barrier) to not execute XCMs that do not pay for their fees.</p>"},{"location":"learn/xcm/fundamentals/weight_and_fees/#executor-config","title":"Executor config","text":"<p>The executor has a <code>Weigher</code> configuration item that specifies the weight of each instruction. It weighs the whole message by adding the weight of each instruction. A simple way of weighing instructions is to assign them a base weight value to all of them. This works, but it is not very accurate, as different instructions use more resources when being executed. A better approach is to benchmark each instruction to find out the actual weight used by each.</p> <p>Another configuration item, <code>Trader</code>, converts the required weight units into fees, which are represented as <code>MultiAsset</code>s. There are two basic approaches: one is to just assign a value (measured in assets) to each unit of weight; the other is to reuse some existing transaction payment method for XCM weight. Custom configurations allow for things like NFT coupons that give you a certain amount of weight for executing the XCM.</p> <p>Naturally, this configuration items allow for any approach you can think of for weighing messages and charging execution fees.</p>"},{"location":"learn/xcm/fundamentals/weight_and_fees/#xcm-pallet","title":"XCM pallet","text":"<p>FRAME pallets, like the XCM pallet, specify weights for each extrinsic they expose. That means that when interacting with pallets that deal with XCM, there will be an additional fee at the beginning for calling the extrinsic locally.</p>"},{"location":"learn/xcm/fundamentals/xcvm/","title":"XCVM","text":"<p>We've already seen an overview of the XCVM. In this section, we'll dive deeper into how it works.</p>"},{"location":"learn/xcm/fundamentals/xcvm/#coming-soon","title":"Coming soon","text":"<p>This chapter is still being worked on.</p>"},{"location":"learn/xcm/fundamentals/multilocation/example/","title":"Example","text":"<p>In this example we show different <code>MultiLocation</code>s for the system hierarchy in the image below. </p> <p>From the perspective of RelayA</p> <pre><code>// ParaA\nlet _: MultiLocation = Parachain(1000).into();\n// AccountId32 in Parachain A\nlet _: MultiLocation = (Parachain(1000), AccountId32 { network: RELAY_A_NETWORK, id: [0u8; 32]}).into();\n// Asset in Parachain A\nlet _: MultiLocation = (Parachain(1000), PalletInstance(1), GeneralIndex(1)).into();\n// Ethereum based account on Parachain B\nlet _: MultiLocation = (Parachain(2000), AccountKey20 { network: RELAY_A_NETWORK, key: [0u8; 20] }).into();\n// Smart Contract\nlet _: MultiLocation = (Parachain(2000), PalletInstance(1), AccountKey20 { network: RELAY_A_NETWORK, key: [0u8; 20] }).into();\n// RelayB\nlet _: MultiLocation = (Parent, GlobalConsensus(RELAY_B_NETWORK)).into();\n// NFT on Parachain C\nlet _: MultiLocation = (Parent, GlobalConsensus(RELAY_B_NETWORK), Parachain(1000), GeneralIndex(1)).into();\n</code></pre> <p>From the perspective of Parachain C</p> <pre><code>// Relay B\nlet _: MultiLocation = Parent.into();\n// Plurality Example. Many more BodyId/BodyPart combos imaginable\nlet _: MultiLocation = (Parent, Plurality { id: BodyId::Index(0), part: BodyPart::Members { count: 10 } }).into();\n// Account in Relay\nlet _: MultiLocation = (Parent, AccountId32 { network: None, id: [0u8; 32] }).into();\n</code></pre> <p>From the perspective of the Smart Contract</p> <pre><code>// Asset in Parachain A\nlet _: MultiLocation = (Parent, Parent, Parachain(1000), PalletInstance(1), GeneralIndex(1)).into();\n</code></pre>"},{"location":"learn/xcm/fundamentals/multilocation/junction/","title":"Junction(s)","text":"<p>In the section on MultiLocations, we looked at the MultiLocation struct. We talked about the Multilocation being a way to describe moving from one place in the system hierarchy to another. The <code>parents</code> parameter expresses the number of steps up in the hierarchy. In this section, we dive further into the MultiLocation struct and explain how we can use the Junctions type to describe steps in the system hierarchy. Take a look at the MultiLocation struct again:</p> <pre><code>pub struct MultiLocation {\n    pub parents: u8,\n    pub interior: Junctions,\n}\n</code></pre> <p>The system hierarchy consists of 1-to-n relations. Each place in the system hierarchy can only ever have one parent, so there is only one way up the hierarchy. That is why we can use a <code>u8</code> to describe the number of <code>parents</code> we want to move up. But moving down is a bit more difficult, as one consensus system can encapsulate multiple other consensus systems(e.g. a relay chain can have multiple parachains). So to describe the correct steps down the hierarchy, we use the <code>Junctions</code> type.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#junctions-type","title":"Junctions Type","text":"<pre><code>pub enum Junctions {\n    /// The interpreting consensus system.\n    Here,\n    /// A relative path comprising 1 junction.\n    X1(Junction),\n    ...\n    /// A relative path comprising 8 junctions.\n    X8(Junction, Junction, Junction, Junction, Junction, Junction, Junction, Junction),\n}\n</code></pre> <p>The <code>Junctions</code> enum can represent zero to eight steps down the hierarchy. When the <code>Here</code> variant is used, it means that we do not have to take steps down the hierarchy. We can for example describe the current location with <code>{parents: 0, interior: Here}</code> or the Parent location with <code>{parents: 1, interior: Here}</code>. If we want to take steps down the hierarchy, we express each step as a Junction.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#junction-type","title":"Junction Type","text":"<p>A Junction describes a step down in the Hierarchy. The <code>Junction</code>s are defined as follows:</p> <pre><code>pub enum Junction {\n    Parachain(u32),\n    AccountId32 {\n        network: Option&lt;NetworkId&gt;,\n        id: [u8; 32],\n    },\n    AccountIndex64 {\n        network: Option&lt;NetworkId&gt;,\n        index: u64,\n    },\n    AccountKey20 {\n        network: Option&lt;NetworkId&gt;,\n        key: [u8; 20],\n    },\n    PalletInstance(u8),\n    GeneralIndex(u128),\n    GeneralKey {\n        length: u8,\n        data: [u8; 32],\n    },\n    OnlyChild,\n    Plurality {\n        id: BodyId,\n        part: BodyPart,\n    },\n    GlobalConsensus(NetworkId),\n}\n</code></pre>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#parachain","title":"Parachain","text":"<p>The <code>Parachain</code> junction is used to describe a parachain from the point of a relay chain. Each parachain has an Id, e.g. Statemine in the Kusama network has Id 1000.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#palletinstance","title":"PalletInstance","text":"<p>The <code>PalletInstance</code> junction is used to describe a pallet in one of the parachains or relay chain. Each pallet has an Id that can be used for the <code>PalletInstance</code>. This junction is mainly used for FRAME based systems.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#accountid32-and-accountkey20","title":"AccountId32 and AccountKey20","text":"<p>Each of these junctions can be used to describe an account located in the current consensus system. The <code>AccountId32</code> is used to describe substrate-based accounts, while the <code>AccountKey20</code> is mainly used to describe Ethereum or Bitcoin-based accounts or smart contracts. Both junctions express an account based on the context they are used in. If the current location is the relay chain, then the junctions describe an account in the relay chain. The same is true for each parachain location.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#generalindex-and-generalkey","title":"GeneralIndex and GeneralKey","text":"<p>Non-descript indices and keys within the current context location. The usage will vary widely owing to its generality. An example use case for the <code>GeneralIndex</code> is to describe an Asset within an Assets Parachain.</p> <p>NOTE: If possible, try to avoid using this and instead use a more specific junction.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#accountindex64","title":"AccountIndex64","text":"<p>The <code>AccountIndex64</code> can be used to describe an account index. This may be used when the context is a Frame-based chain and includes e.g. an indices pallet.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#onlychild","title":"OnlyChild","text":"<p>The <code>OnlyChild</code> junction can be used to describe the child of a location if there exists a 1-to-1 relation between the parent and child in the system hierarchy. The <code>OnlyChild</code> junction is currently not used except as a fallback when deriving context.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#plurality","title":"Plurality","text":"<p>The <code>Plurality</code> junction is used to describe a pluralistic body existing within the current consensus location. Typical to be used to represent a governance origin of a chain, but could in principle be used to represent things such as multisigs also. See the BodyId documentation for a better understanding of the bodies that the <code>Plurality</code> junction can represent.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#globalconsensus","title":"GlobalConsensus","text":"<p>A global network (e.g. Polkadot or Kusama) is capable of externalizing its own consensus. This is not generally meaningful outside of the universal level. An example would be describing the Kusama relay chain from the perspective of the Polkadot relay chain as <code>{parents: 1, interior: GlobalConsensus(Kusama)}</code>. An example use case could be routing XCMs between global consensus networks using bridges.</p>"},{"location":"learn/xcm/fundamentals/multilocation/junction/#multiple-ways-to-create-a-multilocation","title":"Multiple ways to create a MultiLocation","text":"<pre><code>// Current Location\nMultiLocation {parents: 0, interior: Here};\nMultiLocation::new(0, Here);\nMultiLocation::here();\nMultiLocation::default();\nlet _: MultiLocation = Here.into();\n\n// Parent Location\nMultiLocation {parents: 1, interior: Here};\nMultiLocation::parent();\nlet _: MultiLocation = Parent.into();\n\n// Conversion\nMultiLocation { parents: 2, interior: X2(Parachain(1), GeneralIndex(1))};\nlet _: MultiLocation = (Parent, Parent, Parachain(1), GeneralIndex(1)).into();\n</code></pre>"},{"location":"learn/xcm/fundamentals/multilocation/summary/","title":"MultiLocation","text":"<p>The MultiLocation type identifies any single location that exists within the world of consensus. It can represent all manner of things that exist within consensus, from a scalable multi-shard blockchain such as Polkadot down to an ERC-20 asset account on a parachain. MultiLocations are used to identify places to send XCMs, places that can receive assets, and can even help describe the type of an asset itself, as we will see in MultiAsset.</p>"},{"location":"learn/xcm/fundamentals/multilocation/summary/#location-is-relative","title":"Location is relative","text":"<p>MultiLocation always expresses a location relative to the current location. It can be thought of as a file system path, without the ability to directly express the \u201croot\u201d of the file system tree. This is for a simple reason: In the world of Polkadot, blockchains can be merged into, and split from other blockchains. A blockchain can begin as a standalone sovereign chain, and could eventually be elevated to become a parachain within a larger consensus. If it did that, then the meaning of \u201croot\u201d would change overnight and this could spell chaos for XCMs and anything else using MultiLocation. To keep things simple, we exclude this possibility altogether.</p>"},{"location":"learn/xcm/fundamentals/multilocation/summary/#hierarchical-structure","title":"Hierarchical structure","text":"<p>Locations in XCM are hierarchical; some places in consensus are wholly encapsulated within other places in consensus. A parachain of Polkadot exists wholly within the overall Polkadot consensus; we call this an interior location. Or a pallet exists wholly within a parachain or relay chain. Putting it more strictly, say we have two consensus systems, A and B. If any change in A implies a change in B, then we say A is interior to B.</p>"},{"location":"learn/xcm/fundamentals/multilocation/summary/#so-what-is-a-multilocation-simple-example","title":"So what is a MultiLocation: Simple example","text":"<p>A quick summary of the previous points:</p> <ul> <li>A MultiLocation identifies any single location that exists within the world of consensus.</li> <li>A MultiLocation is always relative to the current location.</li> <li>MultiLocations in XCM are hierarchical.</li> </ul> <p>Now take a look at the MultiLocation struct:</p> <pre><code>pub struct MultiLocation {\n    pub parents: u8,\n    pub interior: Junctions,\n}\n</code></pre> <p>As we have already discussed, locations in XCM are hierarchical. The following image shows an example of such a Hierarchy.</p> <p></p> <p>Relay chain A completely encapsulates Parachain A and B (indicated by the arrows) and parachain A encapsulates an account <code>0x00...</code>. So RelayA is higher in the hierarchy than ParaA and ParaB and can be described as the <code>parent</code> of these parachains. The <code>parents: u8</code> in the MultiLocation struct describes the number of steps in the hierarchy we want to move up. The <code>interior: Junctions</code> express the steps in the hierarchy we want to move down. The <code>Junctions</code> type will be further discussed in the next chapter about Junctions, but for now, it's just a way to express a way down the hierarchy. As all MultiLocations are relative to the current location, Parachain B relative to Parachain A is one step up and one step down in the hierarchy.</p> <p>To get a better understanding of this concept, we show some simple MultiLocations in the code example below. The first two examples are relative to RelayA and the second set of examples is relative to ParaB. In the <code>Location</code> comments, we expressed the locations in text. The <code>..</code> express a step up in the hierarchical structure (the \u201cparent\u201d or the encapsulating consensus system). The <code>..</code> are followed by some number of Junctions, all separated by <code>/</code>. The <code>X1</code> and <code>X2</code> variants are expressing the number of <code>Junction</code>s that we step down in the hierarchical structure (see Junctions for an explanation).</p> <pre><code>// From: RelayA\n// To: ParaB\n// Location: Parachain(2000)\nMultiLocation {parents: 0, interior: X1(Parachain(2000))};\n// To: Account in ParaA\n// Location: Parachain(1000)/AccountId32(0x00..)\nMultiLocation {\n    parents: 0,\n    interior: X2(\n        Parachain(1000),\n        AccountId32{network: None, id: [0u8; 32]}\n    )\n};\n\n// From: ParaB\n// To: RelayA\n// Location: ../Here\nMultiLocation {parents: 1, interior: Here};\n// To: Account in ParaA\n// Location: ../Parachain(1000)/AccountId32(0x00..)\nMultiLocation {\n    parents: 1,\n    interior: X2(\n        Parachain(1000),\n        AccountId32{network: None, id: [0u8; 32]}\n    )\n};\n</code></pre>"},{"location":"learn/xcm/fundamentals/multilocation/summary/#whats-next","title":"What's next:","text":"<ul> <li>More information about junctions</li> <li>More MultiLocation examples</li> <li>Expressing assets using Multilocations: [MultiAsset][../multiasset.md]</li> </ul>"},{"location":"learn/xcm/journey/channels-and-bridges/","title":"Channels","text":"<p>XCM has instructions that aid in the establishment of a HRMP channel between parachains. HRMP channels are always unidirectional (one-way); every channel has a static sender and a static recipient. To send messages in the opposite direction (i.e. from recipient to sender), another new HRMP channel must be opened. Unlike other XCM instructions, these HRMP instructions are related to the underlying transport mechanism, and will normally not be sent by developers. We still want to list them, as they are part of XCM:</p> <ul> <li><code>HrmpNewChannelOpenRequest</code></li> <li><code>HrmpChannelAccepted</code></li> <li><code>HrmpChannelClosing</code></li> </ul>"},{"location":"learn/xcm/journey/channels-and-bridges/#hrmpnewchannelopenrequest","title":"HrmpNewChannelOpenRequest","text":"<pre><code>HrmpNewChannelOpenRequest {\n    #[codec(compact)]\n    sender: u32,\n    #[codec(compact)]\n    max_message_size: u32,\n    #[codec(compact)]\n    max_capacity: u32,\n}\n</code></pre> <p>The <code>HrmpNewChannelOpenRequest</code> is an instruction to notify about a new incoming HRMP channel. This message is meant to be sent by the relay chain to a parachain.</p> <p>The <code>sender</code> field represents the ParaId of the parachain initializing the channel. This parachain will also be the sender in the to-be opened channel.</p> <p>The <code>max_message_size</code> field is the maximum size of a message that is send through the channel. This field is the size proposed by the sender, and needs to be accepted by the recipient.</p> <p>The <code>max_capacity</code> is the maximum number of messages that can be queued in the channel.</p>"},{"location":"learn/xcm/journey/channels-and-bridges/#hrmpchannelaccepted","title":"HrmpChannelAccepted","text":"<pre><code>HrmpChannelAccepted {\n    #[codec(compact)]\n    recipient: u32,\n}\n</code></pre> <p>The <code>HrmpChannelAccepted</code> instruction is used to notify about that a previously sent open channel request has been accepted by the recipient. That means that the channel will be opened during the next relay chain session change. This message is meant to be sent by the relay chain to a parachain.</p> <p>The <code>recipient</code> field represents the ParaId of the parachain that initialized the channel, so it equals the <code>sender</code> field in the preceding <code>HrmpNewChannelOpenRequest</code> instruction.</p>"},{"location":"learn/xcm/journey/channels-and-bridges/#hrmpchannelclosing","title":"HrmpChannelClosing","text":"<pre><code>HrmpChannelClosing {\n    #[codec(compact)]\n    initiator: u32,\n    #[codec(compact)]\n    sender: u32,\n    #[codec(compact)]\n    recipient: u32,\n}\n</code></pre> <p>The <code>HrmpChannelClosing</code> instruction is used to notify that the other party in an open channel decided to close it. In particular, <code>initiator</code> is going to close the channel opened from <code>sender</code> to the <code>recipient</code>. The close will be enacted at the next relay chain session change. This message is meant to be sent by the relay chain to a para.</p> <p>The <code>initiator</code> field represents the ParaId of the parachain that is closing the channel. It is equal to either the <code>sender</code> or <code>recipient</code> field.</p> <p>The <code>sender</code> field represents the ParaId of the parachain that is the sender side of the channel.</p> <p>The <code>recipient</code> field represents the ParaId of the parachain that is the recipient side of the channel.</p> <p>Important to note is that both the sender and recipient can close the channel.</p>"},{"location":"learn/xcm/journey/channels-and-bridges/#message-export-bridging","title":"Message Export (Bridging)","text":"<p>XCM has an instruction that allows us to send an XCM to a Non-Local Consensus System, meaning to MultiLocation that is outside our current GlobalConsensus. For example, it allows us to send an XCM from Kusama to Polkadot or from Polkadot to an Ethereum-based chain. Exporting an XCM to another Non-Local Consensus System will tend to utilize some extra consensus layer/mechanism, the obvious one being a bridge. The instruction to export an XCM is called <code>ExportMessage</code>.</p>"},{"location":"learn/xcm/journey/channels-and-bridges/#exportmessage","title":"ExportMessage","text":"<pre><code>ExportMessage { network: NetworkId, destination: InteriorMultiLocation, xcm: Xcm&lt;()&gt; },\n</code></pre> <p>The <code>ExportMessage</code> instruction can be used to export a message to a Non-Local Consensus System. The message is sent to the bridge (or other consensus mechanism) that is able to export the message. A fee is charged for exporting the message via the bridge.</p> <p>The <code>network</code> field is the remote consensus system to which the message should be exported.</p> <p>The <code>destination</code> field is the location relative to the remote consensus system to which the message should be sent on arrival.</p> <p>The <code>xcm</code> field is the message to be exported.</p> <p>As an example, to export a message for execution on Statemine (parachain <code>#1000</code> in the Kusama network), you would call with <code>network: NetworkId::Kusama</code> and <code>destination: X1(Parachain(1000))</code>. Alternatively, to export a message for execution on Polkadot, you would call with <code>network: NetworkId:: Polkadot</code> and <code>destination: Here</code>.</p>"},{"location":"learn/xcm/journey/expects/","title":"Expects","text":"<p>XCM contains instructions to check for specific conditions during the execution of the message. These 'expect' instructions check for a specific condition and if it's not fulfilled, an error is then thrown. These instructions are used for things like checking the state of the registers before executing specific instructions. XCM contains the following expect instructions:</p> <ul> <li><code>ExpectAsset</code></li> <li><code>ExpectOrigin</code></li> <li><code>ExpectPallet</code></li> <li><code>ExpectError</code></li> <li><code>ExpectTransactStatus</code></li> </ul>"},{"location":"learn/xcm/journey/expects/#expectasset","title":"ExpectAsset","text":"<p>The <code>ExpectAsset</code> instruction throws an <code>ExpectationFalse</code> error if the holding register does not contain at least the given assets.</p> <pre><code>ExpectAsset(MultiAssets)\n</code></pre>"},{"location":"learn/xcm/journey/expects/#example","title":"Example","text":"<p>For the full example, check here.</p> <p>```rust, noplayground WithdrawAsset((Here, AMOUNT).into()), BuyExecution { fees: (Here, AMOUNT).into(), weight_limit: WeightLimit::Unlimited }, // Set the instructions that are executed when ExpectAsset does not pass. // In this case, reporting back an error to the Parachain. SetErrorHandler(Xcm(vec![     ReportError(QueryResponseInfo {         destination: Parachain(1).into(),         query_id: QUERY_ID,         max_weight: Weight::from_all(0),     }) ])), ExpectAsset((Here, AMOUNT + 10).into()), // Add Instructions that do something with assets in holding when ExpectAsset passes.</p> <pre><code>## ExpectOrigin\n\nThe `ExpectOrigin` instruction throws an `ExpectationFalse` error if the origin register does not\nequal the expected origin.\n\n```rust\nExpectOrigin(Option&lt;MultiLocation&gt;)\n</code></pre>"},{"location":"learn/xcm/journey/expects/#example_1","title":"Example","text":"<p>For the full example, check here. The <code>ExpectOrigin</code> instruction errors because the <code>ClearOrigin</code> clears the origin register and we expect it to be equal to <code>Parachain(1)</code>.</p> <pre><code>// Set the instructions that are executed when ExpectOrigin does not pass.\n// In this case, reporting back an error to the Parachain.\nSetErrorHandler(Xcm(vec![ReportError(QueryResponseInfo {\n    destination: Parachain(1).into(),\n    query_id: QUERY_ID,\n    max_weight: Weight::from_all(0),\n})])),\nClearOrigin,\n// Checks if the XcmContext origin is equal to `Parachain(1)`.\nExpectOrigin(Some(Parachain(1).into())),\n</code></pre>"},{"location":"learn/xcm/journey/expects/#expectpallet","title":"ExpectPallet","text":"<p>The <code>ExpectPallet</code> instruction ensures that a particular pallet with a particular version exists in the destination's runtime. It throws a <code>PalletNotFound</code> error if there is no pallet at the given index. It throws a <code>NameMismatch</code> error is the <code>name</code> or <code>module_name</code> mismatch and a <code>VersionIncompatible</code> error if the <code>crate_major</code> or <code>crate_minor</code> mismatch. The <code>name</code> and <code>module_name</code> represent a byte representation of the pallet's name and module name (e.g. 'Balances' and 'pallet_balances'). Consensus systems that are not substrate-based may throw an <code>Unimplemented</code> error for this instruction.</p> <pre><code>ExpectPallet {\n    #[codec(compact)]\n    index: u32,\n    name: Vec&lt;u8&gt;,\n    module_name: Vec&lt;u8&gt;,\n    #[codec(compact)]\n    crate_major: u32,\n    #[codec(compact)]\n    min_crate_minor: u32,\n},\n</code></pre>"},{"location":"learn/xcm/journey/expects/#example_2","title":"Example","text":"<p>For the full example, check here.</p> <p><code>``rust, noplayground // Set the instructions that are executed when ExpectPallet does not pass. // In this case, reporting back an error to the Parachain. SetErrorHandler(Xcm(vec![     ReportError(QueryResponseInfo {         destination: Parachain(1).into(),         query_id: QUERY_ID,         max_weight: Weight::from_all(0),     }) ])), // Configured pallet has different</code>crate_major<code>so</code>VersionIncompatible` error is thrown. ExpectPallet {     index: 1,     name: \"Balances\".into(),     module_name: \"pallet_balances\".into(),     crate_major: 3,     min_crate_minor: 0, } <pre><code>## ExpectError\n\nThe `ExpectError` instruction throws an `ExpectationFalse` error if the error register does not\nequal the expected error at that point in the execution. This instruction is useful during the error\nhandler execution to halt the error handler if the error that started the execution of the error\nhandler is not as expected. The `ExpectError` instruction allows to only execute the instructions in\nthe error handler, when a specific error is thrown.\n\n```rust\n    ExpectError(Option&lt;(u32, Error)&gt;)\n</code></pre></p>"},{"location":"learn/xcm/journey/expects/#example_3","title":"Example","text":"<p>For the full example, check here.</p> <pre><code>SetErrorHandler(Xcm(vec![\n    ExpectError(Some((1, XcmError::VersionIncompatible))),\n    ReportError(QueryResponseInfo {\n        destination: Parachain(1).into(),\n        query_id: QUERY_ID,\n        max_weight: Weight::from_all(0),\n    }),\n])),\n// Pallet index is wrong, so throws `PalletNotFound` error.\nExpectPallet {\n    index: 100,\n    name: \"Balances\".into(),\n    module_name: \"pallet_balances\".into(),\n    crate_major: 4,\n    min_crate_minor: 0,\n},\n</code></pre>"},{"location":"learn/xcm/journey/expects/#expecttransactstatus","title":"ExpectTransactStatus","text":"<p>The <code>ExpectTransactStatus</code> instruction throws an <code>ExpectationFalse</code> error if the transact status register does not equal the expected transact status.</p>"},{"location":"learn/xcm/journey/expects/#example_4","title":"Example","text":"<p>For the full example, check here. The transact status is reported to <code>Parachain(1)</code> if the call in the <code>Transact</code> errors.</p> <pre><code>SetErrorHandler(Xcm(vec![ReportTransactStatus(QueryResponseInfo {\n    destination: Parachain(1).into(),\n    query_id: QUERY_ID,\n    max_weight: Weight::from_all(0),\n})])),\nTransact {\n    origin_kind: OriginKind::SovereignAccount,\n    require_weight_at_most: Weight::from_parts(INITIAL_BALANCE as u64, 1024 * 1024),\n    call: call.encode().into(),\n},\nExpectTransactStatus(MaybeErrorCode::Success),\n</code></pre>"},{"location":"learn/xcm/journey/fees/","title":"Fee handling","text":"<p>Like we learnt in the weight and fees chapter, the XCM operations our messages perform need to be paid for. To accomplish this, we'll make use of different instructions in this chapter.</p>"},{"location":"learn/xcm/journey/fees/#buyexecution","title":"BuyExecution","text":"<pre><code>BuyExecution { fees: MultiAsset, weight_limit: WeightLimit }\n</code></pre> <p>This instruction is used to buy weight using fees. While in some cases there's no need to pay for execution (if you control both systems for example), in most cases you'll need to add this instruction. There's a predefined barrier, <code>AllowTopLevelPaidExecutionFrom&lt;T&gt;</code>, that explicitly drops messages that do not include this instruction.</p> <p>Let's grab the teleport message from the transfers chapter and add fee payment.</p> <pre><code>let message = Xcm(vec![\n  WithdrawAsset((Here, withdraw_amount + fee_estimation).into()),\n  BuyExecution { // &lt;-- Added here\n    fees: (Here, fee_estimation).into(),\n    weight_limit: WeightLimit::Limited(weight_estimation),\n  },\n  InitiateTeleport {\n    assets: All.into(),\n    dest: Parachain(1).into(),\n    xcm: Xcm(vec![DepositAsset {\n      assets: All.into(),\n      beneficiary: Junction::AccountId32 {\n        network: None,\n        id: ALICE.into(),\n      },\n    }]),\n  },\n]);\n</code></pre> <p><code>fee_estimation</code> and <code>weight_estimation</code> are values that can be calculated from the configuration of the receiving chain. As mentioned in the weight and fees chapter of the fundamentals, XCMs instructions are usually assigned weights separately, so, in order to estimate the weight, you need to estimate the weight of every instruction and add them together. By using <code>WeightLimit::Limited()</code>, you guarantee the message will error if it tries to use more weight than you expect. If you don't mind this, you can use <code>WeightLimit::Unlimited</code>. The <code>fee_estimation</code> value is the maximum assets you want to use, if it doesn't cover all fees, message execution will fail. You can add a higher value (all of <code>withdraw_amount</code> for example) to make sure you have enough assets for fee payment. If you plan to use the entirety of <code>withdraw_amount</code>, however, it's recommended to add a little extra for fee payment.</p> <p>In our examples, we use a very simple method, where all instructions weigh a constant value. This is very useful for testing purposes, but it's recommended to actually benchmark every instruction as they differ in resource usage. Given our setup, we estimate the weight and fee using only the number of instructions in each message.</p>"},{"location":"learn/xcm/journey/fees/#setfeesmode","title":"SetFeesMode","text":"<pre><code>SetFeesMode { jit_withdraw: bool }\n</code></pre> <p>This instruction changes the fee mode of the XCVM. If <code>jit_withdraw</code> is set to true, then fee assets are taken directly from the origin's on-chain account, instead of the holding register. This means the fees are taken directly from the account, no need for a <code>BuyExecution</code> instruction. That means you make sure the message will get executed, as long as there are enough assets in the account. It's useful when paying sending fees, which are difficult to estimate, as they usually depend on network congestion.</p>"},{"location":"learn/xcm/journey/fees/#unpaidexecution","title":"UnpaidExecution","text":"<pre><code>UnpaidExecution { weight_limit: WeightLimit, check_origin: Option&lt;MultiLocation&gt; }\n</code></pre> <p>This instruction is used for explicitly stating this message shouldn't be paid for. It can be used as a way of identifying certain priviledged messages that don't pay fees, coming from a particular system. This instruction can be searched for in barriers to allow this. Make sure you trust the origin system because it won't be paying fees. There's already a predefined barrier in xcm-builder, <code>AllowExplicitUnpaidExecutionFrom&lt;T&gt;</code>, that makes sure this is the first instruction in the message. As always, you can build your own for your own use-cases.</p> <p>This is safer than allowing all messages from a particular system to not pay fees, as it's an exception to the rule and not the default. Extra measures can be taken to limit who can use this instruction.</p>"},{"location":"learn/xcm/journey/fees/#refundsurplus","title":"RefundSurplus","text":"<pre><code>RefundSurplus\n</code></pre> <p>Refunds any surplus weight previously bought with <code>BuyExecution</code>. This is useful in many cases:</p> <ul> <li>When you pay for execution of your whole message, but there's an error and not all instructions   get executed</li> <li>When you set an error handler, buy weight for it, but in the end there's no error so it doesn't   get called</li> <li>When you use the <code>Transact</code> instruction and the call takes less weight than   expected</li> </ul>"},{"location":"learn/xcm/journey/fees/#example","title":"Example","text":"<pre><code>let message = Xcm(vec![\n  WithdrawAsset((Parent, message_fee).into()),\n  BuyExecution {\n    fees: (Parent, message_fee).into(),\n    weight_limit: WeightLimit::Unlimited,\n  },\n  SetErrorHandler(Xcm(vec![\n    RefundSurplus,\n    DepositAsset {\n      assets: All.into(),\n      beneficiary: AccountId32 {\n        network: Some(ByGenesis([0; 32])),\n        id: relay_sovereign_account_id().into(),\n      }\n      .into(),\n    },\n  ])),\n  Trap(1),\n  ClearOrigin,\n  ClearOrigin,\n  ClearOrigin,\n]);\n</code></pre> <p>In this example, we pay upfront for all the instructions in the XCM. When the <code>Trap</code> instruction throws an error, the error handler will be called and the weight for all the instructions that weren't executed is refunded. For the full example, check our repo.</p>"},{"location":"learn/xcm/journey/holding-modifiers/","title":"Holding Register Modifiers","text":"<p>Most of the XCM instructions alter the Holding Register. We already have seen instructions that alter the Holding Register, like the <code>WithdrawAsset</code> or <code>DepositAsset</code> instructions. In this chapter we go over more instructions that alter the holding register, namely:</p> <ul> <li>BurnAsset</li> <li>ExchangeAsset</li> </ul>"},{"location":"learn/xcm/journey/holding-modifiers/#burnasset","title":"BurnAsset","text":"<pre><code>BurnAsset(MultiAssets)\n</code></pre> <p>The <code>BurnAsset</code> instruction allows for the reduction of assets in the Holding Register by up to the specified assets. The execution of the instruction does not throw an error if the Holding Register does not contain the assets (to make this an error, use <code>ExpectAsset</code> prior).</p>"},{"location":"learn/xcm/journey/holding-modifiers/#example","title":"Example","text":"<p>For the full example, check the repo. The Scenario of the example is as follows: Parachain A withdraws 10 units from its sovereign account on the relay chain and burns 4 of them. The relay chain then reports back the status of the Holding Register to Parachain A. We expect the Holding Register to hold 6 units. Note: If we would have added more then 10 units worth of assets in the <code>BurnAsset</code> instruction, we would have burned all assets in the Holding Register and the execution would succeed.</p> <pre><code>let message = Xcm(vec![\n    WithdrawAsset((Here, 10 * CENTS).into()),\n    BuyExecution { fees: (Here, CENTS).into(), weight_limit: WeightLimit::Unlimited },\n    BurnAsset((Here, 4 * CENTS).into()),\n    ReportHolding {\n        response_info: QueryResponseInfo {\n            destination: Parachain(1).into(),\n            query_id: QUERY_ID,\n            max_weight: Weight::from_parts(1_000_000_000, 64*64) },\n        assets: All.into()\n    }\n]);\n</code></pre> <p>We expect the following response:</p> <pre><code>Response::Assets((Parent, 6 * CENTS).into())\n</code></pre>"},{"location":"learn/xcm/journey/holding-modifiers/#exchangeasset","title":"ExchangeAsset","text":"<pre><code>ExchangeAsset { give: MultiAssetFilter, want: MultiAssets, maximal: bool }\n</code></pre> <p>The <code>ExchangeAsset</code> instruction allows us to remove asset(s) (<code>give</code>) from the Holding Register and replace them with alternative assets (<code>want</code>). The <code>ExchangeAsset</code> instruction has three fields.</p> <p>The <code>give</code> field indicates the maximum number of assets that can be removed from the Holding register.</p> <p>The <code>want</code> field indicates the minimum amount of assets which <code>give</code> should be exchanged for. We should at a minimum get the assets in <code>want</code> for the execution of the instruction not to fail.</p> <p>If the <code>maximal</code> field is <code>true</code>, then we prefer to give as much as possible up to the limit of <code>give</code> and receive accordingly more assets then stated in <code>want</code>. If the <code>maximal</code> field is <code>false</code>, then we prefer to give as little as possible in order to receive as little as possible while receiving at least <code>want</code>.</p>"},{"location":"learn/xcm/journey/holding-modifiers/#example_1","title":"Example","text":"<p>The full example can be found in the repo.</p> <p>The scenario for the example is this: Scenario: The relay chain sends an XCM to Parachain A that: .1 Withdraws some native assets .2 Exchanges these assets for relay chain derivative tokens, with maximal set to true. .3 Deposit all the assets that are in the Holding in the account of Alice.</p> <p>NOTE: The implementation of the AssetExchanger is simple and in this case swaps all the assets in the exchange for the assets in <code>give</code>. Depending on the implementation of AssetExchanger, the test results could differ.</p> <p>The Assets in the exchange in Parachain(1). This is a custom exchange implementation just for testing purposes.</p> <pre><code>let assets_in_exchange = vec![(Parent, 10 * CENTS).into()];\nparachain::set_exchange_assets(assets_in_exchange);\n</code></pre> <p>The message that is send:</p> <pre><code>let message = Xcm(vec![\n    WithdrawAsset((Here, 10 * CENTS).into()),\n    BuyExecution { fees: (Here, CENTS).into(), weight_limit: WeightLimit::Unlimited },\n    // Maximal field set to true.\n    ExchangeAsset {\n        give: Definite((Here, 5 * CENTS).into()),\n        want: (Parent, 5 * CENTS).into(),\n        maximal: true,\n    },\n    DepositAsset {\n        assets: AllCounted(2).into(),\n        beneficiary: AccountId32 {\n            network: Some(parachain::RelayNetwork::get()),\n            id: ALICE.into(),\n        }\n        .into(),\n    },\n]);\n</code></pre> <p>Alice receives <code>5 CENTS</code> worth of native assets (<code>Here</code>) and <code>5 CENTS</code> worth of relay chain derivative assets (<code>Parent</code>).</p>"},{"location":"learn/xcm/journey/origins/","title":"Origin manipulation","text":"<p>An XCVM contains contextual information while executing XCM instructions. It uses the <code>XcmContext</code> struct to provide them. <code>XcmContext</code> contains information such as the origin of the corresponding XCM, the hash of the message, and the topic of the XCM.</p> <pre><code>pub struct XcmContext {\n    /// The `MultiLocation` origin of the corresponding XCM.\n    pub origin: Option&lt;MultiLocation&gt;,\n    /// The hash of the XCM.\n    pub message_hash: XcmHash,\n    /// The topic of the XCM.\n    pub topic: Option&lt;[u8; 32]&gt;,\n}\n</code></pre> <p>In the XCVM, the origin field of the XcmContext indicates which <code>MultiLocation</code>'s privilege level that the current program is using to execute. The origin is important for enforcing restrictions and ensuring appropriate execution of the instructions.</p> <p>There are multiple instructions in XCM that can alter the XcmContext origin field:</p> <ul> <li><code>ClearOrigin</code></li> <li><code>DescendOrigin</code></li> <li><code>UniversalOrigin</code></li> <li><code>AliasOrigin</code></li> </ul>"},{"location":"learn/xcm/journey/origins/#clearorigin","title":"ClearOrigin","text":"<pre><code>ClearOrigin\n</code></pre> <p>The <code>ClearOrigin</code> instruction clears the origin register in the XCVM. Specifically, it sets the origin field of the XCM context to None. This ensures that subsequent instructions in the XCM cannot use the privilege level of the cleared origin to execute operations.</p>"},{"location":"learn/xcm/journey/origins/#descendorigin","title":"DescendOrigin","text":"<pre><code>DescendOrigin(InteriorMultiLocation),\n</code></pre> <p>The <code>DescendOrigin</code> instruction is used to change the XcmContext origin to an interior location of the current origin.</p> <p>This can be useful when executing instructions that require a specific location within the current origin.</p> <p>Note that the XcmContext origin is a <code>MultiLocation</code> containing an <code>InteriorMultiLocation</code> enum; it can only hold up to a maximum of 8 <code>Junction</code>s, so when we try to execute multiple <code>DescendOrigin</code> instructions which would result in an <code>InteriorMultiLocation</code> containing more than 8 <code>Junction</code>s, a <code>LocationFull</code> error is thrown.</p>"},{"location":"learn/xcm/journey/origins/#universalorigin","title":"UniversalOrigin","text":"<pre><code>UniversalOrigin(Junction)\n</code></pre> <p>The UniversalOrigin XCM instruction sets the Origin Register to be a child of the Universal Location. The Junction parameter should generally be a <code>GlobalConsensus</code> variant since only these are children of the Universal Location.</p> <p>Safety Note: Should only be usable if the Origin is trusted to represent a child of the Universal location. In general, no Origin should be able to represent the Universal Location's child which is the root of the local consensus system since it would by extension allow it to act as any location within the local consensus, but it is necessary when bridging XCMs between <code>GlobalConsensus</code> systems.</p>"},{"location":"learn/xcm/journey/origins/#aliasorigin","title":"AliasOrigin","text":"<pre><code>AliasOrigin(MultiLocation)\n</code></pre> <p>The AliasOrigin instruction is similar to the UniversalOrigin instruction, but it is primarily used for account IDs. When executed, it switches out the current origin for the given MultiLocation. THe AliasOrigin instruction would allow to remove certain prefix patterns such as Parent/Parachain(X)/ for certain values of X (thereby allowing sibling chains to use the same account IDs) or Parachain(X)/ (allowing a relay chain to use the account IDs native to its child parachains) or just Parent/ (allowing parachains to use AccountIds of the relay chain).</p>"},{"location":"learn/xcm/journey/queries/","title":"Queries","text":"<p>XCM contains query instructions that can be used to query information from another consensus system:</p> <ul> <li><code>ReportHolding</code></li> <li><code>QueryPallet</code></li> <li><code>ReportError</code></li> <li><code>ReportTransactStatus</code></li> </ul> <p>Each of these instructions is sent to the destination where we would like the information to be reported back to us. Each instruction has a <code>QueryResponseInfo</code> struct as one of its inputs.</p> <p>```rust, noplayground pub struct QueryResponseInfo {     pub destination: MultiLocation,     #[codec(compact)]     pub query_id: QueryId,     pub max_weight: Weight, } <pre><code>The `destination` tells the queried consensus system where to send the response to and the\n`query_id` field links the query and the query response together. The `max_weight` field tells the\nqueried consensus system what the maximum weight is that the response instruction can take.\n\nWhen a query instruction is executed correctly, it sends a `QueryResponse` instruction to the\nlocation defined in the previously described `destination` field. The `QueryResponse` looks like\nthis:\n\n```rust\nQueryResponse {\n    #[codec(compact)]\n    query_id: QueryId,\n    response: Response,\n    max_weight: Weight,\n    querier: Option&lt;MultiLocation&gt;,\n}\n\n// Response Struct\npub enum Response {\n    /// No response. Serves as a neutral default.\n    Null,\n    /// Some assets.\n    Assets(MultiAssets),\n    /// The outcome of an XCM instruction.\n    ExecutionResult(Option&lt;(u32, Error)&gt;),\n    /// An XCM version.\n    Version(super::Version),\n    /// The index, instance name, pallet name and version of some pallets.\n    PalletsInfo(BoundedVec&lt;PalletInfo, MaxPalletsInfo&gt;),\n    /// The status of a dispatch attempt using `Transact`.\n    DispatchResult(MaybeErrorCode),\n}\n</code></pre></p> <p>The <code>QueryResponse</code> has the same <code>query_id</code> as the request to link the request and response and takes over the <code>max_weight</code> from the <code>QueryResponseInfo</code>. It has the requested information in the <code>response</code> field. And it has the location of the querier relative to the queried location in the querier field. The response can be sent back to the requester, or to another location, so the querier field is important to determine where the requested information is needed.</p> <p>Now we take a look at the query instructions.</p>"},{"location":"learn/xcm/journey/queries/#reportholding","title":"ReportHolding","text":"<p>```rust, noplayground ReportHolding { response_info: QueryResponseInfo, assets: MultiAssetFilter } <pre><code>The `ReportHolding` instruction reports to the given destination the contents of the Holding\nRegister. The `assets` field is a filter for the assets that should be reported back. The assets\nreported back will be, asset-wise, _the lesser of this value and the holding register_. For example,\nif the holding register contains 10 units of some fungible asset and the `assets` field specifies 15\nunits of the same asset, the result will return 10 units of that asset. Wild cards can be used to\ndescribe which assets in the holding register to report, but the response always contains assets and\nno wild cards.\n\n### Example\n\nFor the full example, check [here](https://github.com/paritytech/xcm-docs/tree/main/examples).\nAssets are withdrawn from the account of parachain 1 on the relay chain and partly deposited in the\naccount of parachain 2. The remaining assets are reported back to parachain 1.\n\n```rust, noplayground\nXcm(vec![\n    WithdrawAsset((Here, AMOUNT).into()),\n    BuyExecution { fees: (Here, AMOUNT).into(), weight_limit: Unlimited },\n    DepositAsset { assets: Definite((Here, AMOUNT - 5).into()), beneficiary: Parachain(2).into() },\n    ReportHolding {\n        response_info: QueryResponseInfo {\n            destination: Parachain(1).into(),\n            query_id: QUERY_ID,\n            max_weight: Weight::from_all(0),\n        },\n        assets: All.into(),\n    },\n]);\n</code></pre></p>"},{"location":"learn/xcm/journey/queries/#querypallet","title":"QueryPallet","text":"<p>The <code>QueryPallet</code> instruction queries the existence of a particular pallet based on the module name specified in the <code>module_name</code> field.</p> <p>```rust, noplayground QueryPallet { module_name: Vec, response_info: QueryResponseInfo } <pre><code>The destination responds with a vec of `PalletInfo`s if the pallet exists.\n\n```rust\npub struct PalletInfo {\n    #[codec(compact)]\n    index: u32,\n    name: BoundedVec&lt;u8, MaxPalletNameLen&gt;,\n    module_name: BoundedVec&lt;u8, MaxPalletNameLen&gt;,\n    #[codec(compact)]\n    major: u32,\n    #[codec(compact)]\n    minor: u32,\n    #[codec(compact)]\n    patch: u32,\n}\n</code></pre>"},{"location":"learn/xcm/journey/queries/#example","title":"Example","text":"<p>For the full example, check here. It queries for all instances of pallet_balances and sends the result back to parachain 1.</p> <p>```rust, noplayground Xcm(vec![     QueryPallet {         module_name: \"pallet_balances\".into(),         response_info: QueryResponseInfo {             destination: Parachain(1).into(),             query_id: QUERY_ID,             max_weight: Weight::from_all(0),         },     } ]); <pre><code>## ReportError\n\nThe `ReportError` instruction report the contents of the Error Register to the given destination.\nThis instruction is useful in combination with the `SetErrorHandler` instruction. It then only\nreports an error if an error is thrown.\n\n```rust\nReportError(QueryResponseInfo)\n</code></pre></p>"},{"location":"learn/xcm/journey/queries/#example_1","title":"Example","text":"<p>For the full example, check here. The message sets the error handler to report back any error that is thrown during execution of the instructions using the <code>ReportError</code> instruction.</p> <p>```rust, noplayground Xcm(vec![     // Set the Error Handler to report back status of Error register.     SetErrorHandler(Xcm(vec![         ReportError(QueryResponseInfo {             destination: Parachain(1).into(),             query_id: QUERY_ID,             max_weight: Weight::from_all(0),         })     ])),     // If an instruction errors during further processing, the resulting error is reported back to Parachain(1).     // MORE INSTRUCTIONS ]); <pre><code>## ReportTransactStatus\n\nThe `ReportTransactStatus` instruction report the value of the Transact Status Register to the\nspecified destination.\n\n```rust\nReportTransactStatus(QueryResponseInfo)\n</code></pre></p>"},{"location":"learn/xcm/journey/queries/#example_2","title":"Example","text":"<p>For the full example, check here. Dispatches a call on the consensus system receiving this Xcm and reports back the status of the Transact Status Register.</p> <pre><code>Xcm(vec![\n    Transact {\n        origin_kind: OriginKind::SovereignAccount,\n        require_weight_at_most: Weight::from_parts(INITIAL_BALANCE as u64, 1024 * 1024),\n        call: remark.encode().into(),\n    },\n    ReportTransactStatus(QueryResponseInfo {\n        destination: Parachain(1).into(),\n        query_id: QUERY_ID,\n        max_weight: Weight::from_all(0),\n    }),\n]);\n</code></pre>"},{"location":"learn/xcm/journey/register-modifiers/","title":"Register Modifiers","text":"<p>In the previous chapters we already saw instructions that modified the XCVM registers. This chapter contains more instructions that change the XCVM registers. We will discuss the following instructions:</p> <ul> <li><code>SetErrorHandler</code></li> <li><code>SetAppendixHandler</code></li> <li><code>ClearError</code></li> <li><code>ClearTransactStatus</code></li> <li><code>SetTopic</code></li> <li><code>ClearTopic</code></li> </ul>"},{"location":"learn/xcm/journey/register-modifiers/#seterrorhandler","title":"SetErrorHandler","text":"<pre><code>SetErrorHandler(Xcm&lt;Call&gt;)\n</code></pre> <p>The <code>SetErrorHandler</code> instructions is used to set the Error Handler Register. As discussed in the XCVM chapter, the Error Handler is executed when an error is thrown during the regular instruction execution.</p>"},{"location":"learn/xcm/journey/register-modifiers/#setappendix","title":"SetAppendix","text":"<pre><code>SetAppendix(Xcm&lt;Call&gt;)\n</code></pre> <p>The <code>SetAppendix</code> instruction is used to set the Appendix Register. As discussed in the XCVM chapter, the Appendix instructions are executed after the regular and error handler instruction are executed. These instructions are executed regardless of whether an error occurred.</p>"},{"location":"learn/xcm/journey/register-modifiers/#clearerror","title":"ClearError","text":"<pre><code>ClearError\n</code></pre> <p>The <code>ClearError</code> instruction clears the Error Register by setting it to None.</p>"},{"location":"learn/xcm/journey/register-modifiers/#cleartransactstatus","title":"ClearTransactStatus","text":"<pre><code>ClearTransactStatus\n</code></pre> <p>The <code>ClearTransactStatus</code> instruction sets the Transact Status Register to its default, cleared, value.</p>"},{"location":"learn/xcm/journey/register-modifiers/#settopic","title":"SetTopic","text":"<pre><code>SetTopic([u8; 32])\n</code></pre> <p>The <code>SetTopic</code> instruction sets the Topic Register.</p>"},{"location":"learn/xcm/journey/register-modifiers/#cleartopic","title":"ClearTopic","text":"<pre><code>ClearTopic\n</code></pre> <p>The <code>ClearTopic</code> instruction clears the Topic Register.</p>"},{"location":"learn/xcm/journey/summary/","title":"A Journey through XCM","text":"<p>This section will be a step-by-step, practical introduction to all the features XCM has. We'll create XCMs for a variety of use cases, learning about all the instructions available to us along the way. Let's step right in.</p>"},{"location":"learn/xcm/journey/transact/","title":"Transact","text":"<p>XCM contains an instruction that allows for the execution of calls (from a <code>RuntimeCall</code> in a FRAME-based system, to a smart contract function call in an EVM-based system) in a consensus system. It is the <code>Transact</code> instruction and it looks like this:</p> <pre><code>Transact {\n    origin_kind: OriginKind,\n    require_weight_at_most: Weight,\n    call: DoubleEncoded&lt;Call&gt;\n}\n</code></pre> <p>The Transact instruction has three fields. The <code>origin_kind</code> is of type OriginKind and specifies how the origin of the call should be interpreted. In the xcm-executor, the <code>origin_kind</code> is used to determine how to convert a <code>MultiLocation</code> origin into a <code>RuntimeOrigin</code>. For more information, check out the xcm-executor config docs.</p> <p>The <code>require_weight_at_most</code> field tells the XCVM executing the call how much weight it can use. If the call uses more weight than the specified <code>require_weight_at_most</code>, the execution of the call fails.</p> <p>The <code>call</code> field is of type <code>DoubleEncoded&lt;Call&gt;</code>.</p> <pre><code>pub struct DoubleEncoded&lt;T&gt; {\n    encoded: Vec&lt;u8&gt;,\n    #[codec(skip)]\n    decoded: Option&lt;T&gt;,\n}\n</code></pre> <p>XCM is consensus system agnostic; it does not know what is being encoded in the call field. Hence, the field is a byte vector that can be freely interpreted in whatever form possible. However, the XCVM does not inherently know how to interpret this call field nor how to decode it; it is reliant on the <code>T</code> type parameter to specify the proper codec for the byte vector. Instead of just using a <code>Vec&lt;u8&gt;</code> we use <code>DoubleEncoded</code> as a wrapper around a pre-encoded call (<code>Vec&lt;u8&gt;</code>) with extra functionalities such as caching of the decoded value. We like to emphasize that the call in the <code>Transact</code> instruction can be anything from a <code>RuntimeCall</code> in a FRAME-based system, to a smart contract function call in an EVM-based system.</p> <p>Each XCVM has a Transact Status Register, to record the execution result of the call that is dispatched by the <code>Transact</code> instruction. Important note: The execution of the XCM instruction does not error when the dispatched call errors.</p> <p>The status is described by the <code>MaybeErrorCode</code> enum, and can either be a Success, Error or TruncatedError if the length of the error exceeds the MaxDispatchErrorLen. For pallet-based calls, the Error is represented as the scale encoded <code>Error</code> enum of the called pallet.</p> <pre><code>ExpectTransactStatus(MaybeErrorCode)\n\npub enum MaybeErrorCode {\n    Success,\n    Error(BoundedVec&lt;u8, MaxDispatchErrorLen&gt;),\n    TruncatedError(BoundedVec&lt;u8, MaxDispatchErrorLen&gt;),\n}\n</code></pre>"},{"location":"learn/xcm/journey/transact/#xcm-executor","title":"XCM Executor","text":"<p>In this section, we quickly look at how the XCM executor executes the <code>Transact</code> instruction.</p> <p>It executes, among other things, the following steps:</p> <ol> <li>Decode the call field into the actual call that we want to dispatch.</li> <li>Check with the SafeCallFilter on whether the    execution of this call is allowed.</li> <li>Use the OriginConverter to convert the    <code>MultiLocation</code> origin into a <code>RuntimeOrigin</code>.</li> <li>Check whether the call weight does not exceed <code>require_weight_at_most</code>.</li> <li>Dispatch the call with the converted origin and set the <code>transact_status</code> register to be the    result of the dispatch.</li> <li>Calculate the weight that was actually used during the dispatch.</li> </ol>"},{"location":"learn/xcm/journey/transact/#example-1","title":"Example 1","text":"<p>For the full example, check the repo.</p> <p>In this example, the relay chain executes the <code>set_balance</code> function of <code>pallet_balances</code> on <code>Parachain(1)</code>. This function requires the origin to be root. We enable the root origin for the relay chain by setting <code>ParentAsSuperuser</code> for the <code>OriginConverter</code> config type.</p> <pre><code>let call = parachain::RuntimeCall::Balances(\n    pallet_balances::Call::&lt;parachain::Runtime&gt;::set_balance {\n        who: ALICE,\n        new_free: 5 * AMOUNT,\n        new_reserved: 0,\n    },\n);\n\nlet message = Xcm(vec![\n    WithdrawAsset((Here, AMOUNT).into()),\n    BuyExecution { fees: (Here, AMOUNT).into(), weight_limit: WeightLimit::Unlimited },\n    Transact {\n        origin_kind: OriginKind::Superuser,\n        require_weight_at_most: Weight::from_parts(INITIAL_BALANCE as u64, 1024 * 1024),\n        call: call.encode().into(),\n    },\n]);\n</code></pre>"},{"location":"learn/xcm/journey/transact/#example-2","title":"Example 2","text":"<p>For the full example, check the repo.</p> <p>In this example, as Parachain(1), we create an NFT collection on the relay chain and we then mint an NFT with ID 1. The admin for the nft collection is parachain(1). The call looks as follows:</p> <pre><code>let create_collection = relay_chain::RuntimeCall::Uniques(\n    pallet_uniques::Call::&lt;relay_chain::Runtime&gt;::create {\n        collection: 1u32,\n        admin: parachain_sovereign_account_id(1),\n    }\n);\n</code></pre> <p>The owner of the NFT is Alice. The nft mint call looks as follows:</p> <pre><code>let mint = relay_chain::RuntimeCall::Uniques(\n    pallet_uniques::Call::&lt;relay_chain::Runtime&gt;::mint {\n        collection: 1u32,\n        item: 1u32,\n        owner: ALICE,\n    }\n);\n</code></pre> <p>The xcm message contains the following instructions:</p> <ol> <li>Withdraw native assets from the <code>Parachain(1)</code>'s sovereign account.</li> <li>Buy weight with these assets.</li> <li>Create a collection with as admin and owner the sovereign account of <code>Parachain(1)</code>.</li> <li>Mints an NFT in the collection with item ID 1 and as owner Alice.</li> </ol> <pre><code>let message = Xcm(vec![\n    WithdrawAsset((Here, AMOUNT).into()),\n    BuyExecution { fees: (Here, AMOUNT).into(), weight_limit: WeightLimit::Unlimited },\n    Transact {\n        origin_kind: OriginKind::SovereignAccount,\n        require_weight_at_most: Weight::from_parts(INITIAL_BALANCE as u64, 1024 * 1024),\n        call: create_collection.encode().into(),\n    },\n    Transact {\n        origin_kind: OriginKind::SovereignAccount,\n        require_weight_at_most: Weight::from_parts(INITIAL_BALANCE as u64, 1024 * 1024),\n        call: mint.encode().into(),\n    },\n]);\n</code></pre>"},{"location":"learn/xcm/journey/transact/#next","title":"Next:","text":"<p>Check out the following instructions that interact with the Transact Status Register:</p> <ul> <li>ClearTransactStatus</li> <li>ReportTransactStatus</li> <li>ExpectTransactStatus</li> </ul>"},{"location":"learn/xcm/journey/trap-and-claim/","title":"Trapping and Claiming assets.","text":"<p>When we reach the end of the execution of the XCM there can still be assets in the Holding Register. We can do nothing with them (essentially burning the assets) or we can trap the assets. When we trap the assets, we keep track of the assets together with the origin of the XCM. The origin can claim the assets back in one of the next XCMs. We have two instructions related to trapping and claiming assets:</p> <ul> <li><code>Trap</code></li> <li><code>ClaimAsset</code></li> </ul>"},{"location":"learn/xcm/journey/trap-and-claim/#trap","title":"Trap","text":"<pre><code>Trap(#[codec(compact)] u64)\n</code></pre> <p>The <code>Trap</code> instruction throws an error of type <code>Trap</code>. Both the Trap instruction and Trap error take an <code>u64</code> that can be used to represent some value. The Trap instruction is useful for throwing custom errors. An important thing to note is that the Trap instruction does not directly trap assets. It can however forcefully halt the further execution of instructions and if there are still assets in the Holding Register, these assets can be trapped.</p>"},{"location":"learn/xcm/journey/trap-and-claim/#claimasset","title":"ClaimAsset","text":"<pre><code>ClaimAsset { assets: MultiAssets, ticket: MultiLocation }\n</code></pre> <p>Once assets are trapped, the <code>ClaimAsset</code> instruction can be used to claim the assets. The <code>ClaimAsset</code> instruction has two fields.</p> <p>The <code>assets</code> field tells which trapped assets should be claimed. This must match exactly with the assets claimable by the origin.</p> <p>The <code>ticket</code> field is an identifier that helps locating the asset. It is, for example, useful for distinguishing between Asset Versions. Lets say we have an XCM V2 trapped asset and send an XCM V3 <code>ClaimAsset</code> instruction, then the <code>ticket</code> field can be used to tell between the versions. In the xcm-pallet, <code>Here</code> is used to describe the same version as the <code>ClaimAsset</code> instruction, while the <code>GeneralIndex</code> Junction is used to describe other XCM versions.</p>"},{"location":"learn/xcm/journey/trap-and-claim/#example","title":"Example","text":"<p>The full example can be found here.</p> <p>The scenario of the example is this: Parachain A withdraws funds from its sovereign account on the relay chain. The assets are trapped because an error is thrown and the execution is halted. Parachain A claims the trapped assets and receives a report of the holding register.</p> <p>Parachain A sends the following message to the relay chain. The message errors because of the <code>Trap</code> instruction, so all assets in the Holding Register are trapped.</p> <p>```rust, noplayground let message = Xcm(vec![     WithdrawAsset((Here, 10 * CENTS).into()),     BuyExecution { fees: (Here, CENTS).into(), weight_limit: WeightLimit::Unlimited },     Trap(0), // \u2190 Errors     DepositAsset { // \u2190 Not executed because of error.         assets: All.into(),         beneficiary: AccountId32 {             network: Some(parachain::RelayNetwork::get()),             id: ALICE.into()         }.into()     } ]); <pre><code>Parachain A claims the assets, reports them to itself and deposits them in the Account of Alice.\n\n```rust, noplayground\nlet claim_message = Xcm(vec![\n    ClaimAsset { assets: (Here, 10 * CENTS).into(), ticket: Here.into() },\n    ReportHolding {\n        response_info: QueryResponseInfo {\n            destination: Parachain(1).into(),\n            query_id: QUERY_ID,\n            max_weight: Weight::from_parts(1_000_000_000, 64*64) },\n        assets: All.into()\n    },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary: AccountId32 {\n            network: Some(parachain::RelayNetwork::get()),\n            id: ALICE.into()\n        }.into()\n    },\n]);\n</code></pre></p>"},{"location":"learn/xcm/journey/version/","title":"Version Subscription","text":"<p>XCM is a versioned messaging format. One version may contain more or different instructions than another, so for parties to communicate via XCM, it is important to know which version the other party is using. XCM enables a version subscription model, where parties can subscribe to each other to get notified of version updates. XCM has two instructions to enable this:</p> <ul> <li><code>SubscribeVersion</code></li> <li><code>UnsubscribeVersion</code></li> </ul> <p>The version subscription model can differ per XCVM implementation. The <code>xcm-executor</code> has a <code>SubscriptionService</code> config item. Any type specified as the <code>SubscriptionService</code> must implement the <code>VersionChangeNotifier</code> trait. The XCM pallet is one such implementor. When the <code>SubscribeVersion</code> instruction is sent to a consensus system that uses the XCM pallet as the <code>SubscriptionService</code> in the XCM executor, the system will send back its currently <code>AdvertisedVersion</code> and will keep the subscribed location up to date when the version changes. The subscribed location can unsubscribe to version changes by sending the <code>UnsubscribeVersion</code> instruction.</p> <pre><code>SubscribeVersion {\n    #[codec(compact)]\n    query_id: QueryId,\n    max_response_weight: Weight,\n}\n\nUnsubscribeVersion\n</code></pre> <p>Check out the example.</p>"},{"location":"learn/xcm/journey/locks/locks/","title":"Locking","text":"<p>Assets can be locked via XCM, meaning, the transfer or withdrawal of assets can be restricted via messages. The XCM locking mechanism consists of four instructions: <code>LockAsset</code>, <code>UnlockAsset</code>, <code>NoteUnlockable</code>, and <code>RequestUnlock</code>. Let's explore each instruction in detail:</p>"},{"location":"learn/xcm/journey/locks/locks/#lockasset","title":"LockAsset","text":"<pre><code>LockAsset { asset: MultiAsset, unlocker: MultiLocation }\n</code></pre> <p>The LockAsset instruction is used to lock locally held assets and prevent further transfers or withdrawals. This instruction requires two parameters:</p> <ul> <li><code>asset</code>: The asset(s) to be locked.</li> <li><code>unlocker</code>: The MultiLocation that can unlock the asset(s). This value must match the origin of a   corresponding <code>UnlockAsset</code> instruction to unlock the asset.</li> </ul> <p>When the locking operation succeeds, a <code>NoteUnlockable</code> instruction is sent to the unlocker. This instruction serves as a notification that the asset is now unlockable.</p>"},{"location":"learn/xcm/journey/locks/locks/#unlockasset","title":"UnlockAsset","text":"<pre><code>UnlockAsset { asset: MultiAsset, target: MultiLocation }\n</code></pre> <p>The <code>UnlockAsset</code> instruction removes the lock on a specific asset on the local chain, allowing it to be transferred if there are no other restrictions. The following parameters are required:</p> <ul> <li><code>asset</code>: The asset to be unlocked.</li> <li><code>target</code>: The owner of the asset on the local chain.</li> </ul>"},{"location":"learn/xcm/journey/locks/locks/#noteunlockable","title":"NoteUnlockable","text":"<pre><code>NoteUnlockable { asset: MultiAsset, owner: MultiLocation }\n</code></pre> <p>The <code>NoteUnlockable</code> instruction indicates that an asset has been locked on the system which the message originated from. The locked assets can only be unlocked by receiving an <code>UnlockAsset</code> instruction from this chain. This instruction requires the following parameters:</p> <ul> <li><code>asset</code>: The asset(s) which are now unlockable from this origin.</li> <li><code>owner</code>: The owner of the asset on the chain in which it was locked. This may be a location   specific to the origin network. The owner can request this origin to unlock the assets using a   <code>RequestUnlock</code> instruction. However, the owner is not able to unlock the assets themselves.</li> </ul> <p>It is essential to trust the origin to have locked the corresponding asset before sending this message.</p>"},{"location":"learn/xcm/journey/locks/locks/#requestunlock","title":"RequestUnlock","text":"<p>```rust, noplayground RequestUnlock { asset: MultiAsset, locker: MultiLocation } <pre><code>The `RequestUnlock` instruction is used to send an `UnlockAsset` instruction to the `locker` for a\ngiven asset. The following parameters are required:\n\n- `asset`: The asset(s) to be unlocked.\n- `locker`: The location from which a previous `NoteUnlockable` was sent, and where the\n  `UnlockAsset` instruction should be sent.\n\n## Example\n\nTo get a better grasp on how these instructions work together, we give two examples in this section.\nThe examples use the xcm-executor with the pallet-xcm as the implementation for the `AssetLocker`\nconfig item. An important note of this implementation is that only one lock with ID `py/xcmlk` is\nset per account. The pallet-xcm implementation keeps track of all the xcm-related locks that are\nplaced on an account and sets the most restricting one with the `py/xcmlk` lock ID. This principle\nbecomes more clear in the second example.\n\n### Example 1\n\nCheck out the full [example code](https://github.com/paritytech/xcm-docs/tree/main/examples). The\nscenario of this example is as follows:\n\nParachain A locks 5 Cents of relay chain native assets of its Sovereign account on the relay chain\nand assigns Parachain B as unlocker. Parachain A then asks Parachain B to unlock the funds partly.\nParachain B responds by sending an UnlockAssets instruction to the relay chain.\n\n![Example](./images/Example1.png)\n\n1. send `LockAsset` instruction from ParaA to relay.\n\n```rust\nParaA::execute_with(|| {\n    let message = Xcm(vec![LockAsset {\n        asset: (Here, CENTS * 5).into(),\n        unlocker: (Parachain(2)).into(),\n    }]);\n    assert_ok!(ParachainPalletXcm::send_xcm(Here, Parent, message.clone()));\n});\n</code></pre></p> <ol> <li>Parachain B receives this <code>NoteUnlockable</code> instruction from the relay chain.</li> </ol> <pre><code>NoteUnlockable {\n    owner: (Parent, Parachain(1)).into(),\n    asset: (Parent, CENTS * 5).into()\n}\n</code></pre> <ol> <li>Parachain A sends <code>RequestUnlock</code> instruction to Parachain B</li> </ol> <pre><code>ParaA::execute_with(|| {\n    let message = Xcm(vec![RequestUnlock {\n        asset: (Parent, 3 * CENTS).into(),\n        locker: Parent.into(),\n    }]);\n    assert_ok!(ParachainPalletXcm::send_xcm(Here, (Parent, Parachain(2)), message.clone()));\n});\n</code></pre> <ol> <li>Parachain B sends an <code>UnlockAsset</code> instruction to the relay chain. We check if the lock is    updated accordingly:</li> </ol> <pre><code>assert_eq!(\n    relay_chain::Balances::locks(&amp;parachain_sovereign_account_id(1)),\n    vec![BalanceLock { id: *b\"py/xcmlk\", amount: 2 * CENTS, reasons: Reasons::All }]\n);\n</code></pre>"},{"location":"learn/xcm/journey/locks/locks/#example-2","title":"Example 2","text":"<p>Check out the full example code. The scenario of this example is as follows:</p> <p>Parachain A sets two locks on the relay chain with as unlockers Parachain B and Parachain C. Parachain A then requests Parachain B to partly unlock.</p> <p>Note: The locks overlap. When there are two or more locks, the total assets that are locked is equal to the most restrictive lock (the lock that locks the most assets). When the most restrictive lock is unlocked, the total locked assets is than equal to the next most restrictive lock.</p> <p></p> <ol> <li>Set locks on the relay chain. Unlockers: B, C; Locks registered in pallet-xcm: 10, 5. Lock set in    pallet-balances: 10.</li> </ol> <p>```rust, noplayground ParaA::execute_with(|| {     let message = Xcm(vec![         LockAsset { asset: (Here, 10 * CENTS).into(), unlocker: (Parachain(2)).into() },         LockAsset { asset: (Here, 5 * CENTS).into(), unlocker: (Parachain(3)).into() },     ]);     assert_ok!(ParachainPalletXcm::send_xcm(Here, Parent, message.clone())); });</p> <p>Relay::execute_with(|| {     assert_eq!(         relay_chain::Balances::locks(&amp;parachain_sovereign_account_id(1)),         vec![BalanceLock { id: *b\"py/xcmlk\", amount: 10 * CENTS, reasons: Reasons::All }]     ); }); <pre><code>2. Parachain B and C receive the `NoteUnlockable` instruction.\n\n```rust, noplayground\nParaB::execute_with(|| {\n    assert_eq!(\n        parachain::MsgQueue::received_dmp(),\n        vec![Xcm(vec![NoteUnlockable {\n            owner: (Parent, Parachain(1)).into(),\n            asset: (Parent, 10 * CENTS).into()\n        }])]\n    );\n});\n\nParaC::execute_with(|| {\n    assert_eq!(\n        parachain::MsgQueue::received_dmp(),\n        vec![Xcm(vec![NoteUnlockable {\n            owner: (Parent, Parachain(1)).into(),\n            asset: (Parent, 5 * CENTS).into()\n        }])]\n    );\n});\n</code></pre></p> <ol> <li>Parachain A sends a <code>RequestUnlock</code> instruction to Parachain B for 8 CENTS.</li> </ol> <p>```rust, noplayground ParaA::execute_with(|| {     let message = Xcm(vec![RequestUnlock {         asset: (Parent, 8 * CENTS).into(),         locker: Parent.into(),     }]);</p> <pre><code>assert_ok!(ParachainPalletXcm::send_xcm(Here, (Parent, Parachain(2)), message.clone()));\n</code></pre> <p>}); <code>4. Parachain B Unlocks a part of the funds by sending an `UnlockAsset` to the relay chain. we check    the lock in the balances-pallet. Unlockers: B, C; Funds registered in pallet-xcm: 2, 5. Lock set    in pallet-balances: 5.</code>rust Relay::execute_with(|| {     assert_eq!(         relay_chain::Balances::locks(&amp;parachain_sovereign_account_id(1)),         vec![BalanceLock { id: *b\"py/xcmlk\", amount: 5 * CENTS, reasons: Reasons::All }]     ); }); ```</p>"},{"location":"learn/xcm/journey/transfers/reserve/","title":"Reserve-backed transfers","text":"<p>For consensus systems that don't have the level of trust required for asset teleportation, they can instead opt for trusting a third party called a reserve to store the real assets (think Statemine on Kusama, or Statemint on Polkadot). The source and the destination need a way to keep track of the real assets they own on the reserve, this is usually done by minting a new derivative token. Both source and destination now need accounts on the reserve to hold their assets, we call these their sovereign accounts on that system.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#process","title":"Process","text":"<p>The flow in this diagram is further explained below:</p>"},{"location":"learn/xcm/journey/transfers/reserve/#1-initiatereservewithdraw","title":"1. InitiateReserveWithdraw","text":"<p>The source gathers the derivative assets to be transferred from the sending account and burns them, taking note of the amount of derivatives that were burned.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#2-withdrawasset","title":"2. WithdrawAsset","text":"<p>The source sends a <code>WithdrawAsset</code> instruction to the reserve, instructing it to withdraw real assets equivalent to the amount of derivatives burned from the source chain.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#3-depositreserveasset","title":"3. DepositReserveAsset","text":"<p>The reserve deposits the assets withdrawn from the previous step to the destination's sovereign account, taking note of the amount of assets deposited.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#4-reserveassetdeposited","title":"4. ReserveAssetDeposited","text":"<p>The reserve creates a <code>ReserveAssetDeposited</code> instruction with the amount of assets deposited to the destination's sovereign account, and sends this instruction onwards to the destination. The destination receives the instruction and processes it, minting the correct amount of derivative assets.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#5-depositasset","title":"5. DepositAsset","text":"<p>The destination deposits the derivative assets minted to the receiving account.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#thoughts","title":"Thoughts","text":"<p>The addition of a third consensus system is already a hint of the disadvantages of a reserve asset transfer model. Firstly, the reserve could easily become a point of centralization when too many consensus systems rely on it to be the reserve of choice for their assets. Secondly, the sheer amount of steps required necessarily makes it more prone to errors, and as such, implementors will have to consider more possible pitfalls and provide technical support accordingly when an end user encounters issues arising from these steps. Last, but not least, either the source or destination can opt to designate multiple consensus systems to be their reserves. In such a situation, care must be taken in order to ensure that the sovereign accounts on the reserves are balanced, so that one doesn't get drained while the others still contain a healthy balance.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#a-note-on-trust","title":"A note on trust","text":"<p>We mentioned that reserve-backed transfers require the sender and the destination to trust a third party, the reserve, and not each other. This is true, but it doesn't mean the sender and destination have to trust ONLY the reserve, they also have to trust the issuer of the token. Whenever you are dealing with a particular asset, you are always trusting the issuer of said asset, because at any point they could mint a huge amount of that asset, wreaking havoc. You have to make sure you trust the asset, based on the security mechanisms used to protect its issuance. For this reason, reserves work best when they are the issuers of the asset being transacted. In that scenario, you only have to trust the reserve, period.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#example","title":"Example","text":"<p>We'll create a program for the scenario in the diagram. Let's assume that the reserve is a relay chain and both source and destination are parachains 1 and 2 respectively. Let's also say that an account ALICE in parachain 1 wants to transfer the relay chain's native token to their other account (also ALICE) on parachain 2. The program might look like this:</p> <pre><code>let message = Xcm(vec![\n  WithdrawAsset((Parent, amount).into()),\n  InitiateReserveWithdraw {\n    assets: All.into(),\n    reserve: Parent.into(),\n    xcm: Xcm(vec![DepositReserveAsset {\n      assets: All.into(),\n      dest: Parachain(2).into(),\n      xcm: Xcm(vec![DepositAsset {\n        assets: All.into(),\n        beneficiary: AccountId32 { id: ALICE.into(), network: None }.into(),\n      }]),\n    }]),\n  },\n]);\n</code></pre> <p>This program should be executed on the source, so on parachain 1. We start, as usual, with a <code>WithdrawAsset</code> instruction. The <code>MultiAsset</code> here references the relay chain's native token, which means we'll be gathering the derivative on this chain.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#initiatereservewithdraw","title":"InitiateReserveWithdraw","text":"<pre><code>InitiateReserveWithdraw { assets: MultiAssetFilter, reserve: MultiLocation, xcm: Xcm&lt;()&gt; }\n</code></pre> <p>The <code>InitiateReserveWithdraw</code> instruction takes the derivative token from the holding register and burns it. Then it sends a new XCM to the specified <code>reserve</code>, in this example, the relay chain. This new XCM contains the following instructions, in order:</p> <ol> <li>WithdrawAsset</li> <li>ClearOrigin</li> <li>All instructions specified in the <code>xcm</code> operand, in this case <code>DepositReserveAsset</code></li> </ol> <p>As was the case with teleports, instructions 1. and 2. are added automatically by the executor when using <code>InitiateReserveWithdraw</code>.</p> <p>Upon receiving this XCM, the reserve will withdraw the asset from parachain 1's sovereign account (where the real asset is stored), and deposit it on parachain 2's sovereign account.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#depositreserveasset","title":"DepositReserveAsset","text":"<pre><code>DepositReserveAsset { assets: MultiAssetFilter, dest: MultiLocation, xcm: Xcm&lt;()&gt; }\n</code></pre> <p>This instruction is used in this example instead of <code>DepositAsset</code>, because as well as depositing the assets to parachain 2's sovereign account, this instruction will send another XCM to parachain 2. This new XCM has the following instructions:</p> <ol> <li>ReserveAssetDeposited</li> <li>ClearOrigin</li> <li>All instructions specified in the <code>xcm</code> operand, in this case, only <code>DepositAsset</code></li> </ol>"},{"location":"learn/xcm/journey/transfers/reserve/#reserveassetdeposited","title":"ReserveAssetDeposited","text":"<pre><code>ReserveAssetDeposited(MultiAssets)\n</code></pre> <p>Parachain 2 receives the XCM, mints new derivative tokens and deposit them locally to the beneficiary account. <code>ReserveAssetDeposited</code> is a trusted indication. As is the case with teleporting, you need to trust the reserve to have actually put the specified amount of assets in the sovereign account of this system. You can specify which systems you trust as reserves for which assets by configuring the IsReserve type in the executor. In our example, both parachains trust the relay chain as a reserve for its own native token.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#another-example","title":"Another example","text":"<p>We now know this type of transfers requires 3 actors: the source, the reserve, and the destination. However, the source and reserve don't have to be different systems, they could be one and the same, as in the following diagram.</p> <p></p> <p>In this case the message is the following:</p> <pre><code>let message = Xcm(vec![\n  WithdrawAsset((Parent, amount).into()),\n  DepositReserveAsset {\n    assets: All.into(),\n    dest: Parachain(2).into(),\n    xcm: Xcm(vec![DepositAsset {\n      assets: All.into(),\n      beneficiary: AccountId32 { id: ALICE.into(), network: None }.into(),\n    }]),\n  },\n]);\n</code></pre> <p>This simplifies the reserve-backed transfer. However, the destination still needs to:</p> <ul> <li>Recognize the source as the proper reserve for the tokens that are being sent over and</li> <li>Support minting derivatives of the tokens being sent over</li> </ul> <p>It's also possible to skip the <code>WithdrawAsset</code> instruction. The <code>TransferReserveAsset</code> instruction handles the withdrawal already. It can be called like so:</p> <pre><code>let message = Xcm(vec![\n  TransferReserveAsset {\n    assets: (Parent, amount).into(),\n    dest: Parachain(2).into(),\n    xcm: Xcm(vec![DepositAsset {\n      assets: All.into(),\n      beneficiary: AccountId32 { id: ALICE.into(), network: None }.into(),\n    }]),\n  },\n]);\n</code></pre>"},{"location":"learn/xcm/journey/transfers/reserve/#another-note-on-trust","title":"Another note on trust","text":"<p>In this model, where the sender is the reserve, the destination is trusting the sender entirely. It's the sender the one who doesn't need to trust the destination, since it'll ever only be minting derivatives anyway, the sender/reserve controls the real assets and issuance.</p>"},{"location":"learn/xcm/journey/transfers/reserve/#next-steps","title":"Next steps","text":"<p>Next, we'll talk about a very important topic we mentioned before but skipped in this chapter, paying fees for the effects our XCMs have.</p>"},{"location":"learn/xcm/journey/transfers/summary/","title":"Transfers","text":"<p>The first feature you'll be interested in when dealing with XCM is being able to transfer assets between consensus systems. In the quickstart chapter, we saw a simple XCM that when executed, would send assets between two accounts on the same consensus system. Now that we've learnt the fundamentals, let's go over those same instructions once again.</p>"},{"location":"learn/xcm/journey/transfers/summary/#withdrawasset","title":"WithdrawAsset","text":"<pre><code>WithdrawAsset(MultiAssets),\n</code></pre> <p>This instruction is the most common way to get assets to the holding register of the XCVM. The <code>MultiAssets</code> in the operand will be stored in the holding register to be later used for other instructions. As we've seen, we can use the expression <code>(Here, amount).into()</code> to take a certain <code>amount</code> of the native token.</p>"},{"location":"learn/xcm/journey/transfers/summary/#buyexecution","title":"BuyExecution","text":"<pre><code>BuyExecution { fees: MultiAssets, weight_limit: WeightLimit },\n</code></pre> <p>Because XCM is designed to be agnostic to the underlying consensus system, it doesn't have fee payment baked in. This instruction lets you pay for the execution of the XCM using the assets in the holding register. Most XCMs are not allowed to be executed (blocked by the barrier) if they don't contain this instruction as one of the first ones to pay for all future ones.</p>"},{"location":"learn/xcm/journey/transfers/summary/#depositasset","title":"DepositAsset","text":"<pre><code>DepositAsset { assets: MultiAssetFilter, beneficiary: MultiLocation },\n</code></pre> <p>This instruction will put assets from the holding register that match the MultiAssetFilter into the <code>beneficiary</code>. Note that <code>beneficiary</code> must be a location where the local consensus system can actually deposit assets to, e.g. it doesn't make sense to deposit assets to <code>../AccountId32(0x0)</code>.</p>"},{"location":"learn/xcm/journey/transfers/summary/#example","title":"Example","text":"<pre><code>let message = Xcm(vec![\n  WithdrawAsset((Here, amount).into()),\n  BuyExecution { fees: (Here, amount).into(), weight_limit: Unlimited },\n  DepositAsset {\n    assets: All.into(),\n    beneficiary: AccountId32 { id: ALICE.into(), network: None }.into()\n  },\n]);\n</code></pre> <p>As we've seen, the above message results in withdrawing assets from the origin of the message, paying for execution and depositing the rest to another account on the same system. The full example can be seen in the repo.</p>"},{"location":"learn/xcm/journey/transfers/summary/#transferring-between-systems","title":"Transferring between systems","text":"<p>But what if you want to make a transfer from one system to another? There are two ways of doing this:</p> <ul> <li>Asset teleportation</li> <li>Reserve-backed transfers</li> </ul> <p>We'll be discussing both in the following chapters.</p>"},{"location":"learn/xcm/journey/transfers/teleports/","title":"Asset teleportation","text":"<p>Asset teleportation is the simpler method of the two for sending assets from one chain to another. It has only two actors, the source and the destination.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#process","title":"Process","text":"<p>The way in which we transfer assets between the source and the destination are briefly summarized in the numbered labels on the diagram, and are explained in more detail below:</p>"},{"location":"learn/xcm/journey/transfers/teleports/#1-initiateteleport","title":"1. InitiateTeleport","text":"<p>The source gathers the assets to be teleported from the sending account and takes them out of the circulating supply, taking note of the total amount of assets that were taken out.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#2-receiveteleportedassets","title":"2. ReceiveTeleportedAssets","text":"<p>The source then creates an XCM instruction called <code>ReceiveTeleportedAssets</code> and puts the amount of assets taken out of circulation and the receiving account as parameters to this instruction. It then sends this instruction over to the destination, where it gets processed and new assets are put back into the circulating supply accordingly.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#3-depositasset","title":"3. DepositAsset","text":"<p>The destination then deposits the assets to the receiving account of the asset.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#thoughts","title":"Thoughts","text":"<p>The phrases \"taken out of circulating supply\" and \"put back into circulating supply\" are highlighted above to give an indication of how much flexibility an XCM executor has in implementing the semantics of taking an asset out of and putting it back into its circulating supply. The straightforward answer is to burn the assets to take them out of circulation, but there are multiple methods of achieving the same goal, such as transferring the assets locally to an inaccessible account. Likewise for putting assets back to circulation, the receiving consensus system can freely choose to implement such semantics by releasing assets from a pre-filled and inaccessible treasury of the assets transferred, or perform a mint of the assets.</p> <p>The above also gives a hint on the disadvantages of this model, it requires both the source and destination to have a high level of mutual trust. The destination must trust that the source has appropriately removed the assets that were sent over from the circulating supply, and the source must also trust the destination to put the assets back into circulation. An asset teleportation should result in the same circulating supply of the asset. Failing to uphold either of these two conditions will result in a change in the asset's total issuance (in the case of fungible tokens) or a complete loss/duplication of an NFT.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#example","title":"Example","text":"<p>The following is an example XCM program that achieves the process described above.</p> <pre><code>let message = Xcm(vec![\n  WithdrawAsset((Here, teleport_amount).into()),\n  InitiateTeleport {\n    assets: All.into(),\n    dest: Parachain(1).into(),\n    xcm: Xcm(vec![DepositAsset {\n      assets: All.into(),\n      beneficiary: Junction::AccountId32 {\n        network: None,\n        id: ALICE.into(),\n      }\n    }]),\n  },\n]);\n</code></pre> <p>Let's discuss how the new instructions work.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#initiateteleport","title":"InitiateTeleport","text":"<pre><code>InitiateTeleport { assets: MultiAssetFilter, dest: MultiLocation, xcm: Xcm&lt;()&gt; }\n</code></pre> <p>This instruction is intended to be executed from the source system. It takes the assets to be teleported (that match the <code>MultiAssetFilter</code>) from the holding register, which needs to have been populated, usually with a <code>WithdrawAsset</code> instruction. It then sends an XCM to the destination system given by <code>dest</code> with the following instructions:</p> <ol> <li>ReceiveTeleportedAsset</li> <li>ClearOrigin</li> <li>All the instructions from the <code>xcm</code> operand, in this case <code>DepositAsset</code></li> </ol> <p>As we see in the example, instructions 1. and 2. are always added by the executor, no need to specify them.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#receiveteleportedasset","title":"ReceiveTeleportedAsset","text":"<pre><code>ReceiveTeleportedAssets(MultiAssets)\n</code></pre> <p>This instruction is a trusted indication. It should only be executed if the origin of the XCM is trusted for this purpose. This level of care must be taken because this instruction will put assets into the circulating supply, usually minting them. As specified earlier, this can result in an increase/decrease in circulating supply of an asset, or a duplication/loss of an NFT, if the source is not trusted for this purpose.</p> <p>You can set which origins are allowed to act as teleporters by configuring the IsTeleporter type in the XCM executor. If the origin is not allowed to teleport assets to this system, an <code>UntrustedTeleportLocation</code> error is returned.</p> <p>This instruction will populate the holding register with the teleported assets, which can be used by further instructions. In our example, the <code>DepositAsset</code> instruction will deposit these assets to the receiving account.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#clearorigin","title":"ClearOrigin","text":"<pre><code>ClearOrigin\n</code></pre> <p>This instruction clears the origin register of the XCVM. It's mainly used to not allow further instructions to act on behalf of the previous origin. The <code>InitiateTeleport</code> instruction sends a XCM to the destination system with freshly minted assets and immediately clears the origin.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#another-example","title":"Another example","text":"<p>Let's say we want to teleport an NFT (Non-Fungible Token) this time, instead of a fungible token, to another system. We could do so with the following program:</p> <pre><code>let message = Xcm(vec![\n  WithdrawAsset((GeneralIndex(1), 42u32).into()),\n  InitiateTeleport {\n    assets: All.into(),\n    dest: Parachain(1).into(),\n    xcm: Xcm(vec![DepositAsset {\n      assets: All.into(),\n      beneficiary: Junction::AccountId32 {\n        id: ALICE.into(),\n        network: None,\n      }.into()\n    }]),\n  },\n]);\n</code></pre> <p>Very little changes, in fact, only the <code>MultiAsset</code> we're referencing changes, like we would expect. All the teleportation logic stays the same. The example assumes an NFT with index 42 inside a collection with index 1.</p>"},{"location":"learn/xcm/journey/transfers/teleports/#next-steps","title":"Next steps","text":"<p>We'll look at reserve-backed transfers next.</p>"},{"location":"learn/xcm/overview/architecture/","title":"Architecture","text":"<p>XCM is a format. Anyone can create an implementation of the XCVM to interpret said format.</p> <p>Parity Technologies maintains a Rust implementation, primarily for Substrate-based chains in the Polkadot ecosystem. It is this implementation that we use throughout this documentation.</p> <p>All the code lives in the Polkadot repo. The main structure is as follows:</p> <ul> <li>XCM: Defines the   fundamental constructs used in XCM and an enum with all the instructions available.</li> <li>Executor:   Implements the XCVM, capable of executing XCMs. Highly configurable.</li> <li>Builder:   Offers common configuration building blocks for the executor.</li> <li>Pallet:   FRAME pallet that provides extrinsics for interacting with the XCM executor, as well as specific   XCM programs, such as teleports and reserve asset transfers.</li> <li>Simulator:   Allows for testing of XCM programs.</li> </ul>"},{"location":"learn/xcm/overview/architecture/#executor","title":"Executor","text":"<p>The XCM executor is responsible for interpreting and executing XCM messages. It is the core engine that processes and handles XCM instructions, ensuring that they are carried out accurately and in the correct order. The XCM executor follows the Cross-Consensus Virtual Machine (XCVM) specification and can be extended, customized, or even replaced with an alternative construct that adheres to the XCVM spec.</p>"},{"location":"learn/xcm/overview/architecture/#builder","title":"Builder","text":"<p>The XCM executor is highly configurable. XCM builder provides building blocks people can use to configure their executor according to their needs. Many of these building blocks will be explained in the Config Deep Dive chapter. They cover common use-cases but are not meant to be exhaustive. It's very easy to build your own building blocks for your specific configuration when needed, using these as examples.</p>"},{"location":"learn/xcm/overview/architecture/#pallet","title":"Pallet","text":"<p>The XCM pallet is a FRAME pallet that can be used to execute XCMs locally or send them to a different system. It also has extrinsics for specific use cases such as teleporting assets or doing reserve asset transfers, which we'll talk about later. It's the glue between XCM and FRAME, which is highly used in the Polkadot ecosystem.</p>"},{"location":"learn/xcm/overview/architecture/#simulator","title":"Simulator","text":"<p>The simulator allows for testing XCMs fast, without needing to boot up several different nodes in a network, or test in production. It's a very useful tool which we'll use throughout this document to build and test different XCMs.</p>"},{"location":"learn/xcm/overview/format/","title":"A Format, Not a Protocol","text":"<p>It's essential to understand that XCM is a format, not a protocol. It describes how messages should be structured and contains instructions that convey on-chain actions that the message intends to perform. However, XCM does not dictate how messages are delivered. That responsibility falls on transport layer protocols such as XCMP (Cross Chain Message Passing) and VMP (Vertical Message Passing) in the Polkadot ecosystem, or bridging protocols.</p> <p>This separation of concerns is useful, since it allows us to think of the interactions we want to build between systems without having to think about how the messages involved are actually routed.</p> <p>Not every system is expected to be able to interpret any possible XCM. Some messages will not have reasonable interpretations under some systems or will be intentionally unsupported. For example, some consensus systems won't deal with NFTs, and that's okay. Instructions that relate to NFTs will have valid interpretations on some systems but not on others.</p> <p>Furthermore, XCMs by themselves are not considered on-chain transactions: XCM describes how to change the state of the target consensus system, but the message by itself does not perform state changes. XCM communicates intentions; the actual interpretation and behaviour of each instruction in an XCM is defined by target's XCVM implementation.</p> <p>Both simple and more complex scenarios can be expressed, and developers are encouraged to design and implement diverse cross-consensus communication solutions.</p>"},{"location":"learn/xcm/overview/intro/","title":"Introduction","text":"<p>XCM is a language for communicating intentions between consensus systems. Concretely, XCM is a message format, it specifies how to craft messages that communicate intentions to other consensus systems. Some examples of consensus systems are blockchains and smart contracts. XCM comes from the Polkadot ecosystem, but is designed to be general enough to provide a common format for cross-consensus communication that can be used anywhere.</p> <p>Its goal is to let blockchain ecosystems thrive via specialization instead of generalization. If there's no interoperability, a chain is forced to host all services and support all functionalities on its own. With XCM, we are able to achieve an ecosystem-wide division of labour: a chain can specialize and focus on its own business logic, and leverage the benefits of depending on other specialized blockchain for services that it does not provide.</p> <p>XCM makes the following assumptions regarding the underlying environment:</p> <ol> <li>Asynchronous: XCMs in no way assume that the sender will be blocking on its completion.</li> <li>Absolute: XCMs are assumed to be delivered and interpreted accurately, in order and in a timely    fashion. Once a message is sent, one can assume that it will be processed as intended. This    guarantee has to be provided by the transport layer.</li> <li>Asymmetric: XCMs, by default, do not have results that let the sender know that the message was    executed correctly. If results are needed, a new message must be sent.</li> <li>Agnostic: XCM makes no assumptions about the nature of the consensus systems between which the    messages are being passed. XCM should be usable in any system that derives finality through    consensus.</li> </ol> <p>XCM is constantly evolving; the format is expected to change over time. It has an RFC process to propose changes, which end up in newer versions, the current one being v3. To keep up with the development of the format, or to propose changes, go to the XCM format repository.</p>"},{"location":"learn/xcm/overview/summary/","title":"Overview","text":"<p>XCM enables different consensus systems to communicate with each other. Common cross-consensus use-cases include:</p> <ul> <li>Sending tokens between blockchains</li> <li>Locking assets on one blockchain in order to gain some benefit on a smart contract on another   blockchain</li> <li>Calling specific functions on another blockchain</li> </ul> <p>These are just a few basic examples; once you can communicate with other consensus systems, you can create applications that can leverage multiple blockchains' capabilities. The potential it provides is especially evident in an ecosystem of highly specialized blockchains like Polkadot.</p> <p>Decentralized distributed systems are very complex, so it's easy to make errors when building interactions between them. XCM is meant to be used by developers to package these interactions into their runtime logic before exposing that functionality to end users.</p> <p>This chapter will cover what XCM is, what it isn't, and why it matters before exploring the different components that make up the XCM ecosystem.</p>"},{"location":"learn/xcm/overview/xcvm/","title":"The XCVM","text":"<p>At the core of XCM lies the XCVM (Cross-Consensus Virtual Machine). A message in XCM (referred to as an XCM, cross-consensus message, or XCMs for more than one) is an XCVM program. The XCVM is a register-based state machine that executes every program by processing its instructions one at a time. During execution, state is tracked in domain-specific registers, and is constantly being used and updated. Most of the XCM format comprises these registers and the instructions used to compose XCVM programs.</p> <p>Like XCM, the XCVM is also a specification. The implementation that will be used in this documentation is the xcm-executor, provided by Parity. The executor is highly configurable. For more information on the extensive configuration options available, see the Config Deep Dive chapter.</p> <p>Anyone can create an implementation of the XCVM. As long as they follow the standard, they'll be able to send XCMs to systems using other implementations.</p> <p>Typically, an XCM takes the following path through the XCVM:</p> <ul> <li>Instructions within an XCM are read one-by-one.</li> <li>The instruction is executed. This means that the current values of the XCVM registers, the   instruction type, and the instruction operands are all used to execute some operation, which might   result in some registers changing their value, or in an error being thrown, which would halt   execution.</li> <li>Each subsequent instruction within the XCM is read until the end of the message has been reached.</li> </ul> <p>An example of an XCVM register is the holding register. Any XCVM program that handles assets will be putting them in and taking them from this register. This register is used by several of the instructions we will look at later, including <code>DepositAsset</code> and <code>WithdrawAsset</code>.</p> <p>For more information on other registers, see the All XCVM Registers section.</p>"},{"location":"learn/xcm/quickstart/first-look/","title":"First Look","text":"<p>In this section, we take you through a simple example of an XCM. In this example, we withdraw the native token from the account of Alice and deposit this token in the account of Bob. This message simulates a transfer between two accounts in the same consensus system (<code>ParaA</code>). You can find the complete code example in the repo.</p>"},{"location":"learn/xcm/quickstart/first-look/#message","title":"Message","text":"<pre><code> let message = Xcm(vec![\n    WithdrawAsset((Here, amount).into()),\n    BuyExecution{ fees: (Here, amount).into(), weight_limit: WeightLimit::Unlimited },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary:  MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n]);\n</code></pre> <p>The message consists of three instructions: <code>WithdrawAsset</code>, <code>BuyExecution</code>, and <code>DepositAsset</code>. In the following sections we will go over each instruction.</p>"},{"location":"learn/xcm/quickstart/first-look/#withdrawasset","title":"WithdrawAsset","text":"<pre><code>WithdrawAsset((Here, amount).into())\n</code></pre> <p>The first instruction takes as an input the MultiAsset that should be withdrawn. The MultiAsset describes the native parachain token with the <code>Here</code> keyword. The <code>amount</code> parameter is the number of tokens that are transferred. The withdrawal account depends on the origin of the message. In this example the origin of the message is Alice. The WithdrawAsset instruction moves <code>amount</code> number of native tokens from Alice's account into the holding register.</p>"},{"location":"learn/xcm/quickstart/first-look/#buyexecution","title":"BuyExecution","text":"<pre><code>BuyExecution{fees: (Here, amount).into(), weight_limit: WeightLimit::Unlimited}\n</code></pre> <p>To execute XCM instructions, weight (some amount of resources) has to be bought. The amount of weight needed to execute an XCM depends on the number and type of instructions in the XCM. The <code>BuyExecution</code> instruction pays for the weight using the <code>fees</code>. The <code>fees</code> parameter describes the asset in the holding register that should be used for paying for the weight. The <code>weight_limit</code> parameter defines the maximum amount of fees that can be used for buying weight. There are special occasions where it is not necessary to buy weight. See the chapter on weight and fees for more information about the fees in XCM.</p>"},{"location":"learn/xcm/quickstart/first-look/#depositasset","title":"DepositAsset","text":"<pre><code>DepositAsset {\n    assets: All.into(),\n    beneficiary:  MultiLocation {\n        parents: 0,\n        interior: Junction::AccountId32 {\n            network: None,\n            id: BOB.clone().into()\n        }.into(),\n    }.into()\n}\n</code></pre> <p>The DepositAsset instruction is used to deposit funds from the holding register into the account of the beneficiary. We don\u2019t actually know how much is remaining in the holding register after the <code>BuyExecution</code> instruction, but that doesn\u2019t matter since we specify a wildcard for the asset(s) which should be deposited. In this case, the wildcard is <code>All</code>, meaning that all assets in the holding register at that point in the execution should be deposited. The beneficiary in this case is the account of Bob in the current consensus system.</p> <p>When the three instructions are combined, we withdraw <code>amount</code> native tokens from the account of Alice, pay for the execution of these instructions, and deposit the remaining tokens in the account of Bob.</p>"},{"location":"learn/xcm/quickstart/first-look/#what-next","title":"What next?","text":"<p>Now that we have taken a first look at an XCM, we can dive deeper into all the XCM instructions, to be able to build more complex XCVM programs. For an overview of the instructions check out the xcm-format repo. We'll show examples for every instruction in the journey through XCM chapter. First, it's important to learn the fundamentals, <code>MultiLocation</code>, <code>MultiAsset</code>, and other concepts in XCM. We'll talk about those next.</p>"},{"location":"learn/xcm/quickstart/summary/","title":"Quickstart","text":"<p>The XCM code can be found in polkadot repository.</p>"},{"location":"learn/xcm/quickstart/summary/#rust-cargo","title":"Rust &amp; Cargo","text":"<p>A pre-requisite for using XCM is to have a stable Rust version and Cargo installed. Here's an installation guide.</p>"},{"location":"learn/xcm/quickstart/summary/#running-the-examples","title":"Running the Examples","text":"<p>All examples in the documentation are located in the repository. Follow these steps to run the <code>first-look</code> example. First clone the repository:</p> <pre><code>git clone git@github.com:paritytech/xcm-docs.git\ncd xcm-docs/examples\n</code></pre> <p>To run the first-look example, run the following line:</p> <pre><code>cargo test -p xcm-examples para_a_simple_transfer -- --nocapture\n</code></pre> <p>It should show you the following output:</p> <pre><code>running 1 test\ntest first_look::tests::para_a_simple_transfer ... ok\n\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 1 filtered out; finished in 0.01s\n</code></pre>"},{"location":"learn/xcm/quickstart/xcm-simulator/","title":"XCM Simulator","text":"<p>Setting up a live network with multiple connected parachains for testing XCM is not straight forward. The <code>xcm-simulator</code> was created as a solution to this problem. It's a network simulator specifically designed for testing and tinkering with XCM. It uses mock runtimes for a relay chain and parachains.</p> <p>Although it's a great tool to learn and test XCMs, it shouldn't be the only thing you use to actually test your XCM-powered solution. We'll get into tools and best practices for testing in the testing chapter.</p> <p>We'll use the simulator throughout the documentation to show different XCMs in action. In the next section we will take a first look at an XCM.</p>"},{"location":"learn/xcm/reference/glossary/","title":"Glossary","text":""},{"location":"learn/xcm/reference/glossary/#xcm-cross-consensus-messaging","title":"XCM (Cross-Consensus Messaging)","text":"<p>A messaging format meant to communicate intentions between consensus systems. XCM could also refer to a single message.</p>"},{"location":"learn/xcm/reference/glossary/#instructions","title":"Instructions","text":"<p>XCMs are composed of a sequence of instructions. Each instruction aims to convey a particular intention. There are instructions for transferring and locking assets, handling fees, calling arbitrary blobs, and more.</p>"},{"location":"learn/xcm/reference/glossary/#consensus-system","title":"Consensus system","text":"<p>A system that can reach any kind of consensus. For example, relay chains, parachains, smart contracts.</p>"},{"location":"learn/xcm/reference/glossary/#multilocation","title":"MultiLocation","text":"<p>A way of addressing consensus systems. These could be relative or absolute.</p>"},{"location":"learn/xcm/reference/glossary/#junction","title":"Junction","text":"<p>The different ways of descending down a <code>MultiLocation</code> hierarchy. A junction can be a Parachain, an Account, or more.</p>"},{"location":"learn/xcm/reference/glossary/#multiasset","title":"MultiAsset","text":"<p>A way of identifying assets in the same or another consensus system, by using a <code>MultiLocation</code>.</p>"},{"location":"learn/xcm/reference/glossary/#sovereign-account","title":"Sovereign account","text":"<p>An account on a consensus system that is controlled by an account in another consensus system.</p>"},{"location":"learn/xcm/reference/glossary/#teleport","title":"Teleport","text":"<p>A way of transferring assets between two consensus systems without the need of a third party. It consists of the sender system burning the asset that wants to be sent over and the recipient minting an equivalent amount of that asset. It requires a lot of trust between the two systems, since failure to mint or burn will reduce the total issuance of the token.</p>"},{"location":"learn/xcm/reference/glossary/#reserve-asset-transfer","title":"Reserve asset transfer","text":"<p>A way of transferring assets between two consensus systems that don't trust each other, by using a third system they both trust, called the reserve. The real asset only exists on the reserve, both sender and recipient only deal with derivatives. It consists of the sender burning a certain amount of derivatives, telling the reserve to move real assets from its sovereign account to the destination's sovereign account, and then telling the recipient to mint the right amount of derivatives.</p>"},{"location":"learn/xcm/reference/glossary/#xcvm","title":"XCVM","text":"<p>The virtual machine behind XCM. Every XCM is an XCVM programme. Holds state in registers.</p>"},{"location":"learn/xcm/reference/glossary/#holding-register","title":"Holding register","text":"<p>An XCVM register used to hold arbitrary <code>Asset</code>s during the execution of an XCVM programme.</p>"},{"location":"learn/xcm/reference/glossary/#barrier","title":"Barrier","text":"<p>An XCM executor configuration item that works as a firewall for incoming XCMs. All XCMs have to pass the barrier to be executed, else they are dropped. It can be used for whitelisting only certain types or messages or messages from certain senders.</p>"},{"location":"learn/xcm/reference/glossary/#ump-upward-message-passing","title":"UMP (Upward Message Passing)","text":"<p>Transport-layer protocol that allows parachains to send messages upwards to their relay chain.</p>"},{"location":"learn/xcm/reference/glossary/#dmp-downward-message-passing","title":"DMP (Downward Message Passing)","text":"<p>Transport-layer protocol that allows the relay chain to send messages downwards to one of their parachains.</p>"},{"location":"learn/xcm/reference/glossary/#xcmp-cross-consensus-message-passing","title":"XCMP (Cross-Consensus Message Passing)","text":"<p>Transport-layer protocol that allows parachains to send messages between themselves, without going through the relay chain.</p>"},{"location":"learn/xcm/reference/glossary/#hrmp-horizontal-message-passing","title":"HRMP (Horizontal Message Passing)","text":"<p>Transport-layer protocol that allows a parachain to send messages to a sibling parachain going through the relay chain. It's a precursor to XCMP, also known as XCMP-lite. It uses a mixture of UMP and VMP.</p>"},{"location":"learn/xcm/reference/xcvm-registers/","title":"XCVM Registers","text":"<p>Each implementation of an XCVM contains several registers which cannot generally be set at will, but rather begin with specific values and may only be mutated under certain circumstances and/or obeying certain rules. An XCVM has the following registers:</p> <ul> <li>Programme</li> <li>Programme Counter</li> <li>Error</li> <li>Error Handler</li> <li>Appendix</li> <li>Origin</li> <li>Holding</li> <li>Surplus Weight</li> <li>Refunded Weight</li> <li>Transact Status</li> <li>Topic</li> </ul>"},{"location":"maintain/","title":"Network Maintainers","text":"<p>Welcome to the network maintainers section of the Polkadot Wiki. Here you will find information and guides to set up a node and run the network.</p> <ul> <li>Polkadot Parameters - Reference for Polkadot parameters.</li> <li>Nodes and Dapps - Guides for nodes and dapps.</li> <li>Collator Guides - Information for collators.</li> <li>Validator Guides - Information for validators.</li> <li>Archive - Archived maintenance guides.</li> </ul> <p>Polkadot's Canary Network Kusama</p> <p>For more information about being a Kusama maintainer, see the pages below:</p> <ul> <li>Nomination Guide - Walkthrough on how to nominate on the Kusama   canary network.</li> <li>Validation Guide (Kusama) - Walkthrough on how   to validate on the Kusama canary network.</li> </ul>"},{"location":"maintain/maintain-archive/","title":"Archived Maintain Resources","text":"<p>     This section contains archived pages. The content in them no longer applies to Polkadot but can     still be relevant for parachains and related projects.   </p> \u2716"},{"location":"maintain/maintain-bootnode/","title":"Set up a Boot Node","text":"<p>Note</p> <p>When you first start a node, it has to find a way to find other nodes in the network. For that purpose, you need \"bootnodes\". After the first bootnode is found, it can use that node\u2019s connections to continue expanding and play its role in the network, like participating as a validator.</p>"},{"location":"maintain/maintain-bootnode/#accessing-the-bootnode","title":"Accessing the Bootnode","text":"<p>The consensus is that bootnodes have to be accessible in three ways:</p> <ul> <li>p2p: the p2p port, which can be set by <code>--listen-addr /ip4/0.0.0.0/tcp/&lt;port&gt;</code>. This port is   not automatically set on a non-validator node (for example, an archive RPC node).</li> <li>p2p/ws: the WebSocket version, which can be set by <code>--listen-addr /ip4/0.0.0.0/tcp/&lt;port&gt;/ws</code>.</li> <li>p2p/wss: the secure websocket version. An SSL-secured connection to the p2p/ws port must be   achieved by a proxy since the node cannot include certificates. It is needed for light clients.   See here for info about setting this up.</li> </ul>"},{"location":"maintain/maintain-bootnode/#network-key","title":"Network Key","text":"<p>Starting a node creates its node key in the <code>chains/&lt;chain&gt;/network/secret_ed25519</code> file. You can also create a node-key by <code>polkadot key generate-node-key</code> and use that node-key in the startup command line.</p> <p>It is essential you backup the node key, especially if it gets included in the polkadot binary because it gets hardcoded in the binary and needs to be recompiled to change.</p>"},{"location":"maintain/maintain-bootnode/#running-the-bootnode","title":"Running the Bootnode","text":"<p>Say we are running a polkadot node with <code>polkadot --chain polkadot --name dot-bootnode --listen-addr /ip4/0.0.0.0/tcp/30310 --listen-addr /ip4/0.0.0.0/tcp/30311/ws</code> then we would have the p2p on port 30310 and p2p/ws on port 30311. For the p2p/wss port, we need to set up a proxy, a DNS name, and a corresponding certificate. These concepts and example setups are described here. The following example is for the popular nginx server and enables p2p/wss on port 30312 by proxying the p2p/ws port 30311:</p> <p>/etc/nginx/sites-enabled/dot-bootnode</p> <pre><code>server {\n       listen       30312 ssl http2 default_server;\n       server_name  dot-bootnode.stakeworld.io;\n       root         /var/www/html;\n\n       ssl_certificate \"&lt;your_cert\";\n       ssl_certificate_key \"&lt;your_key&gt;\";\n\n       location / {\n         proxy_buffers 16 4k;\n         proxy_buffer_size 2k;\n         proxy_pass http://localhost:30311;\n         proxy_http_version 1.1;\n         proxy_set_header Upgrade $http_upgrade;\n         proxy_set_header Connection \"Upgrade\";\n         proxy_set_header Host $host;\n   }\n\n}\n</code></pre>"},{"location":"maintain/maintain-bootnode/#testing-bootnode-connection","title":"Testing Bootnode Connection","text":"<p>If we have the above node running with DNS name <code>dot-bootnode.stakeworld.io</code>, proxied with a valid certificate and node-id <code>12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg</code> then the following commands should give you a: \"syncing 1 peers\".</p> <p>Tip</p> <p>You can add <code>-lsub-libp2p=trace</code> on the end to get libp2p trace logging for debugging purposes.</p> <p>p2p:</p> <pre><code>polkadot --chain polkadot --base-path /tmp/node --name \"Bootnode testnode\" --reserved-only --reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30310/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" --no-hardware-benchmarks\n</code></pre> <p>p2p/ws:</p> <pre><code>polkadot --chain polkadot --base-path /tmp/node --name \"Bootnode testnode\" --reserved-only --reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30311/ws/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" --no-hardware-benchmarks\n</code></pre> <p>p2p/wss:</p> <pre><code>polkadot --chain polkadot --base-path /tmp/node --name \"Bootnode testnode\" --reserved-only --reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30312/wss/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" --no-hardware-benchmarks\n</code></pre>"},{"location":"maintain/maintain-endpoints/","title":"Node Endpoints","text":"<p>Ideally, one may run their own node when interacting with the Polkadot network via Polkadot-JS Apps or other UIs and programmatic methods. Another option would be to connect to one of the several public endpoints provided by infrastructure and API service providers. For development convenience, Parity Tech maintains archive nodes for Polkadot, Kusama, and their test networks with public endpoints. These endpoints can be used with Polkadot-JS API to interact with their respective chains. The tables below list these endpoints.</p>"},{"location":"maintain/maintain-endpoints/#network-endpoints","title":"Network Endpoints","text":"<p>Endpoints for all production and test networks are listed on the Polkadot-JS UI which are accessed from here. Endpoints for Polkadot relay chain and Kusama relay chain, parachains, and Paseo test network are maintained by the community. System Chains as well as Westend test network endpoints maintained by Parity Technologies are listed below:</p> Polkadot System Chains Network WSS Endpoint Asset Hub wss://polkadot-asset-hub-rpc.polkadot.io Bridge Hub wss://polkadot-bridge-hub-rpc.polkadot.io Collectives wss://polkadot-collectives-rpc.polkadot.io People Chain wss://polkadot-people-rpc.polkadot.io Kusama System Chains Network WSS Endpoint Asset Hub wss://kusama-asset-hub-rpc.polkadot.io Bridge Hub wss://kusama-bridge-hub-rpc.polkadot.io Collectives wss://kusama-collectives-rpc.polkadot.io People Chain wss://kusama-people-rpc.polkadot.io Coretime Chain wss://kusama-coretime-rpc.polkadot.io Test Networks Network WSS Endpoint Westend wss://westend-rpc.polkadot.io"},{"location":"maintain/maintain-endpoints/#example-usage-with-polkadot-js-api","title":"Example usage with Polkadot-JS API","text":"<p>To connect to the Parity node for the Polkadot Asset Hub, use the endpoint in your JavaScript apps like so:</p> <pre><code>// Using the Polkadot Mainnet Endpoint\nconst { ApiPromise, WsProvider } = require('@polkadot/api');\nasync () =&gt; {\n  // Construct a provider with the endpoint URL\n  const provider = new WsProvider('wss://polkadot-asset-hub-rpc.polkadot.io');\n  // Create an API instance for Polkadot\n  const api = await ApiPromise.create({ provider });\n  // ...\n</code></pre>"},{"location":"maintain/maintain-endpoints/#third-party-providers","title":"Third Party Providers","text":"<p>There are a number of third-party providers of RPC infrastructure to the Polkadot and Kusama communities, commonly providing access to multiple networks and parachains in a single service. They provide additional services such as higher rate limits, potentially more reliable and scalable service, and additional metrics.</p> <ul> <li>OnFinality</li> <li>Dwellir</li> <li>Radium Block</li> <li>GetBlock</li> <li>1RPC</li> <li>NOWNodes</li> <li>All That Node</li> <li>SubQuery</li> <li>dRPC</li> </ul> <p>Note</p> <p>The list of third party RPC endpoints above for Polkadot and Kusama is directly fetched from Polkadot-JS UI</p>"},{"location":"maintain/maintain-errors/","title":"Errors and How to Resolve Them","text":"<p>Errors in Substrate-based chains are usually accompanied by descriptive messages. However, to read these messages, a tool parsing the blockchain data needs to request chain metadata from a node. That metadata explains how to read the messages. One such tool with a built-in parser for chain metadata is the Polkadot-JS Apps UI.</p> <p>If this page does not answer your question, try searching for your problem at the Polkadot Knowledge Base for more information on troubleshooting your issue.</p>"},{"location":"maintain/maintain-errors/#polkadot-js-apps-explorer","title":"Polkadot-JS Apps Explorer","text":"<p>Here's how to find out the detailed error description through Polkadot-JS Apps.</p> <p>A typical failed transactions looks something like this:</p> <p></p> <p>The image displays only the error name as defined in the code, not its error message. Despite this error being rather self-explanatory, let's find its details.</p> <p>In the explorer tab, find the block in which this failure occurred. Then, expand the <code>system.ExtrinsicFailed</code> frame:</p> <p></p> <p>Notice how the <code>details</code> field contains a human-readable description of the error. Most errors will have this, if looked up this way.</p> <p>This block is a live example of the above.</p> <p>If you cannot look up the error this way, or there is no message in the <code>details</code> field, consult the table below.</p>"},{"location":"maintain/maintain-errors/#subscan","title":"Subscan","text":"<p>The <code>ExtrinsicFailed</code> event indicates when a transaction does not succeed (example). This event gives us the <code>error</code> and <code>index</code> (as seen in the table of the event, in the <code>dispatch_error</code> row) indices of the error but does not give us a nice message to understand what it means. We will look up the error in the codebase ourselves to understand what went wrong.</p> <p>First, we should understand that the <code>index</code> number is the index of the pallet in the runtime from which the error originated. The <code>error</code> is likewise the index of that pallet's errors which is the exact one we're looking for. Both of these indices start counting from 0.</p> <p>For example, if <code>index</code> is 5 and <code>error</code> is 3, as in the example linked above, we need to look at the runtime for the fourth error (index 3) in the sixth pallet (index 5).</p> <p>By looking at the runtime code we see that the pallet at index 5 is <code>Balances</code>. Now we will check the Balances pallet's code which is hosted in the Substrate repository, and look for the fourth error in the <code>Error enum</code>. According to its source the error that we got is <code>InsufficientBalance</code>, or in other words, \"Balance too low to send value\".</p>"},{"location":"maintain/maintain-errors/#common-errors","title":"Common Errors","text":"<p>The table below lists the most commonly encountered errors and ways to resolve them.</p> Error Description Solution BadOrigin You are not allowed to do this operation, e.g. trying to create a council motion with a non-council account. Either switch to an account that has the necessary permissions, or check if the operation you're trying to execute is permitted at all (e.g. calling <code>system.setCode</code> to do a runtime upgrade directly, without voting). BadProof The transaction's signature seems invalid. It's possible that the node you're connected to is following an obsolete fork - trying again after it catches up usually resolves the issue. To check for bigger problems, inspect the last finalized and current best block of the node you're connected to and compare the values to chain stats exposed by other nodes - are they in sync? If not, try connecting to a different node. Future Transaction nonce too high, i.e. it's \"from the future\", see note below. Reduce the nonce to +1 of current nonce. Check current nonce by inspecting the address you're using to send the transaction. Stale Transaction nonce too low. Increase the nonce to +1 of current nonce. Check current nonce by inspecting the address you're using to send the transaction. ExhaustsResources There aren't enough resources left in the current block to submit this transaction. Try again in the next block. Payment Unable to pay for TX fee. You might not have enough free balance to cover the fee this transaction would incur. Temporarily banned The transaction is temporarily banned. The tx is already in pool. Either try on a different node, or wait to see if the initial transaction goes through. <p>Future Error</p> <p>This error will not cause the TX to be discarded immediately. Instead, it will be sent to the futures queue, where it will wait to be executed at the correct place in the nonce sequence OR it will get discarded due to some other error (ex. the validity period expires).</p>"},{"location":"maintain/maintain-errors/#error-table","title":"Error Table","text":"<p>The below table is a reference to the errors that exists in Polkadot. It is generated from the runtime's metadata.</p>"},{"location":"maintain/maintain-errors/#errors-from-current-pallets-on-polkadot","title":"Errors from Current Pallets on Polkadot","text":"Pallet Error Documentation System (0) InvalidSpecName (0) The name of specification does not match between the current runtime and the new runtime. SpecVersionNeedsToIncrease (1) The specification version is not allowed to decrease between the current runtime and the new runtime. FailedToExtractRuntimeVersion (2) Failed to extract the runtime version from the new runtime. Either calling <code>Core_version</code> or decoding <code>RuntimeVersion</code> failed. NonDefaultComposite (3) Suicide called when the account has non-default composite data. NonZeroRefCount (4) There is a non-zero reference count preventing the account from being purged. Scheduler (1) FailedToSchedule (0) Failed to schedule a call NotFound (1) Cannot find the scheduled call. TargetBlockNumberInPast (2) Given target block number is in the past. RescheduleNoChange (3) Reschedule failed because it does not change scheduled time. Balances (5) VestingBalance (0) Vesting balance too high to send value LiquidityRestrictions (1) Account liquidity restrictions prevent withdrawal Overflow (2) Got an overflow after adding InsufficientBalance (3) Balance too low to send value ExistentialDeposit (4) Value too low to create account due to existential deposit KeepAlive (5) Transfer/payment would kill account ExistingVestingSchedule (6) A vesting schedule already exists for this account DeadAccount (7) Beneficiary account must pre-exist Authorship (6) InvalidUncleParent (0) The uncle parent not in the chain. UnclesAlreadySet (1) Uncles already set in the block. TooManyUncles (2) Too many uncles. GenesisUncle (3) The uncle is genesis. TooHighUncle (4) The uncle is too high in chain. UncleAlreadyIncluded (5) The uncle is already included. OldUncle (6) The uncle isn't recent enough to be included. Staking (7) NotController (0) Not a controller account. NotStash (1) Not a stash account. AlreadyBonded (2) Stash is already bonded. AlreadyPaired (3) Controller is already paired. EmptyTargets (4) Targets cannot be empty. DuplicateIndex (5) Duplicate index. InvalidSlashIndex (6) Slash record index out of bounds. InsufficientValue (7) Can not bond with value less than minimum balance. NoMoreChunks (8) Can not schedule more unlock chunks. NoUnlockChunk (9) Can not rebond without unlocking chunks. FundedTarget (10) Attempting to target a stash that still has funds. InvalidEraToReward (11) Invalid era to reward. InvalidNumberOfNominations (12) Invalid number of nominations. NotSortedAndUnique (13) Items are not sorted and unique. AlreadyClaimed (14) Rewards for this era have already been claimed for this validator. OffchainElectionEarlySubmission (15) The submitted result is received out of the open window. OffchainElectionWeakSubmission (16) The submitted result is not as good as the one stored on chain. SnapshotUnavailable (17) The snapshot data of the current window is missing. OffchainElectionBogusWinnerCount (18) Incorrect number of winners were presented. OffchainElectionBogusWinner (19) One of the submitted winners is not an active candidate on chain (index is out of range in snapshot). OffchainElectionBogusCompact (20) Error while building the assignment type from the compact. This can happen if an index is invalid, or if the weights overflow. OffchainElectionBogusNominator (21) One of the submitted nominators is not an active nominator on chain. OffchainElectionBogusNomination (22) One of the submitted nominators has an edge to which they have not voted on chain. OffchainElectionSlashedNomination (23) One of the submitted nominators has an edge which is submitted before the last non-zero slash of the target. OffchainElectionBogusSelfVote (24) A self vote must only be originated from a validator to ONLY themselves. OffchainElectionBogusEdge (25) The submitted result has unknown edges that are not among the presented winners. OffchainElectionBogusScore (26) The claimed score does not match with the one computed from the data. OffchainElectionBogusElectionSize (27) The election size is invalid. CallNotAllowed (28) The call is not allowed at the given time due to restrictions of election period. IncorrectHistoryDepth (29) Incorrect previous history depth input provided. IncorrectSlashingSpans (30) Incorrect number of slashing spans provided. Session (9) InvalidProof (0) Invalid ownership proof. NoAssociatedValidatorId (1) No associated validator ID for account. DuplicatedKey (2) Registered duplicate key. NoKeys (3) No keys are associated with this account. Grandpa (11) PauseFailed (0) Attempt to signal GRANDPA pause when the authority set isn't live (either paused or already pending pause). ResumeFailed (1) Attempt to signal GRANDPA resume when the authority set isn't paused (either live or already pending resume). ChangePending (2) Attempt to signal GRANDPA change with one already pending. TooSoon (3) Cannot signal forced change so soon after last. InvalidKeyOwnershipProof (4) A key ownership proof provided as part of an equivocation report is invalid. InvalidEquivocationProof (5) An equivocation proof provided as part of an equivocation report is invalid. DuplicateOffenceReport (6) A given equivocation report is valid but already previously reported. ElectionsPhragmen (17) UnableToVote (0) Cannot vote when no candidates or members exist. NoVotes (1) Must vote for at least one candidate. TooManyVotes (2) Cannot vote more than candidates. MaximumVotesExceeded (3) Cannot vote more than maximum allowed. LowBalance (4) Cannot vote with stake less than minimum balance. UnableToPayBond (5) Voter can not pay voting bond. MustBeVoter (6) Must be a voter. ReportSelf (7) Cannot report self. DuplicatedCandidate (8) Duplicated candidate submission. MemberSubmit (9) Member cannot re-submit candidacy. RunnerSubmit (10) Runner cannot re-submit candidacy. InsufficientCandidateFunds (11) Candidate does not have enough funds. NotMember (12) Not a member. InvalidCandidateCount (13) The provided count of number of candidates is incorrect. InvalidVoteCount (14) The provided count of number of votes is incorrect. InvalidRenouncing (15) The renouncing origin presented a wrong <code>Renouncing</code> parameter. InvalidReplacement (16) Prediction regarding replacement after member removal is wrong. Treasury (19) InsufficientProposersBalance (0) Proposer's balance is too low. InvalidIndex (1) No proposal or bounty at that index. ReasonTooBig (2) The reason given is just too big. AlreadyKnown (3) The tip was already found/started. UnknownTip (4) The tip hash is unknown. NotFinder (5) The account attempting to retract the tip is not the finder of the tip. StillOpen (6) The tip cannot be claimed/closed because there are not enough tippers yet. Premature (7) The tip cannot be claimed/closed because it's still in the countdown period. UnexpectedStatus (8) The bounty status is unexpected. RequireCurator (9) Require bounty curator. InvalidValue (10) Invalid bounty value. InvalidFee (11) Invalid bounty fee. PendingPayout (12) A bounty payout is pending. To cancel the bounty, you must unassign and slash the curator. Claims (24) InvalidEthereumSignature (0) Invalid Ethereum signature. SignerHasNoClaim (1) Ethereum address has no claim. SenderHasNoClaim (2) Account ID sending tx has no claim. PotUnderflow (3) There's not enough in the pot to pay out some unvested amount. Generally implies a logic error. InvalidStatement (4) A needed statement was not included. VestedBalanceExists (5) The account already has a vested balance. Vesting (25) NotVesting (0) The account given is not vesting. ExistingVestingSchedule (1) An existing vesting schedule already exists for this account that cannot be clobbered. AmountLow (2) Amount being transferred is too low to create a vesting schedule. Identity (28) TooManySubAccounts (0) Too many subs-accounts. NotFound (1) Account isn't found. NotNamed (2) Account isn't named. EmptyIndex (3) Empty index. FeeChanged (4) Fee is changed. NoIdentity (5) No identity found. StickyJudgement (6) Sticky judgement. JudgementGiven (7) Judgement given. InvalidJudgement (8) Invalid judgement. InvalidIndex (9) The index is invalid. InvalidTarget (10) The target is invalid. TooManyFields (11) Too many additional fields. TooManyRegistrars (12) Maximum amount of registrars reached. Cannot add any more. AlreadyClaimed (13) Account ID is already named. NotSub (14) Sender is not a sub-account. NotOwned (15) Sub-account isn't owned by sender. Proxy (29) TooMany (0) There are too many proxies registered or too many announcements pending. NotFound (1) Proxy registration not found. NotProxy (2) Sender is not a proxy of the account to be proxied. Unproxyable (3) A call which is incompatible with the proxy type's filter was attempted. Duplicate (4) Account is already a proxy. NoPermission (5) Call may not be made by proxy because it may escalate its privileges. Unannounced (6) Announcement, if made at all, was made too recently. Multisig (30) MinimumThreshold (0) Threshold must be 2 or greater. AlreadyApproved (1) Call is already approved by this signatory. NoApprovalsNeeded (2) Call doesn't need any (more) approvals. TooFewSignatories (3) There are too few signatories in the list. TooManySignatories (4) There are too many signatories in the list. SignatoriesOutOfOrder (5) The signatories were provided out of order; they should be ordered. SenderInSignatories (6) The sender was contained in the other signatories; it shouldn't be. NotFound (7) Multisig operation not found when attempting to cancel. NotOwner (8) Only the account that originally created the multisig is able to cancel it. NoTimepoint (9) No timepoint was given, yet the multisig operation is already underway. WrongTimepoint (10) A different timepoint was given to the multisig operation that is underway. UnexpectedTimepoint (11) A timepoint was given, yet no multisig operation is underway. WeightTooLow (12) The maximum weight information provided was too low. AlreadyStored (13) The data to be stored is already stored."},{"location":"maintain/maintain-errors/#errors-from-deprecated-pallets-on-polkadot","title":"Errors from Deprecated Pallets on Polkadot","text":"Pallet Error Documentation Council (15) NotMember (0) Account is not a member DuplicateProposal (1) Duplicate proposals not allowed ProposalMissing (2) Proposal must exist WrongIndex (3) Mismatched index DuplicateVote (4) Duplicate vote ignored AlreadyInitialized (5) Members are already initialized! TooEarly (6) The close call was made too early, before the end of the voting. TooManyProposals (7) There can only be a maximum of <code>MaxProposals</code> active proposals. WrongProposalWeight (8) The given weight bound for the proposal was too low. WrongProposalLength (9) The given length bound for the proposal was too low. TechnicalCommittee (16) NotMember (0) Account is not a member DuplicateProposal (1) Duplicate proposals not allowed ProposalMissing (2) Proposal must exist WrongIndex (3) Mismatched index DuplicateVote (4) Duplicate vote ignored AlreadyInitialized (5) Members are already initialized! TooEarly (6) The close call was made too early, before the end of the voting. TooManyProposals (7) There can only be a maximum of <code>MaxProposals</code> active proposals. WrongProposalWeight (8) The given weight bound for the proposal was too low. WrongProposalLength (9) The given length bound for the proposal was too low. Democracy (14) ValueLow (0) Value too low ProposalMissing (1) Proposal does not exist BadIndex (2) Unknown index AlreadyCanceled (3) Cannot cancel the same proposal twice DuplicateProposal (4) Proposal already made ProposalBlacklisted (5) Proposal still blacklisted NotSimpleMajority (6) Next external proposal not simple majority InvalidHash (7) Invalid hash NoProposal (8) No external proposal AlreadyVetoed (9) Identity may not veto a proposal twice NotDelegated (10) Not delegated DuplicatePreimage (11) Preimage already noted NotImminent (12) Not imminent TooEarly (13) Too early Imminent (14) Imminent PreimageMissing (15) Preimage not found ReferendumInvalid (16) Vote given for invalid referendum PreimageInvalid (17) Invalid preimage NoneWaiting (18) No proposals waiting NotLocked (19) The target account does not have a lock. NotExpired (20) The lock on the account to be unlocked has not yet expired. NotVoter (21) The given account did not vote on the referendum. NoPermission (22) The actor has no permission to conduct the action. AlreadyDelegating (23) The account is already delegating. Overflow (24) An unexpected integer overflow occurred. Underflow (25) An unexpected integer underflow occurred. InsufficientFunds (26) Too high a balance was provided that the account cannot afford. NotDelegating (27) The account is not currently delegating. VotesExist (28) The account currently has votes attached to it and the operation cannot succeed until these are removed, either through <code>unvote</code> or <code>reap_vote</code>. InstantNotAllowed (29) The instant referendum origin is currently disallowed. Nonsense (30) Delegation to oneself makes no sense. WrongUpperBound (31) Invalid upper bound. MaxVotesReached (32) Maximum number of votes reached. InvalidWitness (33) The provided witness data is wrong. TooManyProposals (34) Maximum number of proposals reached."},{"location":"maintain/maintain-guides-async-backing/","title":"Upgrade Parachain for Asynchronous Backing Compatibility","text":"<p>!!!info Who is this guide for?     This guide is relevant for cumulus based parachain projects started in 2023 or before. Later     projects should already be async backing compatible. If starting a new parachain project, please use     an async backing compatible template such as     <code>cumulus/parachain-template</code>.</p> <p>The rollout process for Async Backing has three phases. Phases 1 and 2 below put new infrastructure in place. Then we can simply turn on async backing in phase 3. But first, some pre-reqs and context to set the stage.</p>"},{"location":"maintain/maintain-guides-async-backing/#async-backing-prerequisites","title":"Async Backing Prerequisites","text":"<p>Info</p> <p>For more contextual information about asynchronous backing, see this page.</p> <p>Pull the latest version of Cumulus for use with your parachain. It contains necessary changes for async backing compatibility. Latest on master branch of Polkadot-SDK is currently sufficient. Any 2024 release will work as well.</p>"},{"location":"maintain/maintain-guides-async-backing/#async-backing-terminology-and-parameters","title":"Async Backing Terminology and Parameters","text":"<p>Time for a bit of context before we get started. The following concepts will aid in demystifying the collator side of Async Backing and establish a basic understanding of the changes being made:</p> <ul> <li>Unincluded segment - From the perspective of a parachain block under construction, the   unincluded segment describes a chain of recent block ancestors which have yet to be included on   the relay chain. The ability to build new blocks on top of the unincluded segment rather than on   top of blocks freshly included in the relay chain is the core of asynchronous backing.</li> <li>Capacity - The maximum size of the unincluded segment. The longer this is, the farther ahead a   parachain can work, producing new candidates before the ancestors of those candidates have been   seen as included on-chain. Practically, a capacity of 2-3 is sufficient to realize the full   benefits of asynchronous backing, at least until the release of elastic scaling.</li> <li>Velocity - The base rate at which a parachain should produce blocks. A velocity of 1 indicates   that 1 parachain block should be produced per relay chain block. In order to fill the unincluded   segment with candidates, collators may build up to <code>Velocity + 1</code> candidates per aura slot while   there is remaining capacity. When elastic scaling has been released velocities greater than 1 will   be supported.</li> <li>AllowMultipleBlocksPerSlot - If this is <code>true</code>, Aura will allow slots to stay the same across   sequential parablocks. Otherwise the slot number must increase with each block. To fill the   unincluded segment as described above we need this to be <code>true</code>.</li> <li>FixedVelocityConsensusHook - This is a variety of <code>ConsensusHook</code> intended to be passed to   <code>parachain-system</code> as part of its <code>Config</code>. It is triggered on initialization of a new runtime. An   instance of <code>FixedVelocityConsensusHook</code> is defined with both a fixed capacity and velocity. It   aborts the runtime early if either capacity or velocity is exceeded, as the collator shouldn\u2019t be   creating additional blocks in that case.</li> <li>AsyncBackingParams.max_candidate_depth - This parameter determines the maximum unincluded   segment depth the relay chain will support. Candidates sent to validators which exceed   <code>max_candidate_depth</code> will be ignored. <code>Capacity</code>, as mentioned above, should not exceed   <code>max_candidate_depth</code>.</li> <li>AsyncBackingParams.allowed_ancestry_len - Each parachain block candidate has a <code>relay_parent</code>   from which its execution and validation context is derived. Before async backing the   <code>relay_parent</code> for a candidate not yet backed was required to be the fresh head of a fork. With   async backing we can relax this requirement. Instead we set a conservative maximum age in blocks   for the <code>relay_parent</code>s of candidates in the unincluded segment. This age, <code>allowed_ancestry_len</code>   lives on the relay chain and is queried by parachains when deciding which block to build on top   of.</li> <li>Lookahead Collator - A collator for Aura that looks ahead of the most recently included   parachain block when determining what to build upon. This collator also builds additional blocks   when the maximum backlog is not saturated. The size of the backlog is determined by invoking the   AuraUnincludedSegmentApi. If that runtime API is not supported, this assumes a maximum backlog   size of 1.</li> </ul>"},{"location":"maintain/maintain-guides-async-backing/#prerequisite","title":"Prerequisite","text":"<p>The relay chain needs to have async backing enabled so double-check that the relay chain configuration contains the following three parameters (especially when testing locally e.g. with zombienet):</p> <pre><code>\"async_backing_params\": {\n    \"max_candidate_depth\": 3,\n    \"allowed_ancestry_len\": 2\n},\n\"scheduling_lookahead\": 2\n</code></pre> <p>Warning</p> <p><code>scheduling_lookahead</code> must be set to 2, otherwise parachain block times will degrade to worse than with sync backing! </p>"},{"location":"maintain/maintain-guides-async-backing/#phase-1-update-parachain-runtime","title":"Phase 1 - Update Parachain Runtime","text":"<p>This phase involves configuring your parachain\u2019s runtime to make use of async backing system.</p> <ol> <li> <p>Establish constants for <code>capacity</code> and <code>velocity</code> and set both of them to 1 in    <code>/runtime/src/lib.rs</code>.</p> </li> <li> <p>Establish a constant relay chain slot duration measured in milliseconds equal to <code>6000</code> in    <code>/runtime/src/lib.rs</code>.</p> </li> </ol> <pre><code>/// Maximum number of blocks simultaneously accepted by the Runtime, not yet included into the\n/// relay chain.\npub const UNINCLUDED_SEGMENT_CAPACITY: u32 = 1;\n/// How many parachain blocks are processed by the relay chain per parent. Limits the number of\n/// blocks authored per slot.\npub const BLOCK_PROCESSING_VELOCITY: u32 = 1;\n/// Relay chain slot duration, in milliseconds.\npub const RELAY_CHAIN_SLOT_DURATION_MILLIS: u32 = 6000;\n</code></pre> <ol> <li>Establish constants <code>MILLISECS_PER_BLOCK</code> and <code>SLOT_DURATION</code> if not already present in    <code>/runtime/src/lib.rs</code>.</li> </ol> <pre><code>/// BLOCKSkkhasd will be produced at a minimum duration defined by `SLOT_DURATION`.\n/// `SLOT_DURATION` is picked up by `pallet_timestamp` which is in turn picked\n/// up by `pallet_aura` to implement `fn slot_duration()`.\n///\n/// Change this to adjust the block time.\npub const MILLISECS_PER_BLOCK: u64 = 12000;\npub const SLOT_DURATION: u64 = MILLISECS_PER_BLOCK;\n</code></pre> <ol> <li>Configure <code>cumulus_pallet_parachain_system</code> in <code>runtime/src/lib.rs</code></li> </ol> <ul> <li>Define a <code>FixedVelocityConsensusHook</code> using our capacity, velocity, and relay slot duration      constants. Use this to set the parachain system <code>ConsensusHook</code> property.</li> </ul> <pre><code>impl cumulus_pallet_parachain_system::Config for Runtime {\n type RuntimeEvent = RuntimeEvent;\n type OnSystemEvent = ();\n type SelfParaId = parachain_info::Pallet&lt;Runtime&gt;;\n type OutboundXcmpMessageSource = XcmpQueue;\n type DmpQueue = frame_support::traits::EnqueueWithOrigin&lt;MessageQueue, RelayOrigin&gt;;\n type ReservedDmpWeight = ReservedDmpWeight;\n type XcmpMessageHandler = XcmpQueue;\n type ReservedXcmpWeight = ReservedXcmpWeight;\n type CheckAssociatedRelayNumber = RelayNumberMonotonicallyIncreases;\n // highlight-next-line\n type ConsensusHook = ConsensusHook;\n type WeightInfo = weights::cumulus_pallet_parachain_system::WeightInfo&lt;Runtime&gt;;\n}\n// highlight-start\ntype ConsensusHook = cumulus_pallet_aura_ext::FixedVelocityConsensusHook&lt;\n Runtime,\n RELAY_CHAIN_SLOT_DURATION_MILLIS,\n BLOCK_PROCESSING_VELOCITY,\n UNINCLUDED_SEGMENT_CAPACITY,\n&gt;;\n// highlight-end\n</code></pre> <ul> <li>Set the parachain system property <code>CheckAssociatedRelayNumber</code> to      <code>RelayNumberMonotonicallyIncreases</code></li> </ul> <pre><code>impl cumulus_pallet_parachain_system::Config for Runtime {\n type RuntimeEvent = RuntimeEvent;\n type OnSystemEvent = ();\n type SelfParaId = parachain_info::Pallet&lt;Runtime&gt;;\n type OutboundXcmpMessageSource = XcmpQueue;\n type DmpQueue = frame_support::traits::EnqueueWithOrigin&lt;MessageQueue, RelayOrigin&gt;;\n type ReservedDmpWeight = ReservedDmpWeight;\n type XcmpMessageHandler = XcmpQueue;\n type ReservedXcmpWeight = ReservedXcmpWeight;\n // highlight-next-line\n type CheckAssociatedRelayNumber = RelayNumberMonotonicallyIncreases;\n type ConsensusHook = ConsensusHook;\n type WeightInfo = weights::cumulus_pallet_parachain_system::WeightInfo&lt;Runtime&gt;;\n}\ntype ConsensusHook = cumulus_pallet_aura_ext::FixedVelocityConsensusHook&lt;\n Runtime,\n RELAY_CHAIN_SLOT_DURATION_MILLIS,\n BLOCK_PROCESSING_VELOCITY,\n UNINCLUDED_SEGMENT_CAPACITY,\n&gt;;\n</code></pre> <ol> <li>Configure <code>pallet_aura</code> in <code>runtime/src/lib.rs</code></li> </ol> <ul> <li>Set <code>AllowMultipleBlocksPerSlot</code> to <code>false</code> (don't worry, we will set it to <code>true</code> when we      activate async backing in phase 3).</li> <li>Define <code>pallet_aura::SlotDuration</code> using our constant <code>SLOT_DURATION</code></li> </ul> <pre><code>impl pallet_aura::Config for Runtime {\n type AuthorityId = AuraId;\n type DisabledValidators = ();\n type MaxAuthorities = ConstU32&lt;100_000&gt;;\n // highlight-start\n type AllowMultipleBlocksPerSlot = ConstBool&lt;false&gt;;\n #[cfg(feature = \"experimental\")]\n type SlotDuration = ConstU64&lt;SLOT_DURATION&gt;;\n // highlight-end\n}\n</code></pre> <ol> <li>Update <code>aura_api::SlotDuration()</code> to match the constant <code>SLOT_DURATION</code></li> </ol> <pre><code>impl_runtime_apis! {\n impl sp_consensus_aura::AuraApi&lt;Block, AuraId&gt; for Runtime {\n     fn slot_duration() -&gt; sp_consensus_aura::SlotDuration {\n         // highlight-next-line\n         sp_consensus_aura::SlotDuration::from_millis(SLOT_DURATION)\n     }\n\n     fn authorities() -&gt; Vec&lt;AuraId&gt; {\n         Aura::authorities().into_inner()\n     }\n }\n...\n</code></pre> <ol> <li>Implement the <code>AuraUnincludedSegmentApi</code>, which allows the collator client to query its runtime    to determine whether it should author a block.</li> </ol> <ul> <li>Add the dependency <code>cumulus-primitives-aura</code> to the <code>runtime/Cargo.toml</code> file for your runtime</li> </ul> <pre><code>cumulus-pallet-aura-ext = { path = \"../../../../pallets/aura-ext\", default-features = false }\ncumulus-pallet-parachain-system = { path = \"../../../../pallets/parachain-system\", default-features = false, features = [\"parameterized-consensus-hook\"] }\ncumulus-pallet-session-benchmarking = { path = \"../../../../pallets/session-benchmarking\", default-features = false }\ncumulus-pallet-xcm = { path = \"../../../../pallets/xcm\", default-features = false }\ncumulus-pallet-xcmp-queue = { path = \"../../../../pallets/xcmp-queue\", default-features = false, features = [\"bridging\"] }\n// highlight-next-line\ncumulus-primitives-aura = { path = \"../../../../primitives/aura\", default-features = false }\n</code></pre> <ul> <li> <p>In the same file, add <code>\"cumulus-primitives-aura/std\",</code> to the <code>std</code> feature.</p> </li> <li> <p>Inside the <code>impl_runtime_apis!</code> block for your runtime, implement the <code>AuraUnincludedSegmentApi</code>   as shown below.</p> </li> </ul> <pre><code>impl cumulus_primitives_aura::AuraUnincludedSegmentApi&lt;Block&gt; for Runtime {\n    fn can_build_upon(\n        included_hash: &lt;Block as BlockT&gt;::Hash,\n        slot: cumulus_primitives_aura::Slot,\n    ) -&gt; bool {\n        ConsensusHook::can_build_upon(included_hash, slot)\n    }\n}\n</code></pre> <p>Note: With a capacity of 1 we have an effective velocity of \u00bd even when velocity is configured to some larger value. This is because capacity will be filled after a single block is produced and will only be freed up after that block is included on the relay chain, which takes 2 relay blocks to accomplish. Thus with capacity 1 and velocity 1 we get the customary 12 second parachain block time.</p> <ol> <li>If your <code>runtime/src/lib.rs</code> provides a <code>CheckInherents</code> type to <code>register_validate_block</code>,    remove it. <code>FixedVelocityConsensusHook</code> makes it unnecessary. The following example shows how    <code>register_validate_block</code> should look after removing <code>CheckInherents</code>.</li> </ol> <pre><code>cumulus_pallet_parachain_system::register_validate_block! {\n    Runtime = Runtime,\n    BlockExecutor = cumulus_pallet_aura_ext::BlockExecutor::&lt;Runtime, Executive&gt;,\n}\n</code></pre>"},{"location":"maintain/maintain-guides-async-backing/#phase-2-update-parachain-nodes","title":"Phase 2 - Update Parachain Nodes","text":"<p>This phase consists of plugging in the new lookahead collator node.</p> <ol> <li>Import <code>cumulus_primitives_core::ValidationCode</code> to <code>node/src/service.rs</code></li> </ol> <pre><code>use cumulus_primitives_core::{\n// highlight-next-line\n    relay_chain::{CollatorPair, ValidationCode},\n    ParaId,\n};\n</code></pre> <ol> <li>In <code>node/src/service.rs</code>, modify <code>sc_service::spawn_tasks</code> to use a clone of <code>Backend</code> rather    than the original</li> </ol> <pre><code>sc_service::spawn_tasks(sc_service::SpawnTasksParams {\n    rpc_builder,\n    client: client.clone(),\n    transaction_pool: transaction_pool.clone(),\n    task_manager: &amp;mut task_manager,\n    config: parachain_config,\n    keystore: params.keystore_container.keystore(),\n  // highlight-next-line\n    backend: backend.clone(),\n    network: network.clone(),\n    sync_service: sync_service.clone(),\n    system_rpc_tx,\n    tx_handler_controller,\n    telemetry: telemetry.as_mut(),\n})?;\n</code></pre> <ol> <li>Add <code>backend</code> as a parameter to <code>start_consensus()</code> in <code>node/src/service.rs</code></li> </ol> <pre><code>fn start_consensus(\n    client: Arc&lt;ParachainClient&gt;,\n    // highlight-next-line\n    backend: Arc&lt;ParachainBackend&gt;,\n    block_import: ParachainBlockImport,\n    prometheus_registry: Option&lt;&amp;Registry&gt;,\n    telemetry: Option&lt;TelemetryHandle&gt;,\n    task_manager: &amp;TaskManager,\n</code></pre> <pre><code>if validator {\n    start_consensus(\n    client.clone(),\n    // highlight-next-line\n    backend.clone(),\n    block_import,\n    prometheus_registry.as_ref(),\n</code></pre> <ol> <li>In <code>node/src/service.rs</code> import the lookahead collator rather than the basic collator</li> </ol> <pre><code>use cumulus_client_consensus_aura::collators::lookahead::{self as aura, Params as AuraParams};\n</code></pre> <ol> <li>In <code>start_consensus()</code> replace the <code>BasicAuraParams</code> struct with <code>AuraParams</code>    - Change the struct type from <code>BasicAuraParams</code> to <code>AuraParams</code>    - In the <code>para_client</code> field, pass in a cloned para client rather than the original    - Add a <code>para_backend</code> parameter after <code>para_client</code>, passing in our para backend    - Provide a <code>code_hash_provider</code> closure like that shown below    - Increase <code>authoring_duration</code> from 500 milliseconds to 1500</li> </ol> <pre><code>let params = AuraParams {\n    create_inherent_data_providers: move |_, ()| async move { Ok(()) },\n    block_import,\n    para_client: client.clone(),\n    para_backend: backend.clone(),\n    relay_client: relay_chain_interface,\n    code_hash_provider: move |block_hash| {\n        client.code_at(block_hash).ok().map(|c| ValidationCode::from(c).hash())\n    },\n    sync_oracle,\n    keystore,\n    collator_key,\n    para_id,\n    overseer_handle,\n    relay_chain_slot_duration,\n    proposer,\n    collator_service,\n    // highlight-next-line\n    authoring_duration: Duration::from_millis(1500),\n    reinitialize: false,\n};\n</code></pre> <p>Note: Set <code>authoring_duration</code> to whatever you want, taking your own hardware into account. But if the backer who should be slower than you due to reading from disk, times out at two seconds your candidates will be rejected.</p> <ol> <li>In <code>start_consensus()</code> replace <code>basic_aura::run</code> with <code>aura::run</code></li> </ol> <pre><code>let fut = aura::run::&lt;\n    Block,\n    sp_consensus_aura::sr25519::AuthorityPair,\n    _,\n    _,\n    _,\n    _,\n    _,\n    _,\n    _,\n    _,\n    _,\n    &gt;(params);\ntask_manager.spawn_essential_handle().spawn(\"aura\", None, fut);\n</code></pre>"},{"location":"maintain/maintain-guides-async-backing/#phase-3-activate-async-backing","title":"Phase 3 - Activate Async Backing","text":"<p>This phase consists of changes to your parachain\u2019s runtime that activate async backing feature.</p> <ol> <li>Configure <code>pallet_aura</code>, setting <code>AllowMultipleBlocksPerSlot</code> to true in <code>runtime/src/lib.rs</code>.</li> </ol> <pre><code>impl pallet_aura::Config for Runtime {\n    type AuthorityId = AuraId;\n    type DisabledValidators = ();\n    type MaxAuthorities = ConstU32&lt;100_000&gt;;\n    // highlight-next-line\n    type AllowMultipleBlocksPerSlot = ConstBool&lt;true&gt;;\n    #[cfg(feature = \"experimental\")]\n    type SlotDuration = ConstU64&lt;SLOT_DURATION&gt;;\n}\n</code></pre> <ol> <li>Increase the maximum <code>UNINCLUDED_SEGMENT_CAPACITY</code> in <code>runtime/src/lib.rs</code>.</li> </ol> <pre><code>/// Maximum number of blocks simultaneously accepted by the Runtime, not yet included into the\n/// relay chain.\npub const UNINCLUDED_SEGMENT_CAPACITY: u32 = 3;\n/// How many parachain blocks are processed by the relay chain per parent. Limits the number of\n/// blocks authored per slot.\npub const BLOCK_PROCESSING_VELOCITY: u32 = 1;\n</code></pre> <ol> <li>Decrease <code>MILLISECS_PER_BLOCK</code> to 6000.</li> </ol> <ul> <li>Note: For a parachain which measures time in terms of its own block number rather than by relay   block number it may be preferable to increase velocity. Changing block time may cause   complications, requiring additional changes. See the section \u201cTiming by Block Number\u201d.</li> </ul> <pre><code>/// This determines the average expected block time that we are targeting.\n/// Blocks will be produced at a minimum duration defined by `SLOT_DURATION`.\n/// `SLOT_DURATION` is picked up by `pallet_timestamp` which is in turn picked\n/// up by `pallet_aura` to implement `fn slot_duration()`.\n///\n/// Change this to adjust the block time.\npub const MILLISECS_PER_BLOCK: u64 = 6000;\n</code></pre> <ol> <li>Update <code>MAXIMUM_BLOCK_WEIGHT</code> to reflect the increased time available for block production.</li> </ol> <pre><code>/// We allow for 2 seconds of compute with a 6 second average block.\npub const MAXIMUM_BLOCK_WEIGHT: Weight = Weight::from_parts(\n    WEIGHT_REF_TIME_PER_SECOND.saturating_mul(2),\n    cumulus_primitives_core::relay_chain::MAX_POV_SIZE as u64,\n);\n</code></pre> <ol> <li>Add a feature flagged alternative for <code>MinimumPeriod</code> in <code>pallet_timestamp</code>. The type should be    <code>ConstU64&lt;0&gt;</code> with the feature flag experimental, and <code>ConstU64&lt;{SLOT_DURATION / 2}&gt;</code> without.</li> </ol> <pre><code>impl pallet_timestamp::Config for Runtime {\n    type Moment = u64;\n    type OnTimestampSet = Aura;\n    #[cfg(feature = \"experimental\")]\n    type MinimumPeriod = ConstU64&lt;0&gt;;\n    #[cfg(not(feature = \"experimental\"))]\n    type MinimumPeriod = ConstU64&lt;{ SLOT_DURATION / 2 }&gt;;\n    type WeightInfo = weights::pallet_timestamp::WeightInfo&lt;Runtime&gt;;\n}\n</code></pre>"},{"location":"maintain/maintain-guides-async-backing/#timing-by-block-number","title":"Timing by Block Number","text":"<p>With asynchronous backing it will be possible for parachains to opt for a block time of 6 seconds rather than 12 seconds. But modifying block duration isn\u2019t so simple for a parachain which was measuring time in terms of its own block number. It could result in expected and actual time not matching up, stalling the parachain.</p> <p>One strategy to deal with this issue is to instead rely on relay chain block numbers for timing. Relay block number is kept track of by each parachain in <code>pallet-parachain-system</code> with the storage value <code>LastRelayChainBlockNumber</code>. This value can be obtained and used wherever timing based on block number is needed.</p>"},{"location":"maintain/maintain-guides-how-to-chill/","title":"How to Chill","text":"<p>Staking bonds can be in any of the three states: validating, nominating, or chilled (neither validating nor nominating). When a staker wants to temporarily pause their active engagement in staking but does not want to unbond their funds, they can choose to \"chill\" their involvement and keep their funds bonded.</p> <p>An account can step back from participating in active staking by clicking \"Stop\" under the Network &gt; Staking &gt; Account actions page in PolkadotJS Apps or by calling the <code>chill</code> extrinsic in the staking pallet. When an account chooses to chill, it becomes inactive in the next era. The call must be signed by the staking proxy account, not the stash.</p> <p>Primer on stash and staking proxy accounts</p> <p>If you need a refresher on the different responsibilities of the stash and staking proxy account when staking, take a look at the accounts section in the general staking guide.</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-chill/#consideration-for-staking-election","title":"Consideration for Staking Election","text":"<p>A bond that is actively participating in staking but chilled would continue to participate in staking for the rest of the current era. If the bond was chilled in sessions 1 through 4 and continues to be chilled for the rest of the era, it would NOT be selected for election in the next era. If a bond was chilled for the entire session 5, it would not be considered in the next election. If the bond was chilled in session 6, its participation in the next era's election would depend on its state in session 5.</p>"},{"location":"maintain/maintain-guides-how-to-chill/#chilling-as-a-nominator","title":"Chilling as a Nominator","text":"<p>When you chill after being a nominator, your nominations will be reset. This means that when you decide to start nominating again you will need to select validators to nominate once again. These can be the same validators if you prefer, or, a completely new set. Just be aware - your nominations will not persist across chills.</p> <p>Your nominator will remain bonded when it is chilled. When you are ready to nominate again, you will not need to go through the whole process of bonding again, rather, you will issue a new nominate call that specifies the new validators to nominate.</p>"},{"location":"maintain/maintain-guides-how-to-chill/#chilling-as-a-validator","title":"Chilling as a Validator","text":"<p>When you voluntarily chill after being a validator, your nominators will remain. As long as your nominators make no action, you will still have the nominations when you choose to become an active validator once again. You bond however would not be listed as a nominable validator thus any nominators issuing new or revisions to existing nominations would not be able to select your bond.</p> <p>When you become an active validator, you will also need to reset your validator preferences (commission, etc.). These can be configured as the same values set previously or something different.</p>"},{"location":"maintain/maintain-guides-how-to-chill/#chill-other","title":"Chill Other","text":"<p>An unbounded and unlimited number of nominators and validators in Polkadot's NPoS is not possible due to constraints in the runtime. As a result, multiple checks are incorporated to keep the size of staking system manageable, like mandating minimum active bond requirements for both nominators and validators. When these requirements are modified through on-chain governance, they can be enforced only on the accounts that newly call <code>nominate</code> or <code>validate</code> after the update. The changes to the bonding parameters would not automatically chill the active accounts on-chain which do not meet the requirements.</p> <p>Chill Threshold</p> <p><code>ChillThreshold</code> defines how close to the max nominators or validators we must reach before users can start chilling one another.</p> <p>For instance, let us consider a scenario where the minimum staking requirement for nominators is changed from 80 DOTs to 120 DOTs. An account that was actively nominating with 80 DOTs before this update would still keep receiving staking rewards. To handle this corner case, the <code>chillOther</code> extrinsic was incorporated which also helps to keep things backwards compatible and safe. The <code>chillOther</code> extrinsic is permissionless and any third party user can target it on an account where the minimum active bond is not satisfied, and chill that account. The list of addresses of all the active validators and their nominators can be viewed by running validator stats script.</p> <p>Chill Other on Polkadot Network</p> <p>Through Referendum 90, <code>maxNominatorCount</code> on Polkadot is set to <code>None</code> eliminating the upper bound on the number of nominators on the network. Due to this, the <code>chillOther</code> extrinsic on Polkadot network has no effect as the chill threshold will never be met.</p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/","title":"Monitor your node","text":"<p>This guide will walk you through how to set up Prometheus with Grafana to monitor your node using Ubuntu 18.04 or 20.04.</p> <p>A Substrate-based chain exposes data such as the height of the chain, the number of connected peers to your node, CPU, memory usage of your machine, and more. To monitor this data, Prometheus is used to collect metrics and Grafana allows for displaying them on the dashboard.</p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#preparation","title":"Preparation","text":"<p>First, create a user for Prometheus by adding the <code>--no-create-home</code> flag to disallow <code>prometheus</code> from logging in.</p> <pre><code>sudo useradd --no-create-home --shell /usr/sbin/nologin prometheus\n</code></pre> <p>Create the directories required to store the configuration and executable files.</p> <pre><code>sudo mkdir /etc/prometheus\nsudo mkdir /var/lib/prometheus\n</code></pre> <p>Change the ownership of these directories to <code>prometheus</code> so that only prometheus can access them.</p> <pre><code>sudo chown -R prometheus:prometheus /etc/prometheus\nsudo chown -R prometheus:prometheus /var/lib/prometheus\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#installing-and-configuring-prometheus","title":"Installing and Configuring Prometheus","text":"<p>After setting up the environment, update your OS, and install the latest Prometheus. You can check the latest release by going to their GitHub repository under the releases page.</p> <pre><code>sudo apt-get update &amp;&amp; apt-get upgrade\nwget https://github.com/prometheus/prometheus/releases/download/v2.26.0/prometheus-2.26.0.linux-amd64.tar.gz\ntar xfz prometheus-*.tar.gz\ncd prometheus-2.26.0.linux-amd64\n</code></pre> <p>The following two binaries are in the directory:</p> <ul> <li>prometheus - Prometheus main binary file</li> <li>promtool</li> </ul> <p>The following two directories (which contain the web interface, configuration files examples and the license) are in the directory:</p> <ul> <li>consoles</li> <li>console_libraries</li> </ul> <p>Copy the executable files to the <code>/usr/local/bin/</code> directory.</p> <pre><code>sudo cp ./prometheus /usr/local/bin/\nsudo cp ./promtool /usr/local/bin/\n</code></pre> <p>Change the ownership of these files to the <code>prometheus</code> user.</p> <pre><code>sudo chown prometheus:prometheus /usr/local/bin/prometheus\nsudo chown prometheus:prometheus /usr/local/bin/promtool\n</code></pre> <p>Copy the <code>consoles</code> and <code>console_libraries</code> directories to <code>/etc/prometheus</code></p> <pre><code>sudo cp -r ./consoles /etc/prometheus\nsudo cp -r ./console_libraries /etc/prometheus\n</code></pre> <p>Change the ownership of these directories to the <code>prometheus</code> user.</p> <pre><code>sudo chown -R prometheus:prometheus /etc/prometheus/consoles\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\n</code></pre> <p>Once everything is done, run this command to remove <code>prometheus</code> directory.</p> <pre><code>cd .. &amp;&amp; rm -rf prometheus*\n</code></pre> <p>Before using Prometheus, it needs some configuration. Create a YAML configuration file named <code>prometheus.yml</code> by running the command below.</p> <pre><code>sudo nano /etc/prometheus/prometheus.yml\n</code></pre> <p>The configuration file is divided into three parts which are <code>global</code>, <code>rule_files</code>, and <code>scrape_configs</code>.</p> <ul> <li> <p><code>scrape_interval</code> defines how often Prometheus scrapes targets, while <code>evaluation_interval</code>   controls how often the software will evaluate rules.</p> </li> <li> <p><code>rule_files</code> block contains information of the location of any rules we want the Prometheus server   to load.</p> </li> <li> <p><code>scrape_configs</code> contains the information which resources Prometheus monitors.</p> </li> </ul> <p>The configuration file should look like this below:</p> <pre><code>global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nrule_files:\n  # - \"first.rules\"\n  # - \"second.rules\"\n\nscrape_configs:\n  - job_name: \"prometheus\"\n    scrape_interval: 5s\n    static_configs:\n      - targets: [\"localhost:9090\"]\n  - job_name: \"substrate_node\"\n    scrape_interval: 5s\n    static_configs:\n      - targets: [\"localhost:9615\"]\n</code></pre> <p>With the above configuration file, the first exporter is the one that Prometheus exports to monitor itself. As we want to have more precise information about the state of the Prometheus server we reduced the <code>scrape_interval</code> to 5 seconds for this job. The parameters <code>static_configs</code> and <code>targets</code> determine where the exporters are running. The second exporter is capturing the data from your node, and the port by default is <code>9615</code>.</p> <p>You can check the validity of this configuration file by running <code>promtool check config /etc/prometheus/prometheus.yml</code>.</p> <p>Save the configuration file and change the ownership of the file to <code>prometheus</code> user.</p> <pre><code>sudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#starting-prometheus","title":"Starting Prometheus","text":"<p>To test that Prometheus is set up properly, execute the following command to start it as the <code>prometheus</code> user.</p> <pre><code>sudo -u prometheus /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\n</code></pre> <p>The following messages indicate the status of the server. If you see the following messages, your server is set up properly.</p> <pre><code>level=info ts=2021-04-16T19:02:20.167Z caller=main.go:380 msg=\"No time or size retention was set so using the default time retention\" duration=15d\nlevel=info ts=2021-04-16T19:02:20.167Z caller=main.go:418 msg=\"Starting Prometheus\" version=\"(version=2.26.0, branch=HEAD, revision=3cafc58827d1ebd1a67749f88be4218f0bab3d8d)\"\nlevel=info ts=2021-04-16T19:02:20.167Z caller=main.go:423 build_context=\"(go=go1.16.2, user=root@a67cafebe6d0, date=20210331-11:56:23)\"\nlevel=info ts=2021-04-16T19:02:20.167Z caller=main.go:424 host_details=\"(Linux 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 ubuntu2004 (none))\"\nlevel=info ts=2021-04-16T19:02:20.167Z caller=main.go:425 fd_limits=\"(soft=1024, hard=1048576)\"\nlevel=info ts=2021-04-16T19:02:20.167Z caller=main.go:426 vm_limits=\"(soft=unlimited, hard=unlimited)\"\nlevel=info ts=2021-04-16T19:02:20.169Z caller=web.go:540 component=web msg=\"Start listening for connections\" address=0.0.0.0:9090\nlevel=info ts=2021-04-16T19:02:20.170Z caller=main.go:795 msg=\"Starting TSDB ...\"\nlevel=info ts=2021-04-16T19:02:20.171Z caller=tls_config.go:191 component=web msg=\"TLS is disabled.\" http2=false\nlevel=info ts=2021-04-16T19:02:20.174Z caller=head.go:696 component=tsdb msg=\"Replaying on-disk memory mappable chunks if any\"\nlevel=info ts=2021-04-16T19:02:20.175Z caller=head.go:710 component=tsdb msg=\"On-disk memory mappable chunks replay completed\" duration=1.391446ms\nlevel=info ts=2021-04-16T19:02:20.175Z caller=head.go:716 component=tsdb msg=\"Replaying WAL, this may take a while\"\nlevel=info ts=2021-04-16T19:02:20.178Z caller=head.go:768 component=tsdb msg=\"WAL segment loaded\" segment=0 maxSegment=4\nlevel=info ts=2021-04-16T19:02:20.193Z caller=head.go:768 component=tsdb msg=\"WAL segment loaded\" segment=1 maxSegment=4\nlevel=info ts=2021-04-16T19:02:20.221Z caller=head.go:768 component=tsdb msg=\"WAL segment loaded\" segment=2 maxSegment=4\nlevel=info ts=2021-04-16T19:02:20.224Z caller=head.go:768 component=tsdb msg=\"WAL segment loaded\" segment=3 maxSegment=4\nlevel=info ts=2021-04-16T19:02:20.229Z caller=head.go:768 component=tsdb msg=\"WAL segment loaded\" segment=4 maxSegment=4\nlevel=info ts=2021-04-16T19:02:20.229Z caller=head.go:773 component=tsdb msg=\"WAL replay completed\" checkpoint_replay_duration=43.716\u00b5s wal_replay_duration=53.973285ms total_replay_duration=55.445308ms\nlevel=info ts=2021-04-16T19:02:20.233Z caller=main.go:815 fs_type=EXT4_SUPER_MAGIC\nlevel=info ts=2021-04-16T19:02:20.233Z caller=main.go:818 msg=\"TSDB started\"\nlevel=info ts=2021-04-16T19:02:20.233Z caller=main.go:944 msg=\"Loading configuration file\" filename=/etc/prometheus/prometheus.yml\nlevel=info ts=2021-04-16T19:02:20.234Z caller=main.go:975 msg=\"Completed loading of configuration file\" filename=/etc/prometheus/prometheus.yml totalDuration=824.115\u00b5s remote_storage=3.131\u00b5s web_handler=401ns query_engine=1.056\u00b5s scrape=236.454\u00b5s scrape_sd=45.432\u00b5s notify=723ns notify_sd=2.61\u00b5s rules=956ns\nlevel=info ts=2021-04-16T19:02:20.234Z caller=main.go:767 msg=\"Server is ready to receive web requests.\"\n</code></pre> <p>Go to <code>http://SERVER_IP_ADDRESS:9090/graph</code> to check whether you are able to access the Prometheus interface or not. If it is working, exit the process by pressing on <code>CTRL + C</code>.</p> <p>Next, we would like to automatically start the server during the boot process, so we have to create a new <code>systemd</code> configuration file with the following config.</p> <pre><code>sudo nano /etc/systemd/system/prometheus.service\n</code></pre> <pre><code>[Unit]\n  Description=Prometheus Monitoring\n  Wants=network-online.target\n  After=network-online.target\n\n[Service]\n  User=prometheus\n  Group=prometheus\n  Type=simple\n  ExecStart=/usr/local/bin/prometheus \\\n  --config.file /etc/prometheus/prometheus.yml \\\n  --storage.tsdb.path /var/lib/prometheus/ \\\n  --web.console.templates=/etc/prometheus/consoles \\\n  --web.console.libraries=/etc/prometheus/console_libraries\n  ExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\n  WantedBy=multi-user.target\n</code></pre> <p>Once the file is saved, execute the command below to reload <code>systemd</code> and enable the service so that it will be loaded automatically during the operating system's startup.</p> <pre><code>sudo systemctl daemon-reload &amp;&amp; systemctl enable prometheus &amp;&amp; systemctl start prometheus\n</code></pre> <p>Prometheus should be running now, and you should be able to access its front again end by re-visiting <code>IP_ADDRESS:9090/</code>.</p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#installing-grafana","title":"Installing Grafana","text":"<p>In order to visualize your node metrics, you can use Grafana to query the Prometheus server. Run the following commands to install it first.</p> <pre><code>sudo apt-get install -y adduser libfontconfig1\nwget https://dl.grafana.com/oss/release/grafana_7.5.4_amd64.deb\nsudo dpkg -i grafana_7.5.4_amd64.deb\n</code></pre> <p>If everything is fine, configure Grafana to auto-start on boot and then start the service.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable grafana-server\nsudo systemctl start grafana-server\n</code></pre> <p>You can now access it by going to the <code>http://SERVER_IP_ADDRESS:3000/login</code>. The default user and password is admin/admin.</p> <p>Note</p> <p>If you want to change the port on which Grafana runs (3000 is a popular port), edit the file <code>/usr/share/grafana/conf/defaults.ini</code> with a command like <code>sudo vim /usr/share/grafana/conf/defaults.ini</code> and change the <code>http_port</code> value to something else. Then restart grafana with <code>sudo systemctl restart grafana-server</code>.</p> <p></p> <p>In order to visualize the node metrics, click settings to configure the <code>Data Sources</code> first.</p> <p></p> <p>Click <code>Add data source</code> to choose where the data is coming from.</p> <p></p> <p>Select <code>Prometheus</code>.</p> <p></p> <p>The only thing you need to input is the <code>URL</code> that is <code>https://localhost:9090</code> and then click <code>Save &amp; Test</code>. If you see <code>Data source is working</code>, your connection is configured correctly.</p> <p></p> <p>Next, import the dashboard that lets you visualize your node data. Go to the menu bar on the left and mouse hover \"+\" then select <code>Import</code>.</p> <p><code>Import via grafana.com</code> - It allows you to use a dashboard that someone else has created and made public. You can check what other dashboards are available via https://grafana.com/grafana/dashboards. In this guide, we use \"Substrate Node Metrics\", so input \"21715\" under the id field and click <code>Load</code>.</p> <p></p> <p>Once it has been loaded, make sure to select \"Prometheus\" in the Prometheus dropdown list. Then click <code>Import</code>.</p> <p></p> <p>In the meantime, start your Polkadot node by running <code>./polkadot</code>. If everything is done correctly, you should be able to monitor your node's performance such as the current block height, network traffic, running tasks, etc. on the Grafana dashboard.</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#installing-and-configuring-alertmanager-optional","title":"Installing and Configuring Alertmanager (Optional)","text":"<p>In this section, let's configure the Alertmanager that helps to predict the potential problem or notify you of the current problem in your server. Alerts can be sent in Slack, Email, Matrix, or others. In this guide, we will show you how to configure the email notifications using Gmail if your node goes down.</p> <p>First, download the latest binary of AlertManager and unzip it by running the command below:</p> <pre><code>wget https://github.com/prometheus/alertmanager/releases/download/v0.26.0/alertmanager-0.26.0.linux-amd64.tar.gz\ntar -xvzf alertmanager-0.26.0.linux-amd64.tar.gz\nmv alertmanager-0.26.0.linux-amd64/alertmanager /usr/local/bin\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#gmail-setup","title":"Gmail Setup","text":"<p>To allow AlertManager to send an email to you, you will need to generate something called an <code>app password</code> in your Gmail account. For details, click here to follow the whole setup.</p> <p>You should see something like below:</p> <p></p> <p>Copy and save it somewhere else first.</p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#alertmanager-configuration","title":"AlertManager Configuration","text":"<p>There is a configuration file named <code>alertmanager.yml</code> inside the directory that you just extracted in the previous command, but that is not of our use. We will create our <code>alertmanager.yml</code> file under <code>/etc/alertmanager</code> with the following config.</p> <p>!!!:note     Ensure to change the ownership of \"/etc/alertmanager\" to <code>prometheus</code> by executing</p> <pre><code>```bash\nsudo chown -R prometheus:prometheus /etc/alertmanager\n```\n</code></pre> <pre><code>global:\n resolve_timeout: 1m\n\nroute:\n receiver: 'gmail-notifications'\n\nreceivers:\n- name: 'gmail-notifications'\n  email_configs:\n  - to: YOUR_EMAIL\n    from: YOUR_EMAIL\n    smarthost: smtp.gmail.com:587\n    auth_username: YOUR_EMAIL\n    auth_identity: YOUR_EMAIL\n    auth_password: YOUR_APP_PASSWORD\n    send_resolved: true\n</code></pre> <p>With the above configuration, alerts will be sent using the email you set above. Remember to change <code>YOUR_EMAIL</code> to your email and paste the app password you just saved earlier to the <code>YOUR_APP_PASSWORD</code>.</p> <p>Next, create another <code>systemd</code> configuration file named <code>alertmanager.service</code> by running the command <code>sudo nano /etc/systemd/system/alertmanager.service</code> with the following config.</p> <p>!!!:info \"SERVER_IP\"     Change to your host IP address and make sure port 9093 is opened.</p> <pre><code>[Unit]\nDescription=AlertManager Server Service\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=root\nGroup=root\nType=simple\nExecStart=/usr/local/bin/alertmanager --config.file /etc/alertmanager/alertmanager.yml --web.external-url=http://SERVER_IP:9093 --cluster.advertise-address='0.0.0.0:9093'\n\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>To the start the Alertmanager, run the following commands:</p> <pre><code>sudo systemctl daemon-reload &amp;&amp; sudo systemctl enable alertmanager &amp;&amp; sudo systemctl start alertmanager &amp;&amp; sudo systemctl status alertmanager\n</code></pre> <pre><code>\u25cf alertmanager.service - AlertManager Server Service\n   Loaded: loaded (/etc/systemd/system/alertmanager.service; enabled; vendor preset: enabled)\n   Active: active (running) since Thu 2020-08-20 22:01:21 CEST; 3 days ago\n Main PID: 20592 (alertmanager)\n    Tasks: 70 (limit: 9830)\n   CGroup: /system.slice/alertmanager.service\n</code></pre> <p>You should see the process status is \"active (running)\" if you have configured properly.</p> <p>There is a Alertmanager plugin in Grafana that can help you to monitor the alert information. To install it, execute the command below:</p> <pre><code>sudo grafana-cli plugins install camptocamp-prometheus-alertmanager-datasource\n</code></pre> <p>And restart Grafana once the plugin is successfully installed.</p> <pre><code>sudo systemctl restart grafana-server\n</code></pre> <p>Now go to your Grafana dashboard <code>SERVER_IP:3000</code> and configure the Alertmanager datasource.</p> <p></p> <p>Go to Configuration -&gt; Data Sources, search \"Prometheus AlertManger\" if you cannot find it at the top.</p> <p></p> <p>Fill in the <code>URL</code> to your server location followed by the port number used in the Alertmanager.</p> <p>Then click \"Save &amp; Test\" at the bottom to test the connection.</p> <p></p> <p>To monitor the alerts, let's import dashboard \"8010\" that is used for Alertmanager. And make sure to select the \"Prometheus AlertManager\" in the last column. Then click \"Import\".</p> <p>You will end up having the following:</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-monitor-your-node/#alertmanager-integration","title":"AlertManager Integration","text":"<p>To let the Prometheus server be able to talk to the AlertManager, we will need to add the following config in the <code>etc/prometheus/prometheus.yml</code>.</p> <pre><code>rule_files:\n  - 'rules.yml'\n\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - localhost:9093\n</code></pre> <p>That is the updated <code>etc/prometheus/prometheus.yml</code>.</p> <pre><code>global:\n  scrape_interval:     15s\n  evaluation_interval: 15s\n\nrule_files:\n  - 'rules.yml'\n\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - localhost:9093\n\nscrape_configs:\n  - job_name: 'prometheus'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9090']\n  - job_name: 'substrate_node'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9615']\n</code></pre> <p>We will need to create a new file called \"rules.yml\" under <code>/etc/prometheus/</code> that is defined all the rules we would like to detect. If any of the rules defined in this file is fulfilled, an alert will be triggered. The rule below checks whether the instance is down. If it is down for more than 5 minutes, an email notification will be sent. If you would like to learn more about the details of the rule defining, go here. There are other interesting alerts you may find useful here.</p> <pre><code>groups:\n  - name: alert_rules\n    rules:\n      - alert: InstanceDown\n        expr: up == 0\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Instance [{{ $labels.instance }}] down\"\n          description: \"[{{ $labels.instance }}] of job [{{ $labels.job }}] has been down for more than 1 minute.\"\n</code></pre> <p>Change the ownership of this file to <code>prometheus</code> instead of <code>root</code> by running:</p> <pre><code>sudo chown prometheus:prometheus rules.yml\n</code></pre> <p>To check the rules defined in the \"rules.yml\" is syntactically correct, run the following command:</p> <pre><code>sudo -u prometheus promtool check rules rules.yml\n</code></pre> <p>Finally, restart everything by running:</p> <pre><code>sudo systemctl restart prometheus &amp;&amp; sudo systemctl restart alertmanager\n</code></pre> <p>Now if one of your target instances down, you will receive an alert on the AlertManager and Gmail like below.</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-stop-validating/","title":"How to Stop Validating","text":"<p>If you wish to remain a validator or nominator (e.g. you're only stopping for planned downtime or server maintenance), submitting the <code>chill</code> extrinsic in the <code>staking</code> pallet should suffice. It is only if you wish to unbond funds or reap an account that you should continue with the following.</p> <p>To ensure a smooth stop to validation, make sure you should do the following actions:</p> <ul> <li>Chill your validator</li> <li>Purge validator session keys</li> <li>Unbond your tokens</li> </ul> <p>These can all be done with PolkadotJS Apps interface or with extrinsics.</p>"},{"location":"maintain/maintain-guides-how-to-stop-validating/#chill-validator","title":"Chill Validator","text":"<p>To chill your validator or nominator, call the <code>staking.chill()</code> extrinsic. See the How to Chill page for more information. You can also claim your rewards at this time.</p>"},{"location":"maintain/maintain-guides-how-to-stop-validating/#purge-validator-session-keys","title":"Purge validator session keys","text":"<p>Purging the validator's session keys removes the key reference. This can be done through the <code>session.purgeKeys()</code> extrinsic. The key reference exists on the account that originally called the <code>session.set_keys()</code> extrinsic, which could be the stash or the staking proxy (at the time the keys were set).</p> <p>Purge keys using the same account that set the keys</p> <p>Make sure to call the session.purge_keys() extrinsic from the same account that set the keys in the first place in order for the correct reference to be removed. Calling the <code>session.purge_keys()</code> from the wrong account, although it may succeed, will result in a reference on the other account that cannot be removed, and as a result that account cannot be reaped.</p> <p>Caution</p> <p>If you skip this step, you will not be able to reap your stash account, and you will also need to rebond, purge the session keys, unbond, and wait the unbonding period again before being able to transfer your tokens.</p> <p>See Unbonding and Rebonding for more details.</p>"},{"location":"maintain/maintain-guides-how-to-stop-validating/#unbond-your-tokens","title":"Unbond your tokens","text":"<p>Unbonding your tokens can be done through the <code>Network &gt; Staking &gt; Account actions</code> page in PolkadotJS Apps by clicking the corresponding stash account dropdown and selecting \"Unbond funds\". This can also be done through the <code>staking.unbond()</code> extrinsic with the staking proxy account.</p>"},{"location":"maintain/maintain-guides-how-to-systemd/","title":"Using systemd for a Validator Node","text":"<p>You can run your validator as a systemd process so that it will automatically restart on server reboots or crashes (and helps to avoid getting slashed).</p> <p>Before following this guide you should have already set up your validator by following the How to validate article.</p> <p>First create a new unit file called <code>polkadot-validator.service</code> in <code>/etc/systemd/system/</code>.</p> <pre><code>touch /etc/systemd/system/polkadot-validator.service\n</code></pre> <p>In this unit file you will write the commands that you want to run on server boot / restart.</p> <pre><code>[Unit]\nDescription=Polkadot Validator\n\n[Service]\nExecStart=PATH_TO_POLKADOT_BIN --validator --name SHOW_ON_TELEMETRY\nRestart=always\nRestartSec=120\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Warning</p> <p>It is recommended to delay the restart of a node with <code>RestartSec</code> in the case of node crashes. It's possible that when a node crashes, consensus votes in GRANDPA aren't persisted to disk. In this case, there is potential to equivocate when immediately restarting. What can happen is the node will not recognize votes that didn't make it to disk, and will then cast conflicting votes. Delaying the restart will allow the network to progress past potentially conflicting votes, at which point other nodes will not accept them.</p> <p>To enable this to autostart on bootup run:</p> <pre><code>systemctl enable polkadot-validator.service\n</code></pre> <p>Start it manually with:</p> <pre><code>systemctl start polkadot-validator.service\n</code></pre> <p>You can check that it's working with:</p> <pre><code>systemctl status polkadot-validator.service\n</code></pre> <p>You can tail the logs with <code>journalctl</code> like so:</p> <pre><code>journalctl -f -u polkadot-validator\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-upgrade/","title":"How to Upgrade Your Validator","text":"<p>Validators perform critical functions for the network by backing and including blocks. Validators may have to go offline for short-periods of time to upgrade client software or to upgrade the host machine. Usually, standard client upgrades will only require you to stop the service, replace the binary and restart the service. This operation can be executed within a session.</p> <p>Validators may also need to perform long-lead maintenance tasks that will span more than one session. Under these circumstances, an active validator may chill their stash and be removed from the active validator set. Alternatively, the validator may substitute the active validator server with another allowing the former to undergo maintenance activities.</p> <p>This guide will provide an option for validators to seamlessly substitute an active validator server to allow for maintenance operations.</p> <p>The process can take several hours, so make sure you understand the instructions first and plan accordingly.</p> <p>Keep an eye out on new releases from the community</p> <p>Upgrade or downgrade accordingly.</p>"},{"location":"maintain/maintain-guides-how-to-upgrade/#key-components","title":"Key Components","text":""},{"location":"maintain/maintain-guides-how-to-upgrade/#session-keys","title":"Session Keys","text":"<p>Session keys are stored in the client and used to sign validator operations. They are what link your validator node to your staking proxy. If you change them within a session you will have to wait for the current session to finish and a further two sessions to elapse before they are applied.</p> <p>More info about keys in Polkadot.</p>"},{"location":"maintain/maintain-guides-how-to-upgrade/#keystore","title":"Keystore","text":"<p>Each validator server contains essential private keys in a folder called the keystore. These keys are used by a validator to sign transactions at the network level. If two or more validators sign certain transactions using the same keys, it can lead to an equivocation slash.</p> <p>For this reason, it is advised that validators DO NOT CLONE or COPY the keystore folder and instead generate session keys for each new validator instance.</p> <p>Default keystore path - <code>/home/polkadot/.local/share/polkadot/chains/&lt;chain&gt;/keystore</code></p>"},{"location":"maintain/maintain-guides-how-to-upgrade/#steps","title":"Steps","text":"<p>The following steps require a second validator which will be referred to as <code>Validator B</code>; the original server that is in the active set will be referred to as <code>Validator A</code>.</p>"},{"location":"maintain/maintain-guides-how-to-upgrade/#session-n","title":"Session <code>N</code>","text":"<ol> <li>Start a second node. Once it is synced, use the <code>--validator</code> flag. This is now \"Validator B.\"</li> <li>Generate Session keys for Validator B.</li> <li>Submit a <code>set_key</code> extrinsic from your staking proxy with the session key generated from    Validator B.</li> <li>Take note of the Session that this extrinsic was executed in.</li> <li>Allow the current session to elapse and then wait for two full sessions.</li> </ol> <p>It is imperative that you keep Validator A running during this time. <code>set_key</code> does not have an immediate effect and requires two full sessions to elapse before it does. If you do switch off Validator A too early you may risk being chilled and face a fault within the Decentralized Nodes program.</p>"},{"location":"maintain/maintain-guides-how-to-upgrade/#session-n3","title":"Session <code>N+3</code>","text":"<p>Validator B is now acting as your validator - you can safely perform operations on Validator A.</p> <p>When you are ready to restore Validator A:</p> <ol> <li>Start Validator A, sync the database and ensure that it is operating with the <code>--validator</code>    flag.</li> <li>Generate new Session keys for Validator A.</li> <li>Submit a <code>set_key</code> extrinsic from your staking proxy with the session key generated from    Validator A.</li> <li>Take note of the Session that this extrinsic was executed in.</li> </ol> <p>Again, it is imperative that Validator B is kept running until the current session finishes and two further full sessions have elapsed.</p> <p>Once this time has elapsed, Validator A will take over. You can safely stop Validator B.</p> <p>NOTE: To verify that the Session has changed, make sure that a block in the new Session is finalized. You should see log messages like the ones below to confirm the change:</p> <pre><code>2019-10-28 21:44:13 Applying authority set change scheduled at block #450092\n2019-10-28 21:44:13 Applying GRANDPA set change to new set with 20 authorities\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/","title":"Run a Validator (Polkadot)","text":"<p>Tip</p> <p>If you are a beginner, it is recommended that you start your validator journey on Kusama network. Check the Kusama guide for details on how to get started.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#preliminaries","title":"Preliminaries","text":"<p>Running a validator on a live network is a lot of responsibility! You will be accountable for not only your own stake, but also the stake of your current nominators. If you make a mistake and get slashed, your tokens and your reputation will be at risk. However, running a validator can also be very rewarding, knowing that you contribute to the security of a decentralized network while growing your stash.</p> <p>Warning</p> <p>It is highly recommended that you have significant system administration experience before attempting to run your own validator.</p> <p>You must be able to handle technical issues and anomalies with your node which you must be able to tackle yourself. Being a validator involves more than just executing the Polkadot binary.</p> <p>Since security is so important to running a successful validator, you should take a look at the secure validator information to make sure you understand the factors to consider when constructing your infrastructure. As you progress in your journey as a validator, you will likely want to use this repository as a starting point for your own modifications and customizations.</p> <p>If you need help, please reach out on the Polkadot Validator Lounge on Element. The team and other validators are there to help answer questions and provide tips from experience.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#how-many-dot-do-i-need-to-become-an-active-validator","title":"How many DOT do I need to become an active Validator?","text":"<p>You can have a rough estimate on that by using the methods listed here. To be elected into the set, you need a minimum stake behind your validator. This stake can come from yourself or from nominators. This means that as a minimum, you will need enough DOT to set up stash (and optionally a staking proxy account) with the existential deposit, plus a little extra for transaction fees. The rest can come from nominators. To understand how validators are elected, check the NPoS Election algorithms page.</p> <p>For further reference, you may look at the statistics for current, active validators. For Kusama see here.</p> <p>Warning: Any DOT that you stake for your validator is liable to be slashed, meaning that an insecure or improper setup may result in loss of DOT tokens! If you are not confident in your ability to run a validator node, it is recommended to nominate your DOT to a trusted validator node instead.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#initial-set-up","title":"Initial Set-up","text":""},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#requirements","title":"Requirements","text":"<p>The most common way for a beginner to run a validator is on a cloud server running Linux. You may choose whatever VPS provider that you prefer. As OS it is best to use a recent Debian Linux. For this guide we will be using Ubuntu 22.04, but the instructions should be similar for other platforms.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#reference-hardware","title":"Reference Hardware","text":"<p>The transaction weights in Polkadot are benchmarked on reference hardware. We ran the benchmark on VM instances of two major cloud providers: Google Cloud Platform (GCP) and Amazon Web Services (AWS). To be specific, we used <code>n2-standard-8</code> VM instance on GCP and <code>c6i.4xlarge</code> on AWS. It is recommended that the hardware used to run the validators at least matches the specs of the reference hardware in order to ensure they are able to process all blocks in time. If you use subpar hardware you will possibly run into performance issues, get less era points, and potentially even get slashed.</p> <ul> <li>CPU</li> <li>x86-64 compatible;</li> <li>Intel Ice Lake, or newer (Xeon or Core series); AMD Zen3, or newer (EPYC or Ryzen);</li> <li><sub>4</sub> 8 physical cores @ 3.4GHz; starting with January 2025, the recommendation is to use a     hardware with at least 8 physical cores, see     referenda for more details about the rationale;</li> <li>Simultaneous multithreading disabled (Hyper-Threading on Intel, SMT on AMD);</li> <li>Prefer single-threaded performance over higher cores count. A comparison of single-threaded     performance can be found here.</li> <li>Storage</li> <li>An NVMe SSD of 1 TB (As it should be reasonably sized to deal with blockchain growth). An     estimation of current chain snapshot sizes can be found     here. In general, the latency is more important than the     throughput.</li> <li>Memory</li> <li>32 GB DDR4 ECC.</li> <li>System</li> <li>Linux Kernel 5.16 or newer.</li> <li>Network</li> <li>The minimum symmetric networking speed is set to 500 Mbit/s (= 62.5 MB/s). This is required to     support a large number of parachains and allow for proper congestion control in busy network     situations.</li> </ul> <p>The specs posted above are not a hard requirement to run a validator, but are considered best practice. Running a validator is a responsible task; using professional hardware is a must in any way.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#install-configure-network-time-protocol-ntp-client","title":"Install &amp; Configure Network Time Protocol (NTP) Client","text":"<p>NTP is a networking protocol designed to synchronize the clocks of computers over a network. NTP allows you to synchronize the clocks of all the systems within the network. Currently it is required that validators' local clocks stay reasonably in sync, so you should be running NTP or a similar service. You can check whether you have the NTP client by running:</p> <p>If you are using Ubuntu 18.04 or a newer version, NTP Client should be installed by default.</p> <pre><code>timedatectl\n</code></pre> <p>If NTP is installed and running, you should see <code>System clock synchronized: yes</code> (or a similar message). If you do not see it, you can install it by executing:</p> <pre><code>sudo apt-get install ntp\n</code></pre> <p>ntpd will be started automatically after install. You can query ntpd for status information to verify that everything is working:</p> <pre><code>sudo ntpq -p\n</code></pre> <p>Warning</p> <p>Skipping this can result in the validator node missing block authorship opportunities. If the clock is out of sync (even by a small amount), the blocks the validator produces may not get accepted by the network.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#make-sure-landlock-is-enabled","title":"Make Sure Landlock is Enabled","text":"<p>Landlock is a Linux security feature used in Polkadot:</p> <p>Landlock empowers any process, including unprivileged ones, to securely restrict themselves.</p> <p>To make use of landlock, make sure you are on the reference kernel version or newer. Most Linux distributions should already have landlock enabled, but you can check by running the following as root:</p> <pre><code>dmesg | grep landlock || journalctl -kg landlock\n</code></pre> <p>If it is not enabled, please see the official docs (\"Kernel support\") if you would like to build Linux with landlock enabled.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#installing-the-polkadot-binaries","title":"Installing the Polkadot binaries","text":"<p>Multiple Validator Binaries</p> <p>In addition to the <code>polkadot</code> binary, recent changes have separated out functionality into two additional needed binaries, <code>polkadot-prepare-worker</code>, and <code>polkadot-execute-worker</code>. All three binaries are needed to properly run a validator node. More context on these changes can be found here</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#installation-from-official-releases","title":"Installation from official releases","text":"<p>The official binaries can be downloaded from the Github Releases. You should download the latest available version. You can also download the binaries by using the following direct links (replace X.Y.Z by the appropriate version):</p> <pre><code>https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-vX.Y.Z/polkadot\nhttps://github.com/paritytech/polkadot-sdk/releases/download/polkadot-vX.Y.Z/polkadot-execute-worker\nhttps://github.com/paritytech/polkadot-sdk/releases/download/polkadot-vX.Y.Z/polkadot-prepare-worker\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#optional-installation-with-package-managers","title":"Optional: Installation with Package Managers","text":"<p>The Polkadot Binary in included in <code>Debian</code> derivatives (i.e. Debian, Ubuntu) and <code>RPM-based</code> distros (i.e. Fedora, CentOS).</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#debian-based-debian-ubuntu","title":"Debian-based (Debian, Ubuntu)","text":"<p>Run the following commands as the root user:</p> <pre><code># Import the security@parity.io GPG key\ngpg --recv-keys --keyserver hkps://keys.mailvelope.com 9D4B2B6EB8F97156D19669A9FF0812D491B96798\ngpg --export 9D4B2B6EB8F97156D19669A9FF0812D491B96798 &gt; /usr/share/keyrings/parity.gpg\n# Add the Parity repository and update the package index\necho 'deb [signed-by=/usr/share/keyrings/parity.gpg] https://releases.parity.io/deb release main' &gt; /etc/apt/sources.list.d/parity.list\napt update\n# Install the `parity-keyring` package - This will ensure the GPG key\n# used by APT remains up-to-date\napt install parity-keyring\n# Install polkadot\napt install polkadot\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#rpm-based-fedora-centos","title":"RPM-based (Fedora, CentOS)","text":"<p>Run the following commands as the root user:</p> <pre><code># Install dnf-plugins-core (This might already be installed)\ndnf install dnf-plugins-core\n# Add the repository and enable it\ndnf config-manager --add-repo https://releases.parity.io/rpm/polkadot.repo\ndnf config-manager --set-enabled polkadot\n# Install polkadot (You may have to confirm the import of the GPG key, which\n# should have the following fingerprint: 9D4B2B6EB8F97156D19669A9FF0812D491B96798)\ndnf install polkadot\n</code></pre> <p>Make sure you verify the installation (see the \"Verify the installation\" section).</p> <p>By default, the Polkadot systemd service is disabled</p> <p>To start the service, run:</p> <pre><code>sudo systemctl start polkadot.service\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#optional-installation-with-ansible","title":"Optional: Installation with Ansible","text":"<p>To manage Polkadot installation with Ansible, you can use the Substrate node role distributed on the Parity chain operations Ansible collection</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#optional-installation-with-docker","title":"Optional: Installation with Docker","text":"<p>To run Polkadot on a Docker or an OCI compatible container runtime, you can use the official parity/polkadot docker image, available on Docker Hub (replace X.Y.Z by the appropriate version):</p> <pre><code>docker.io/parity/polkadot:vX.Y.Z\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#optional-building-the-polkadot-binaries-from-sources","title":"Optional: Building the Polkadot binaries from sources","text":""},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#prerequisites-install-rust-and-dependencies","title":"Prerequisites: Install Rust and Dependencies","text":"<p>If you have never installed Rust, you should do this first.</p> <p>If you have already installed Rust, run the following command to make sure you are using the latest version.</p> <pre><code>rustup update\n</code></pre> <p>If not, this command will fetch the latest version of Rust and install it.</p> <pre><code>curl https://sh.rustup.rs -sSf | sh -s -- -y\n</code></pre> <p>Note</p> <p>If you do not have \"curl\" installed, run:</p> <pre><code>sudo apt install curl\n</code></pre> <p>It will also be valuable to have \"websocat\" (Netcat, curl and socat for WebSockets) installed for RPC interactions. Installation instructions for various operating systems can be found here.</p> <p>To configure your shell, run the following command.</p> <pre><code>source $HOME/.cargo/env\n</code></pre> <p>Verify your installation.</p> <pre><code>rustc --version\n</code></pre> <p>Finally, run this command to install the necessary dependencies for compiling and running the Polkadot node software.</p> <pre><code>sudo apt install make clang pkg-config libssl-dev build-essential\n</code></pre> <p>Note</p> <p>If you are using OSX and you have Homebrew installed, you can issue the following equivalent command INSTEAD of the previous one:</p> <pre><code>brew install cmake pkg-config openssl git llvm\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#building-the-binaries","title":"Building the binaries","text":"<p>You can build the Polkadot binaries from the paritytech/polkadot-sdk repository on GitHub.</p> <p>You should generally use the latest X.Y.Z tag. You should either review the output from the \"git tag\" command or view the Polkadot SDK Github tags to see a list of all the available release versions. You should replace <code>VERSION</code> below with the latest build (i.e., the highest number).</p> <p>Note</p> <p>If you prefer to use SSH rather than HTTPS, you can replace the first line of the below with</p> <pre><code>git clone git@github.com:paritytech/polkadot-sdk.git\n</code></pre> <pre><code>git clone https://github.com/paritytech/polkadot-sdk.git\ncd polkadot-sdk/polkadot\n</code></pre> <p>Run the following command to find the latest version.</p> <pre><code>git tag -l | sort -V | grep -v -- '-rc'\n</code></pre> <p>Find the latest version; replace \"VERSION\" in the command below and run to change your branch.</p> <pre><code>git checkout VERSION\n</code></pre> <p>Build native code with the production profile. The following will make sure that the binaries are all in your <code>$PATH</code>.</p> <pre><code>cargo install --force --path . --profile production\n</code></pre> <p>This step will take a while (generally 10 - 40 minutes, depending on your hardware).</p> <p>Compilation Errors</p> <p>If you run into compile errors, you may have to pin the version of Rust compiler to the one that was used to build the release. Check out <code>Rust compiler versions</code> section in the release notes. This can be done by running:</p> <pre><code>rustup install nightly-2022-05-18\nrustup target add wasm32-unknown-unknown --toolchain nightly-2022-05-18\ncargo +nightly-2022-05-18 build --release\n</code></pre> <p>You may also need to run the build more than once.</p> <p>If you would like to execute the tests, run the following command:</p> <pre><code>cargo test --all\n</code></pre> <p>If you are interested in generating keys locally, you can also install <code>subkey</code> from the same directory. You may then take the generated <code>subkey</code> executable and transfer it to an air-gapped machine for extra security.</p> <pre><code>cargo install --force --git https://github.com/paritytech/polkadot-sdk subkey\n</code></pre>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#verify-the-installation","title":"Verify the installation","text":"<p>After installing Polkadot, you can verify the installation by running</p> <pre><code>polkadot --version\npolkadot-execute-worker --version\npolkadot-prepare-worker --version\n</code></pre> <p>It should return something like this (the exact versions don't matter, but they must all be the same):</p> <pre><code>0.9.43-36264cb36db\n0.9.43-36264cb36db\n0.9.43-36264cb36db\n</code></pre> <p>If not, make sure that you installed all the binaries, all the binaries are somewhere in your <code>$PATH</code> and they are all in the same folder.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#synchronize-chain-data","title":"Synchronize Chain Data","text":"<p>You can begin syncing your node by running the following command if you do not want to start in validator mode right away:</p> <pre><code>polkadot\n</code></pre> <p>Info</p> <p>If you want to run a validator on Kusama, you have an option to specify the chain. With no specification, this would default to Polkadot.</p> <pre><code>polkadot --chain=kusama\n</code></pre> <pre><code>2021-06-17 03:07:07 Parity Polkadot\n2021-06-17 03:07:07 \u270c\ufe0f  version 0.9.5-95f6aa201-x86_64-linux-gnu\n2021-06-17 03:07:07 \u2764\ufe0f  by Parity Technologies &lt;admin@parity.io&gt;, 2017-2021\n2021-06-17 03:07:07 \ud83d\udccb Chain specification: Polkadot\n2021-06-17 03:07:07 \ud83c\udff7 Node name: boiling-pet-7554\n2021-06-17 03:07:07 \ud83d\udc64 Role: FULL\n2021-06-17 03:07:07 \ud83d\udcbe Database: RocksDb at /root/.local/share/polkadot/chains/polkadot/db\n2021-06-17 03:07:07 \u26d3  Native runtime: polkadot-9050 (parity-polkadot-0.tx7.au0)\n2021-06-17 03:07:10 \ud83c\udff7 Local node identity is: 12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u\n2021-06-17 03:07:10 \ud83d\udce6 Highest known block at #17914\n2021-06-17 03:07:10 \u303d\ufe0f Prometheus server started at 127.0.0.1:9615\n2021-06-17 03:07:10 Listening for new connections on 127.0.0.1:9944.\n</code></pre> <p>Example of node sync</p> <pre><code>2021-06-17 03:07:39 \ud83d\udd0d Discovered new external address for our node: /ip4/10.26.16.1/tcp/30333/ws/p2p/12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u\n2021-06-17 03:07:40 \u2699\ufe0f  Syncing 218.8 bps, target=#5553764 (17 peers), best: #24034 (0x08af\u2026dcf5), finalized #23552 (0xd4f0\u20262642), \u2b07 173.5kiB/s \u2b06 12.7kiB/s\n2021-06-17 03:07:45 \u2699\ufe0f  Syncing 214.8 bps, target=#5553765 (20 peers), best: #25108 (0xb272\u2026e800), finalized #25088 (0x94e6\u20268a9f), \u2b07 134.3kiB/s \u2b06 7.4kiB/s\n2021-06-17 03:07:50 \u2699\ufe0f  Syncing 214.8 bps, target=#5553766 (21 peers), best: #26182 (0xe7a5\u202601a2), finalized #26112 (0xcc29\u2026b1a9), \u2b07 5.0kiB/s \u2b06 1.1kiB/s\n2021-06-17 03:07:55 \u2699\ufe0f  Syncing 138.4 bps, target=#5553767 (21 peers), best: #26874 (0xcf4b\u20266553), finalized #26624 (0x9dd9\u202627f8), \u2b07 18.9kiB/s \u2b06 2.0kiB/s\n2021-06-17 03:08:00 \u2699\ufe0f  Syncing 37.0 bps, target=#5553768 (22 peers), best: #27059 (0x5b73\u20266fc9), finalized #26624 (0x9dd9\u202627f8), \u2b07 14.3kiB/s \u2b06 4.4kiB/s\n</code></pre> <p>Use Warp sync for faster syncing</p> <p>By default, the node performs <code>full</code> sync, which downloads and validates the full blockchain history. Full sync works by listening to announced blocks and requesting the blocks from the announcing peers, or just the block headers in case of light clients.</p> <p><code>Fast</code> sync is another option that works by downloading the block header history and validating the authority set changes in order to arrive at a specific (usually the most recent) header. After the desired header has been reached and verified, the state can be downloaded and imported. Once this process has been completed, the node can proceed with a full sync.</p> <pre><code>polkadot --sync warp\n</code></pre> <p><code>Warp sync</code> initially downloads and validates the finality proofs from GRANDPA and then downloads the state of the latest finalized block. After the warp sync, the node is ready to import the latest blocks from the network and can be used as a Validator. The blocks from genesis will be downloaded in the background. Check this discussion for more information about the different sync options available.</p> <p>Validators should sync using the RocksDb backend</p> <p>This is implicit by default, but can be explicit by passing the <code>--database RocksDb</code> flag.</p> <p>In the future, it is recommended to switch to the faster and more efficient ParityDB option. Note that ParityDB is still experimental and should not be used in production. If you want to test out ParityDB, you can add the flag <code>--database paritydb</code>. Switching between database backends will require a resync.</p> <p>Depending on the size of the chain when you do this, this step may take anywhere from a few minutes to a few hours.</p> <p>If you are interested in determining how much longer you have to go, your server logs (printed to STDOUT from the <code>polkadot</code> process) will tell you the latest block your node has processed and verified. You can then compare that to the current highest block via Telemetry or the PolkadotJS Block Explorer.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#database-snapshot-services","title":"Database Snapshot Services","text":"<p>If you start a node for the first time, it will start building from the genesis block. This process can take a while depending on the database size. To make this process faster, snapshots can be used. Snapshots are compressed backups of the database directory of Polkadot/Kusama nodes, containing the whole chain (or a pruned version of it, with states only from the latest 1000 or 256 blocks). Listed below are a few public snapshot providers for Polkadot and Kusama.</p> <ul> <li>Stakeworld</li> <li>Polkachu</li> <li>Polkashots</li> </ul> <p>Caution</p> <p>For the security of the network, it is recommended that you sync from scratch, even if you are running your node in pruning mode for validation. The reason is that if these snapshots get corrupted and a majority of nodes run based on these snapshots, the network could end up running on a non-canonical chain.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#bond-dot","title":"Bond DOT","text":"<p>There is a minimum bond to start a validator instance, but to enter the active validator set and be eligible to earn rewards, your validator node should be nominated by a minimum number of DOT tokens.</p> <p>If you are validator who intends to get DOT/KSM nominations from the community, you will need to show some skin in the game. For that, you need to bond some DOT/KSM as own stake. Make sure not to bond all your DOT balance since you will be unable to pay transaction fees from your bonded balance.</p> <p>Controller accounts are deprecated. Use Staking Proxy.</p> <p>Controller accounts are deprecated. For more information, see this discussion. It is highly recommended that you setup an account with a staking proxy, which can be used for issuing start and stop validating calls. Read more about proxy accounts here.</p> <p>First, go to the Staking section. Click on \"Account Actions\", and then the \"+ Stash\" button.</p> <p></p> <ul> <li>Stash account - Select your Stash account (which is the account with the DOT/KSM balance)</li> <li>Value bonded - How much DOT from the Stash account you want to bond/stake. Note that you do   not need to bond all of the DOT in that account. Also note that you can always bond more DOT   later. However, withdrawing any bonded amount requires the duration of the unbonding period. On   Kusama, the unbonding period is 7 days. On Polkadot, the planned unbonding period is 28 days.</li> <li>Payment destination - The account where the rewards from validating are sent. More info   here. Starting with runtime version v23   natively included in client version   0.9.3, payouts can go to any custom   address. If you'd like to redirect payments to an account that is not the stash account, you can   do it by entering the address here. Note that it is extremely unsafe to set an exchange address as   the recipient of the staking rewards.</li> </ul> <p>Once everything is filled in properly, click <code>Bond</code> and sign the transaction with your Stash account.</p> <p></p> <p>After a few seconds, you should see an <code>ExtrinsicSuccess</code> message.</p> <p>Your bonded account will be available under <code>Stashes</code>. You should now see a new card with all your accounts (note: you may need to refresh the screen). The bonded amount on the right corresponds to the funds bonded by the Stash account.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#set-session-keys","title":"Set Session Keys","text":"<p>Session keys are consensus critical</p> <p>If you are not sure if your node has the current session keys that you made the <code>setKeys</code> transaction then you can use one of the two available RPC methods to query your node: hasKey to check for a specific key or hasSessionKeys to check the full session key public key string.</p> <p>Once your node is fully synced, stop the process by pressing Ctrl-C. At your terminal prompt, you will now start running the node.</p> <pre><code>polkadot --validator --name \"name on telemetry\"\n</code></pre> <p>Similarly:</p> <pre><code>2021-06-17 03:12:08 Parity Polkadot\n2021-06-17 03:12:08 \u270c\ufe0f  version 0.9.5-95f6aa201-x86_64-linux-gnu\n2021-06-17 03:12:08 \u2764\ufe0f  by Parity Technologies &lt;admin@parity.io&gt;, 2017-2021\n2021-06-17 03:12:08 \ud83d\udccb Chain specification: Polkadot\n2021-06-17 03:12:08 \ud83c\udff7 Node name: nateched-test\n2021-06-17 03:12:08 \ud83d\udc64 Role: AUTHORITY\n2021-06-17 03:12:08 \ud83d\udcbe Database: RocksDb at /root/.local/share/polkadot/chains/polkadot/db\n2021-06-17 03:12:08 \u26d3  Native runtime: polkadot-9050 (parity-polkadot-0.tx7.au0)\n2021-06-17 03:12:12 \ud83c\udff7 Local node identity is: 12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u\n2021-06-17 03:12:12 \ud83d\udce6 Highest known block at #64673\n2021-06-17 03:12:12 \u303d\ufe0f Prometheus server started at 127.0.0.1:9615\n2021-06-17 03:12:12 Listening for new connections on 127.0.0.1:9944.\n2021-06-17 03:12:12 \ud83d\udc76 Starting BABE Authorship worker\n</code></pre> <pre><code>2021-06-17 03:12:16 \ud83d\udd0d Discovered new external address for our node: /ip4/10.26.11.1/tcp/30333/p2p/12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u\n2021-06-17 03:12:17 \u2699\ufe0f  Syncing, target=#5553810 (14 peers), best: #65068 (0x6da5\u20260662), finalized #65024 (0x4e84\u2026d170), \u2b07 352.2kiB/s \u2b06 75.6kiB/s\n</code></pre> <p>You can give your validator any name that you like, but note that others will be able to see it, and it will be included in the list of all servers using the same telemetry server. Since numerous people are using telemetry, it is recommended that you choose something likely to be unique.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#generating-the-session-keys","title":"Generating the Session Keys","text":"<p>You need to tell the chain your Session keys by signing and submitting an extrinsic. This is what associates your validator node with your stash account on Polkadot.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#option-1-polkadotjs-apps","title":"Option 1: PolkadotJS-APPS","text":"<p>You can generate your Session keys in the client via the apps RPC. If you are doing this, make sure that you have the PolkadotJS-Apps explorer attached to your validator node. You can configure the apps dashboard to connect to the endpoint of your validator in the Settings tab. If you are connected to a default endpoint hosted by Parity of Web3 Foundation, you will not be able to use this method since making RPC requests to this node would effect the local keystore hosted on a public node and you want to make sure you are interacting with the keystore for your node.</p> <p>Once ensuring that you have connected to your node, the easiest way to set session keys for your node is by calling the <code>author_rotateKeys</code> RPC request to create new keys in your validator's keystore. Navigate to Toolbox tab and select RPC Calls then select the author &gt; rotateKeys() option and remember to save the output that you get back for a later step.</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#option-2-cli","title":"Option 2: CLI","text":"<p>If you are on a remote server, it is easier to run this command on the same machine (while the node is running with the default WS RPC port configured):</p> <pre><code>curl -H \"Content-Type: application/json\" -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"author_rotateKeys\", \"params\":[]}' http://localhost:9944\n</code></pre> <p>The output will have a hex-encoded \"result\" field. The result is the concatenation of the four public keys. Save this result for a later step.</p> <p>You can restart your node at this point.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#submitting-the-setkeys-transaction","title":"Submitting the <code>setKeys</code> Transaction","text":"<p>You need to tell the chain your Session keys by signing and submitting an extrinsic. This is what associates your validator with your staking proxy.</p> <p>Go to Staking &gt; Account Actions, and click \"Set Session Key\" on the bonding account you generated earlier. Enter the output from <code>author_rotateKeys</code> in the field and click \"Set Session Key\".</p> <p> </p> <p>Submit this extrinsic and you are now ready to start validating.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#setting-the-node-aka-network-key","title":"Setting the Node (aka Network) Key","text":"<p>Validators must use a static network key to maintain a stable node identity across restarts. Starting with Polkadot version 1.11, a check is performed on startup, and the following error will be printed if a static node key is not set:</p> <pre><code>Error:\n0: Starting an authority without network key\nThis is not a safe operation because other authorities in the network may depend on your node having a stable identity.\nOtherwise these other authorities may not being able to reach you.\n\nIf it is the first time running your node you could use one of the following methods:\n1. [Preferred] Separately generate the key with: &lt;NODE_BINARY&gt; key generate-node-key --base-path &lt;YOUR_BASE_PATH&gt;\n2. [Preferred] Separately generate the key with: &lt;NODE_BINARY&gt; key generate-node-key --file &lt;YOUR_PATH_TO_NODE_KEY&gt;\n3. [Preferred] Separately generate the key with: &lt;NODE_BINARY&gt; key generate-node-key --default-base-path\n4. [Unsafe] Pass --unsafe-force-node-key-generation and make sure you remove it for subsequent node restarts\"\n</code></pre> <p>The recommended solution is to generate a node key and save it to a file using <code>polkadot key generate-node-key --file &lt;PATH_TO_NODE_KEY&gt;</code>, then attach it to your node with <code>--node-key-file &lt;PATH_TO_NODE_KEY&gt;</code>.</p> <p>Please see polkadot-sdk#3852 for the rationale behind this change.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#validate","title":"Validate","text":"<p>To verify that your node is live and synchronized, head to Telemetry and find your node. Note that this will show all nodes on the Polkadot network, which is why it is important to select a unique name!</p> <p>In this example, we used the name <code>techedtest</code> and have successfully located it upon searching:</p> <p></p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#setup-via-validator-tab","title":"Setup via Validator Tab","text":"<p>Here you will need to input the Keys from <code>rotateKeys</code>, which is the Hex output from <code>author_rotateKeys</code>. The keys will show as pending until applied at the start of a new session.</p> <p>The \"reward commission percentage\" is the commission percentage that you can declare against your validator's rewards. This is the rate that your validator will be commissioned with.</p> <ul> <li>Payment preferences - You can specify the percentage of the rewards that will get paid to you.   The remaining will be split among your nominators.</li> </ul> <p>Caution</p> <p>Setting a commission rate of 100% suggests that you do not want your validator to receive nominations.</p> <p>You can also determine if you would like to receive nominations with the \"allows new nominations\" option.</p> <p></p> <p>Click \"Bond &amp; Validate\".</p> <p>If you go to the \"Staking\" tab, you will see a list of active validators currently running on the network. At the top of the page, it shows the number of validator slots that are available as well as the number of nodes that have signaled their intention to be a validator. You can go to the \"Waiting\" tab to double check to see whether your node is listed there.</p> <p></p> <p>The validator set is refreshed every era. In the next era, if there is a slot available and your node is selected to join the validator set, your node will become an active validator. Until then, it will remain in the waiting queue. If your validator is not selected to become part of the validator set, it will remain in the waiting queue until it is. There is no need to re-start if you are not selected for the validator set in a particular era. However, it may be necessary to increase the number of DOT staked or seek out nominators for your validator in order to join the validator set.</p> <p>Congratulations! If you have followed all of these steps, and been selected to be a part of the validator set, you are now running a Polkadot validator! If you need help, reach out on the Polkadot Validator chat.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#decentralized-nodes-program","title":"Decentralized Nodes Program","text":"<p>The Decentralized Nodes program is a joint initiative by Web3 Foundation and Parity Technologies to provide support for community validators. If you are interested in applying for the program, you can find more information here.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#running-a-validator-on-a-testnet","title":"Running a validator on a testnet","text":"<p>To verify your validator setup, it is possible to run it against a PoS test network such as Westend. However, validator slots are intentionally limited on Westend to ensure stability and availability of the testnet for the Polkadot release process.</p> <p>Here is a small comparison of each network characteristics as relevant to validators:</p> Network Polkadot Westend epoch 4h 1h era 1d 6h token DOT WND (test) active validators ~300 ~20"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#faq","title":"FAQ","text":""},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#why-am-i-unable-to-synchronize-the-chain-with-0-peers","title":"Why am I unable to synchronize the chain with 0 peers?","text":"<p>Make sure to enable <code>30333</code> libp2p port. Eventually, it will take a little bit of time to discover other peers over the network.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#how-do-i-clear-all-my-chain-data","title":"How do I clear all my chain data?","text":"<pre><code>polkadot purge-chain\n</code></pre> <p>Info</p> <p>Check out the Substrate StackExchange to quickly get the answers you need.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#note-about-vps","title":"Note about VPS","text":"<p>VPS providers are very popular for running servers of any kind. Extensive benchmarking was conducted to ensure that VPS servers are able to keep up with the work load in general.</p> <p>Note</p> <p>Before you run a live Validator, please verify if the advertised performance is actually delivered consistently by the VPS provider.</p> <p>The following server types showed acceptable performance during the benchmark tests. Please note that this is not an endorsement in any way:</p> <ul> <li>GCP's c2 and c2d machine families</li> <li>AWS's c6id machine family</li> </ul> <p>The following additional configurations were applied to the instances to tune their performance:</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#disable-smt","title":"Disable SMT","text":"<p>As critical path of Substrate is single-threaded we need to optimize for single-core CPU performance. The node still profits from multiple cores when doing networking and other non-runtime operations. It is therefore still necessary to run it on at least the minimum required number of cores. Disabling SMT improves the performance as each vCPU becomes mapped to a physical CPU core rather than being presented to the OS as two logical cores. SMT implementation is called Hyper-Threading on Intel and 2-way SMT on AMD Zen. To disable SMT in runtime:</p> <pre><code>for cpunum in $(cat /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | cut -s -d, -f2- | tr ',' '\\n' | sort -un)\ndo\n  echo 0 &gt; /sys/devices/system/cpu/cpu$cpunum/online\ndone\n</code></pre> <p>It will disable every other (vCPU) core.</p> <p>To save changes permanently add <code>nosmt=force</code> as kernel parameter. Edit <code>/etc/default/grub</code> and add <code>nosmt=force</code> to <code>GRUB_CMDLINE_LINUX_DEFAULT</code> variable and run <code>sudo update-grub</code>. After the reboot you should see half of the cores are offline. Run <code>lscpu --extended</code> to confirm.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#disable-automatic-numa-balancing","title":"Disable automatic NUMA balancing","text":"<p>If you have multiple physical CPUs (CPU0 and CPU1) in the system each with its own memory bank (MB0 and MB1), then it is usually slower for a CPU0 to access MB1 due to the slower interconnection. To prevent the OS from automatically moving the running Substrate process from one CPU to another and thus causing an increased latency, it is recommended to disable automatic NUMA balancing.</p> <p>With automatic NUMA balancing disabled, an OS will always run a process on the same NUMA node where it was initially scheduled.</p> <p>To disable NUMA balancing in runtime:</p> <pre><code>sysctl kernel.numa_balancing=0\n</code></pre> <p>To save changes permanently, update startup options and reconfigure GRUB. Edit <code>/etc/default/grub</code> and add <code>numa_balancing=disable</code> to <code>GRUB_CMDLINE_LINUX_DEFAULT</code> variable and run <code>sudo update-grub</code>. After reboot you can confirm the change by running <code>sysctl -a | grep 'kernel.numa_balancing'</code> and checking if the parameter is set to 0</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#configure-spectremeltdown-mitigations","title":"Configure Spectre/Meltdown Mitigations","text":"<p>Spectre and Meltdown are vulnerabilities discovered in modern CPUs a few years ago. Mitigations were made to the Linux kernel to cope with the multiple variations of these attacks. Check out https://meltdownattack.com/ for more info.</p> <p>Initially those mitigations added ~20% penalty to the performance of the workloads. As CPU manufacturers started to roll-out mitigations implemented in hardware, the performance gap narrowed down. As the benchmark demonstrates, the performance penalty got reduced to ~7% on Intel 10<sup>th</sup> Gen CPUs. This is true for the workloads running on both bare-metal and VMs. But the penalty remains high for the containerized workloads in some cases.</p> <p>As demonstrated in Yusuke Endoh's article, a performance penalty for containerized workloads can be as high as 100%. This is due to SECCOMP profile being overprotective about applying Spectre/Meltdown mitigations without providing real security. A longer explanation is available in the kernel patch discussion.</p> <p>Linux 5.16 loosened the protections applied to SECCOMP threads by default. Containers running on kernel 5.16 and later now don't suffer from the performance penalty implied by using a SECCOMP profile in container runtimes.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#for-linux-516","title":"For Linux &gt;= 5.16","text":"<p>You are all set. The performance of containerized workloads is on par with non-containerized ones. You don't have to do anything.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#for-linux-516_1","title":"For Linux &lt; 5.16","text":"<p>You'll need to disable mitigations for Spectre V2 for user-space tasks as well as Speculative Store Bypass Disable (SSBD) for Spectre V4. This patch message describes the reasoning for this default change in more detail:</p> <p>Ultimately setting SSBD and STIBP by default for all seccomp jails is a bad sweet spot and bad default with more cons than pros that end up reducing security in the public cloud (by giving an huge incentive to not expose SPEC_CTRL which would be needed to get full security with IBPB after setting nosmt in the guest) and by excessively hurting performance to more secure apps using seccomp that end up having to opt out with SECCOMP_FILTER_FLAG_SPEC_ALLOW.</p> <p>To disable the mitigations edit <code>/etc/default/grub</code> and add <code>spec_store_bypass_disable=prctl spectre_v2_user=prctl</code> to <code>GRUB_CMDLINE_LINUX_DEFAULT</code> variable, run <code>sudo update-grub</code>, then reboot.</p> <p>Note that mitigations are not disabled completely. You can fully disable all the available kernel mitigations by setting <code>mitigations=off</code>. But we don't recommend doing this unless you run a fully trusted code on the host.</p>"},{"location":"maintain/maintain-guides-how-to-validate-polkadot/#vps-list","title":"VPS List","text":"<ul> <li>Google Cloud</li> <li>Amazon AWS</li> <li>OVH</li> <li>Digital Ocean</li> <li>Vultr</li> <li>Linode</li> <li>Scaleway</li> <li>OnFinality</li> </ul> <p>Beware of the Terms and Conditions and Acceptable Use Policies for each VPS provider</p> <p>You may be locked out of your account and your server shut down if you come in violation. For instance, Digital Ocean lists \"Mining of Cryptocurrencies\" under the Network Abuse section of their Acceptable Use Policy and requires explicit permission to do so. This may extend to other cryptocurrency activity.</p>"},{"location":"maintain/maintain-guides-secure-validator/","title":"Secure Validator","text":"<p>Validators in a Proof of Stake network are responsible for keeping the network in consensus and verifying state transitions. As the number of validators is limited, validators in the set have the responsibility to be online and faithfully execute their tasks.</p> <p>This primarily means that validators:</p> <ul> <li>Must be high availability.</li> <li>Must have infrastructure that protects the validator's signing keys so that an attacker cannot   take control and commit slashable behavior.</li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#high-availability","title":"High Availability","text":"<p>High availability set-ups that involve redundant validator nodes may seem attractive at first. However, they can be very dangerous if they are not set up perfectly. The reason for this is that the session keys used by a validator should always be isolated to just a single node. Replicating session keys across multiple nodes could lead to equivocation slashes or parachain validity slashes which can make you lose 100% of your staked funds.</p> <p>The good news is that 100% uptime of your validator is not really needed, as it has some buffer within eras in order to go offline for a little while and upgrade. For this reason, we advise that you only attempt a high availability set-up if you're confident you know exactly what you're doing.</p> <p>Many expert validators have made mistakes in the past due to the handling of session keys.</p>"},{"location":"maintain/maintain-guides-secure-validator/#key-management","title":"Key Management","text":"<p>See the Polkadot Keys guide for more information on keys. The keys that are of primary concern for validator infrastructure are the Session keys. These keys sign messages related to consensus and parachains. Although Session keys are not account keys and therefore cannot transfer funds, an attacker could use them to commit slashable behavior.</p> <p>Session keys are generated inside the node via RPC call. See the How to Validate guide for instructions on setting Session keys. These should be generated and kept within your client. When you generate new Session keys, you must submit an extrinsic (a Session certificate) from your staking proxy key telling the chain your new Session keys.</p> <p>Generating session keys</p> <p>Session keys can also be generated outside the client and inserted into the client's keystore via RPC. For most users, we recommend using the key generation functionality within the client.</p>"},{"location":"maintain/maintain-guides-secure-validator/#signing-outside-the-client","title":"Signing Outside the Client","text":"<p>In the future, Polkadot will support signing payloads outside the client so that keys can be stored on another device, e.g. a hardware security module (HSM) or secure enclave. For the time being, however, Session key signatures are performed within the client.</p> <p>HSMs are not a panacea</p> <p>They do not incorporate any logic and will just sign and return whatever payload they receive. Therefore, an attacker who gains access to your validator node could still commit slashable behavior.</p>"},{"location":"maintain/maintain-guides-secure-validator/#secure-validator-mode","title":"Secure-Validator Mode","text":"<p>Parity Polkadot has a Secure-Validator Mode, enabling several protections for keeping keys secure. The protections include highly strict filesystem, networking, and process sandboxing on top of the existing wasmtime sandbox.</p> <p>This mode is activated by default if the machine meets the following requirements. If not, there is an error message with instructions on disabling Secure-Validator Mode, though this is not recommended due to the security risks involved.</p>"},{"location":"maintain/maintain-guides-secure-validator/#requirements","title":"Requirements","text":"<ol> <li>Linux on x86-64 family (usually Intel or AMD).</li> <li>seccomp enabled. You can check that this is the case by running the following command:</li> </ol> <pre><code>cat /boot/config-`uname -r` | grep CONFIG_SECCOMP=\n</code></pre> <p>The expected output, if enabled, is:</p> <pre><code>CONFIG_SECCOMP=y\n</code></pre> <ol> <li>OPTIONAL: Linux 5.13. Provides access to even more strict filesystem protections.</li> </ol>"},{"location":"maintain/maintain-guides-secure-validator/#monitoring-tools","title":"Monitoring Tools","text":"<ul> <li> <p>Telemetry This tracks your node details   including the version you are running, block height, CPU &amp; memory usage, block propagation time,   etc.</p> </li> <li> <p>Prometheus-based monitoring stack, including   Grafana for dashboards and log aggregation. It includes alerting, querying,   visualization, and monitoring features and works for both cloud and on-premise systems. The data   from <code>substrate-telemetry</code> can be made available to Prometheus through exporters like   this.</p> </li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#linux-best-practices","title":"Linux Best Practices","text":"<ul> <li>Never use the root user.</li> <li>Always update the security patches for your OS.</li> <li>Enable and set up a firewall.</li> <li>Never allow password-based SSH, only use key-based access.</li> <li>Disable non-essential SSH subsystems (banner, motd, scp, X11 forwarding) and harden your SSH   configuration   (reasonable guide to begin with).</li> <li>Back up your storage regularly.</li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#conclusions","title":"Conclusions","text":"<ul> <li> <p>At the moment, Polkadot/Substrate can't interact with HSM/SGX, so we need to provide the signing   key seeds to the validator machine. This key is kept in memory for signing operations and   persisted to disk (encrypted with a password).</p> </li> <li> <p>Given that HA setups would always be at risk of double-signing and there's currently no built-in   mechanism to prevent it, we propose having a single instance of the validator to avoid slashing.</p> </li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#validators","title":"Validators","text":"<ul> <li> <p>Validators should only run the Polkadot binary, and they should not listen on any port other than   the configured p2p port.</p> </li> <li> <p>Validators should run on bare-metal machines, as opposed to VMs. This will prevent some of the   availability issues with cloud providers, along with potential attacks from other VMs on the same   hardware. The provisioning of the validator machine should be automated and defined in code. This   code should be kept in private version control, reviewed, audited, and tested.</p> </li> <li> <p>Session keys should be generated and provided in a secure way.</p> </li> <li> <p>Polkadot should be started at boot and restarted if stopped for any reason (supervisor process).</p> </li> <li> <p>Polkadot should run as a non-root user.</p> </li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#monitoring","title":"Monitoring","text":"<ul> <li> <p>There should be an on-call rotation for managing the alerts.</p> </li> <li> <p>There should be a clear protocol with actions to perform for each level of each alert and an   escalation policy.</p> </li> </ul>"},{"location":"maintain/maintain-guides-secure-validator/#resources","title":"Resources","text":"<ul> <li>Figment Network's Full Disclosure of Cosmos Validator Infrastructure</li> <li>Certus One's Knowledge Base</li> <li>EOS Block Producer Security List</li> <li>HSM Policies and the Important of Validator Security</li> </ul>"},{"location":"maintain/maintain-guides-validator-community/","title":"Validator Community Overview","text":""},{"location":"maintain/maintain-guides-validator-community/#building-a-community-and-attracting-nominations","title":"Building a Community and Attracting Nominations","text":"<p>After setting up a validator, nominations will only come in with extra work. The community of nominators will need to know about the validator to trust staking with them, and thus the validator must distinguish themselves to attract nominations. The following gives some general guidance on different approaches to building a community and attracting nominations.</p> <p>Being a high-quality validator entails effectively running nodes and building a brand, reputation, and community around validation services. The responsibilities of a quality validator additionally include marketing oneself and participating in the greater community. Becoming a known participant throughout the ecosystem is a great way to attract nominations and solidify longevity and sustainability as a validator.</p> <p>One thing to remember is that there is a risk involved in staking for both validators and nominators, as both can lose up to 100% of their funds if a validator gets slashed. This means it is paramount for nominators only to nominate validators that they trust, as well as for validators to do their best to instill confidence in their ability to provide validation services. Validators should do their best to build a reputation through many different means, as this is one of the most important factors in how nominators should pick whom they stake with.</p>"},{"location":"maintain/maintain-guides-validator-community/#gaining-visibility","title":"Gaining Visibility","text":"<p>Nominators should be able to know whom they are staking with. If nominators stake with a bunch of pseudo-anonymous addresses because it seems profitable, they expose themselves to more risks than nominating validators that follow best practices to whom they know the addresses belong. Establishing a clear identity in multiple places can help gain visibility across the ecosystem. This includes setting an on-chain identity and making a known presence throughout various community channels.</p>"},{"location":"maintain/maintain-guides-validator-community/#setting-identity","title":"Setting Identity","text":"<p>All validators should set an on-chain identity and get a judgement on the identity so that nominators can find nodes when browsing through various dashboards and UIs. When someone interacts with the chain, it ensures that an address they may come across belongs to the validator, and actions of that identity throughout various parts of the ecosystem (staking, governance, block explorers, etc.) form a cohesive representation of their participation.</p> <p>Note</p> <p>When running multiple validator nodes, the best way to scale an identity is to use multiple sub-identities from a single verified identity</p> <p>It's recommended to fill out as many fields in the identity as possible so Nominators have ample means of reaching out. Nominators may wish to know more about the Validator, the particular setup, future staking plans, tooling used, or several additional topics. Having a dedicated website additionally to provide this sort of information is ideal.</p> <p>Note</p> <p>Ledger app on Nano S doesn't support the extrinsic for setting identity yet.</p>"},{"location":"maintain/maintain-guides-validator-community/#website","title":"Website","text":"<p>One strategy for helping gain additional visibility is to set up a dedicated site for your validator, which includes the networks that one is a validator for and validator details such as addresses, commission, and so forth. Including all suggestions from this page is potential content to include on the site. After setting up a website, a validator should add this website to the corresponding field in their identity so nominators can find it easily.</p>"},{"location":"maintain/maintain-guides-validator-community/#transparency-establishing-trust","title":"Transparency &amp; Establishing Trust","text":"<p>Considering the risks involved for both Validators and Nominators, establishing trust is one of the most essential factors in running quality validator services.</p>"},{"location":"maintain/maintain-guides-validator-community/#self-stake","title":"Self Stake","text":"<p>Validators should have skin in the game in their operations in the form of a stake that is self-bonded to their validator stash. Slashing applies to the total stake of a Validator, therefore having a high self-stake shows confidence in the operations. This helps show commitment from the Validator as they have skin in the game and can be penalized for negative actions or poor maintenance. mess up. Having very little self-stake can signal to nominators that they have nothing to lose in the case of failures.</p> <p>Additionally, it can help nominators to get a sense of how validators manage their stakes. Defining a self-allocation strategy is also helpful in seeing how efficiently a validator's stake can be utilized.</p>"},{"location":"maintain/maintain-guides-validator-community/#commission-rewards","title":"Commission &amp; Rewards","text":""},{"location":"maintain/maintain-guides-validator-community/#commission","title":"Commission","text":"<p>What does your validator charge as commission, and how did you reach this number? It can be helpful to be transparent about the long-term plans around the business models of running a validator, including the costs for infrastructure and person-hours involved in maintaining operations. As many validators will charge low commissions that often do not cover costs, outlining what commission is charged and why can help justify higher commission rates.</p> <p>Besides the current commission, it would be helpful to describe the range of commission charged, as nominators can know what to expect if the rate goes up or down. Nominators may want to nominate a validator with a very narrow commission percent range, as this signals stability in a validator's operations and business plans.</p> <p>Many validators will charge 0% or near 0% commission to bootstrap themselves at first, with plans to raise that over time. It can be helpful to elaborate on these plans in the future. For example \"after x amount of months in the active set with 0% commission, we plan to increase it to 1%.\"</p>"},{"location":"maintain/maintain-guides-validator-community/#rewards","title":"Rewards","text":"<p>Another factor to consider is that claiming rewards for both the validator and the nominator is not automatic. Rewards must be claimed manually or set up in an automated way. Validators are suggested to claim rewards on behalf of their nominators and be transparent about how often claiming will happen. A nominator may be more likely to stake with a validator that claims rewards daily instead of one that doesn't claim rewards at all.</p> <p>The following are some tools for automating reward claiming:</p> <ul> <li>staking-payouts</li> <li>substrate-payctl</li> </ul>"},{"location":"maintain/maintain-guides-validator-community/#validator-experience","title":"Validator Experience","text":""},{"location":"maintain/maintain-guides-validator-community/#architecture","title":"Architecture","text":"<p>One aspect of building trust is being transparent about your validator infrastructure. If nominators know that you are running a tight ship that is focused on security, they are more likely to trust you compared to those that do not disclose their infrastructure.</p> <p>Some factors of architecture to highlight might include:</p>"},{"location":"maintain/maintain-guides-validator-community/#servers","title":"Servers","text":"<p>Outlining how a validator runs its servers helps nominators understand how diversified a validator is. Does the Validator run in the cloud, on dedicated machines, in a co-located datacenter, or in a home residential setup? Do they run multiple nodes on the same machine? If every validator is hosted in AWS, there is a risk of potential outages that cause large amounts of nodes to go offline. Nominators may want to choose validators that have thoroughly diversified the providers they use or the facilities they operate in.</p> <p>Additionally, how does a Validator contribute to decentralization? It can be helpful to outline these efforts so that the values of a Nominator and Validator are aligned.</p> <p>It's also helpful to outline what kind of OS is used on these servers and what is the updating policy for the software on that OS. For example, are LTS versions used? Do they use NiXOS, distro-packaged libraries? Any server hardening practices, etc.</p>"},{"location":"maintain/maintain-guides-validator-community/#specs","title":"Specs","text":"<p>Are you running the recommended Standard Hardware for Polkadot? Can you ensure that machines have enough processing power, memory, file storage, and network connectivity? It's helpful for nominators to know the specs of the machines a validator uses to assess how they may perform in the network. If a validator is running underpowered machines, they may not want to nominate them, as these can result in fewer blocks produced and fewer overall rewards. In certain circumstances, more powerful machines can result in higher rewards for both the Validator and their Nominators.</p>"},{"location":"maintain/maintain-guides-validator-community/#automation-and-orchestration-approaches-terraform-ansible-chef-puppet-kubernetes-etc","title":"Automation and orchestration approaches (Terraform, Ansible, Chef, Puppet, Kubernetes, etc.)","text":"<p>What kind of approach is taken for spinning up and provisioning nodes? How might you automate spinning up large clusters of nodes and upgrading them? Elaborating on what type of automation (or lack thereof) can help get a sense of how robust a validator setup is. Many everyday actions or routine maintenance needs to be done, and automating this type of thing often helps mitigate human errors.</p>"},{"location":"maintain/maintain-guides-validator-community/#network-topology","title":"Network Topology","text":"<p>Does the Validator node have protection against Denial of Service attacks, and if so, how is that done? Outlining a desired network topology for a Validators infrastructure design will help Nominators understand how resilient their operations are to attacks. Some things to highlight are the usage of firewalls, VPNs, network segmentation, proxies, or other layers separation.</p>"},{"location":"maintain/maintain-guides-validator-community/#upgrading","title":"Upgrading","text":"<p>Both Polkadot and Kusama releases are published. here. Validators are expected to upgrade their nodes as soon as a new release comes. Although not every release is mandatory to upgrade, each new release usually has bug fixes, optimizations, new features, or other beneficial changes. It's in the best interest of the entire network that validators update their nodes in a timely fashion. This signals to nominators that a validator is timely care about their operations and is quick to adapt to necessary circumstances.</p> <p>It can also be helpful for Nominators to know how the Validator runs software and where they get new binaries. How do they get alerted for new releases? Do they receive updates from the matrix chatrooms? Do they have alerts for particular GitHub activities? Do they use the Debian/RPM packages? Do they use the Parity-provided GitHub binaries? Do they use Parity Docker images? Do they make their own Docker images? Do they build the binaries themselves? Validators often have their own build server for making binaries. If they take the extra steps to make these and do not rely on external parties, this can be seen as a plus from nominators, as it helps contribute to decentralization.</p>"},{"location":"maintain/maintain-guides-validator-community/#logging-metrics-monitoring-and-observability","title":"Logging, metrics, monitoring, and observability","text":"<p>Good node operators keep tabs on how their systems are running. Observability is one of the most critical aspects of understanding the performance and behavior of a node. One should be able to outline the efforts taken in building out monitoring and observability practices. Are Prometheus and Grafana set up? What types of metrics are collected and looked at? How is this done across multiple nodes? A quality validator may make these metrics and graphs public so that Nominators can see how these nodes are running.</p>"},{"location":"maintain/maintain-guides-validator-community/#health-checks-and-alerting-conditions","title":"Health checks and alerting conditions","text":"<p>Similar to the last point, it can be helpful for nominators to know what kind of health checks and alerting conditions are in place for validator nodes. What conditions are not typical and may need to be looked at? If conditions are not specific, how is the node operator alerted to this? Are there any public Telegram, SMS, or email alerts? Nominators will want to know that a Validator can respond to abnormal conditions promptly, as their tokens are on the line of potentially being lost.</p>"},{"location":"maintain/maintain-guides-validator-community/#scenario-runbooks","title":"Scenario runbooks","text":"<p>Many scenarios happen routinely, such as upgrading nodes, restoring backups, or moving servers. Creating runbooks and sharing the procedures and precautions taken around these can instill confidence in nominators that various scenarios are thought out and planned for.</p>"},{"location":"maintain/maintain-guides-validator-community/#which-regions-nodes-are-in","title":"Which regions nodes are in","text":"<p>A diverse network of nodes in varying different regions helps strengthen decentralized networks. Outlining what regions nodes are in gives clarity to this facet of networks. Nominators may want to promote validators that actively try to decentralize networks operating in regions in which others do not run nodes.</p>"},{"location":"maintain/maintain-guides-validator-community/#security-key-handling-policies","title":"Security / Key handling policies","text":"<p>It is paramount that session keys and stash/staking proxy keys are stored and handled with the utmost care. If compromised, both the validator and nominator can be slashed. Outlining how keys are handled, how they are stored, who has access to them, and the overall policies and procedures around them is a great point of reference for nominators to gauge how comfortable they are with the security a validator takes.</p>"},{"location":"maintain/maintain-guides-validator-community/#robust-communication","title":"Robust Communication","text":"<p>The relationship between Validators and Nominators is one built on trust, and as such, having direct lines of communication with Nominators is a great way to build and reinforce that trust. This could mean setting up dedicated Telegram / Matrix / Discord channels or hosting a reoccurring call where anyone can join. Creating inclusive environments with direct connections between parties is going the extra mile to ensure that nominators know they're in good hands. Many updates can be given, such as nodes being updated to a new version, rewards being paid out, servers being migrated, new features or tools being built, or just checking in to say hello. These kinds of gestures can be much appreciated in putting words and a person behind the name of someone running a server.</p>"},{"location":"maintain/maintain-guides-validator-community/#actively-participating-in-the-community","title":"Actively Participating in the Community","text":"<p>Participating in the community goes hand in hand with building a reputation. This is not only for Nominators, but for other Validators, builders, developers, governance participants, and general enthusiasts. Being helpful or contributing to discussions can go a long way in building a trusted brand and reputation.</p> <p>There are many communities to participate in, from validator, developer, and governance communities, to local communities dedicated to specific regions. For example, one can be pretty active in the South American communities and building camaraderie among those who speak the same language or can attend the same meetups in an area. One absolute best way to build trust is meeting people in person.</p>"},{"location":"maintain/maintain-guides-validator-community/#participating-in-governance","title":"Participating in Governance","text":"<p>Another way to show that one cares about the network is by actively participating in governance. Whether by voting on-chain, or by discussing off-chain, or proposing new things, active participation in the direction of the chain is an excellent signal that a validator is there for the network\u2019s good. There are many ways to participate in different governance aspects, such as weighing in on treasury proposals, voting on public referenda, delegating voting power, and more. See the section on Polkadot OpenGov for additional details.</p>"},{"location":"maintain/maintain-guides-validator-community/#producing-educational-content","title":"Producing Educational Content","text":"<p>With a fast-moving ecosystem, there often are gaps in educational content where there are new features, changes, deprecations, or just a slow-moving process for putting out information about very complex concepts. Putting out educational content in the form of blog posts, videos, tutorials, development guides, and more (especially if it's geared toward nominators) provides tangible value to the ecosystem. It shows that one has a good grasp of how things work, and disseminating this knowledge to others can give some credence to one's brand and reputation as a competent entity in the space. Furthermore, one might get tips from the treasury if the community finds something beneficial.</p>"},{"location":"maintain/maintain-guides-validator-community/#building-tooling","title":"Building Tooling","text":"<p>Building public tooling is a great way to support the ecosystem. This provides tangible value to those that use this tooling and gives visibility to the validator for their contributions. A nominator might be more likely to nominate a validator for the utilities they provide the ecosystem since the validator then can build a reputation around the quality of their work outside their validation services. Some potential building categories are block explorers, deployment scripts, monitoring, observability services, staking dashboards, wallets, command-line utilities, or porting implementations to other languages. Additionally, this may also be eligible to be funded via a Web3 Foundation Grant.</p>"},{"location":"maintain/maintain-guides-validator-payout/","title":"Validator Payout Overview","text":""},{"location":"maintain/maintain-guides-validator-payout/#era-points","title":"Era Points","text":"<p>For every era (a period of time approximately 6 hours in length in Kusama, and 24 hours in Polkadot), validators are paid proportionally to the amount of era points they have collected. Era points are reward points earned for payable actions like:</p> <ul> <li>issuing validity statements for parachain blocks.</li> <li>producing a non-uncle block in the relay chain.</li> <li>producing a reference to a previously unreferenced uncle block.</li> <li>producing a referenced uncle block.</li> </ul> <p>Note</p> <p>An uncle block is a relay chain block that is valid in every regard, but which failed to become canonical. This can happen when two or more validators are block producers in a single slot, and the block produced by one validator reaches the next block producer before the others. We call the lagging blocks uncle blocks.</p> <p>Payments occur at the end of every era.</p> <p>Era points create a probabilistic component for staking rewards.</p> <p>If the mean of staking rewards is the average rewards per era, then the variance is the variability from the average staking rewards. The exact DOT value of each era point is not known in advance since it depends on the total number of points earned by all validators in a given era. This is designed this way so that the total payout per era depends on Polkadot's inflation model, and not on the number of payable actions (f.e., authoring a new block) executed. For more information, check this stackexchange post.</p> <p>With parachains now on Polkadot, a large percentage of era points will come from parachain validation, as a subset of validators are selected to para-validate for all parachains each epoch, and those para-validators can generate more era points as a result. Para-validators are rewarded 20 era points each for each parachain block that they validate.</p> <p>In this case, analyzing the expected value of staking rewards will paint a better picture as the weight of era points of validators and para-validators in the reward average are taken into consideration.</p> <p>High-level breakdown of reward variance</p> <p>This should only serve as a high-level overview of the probabilistic nature for staking rewards.</p> <p>Let:</p> <ul> <li><code>pe</code> = para-validator era points,</li> <li><code>ne</code> = non-para-validator era points,</li> <li><code>EV</code> = expected value of staking rewards,</li> </ul> <p>Then, <code>EV(pe)</code> has more influence on the <code>EV</code> than <code>EV(ne)</code>.</p> <p>Since <code>EV(pe)</code> has a more weighted probability on the <code>EV</code>, the increase in variance against the <code>EV</code> becomes apparent between the different validator pools (aka. validators in the active set and the ones chosen to para-validate).</p> <p>Also, let:</p> <ul> <li><code>v</code> = the variance of staking rewards,</li> <li><code>p</code> = number of para-validators,</li> <li><code>w</code> = number validators in the active set,</li> <li><code>e</code> = era,</li> </ul> <p>Then, <code>v</code> \u2191 if <code>w</code> \u2191, as this reduces <code>p</code> : <code>w</code>, with respect to <code>e</code>.</p> <p>Increased <code>v</code> is expected, and initially keeping <code>p</code> \u2193 using the same para-validator set for all parachains ensures availability and voting. In addition, despite <code>v</code> \u2191 on an <code>e</code> to <code>e</code> basis, over time, the amount of rewards each validator receives will equal out based on the continuous selection of para-validators.</p> <p>There are plans to scale the active para-validation set in the future</p>"},{"location":"maintain/maintain-guides-validator-payout/#payout-scheme","title":"Payout Scheme","text":"<p>No matter how much total stake is behind a validator, all validators split the block authoring payout essentially equally. The payout of a specific validator, however, may differ based on era points, as described above. Although there is a probabilistic component to receiving era points, and they may be impacted slightly depending on factors such as network connectivity, well-behaving validators should generally average out to having similar era point totals over a large number of eras.</p> <p>Validators may also receive \"tips\" from senders as an incentive to include transactions in their produced blocks. Validators will receive 100% of these tips directly.</p> <p>Validators will receive staking rewards in the form of the native token of that chain (KSM for Kusama and DOT for Polkadot).</p> <p>For simplicity, the examples below will assume all validators have the same amount of era points, and received no tips.</p> <pre><code>Validator Set Size (v): 4\nValidator 1 Stake (v1): 18 tokens\nValidator 2 Stake (v2):  9 tokens\nValidator 3 Stake (v3):  8 tokens\nValidator 4 Stake (v4):  7 tokens\nPayout (p): 8 DOT\n\nPayout for each validator (v1 - v4):\np / v = 8 / 4 = 2 tokens\n</code></pre> <p>Note that this is different than most other Proof-of-Stake systems such as Cosmos. As long as a validator is in the validator set, it will receive the same block reward as every other validator. Validator <code>v1</code>, who had 18 tokens staked, received the same reward (2 tokens) in this era as <code>v4</code> who had only 7 tokens staked.</p>"},{"location":"maintain/maintain-guides-validator-payout/#running-multiple-validators","title":"Running Multiple Validators","text":"<p>It is possible for a single entity to run multiple validators. Running multiple validators may provide a better risk/reward ratio. Assuming you have enough DOT, or enough stake nominates your validator, to ensure that your validators remain in the validator set, running multiple validators will result in a higher return than running a single validator.</p> <p>For the following example, assume you have 18 DOT to stake. For simplicity's sake, we will ignore nominators. Running a single validator, as in the example above, would net you 2 DOT in this era.</p> <p>Note that while DOT is used as an example, this same formula would apply to KSM when running a validator on Kusama.</p> <pre><code>Validator Set Size (v): 4\nValidator 1 Stake (v1): 18 DOT &lt;- Your validator\nValidator 2 Stake (v2):  9 DOT\nValidator 3 Stake (v3):  8 DOT\nValidator 4 Stake (v4):  7 DOT\nPayout (p): 8 DOT\n\nYour payout = (p / v) * 1 = (8 / 4) * 1 = 2\n</code></pre> <p>Running two validators, and splitting the stake equally, would result in the original validator <code>v4</code> to be kicked out of the validator set, as only the top <code>v</code> validators (as measured by stake) are selected to be in the validator set. More important, it would also double the reward that you get from each era.</p> <pre><code>Validator Set Size (v): 4\nValidator 1 Stake (v1): 9 DOT &lt;- Your first validator\nValidator 2 Stake (v2): 9 DOT &lt;- Your second validator\nValidator 3 Stake (v3): 9 DOT\nValidator 4 Stake (v4): 8 DOT\nPayout (p): 8 DOT\n\nYour payout = (p / v) * 2 = (8 / 4) * 2 = 4\n</code></pre> <p>With enough stake, you could run more than two validators. However, each validator must have enough stake behind it to be in the validator set.</p> <p>The incentives of the system favor equally-staked validators. This works out to be a dynamic, rather than static, equilibrium. Potential validators will run different numbers of validators and apply different amounts of stake to them as time goes on, and in response to the actions of other validators on the network.</p>"},{"location":"maintain/maintain-guides-validator-payout/#nominators-and-validator-payments","title":"Nominators and Validator Payments","text":"<p>A nominated stake allows you to \"vote\" for validators and share the rewards (but also slashing) without running a validator node yourself.</p> <p>Although staking rewards are based on the activities of the validator node during a specific era, the validator never has access to or ownership of staking rewards. In fact, <code>staking.payoutStakers</code> or <code>staking.payoutStakerByPage</code> calls are necessary to payout staking rewards, can be called by anyone, and the staking rewards are \"generated\" because of it and automatically sent to nominators (i.e., rewards are produced or minted and sent to nominators, not sent from validators to nominators).</p> <p>This includes the stake of the validator itself plus any stake bonded by nominators.</p> <p>Info</p> <p>Validators set their preference as a percentage of the block reward, not an absolute number of DOT. Polkadot's block reward is based on the total amount at stake. The commission is set as the amount taken by the validator; that is, 0% commission means that the validator does not receive any proportion of the rewards besides that owed to it from self-stake, and 100% commission means that the validator operator gets all rewards and gives none to its nominators.</p> <p>In the following examples, we can see the results of several different validator payment schemes and split between nominator and validator stake. We will assume a single nominator for each validator. However, there can be numerous nominators for each validator. Rewards are still distributed proportionally - for example, if the total rewards to be given to nominators is 2 DOT, and there are four nominators with equal stake bonded, each will receive 0.5 DOT. Note also that a single nominator may stake different validators.</p> <p>Each validator in the example has selected a different validator payment (that is, a percentage of the reward set aside directly for the validator before sharing with all bonded stake). The validator's payment percentage (in DOT, although the same calculations work for KSM) is listed in brackets (<code>[]</code>) next to each validator. Note that since the validator payment is public knowledge, having a low or non-existent validator payment may attract more stake from nominators, since they know they will receive a larger reward.</p> <pre><code>Validator Set Size (v): 4\nValidator 1 Stake (v1) [20% commission]: 18 DOT (9 validator, 9 nominator)\nValidator 2 Stake (v2) [40% commission]:  9 DOT (3 validator, 6 nominator)\nValidator 3 Stake (v3) [10% commission]:  8 DOT (4 validator, 4 nominator)\nValidator 4 Stake (v4) [ 0% commission]:  6 DOT (1 validator, 5 nominator)\nPayout (p): 8 DOT\n\nPayout for each validator (v1 - v4):\np / v = 8 / 4 = 2 DOT\n\nv1:\n(0.2 * 2) = 0.4 DOT -&gt; validator payment\n(2 - 0.4) = 1.6 -&gt; shared between all stake\n(9 / 18) * 1.6 = 0.8 -&gt; validator stake share\n(9 / 18) * 1.6 = 0.8 -&gt; nominator stake share\nv1 validator total reward: 0.4 + 0.8 = 1.2 DOT\nv1 nominator reward: 0.8 DOT\n\nv2:\n(0.4 * 2) = 0.8 DOT -&gt; validator payment\n(2 - 0.8) = 1.2 -&gt; shared between all stake\n(3 / 9) * 1.2 = 0.4 -&gt; validator stake share\n(6 / 9) * 1.2 = 0.8 -&gt; nominator stake share\nv2 validator total reward: 0.8 + 0.4 = 1.2 DOT\nv2 nominator reward: 0.8 DOT\n\nv3:\n(0.1 * 2) = 0.2 DOT -&gt; validator payment\n(2 - 0.2) = 1.8 -&gt; shared between all stake\n(4 / 8) * 1.8 = 0.9 -&gt; validator stake share\n(4 / 8) * 1.8 = 0.9 -&gt; nominator stake share\nv3 validator total reward: 0.2 + 0.9 DOT = 1.1 DOT\nv3 nominator reward: 0.9 DOT\n\nv4:\n(0 * 2) = 0 DOT -&gt; validator payment\n(2 - 0) = 2.0 -&gt; shared between all stake\n(1 / 6) * 2 = 0.33 -&gt; validator stake share\n(5 / 6) * 2 = 1.67 -&gt; nominator stake share\nv4 validator total reward: 0 + 0.33 DOT = 0.33 DOT\nv4 nominator reward: 1.67 DOT\n</code></pre>"},{"location":"maintain/maintain-networks/","title":"Networks","text":"<p>Polkadot is built on top of Substrate, a modular framework for blockchains. One feature of Substrate is to allow for connection to different networks using a single executable and configuring it with a start-up flag. Here are some of the networks associated with Polkadot or Substrate that you may want to connect to and join.</p>"},{"location":"maintain/maintain-networks/#main-networks","title":"Main networks","text":"<p>To connect to a Polkadot network please follow the instructions for installing the Polkadot executable.</p>"},{"location":"maintain/maintain-networks/#polkadot-mainnet","title":"Polkadot Mainnet","text":"<p>Connecting to the Polkadot network is the default option when starting a node.</p> <p>To start a Polkadot node, run the Polkadot binary:</p> <pre><code>polkadot\n</code></pre> <p>and you will connect and start syncing to Polkadot.</p> <p>Check your node is connected by viewing it on Telemetry (you can set a custom node name by specifying <code>--name \"my-custom-node-name\"</code>)</p>"},{"location":"maintain/maintain-networks/#kusama-canary-network","title":"Kusama Canary Network","text":"<p>Kusama is a canary network and holds real economic value.</p> <p>Run the Polkadot binary and specify <code>kusama</code> as the chain:</p> <pre><code>polkadot --chain=kusama\n</code></pre> <p>and you will connect and start syncing to Kusama.</p> <p>Check your node is connected by viewing it on Kusama Telemetry (you can set a custom node name by specifying <code>--name \"my-custom-node-name\"</code>)</p>"},{"location":"maintain/maintain-networks/#test-networks","title":"Test Networks","text":""},{"location":"maintain/maintain-networks/#westend-test-network","title":"Westend Test Network","text":"<p>Westend is the primary test network of Polkadot. The tokens on this network are called Westies (WND) and they purposefully hold no economic value.</p> <p>Run the Polkadot binary and specify <code>westend</code> as the chain:</p> <pre><code>polkadot --chain=westend\n</code></pre> <p>and you will connect and start syncing to Westend.</p> <p>Check that your node is connected by viewing it on Westend Telemetry (you can set a custom node name by specifying <code>--name \"my-custom-node-name\"</code>).</p>"},{"location":"maintain/maintain-networks/#westend-faucet","title":"Westend Faucet","text":"<p>Follow the instruction here to get Westies (WND) tokens.</p>"},{"location":"maintain/maintain-networks/#westend-asset-hub","title":"Westend Asset Hub","text":"<p>The Westend Asset Hub is a system parachain on Westend network.</p>"},{"location":"maintain/maintain-networks/#westend-asset-hub-faucet","title":"Westend Asset Hub Faucet","text":"<p>Claim WND tokens from the faucet on Westend and teleport them to Westend Asset Hub.</p>"},{"location":"maintain/maintain-networks/#rococo-test-network","title":"Rococo Test Network","text":"<p>Rococo used to be a Polkadot test network for parachains. The network was shut down following its replacement by Paseo.</p>"},{"location":"maintain/maintain-networks/#paseo-test-network","title":"Paseo Test Network","text":"<p>Paseo is a test network built for parachains. The native token of this network (PAS) holds no economic value.</p>"},{"location":"maintain/maintain-networks/#paseo-faucet","title":"Paseo Faucet","text":"<p>Follow the instruction here to get PAS tokens.</p>"},{"location":"maintain/maintain-networks/#wococo-test-network-inactive","title":"Wococo Test Network (inactive)","text":"<p>Wococo used to be a Polkadot test network for testing bridges. The network was shut down following the bridge between Westend and Rococo deployment.</p>"},{"location":"maintain/maintain-networks/#differences","title":"Differences","text":"<p>Runtime differences (e.g. existential and multisignature deposit sizes) between the different networks can be found by doing a <code>diff</code> between the <code>src/lib.rs</code> of the repositories. For example, to compare the Polkadot and Kusama runtimes:</p> <ul> <li><code>git clone https://github.com/polkadot-fellows/runtimes &amp;&amp; cd runtimes/relay</code></li> <li><code>ls</code> - show the available runtimes</li> <li><code>diff polkadot/src/lib.rs kusama/src/lib.rs</code></li> </ul> <p>You can also paste the runtimes (Polkadot, Kusama) into a web-based diff tool like Diffchecker if you're not comfortable with the CLI.</p>"},{"location":"maintain/maintain-networks/#telemetry-dashboard","title":"Telemetry Dashboard","text":"<p>If you connect to the public networks, the default configuration for your node will connect it to the public Telemetry service.</p> <p>You can verify that your node is connected by navigating to the correct network on the dashboard and finding the name of your node.</p> <p>There is a built-in search function on the nodes page. Simply start typing keystrokes in the main window to make it available.</p>"},{"location":"maintain/maintain-polkadot-parameters/","title":"Polkadot Parameters","text":"<p>Many of these parameter values can be updated via on-chain governance. If you require absolute certainty of these parameter values, it is recommended you directly check the constants by looking at the chain state and/or storage.</p>"},{"location":"maintain/maintain-polkadot-parameters/#periods-of-common-actions-and-attributes","title":"Periods of common actions and attributes","text":"<p>NOTE: Polkadot generally runs at \u00bcth the speed of Kusama, except in the time slot duration itself.</p> PolkadotKusama <ul> <li>Slot: 6 seconds *(generally one block per slot, although see note below)</li> <li>Epoch: 4 hours (2_400 slots x 6 seconds)</li> <li>Session: 4 hours (Session and Epoch lengths are the same)</li> <li>Era: 24 hours (6 sessions per Era, 2_400 slots x 6 epochs x 6 seconds)</li> </ul> Polkadot Time Slots* Slot 6 seconds 1 Epoch 4 hours 2_400 Session 4 hours 2_400 Era 24 hours 14_400 <ul> <li>Slot: 6 seconds *(generally one block per slot, although see note below)</li> <li>Epoch: 1 hour (600 slots x 6 seconds)</li> <li>Session: 1 hour (6 sessions per Era)</li> <li>Era: 6 hours (3600 slots x 6 seconds)</li> </ul> Kusama Time Slots* Slot 6 seconds 1 Epoch 1 hour 600 Session 1 hour 600 Era 6 hours 3_600 <p>*A maximum of one block per slot can be in a canonical chain. Occasionally, a slot will be without a block in the chain. Thus, the times given are estimates. See Consensus for more details.</p>"},{"location":"maintain/maintain-polkadot-parameters/#governance","title":"Governance","text":"PolkadotKusama Parameter Time Slots Description Voting period 28 days 403_200 How long the public can vote on a referendum. Enactment period 28 days 403_200 Time it takes for a successful referendum to be implemented on the network. Parameter Time Slots Description Voting period 7 days 100_800 How long the public can vote on a referendum. Enactment period 8 days 115_200 Time it takes for a successful referendum to be implemented on the network."},{"location":"maintain/maintain-polkadot-parameters/#staking-validating-and-nominating","title":"Staking, Validating, and Nominating","text":"<p>The maximum number of validators that can be nominated by a nominator is can be see here.</p> PolkadotKusama Parameter Time Slots Description Term duration 1 Day 14_400 The time for which a validator is in the set after being elected. Note, this duration can be shortened in the case that a validator misbehaves. Nomination period 1 Day 14_400 How often a new validator set is elected according to Phragm\u00e9n's method. Bonding duration 28 days 403_200 How long until your funds will be transferrable after unbonding. Note that the bonding duration is defined in eras, not directly by slots. Slash defer duration 28 days 403_200 Prevents overslashing and validators \"escaping\" and getting their nominators slashed with no repercussions to themselves. Note that the bonding duration is defined in eras, not directly by slots. Parameter Time Slots Description Term duration 6 hours 3_600 The time for which a validator is in the set after being elected. Note, this duration can be shortened in the case that a validator misbehaves. Nomination period 6 hours 3_600 How often a new validator set is elected according to Phragm\u00e9n's method. Bonding duration 7 days 604_800 How long until your funds will be transferrable after unbonding. Note that the bonding duration is defined in eras, not directly by slots. Slash defer duration 7 days 604_800 Prevents overslashing and validators \"escaping\" and getting their nominators slashed with no repercussions to themselves. Note that the bonding duration is defined in eras, not directly by slots."},{"location":"maintain/maintain-polkadot-parameters/#treasury","title":"Treasury","text":"PolkadotKusama Treasury Time Slots Description Periods between spends 24 days 345_600 When the treasury can spend again after spending previously. <p>Burn percentage is currently <code>1.00%</code>.</p> Treasury Time Slots Description Periods between spends 6 days 86_400 When the treasury can spend again after spending previously. <p>Burn percentage is currently <code>0.20%</code>, though instead of being burned this amount is temporarily redirected into the Society's treasury to fund growth.</p>"},{"location":"maintain/maintain-polkadot-parameters/#precision","title":"Precision","text":"PolkadotKusama <p>DOT have 10 decimals of precision. In other words, 10 ** 10 (10_000_000_000 or ten billion) Plancks make up a DOT.</p> <p>The denomination of DOT was changed from 12 decimals of precision at block #1,248,328 in an event known as Denomination Day. See Redenomination for details.</p> <p>KSM have 12 decimals of precision. In other words, 1e12 (1_000_000_000_000, or one trillion) Plancks make up a single KSM.</p>"},{"location":"maintain/maintain-rpc/","title":"Set up a RPC node","text":"<p>The substrate node RPC server can be accessed over the WebSocket protocol, which can be used to access the underlying network and/or validator node. By default, you can access your node's RPC server from localhost (for example, to rotate keys or do other maintenance). To access it from another server or an applications UI (such as Polkadot-JS UI) it is recommended to enable access to the RPC node over an SSL connection and encrypt the connection between the end user and the RPC server. This can be achieved by setting up a secure proxy. Many browsers, such as Google Chrome, will block non-secure ws endpoints if they come from a different origin.</p> <p>Note</p> <p>Enabling remote access to your validator node should not be necessary and is not suggested, as it can often lead to security problems</p>"},{"location":"maintain/maintain-rpc/#set-up-a-node","title":"Set up a Node","text":"<p>Setting up any Substrate-based node relies on a similar process. For example, by default, they will all share the same WebSocket connection at port 9944 on localhost. In this example, we'll set up a Polkadot sync node on a Debian-flavoured server (such as Ubuntu 22.04). Create a new server on your provider of choice or locally at home. See Set up a Full Node for additional instructions. You can install from the default apt repository or build from scratch. The startup options in the setup process provide various settings that can be modified.</p> <p>A typical setting for an externally accessible polkadot archive RPC node would be:</p> <pre><code>polkadot --chain polkadot --name myrpc --state-pruning archive --blocks-pruning archive --rpc-max-connections 100 --rpc-cors all --rpc-methods Safe --rpc-port 9944\n</code></pre> <p>Or for a Polkadot pruned RPC node:</p> <pre><code>polkadot --chain polkadot --name myrpc --state-pruning 1000 --blocks-pruning archive --rpc-max-connections 100 --rpc-cors all --rpc-methods Safe --rpc-port 9944\n</code></pre> <p>The specified flag options are outlined in greater detail below.</p>"},{"location":"maintain/maintain-rpc/#archive-node-vs-pruned-node","title":"Archive Node vs. Pruned Node","text":"<p>A pruned node only keeps a limited number of finalized blocks of the network, not its full history. Most frequently required actions can be completed with a pruned node, such as displaying account balances, making transfers, setting up session keys, staking, etc. An archive node has the full history (database) of the network. It can be queried in various ways, such as providing historical information regarding transfers, balance histories, and more advanced queries involving past events.</p> <p>An archive node requires a lot more disk space. At the start of April 2023, Polkadot disk usage was 160 GB for a pruned node and 1 TB for an archive node. This value will increase with time. For an archive node, you need the options <code>--state-pruning archive --blocks-pruning archive</code> in your startup settings.</p> <p>Tip</p> <p>Inclusion in the Polkadot.js UI requires an archive node.</p>"},{"location":"maintain/maintain-rpc/#secure-the-rpc-server","title":"Secure the RPC server","text":"<p>The node startup settings allow you to choose what to expose, how many connections to expose and from where access should be granted through the RPC server.</p> <p>How many: You can set your maximum connections through <code>--rpc-max-connections</code>, for example <code>--rpc-max-connections 100</code></p> <p>From where: by default localhost and the polkadot.js are allowed to access the RPC server; you can change this by setting <code>--rpc-cors</code>, to allow access from everywhere you need <code>--rpc-cors all</code></p> <p>What: you can limit the methods to use with <code>--rpc-methods</code>, an easy way to set this to a safe mode is <code>--rpc-methods Safe</code></p>"},{"location":"maintain/maintain-rpc/#secure-the-ws-port","title":"Secure the ws port","text":"<p>To safely access your ws connection over an SSL-enabled connection (needed for polkadot.js), you have to convert the ws connection to a secure (wss) connection by using a proxy and an SSL certificate, you can find instructions on securing the ws port here.</p>"},{"location":"maintain/maintain-rpc/#connecting-to-the-node","title":"Connecting to the Node","text":"<p>Open Polkadot-JS UI and click the logo in the top left to switch the node. Activate the \"Development\" toggle and input your node's address - either the domain or the IP address. Remember to prefix with <code>wss://</code>, and if you're using the 443 port, append <code>:443</code> like so: <code>wss://example.com:443</code>.</p> <p></p> <p>Now you have a secure remote connect setup for your Substrate node.</p>"},{"location":"maintain/maintain-sync/","title":"Set up a Full Node","text":"<p>If you're building dApps or products on a Substrate-based chain like Polkadot, Kusama, or a custom Substrate implementation, you want the ability to run a node-as-a-back-end. After all, relying on your infrastructure is always better than a third-party-hosted one in this brave new decentralized world.</p> <p>This guide will show you how to connect to Polkadot network, but the same process applies to any other Substrate-based chain. First, let's clarify the term full node.</p>"},{"location":"maintain/maintain-sync/#types-of-nodes","title":"Types of Nodes","text":"<p>A blockchain's growth comes from a genesis block, extrinsics, and events.</p> <p>When a validator seals block 1, it takes the blockchain's state at block 0. It then applies all pending changes on top of it and emits the events resulting from these changes. Later, the chain\u2019s state at block one is used the same way to build the chain\u2019s state at block 2, and so on. Once two-thirds of the validators agree on a specific block being valid, it is finalized.</p> <p>An archive node keeps all the past blocks and their states. An archive node makes it convenient to query the past state of the chain at any point in time. Finding out what an account's balance at a particular block was or which extrinsics resulted in a specific state change are fast operations when using an archive node. However, an archive node takes up a lot of disk space - around Kusama's 12 millionth block, this was around 660 GB.</p> <p>Tip</p> <p>On the Paranodes or Stakeworld websites, you can find lists of the database sizes of Polkadot and Kusama nodes.</p> <p>Archive nodes are used by utilities that need past information - like block explorers, council scanners, discussion platforms like Polkassembly, and others. They need to be able to look at past on-chain data.</p> <p>A full node prunes historical states: all finalized blocks' states older than a configurable number except the genesis block's state. This is 256 blocks from the last finalized one by default. A pruned node this way requires much less space than an archive node.</p> <p>A full node could eventually rebuild every block's state without additional information and become an archive node. This still needs to be implemented at the time of writing. If you need to query historical blocks' states past what you pruned, you must purge your database and resync your node, starting in archive mode. Alternatively, you can use a backup or snapshot of a trusted source to avoid needing to sync from genesis with the network and only need the states of blocks past that snapshot.</p> <p>Full nodes allow you to read the current state of the chain and to submit and validate extrinsics directly on the network without relying on a centralized infrastructure provider.</p> <p>Another type of node is a light node. A light node has only the runtime and the current state but does not store past blocks and so cannot read historical data without requesting it from a node that has it. Light nodes are useful for resource-restricted devices. An interesting use-case of light nodes is a browser extension, which is a node in its own right, running the runtime in WASM format, as well as a full or light node that is completely encapsulated in WASM and can be integrated into web apps: https://github.com/smol-dot/smoldot.</p> <p>Substrate Connect</p> <p>Substrate Connect provides a way to interact with substrate-based blockchains in the browser without using an RPC server. It is a light node that runs entirely in Javascript. Substrate Connect uses a smoldot WASM light client to securely connect to the blockchain network without relying on specific 3<sup>rd</sup> parties. Substrate Connect is available on Chrome and Firefox as a browser extension.</p>"},{"location":"maintain/maintain-sync/#setup-instructions","title":"Setup Instructions","text":"<p>This is not recommended if you're a validator. Please see the secure validator setup if you are running validator.</p> <p>!!!note \"The bash commands that are provided to run against your node use <code>Polkadot</code> as the default chain\"     Use the <code>--chain</code> flag if you follow the setup instructions to setup a <code>Kusama</code> node. For example:</p> <pre><code>```bash\n./target/release/polkadot --name \"Your Node's Name\" --chain kusama\n```\n</code></pre> macOSWindowsLinux (standalone)Linux (package) <ul> <li>Install Homebrew within the terminal by running:   <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n</code></pre></li> <li>Then, run:</li> </ul> <pre><code>brew install openssl cmake llvm protobuf\n</code></pre> <ul> <li>Install Rust by running:   <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre></li> <li>After Rust is installed, update and add the nightly version:</li> </ul> <pre><code># Ensure the current shell has cargo\nsource ~/.cargo/env\n\n# Update the Rust toolchain\nrustup default stable\nrustup update\n\n# Add the nightly and WebAssembly targets:\nrustup update nightly\nrustup target add wasm32-unknown-unknown --toolchain nightly\n</code></pre> <ul> <li>Verify your installation by running the following:</li> </ul> <pre><code>rustup show\n\n# You should see output similar to:\n\nactive toolchain\n----------------\n\nstable-aarch64-apple-darwin (default)\nrustc 1.68.1 (8460ca823 2023-03-20)\n</code></pre> <pre><code>rustup +nightly show\n\n# You should see output similar to:\n\ninstalled targets for active toolchain\n--------------------------------------\n\naarch64-apple-darwin\nwasm32-unknown-unknown\n\nactive toolchain\n----------------\n\nnightly-aarch64-apple-darwin (overridden by +toolchain on the command line)\nrustc 1.71.0-nightly (9ecda8de8 2023-04-30)\n</code></pre> <ul> <li>Once Rust is configured, run the following command to clone and build the Polkadot code:   <pre><code>git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\ncd polkadot-sdk\n./scripts/getting-started.sh\ncargo build --release\n</code></pre></li> <li>Start your node:</li> </ul> <pre><code>./target/release/polkadot --name \"Your Node's Name\"\n</code></pre> <ul> <li>Find your node on Telemetry</li> </ul> <ul> <li>Install WSL.</li> <li> <p>Install Ubuntu (same webpage).</p> </li> <li> <p>Determine the latest version of the   Polkadot binary.</p> </li> <li>Download the correct Polkadot binary within Ubuntu by running the following command. Replace   <code>*VERSION*</code> with the tag of the latest version from the last step (e.g. <code>v0.8.22</code>):</li> </ul> <pre><code>curl -sL https://github.com/paritytech/polkadot-sdk/releases/download/*VERSION*/polkadot -o polkadot\n</code></pre> <ul> <li>Then, run the following:   <pre><code>sudo chmod +x polkadot\n</code></pre></li> <li>Start your node:</li> </ul> <pre><code>./polkadot --name \"Your Node's Name\"\n</code></pre> <ul> <li>Find your node on Telemetry</li> </ul> <ul> <li>Determine the latest version of the   Polkadot binary.</li> </ul> <p>Info</p> <p>The nature of pre-built binaries means that they may not work on your particular architecture or Linux distribution. If you see an error like <code>cannot execute binary file: Exec format error</code> it likely means the binary is not compatible with your system. You will either need to compile the source code or use Docker.</p> <ul> <li>Download the correct Polkadot binary within Ubuntu by running the following command. Replace   <code>*VERSION*</code> with the tag of the latest version from the last step (e.g. <code>v0.8.22</code>):</li> </ul> <pre><code>curl -sL https://github.com/paritytech/polkadot-sdk/releases/download/*VERSION*/polkadot -o polkadot\n</code></pre> <ul> <li>Run the following: <code>sudo chmod +x polkadot</code></li> <li>Run the following:</li> </ul> <pre><code>./target/release/polkadot --name \"Your Node's Name\"\n</code></pre> <ul> <li>Find your node on Telemetry</li> </ul> <p>You can also install Polkadot from one of our package repositories.</p> <p>Installation from the Debian or rpm repositories will create a <code>systemd</code> service that can be used to run a Polkadot node. The service is disabled by default, and can be started by running <code>systemctl start polkadot</code> on demand (use <code>systemctl enable polkadot</code> to make it auto-start after reboot). By default, it will run as the <code>polkadot</code> user. Command-line flags passed to the binary can be customized by editing <code>/etc/default/polkadot</code>. This file will not be overwritten on updating polkadot.</p>"},{"location":"maintain/maintain-sync/#debian-based-debian-ubuntu","title":"Debian-based (Debian, Ubuntu)","text":"<p>Currently supports Debian 10 (Buster) and Ubuntu 20.04 (Focal), and derivatives. Run the following commands as the <code>root</code> user.</p> <pre><code># Import the security@parity.io GPG key\ngpg --recv-keys --keyserver hkps://keys.mailvelope.com 9D4B2B6EB8F97156D19669A9FF0812D491B96798\ngpg --export 9D4B2B6EB8F97156D19669A9FF0812D491B96798 &gt; /usr/share/keyrings/parity.gpg\n# Add the Parity repository and update the package index\necho 'deb [signed-by=/usr/share/keyrings/parity.gpg] https://releases.parity.io/deb release main' &gt; /etc/apt/sources.list.d/parity.list\napt update\n# Install the `parity-keyring` package - This will ensure the GPG key\n# used by APT remains up-to-date\napt install parity-keyring\n# Install polkadot\napt install polkadot\n</code></pre> <p>If you don't want polkadot package to be automatically updated when you update packages on your server, you can issue the following command:</p> <pre><code>sudo apt-mark hold polkadot\n</code></pre>"},{"location":"maintain/maintain-sync/#rpm-based-fedora-centos","title":"RPM-based (Fedora, CentOS)","text":"<p>Currently supports Fedora 32 and CentOS 8, and derivatives.</p> <pre><code># Install dnf-plugins-core (This might already be installed)\ndnf install dnf-plugins-core\n# Add the repository and enable it\ndnf config-manager --add-repo https://releases.parity.io/rpm/polkadot.repo\ndnf config-manager --set-enabled polkadot\n# Install polkadot (You may have to confirm the import of the GPG key, which\n# should have the following fingerprint: 9D4B2B6EB8F97156D19669A9FF0812D491B96798)\ndnf install polkadot\n</code></pre> <p>Info</p> <p>If you choose to use a custom folder for the polkadot home by passing <code>--base-path '/custom-path'</code>, you will need to issue following command:</p> <pre><code>sudo mkdir /etc/systemd/system/polkadot.service.d\n</code></pre> <p>And create a new file inside this folder:</p> <pre><code>sudo -e /etc/systemd/system/polkadot.service.d/custom.conf\n</code></pre> <p>With the following content:</p> <pre><code>[Service]\nReadWritePaths=/custom-path\n</code></pre> <p>And finally issue a reload to have your modifications applied by systemd:</p> <pre><code>systemctl daemon-reload\n</code></pre>"},{"location":"maintain/maintain-sync/#get-substrate","title":"Get Substrate","text":"<p>Follow instructions as outlined here - note that Windows users will have their work cut out for them. It's better to use a virtual machine instead.</p> <p>Test if the installation was successful by running <code>cargo --version</code>.</p> <pre><code>\u03bb cargo --version\ncargo 1.41.0 (626f0f40e 2019-12-03)\n</code></pre>"},{"location":"maintain/maintain-sync/#clone-and-build","title":"Clone and Build","text":"<p>The paritytech/polkadot repo's master branch contains the latest Polkadot code.</p> <pre><code>git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\ncd polkadot-sdk\n./scripts/init.sh\ncargo build --release\n</code></pre> <p>Alternatively, if you wish to use a specific release, you can check out a specific tag (<code>v0.8.3</code> in the example below):</p> <pre><code>git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\ncd polkadot-sdk\ngit checkout tags/polkadot-v1.9.0\n./scripts/init.sh\ncargo build --release\n</code></pre>"},{"location":"maintain/maintain-sync/#run","title":"Run","text":"<p>The built binary will be in the <code>target/release</code> folder, called <code>polkadot</code>.</p> <p>Polkadot:</p> <pre><code>./target/release/polkadot --name \"Your Node's Name\"\n</code></pre> <p>Use the <code>--help</code> flag to determine which flags you can use when running the node. For example, if connecting to your node remotely, you'll probably want to use <code>--rpc-external</code> and <code>--rpc-cors all</code>.</p> <p>The syncing process will take a while, depending on your capacity, processing power, disk speed and RAM. On a $10 DigitalOcean droplet, the process can complete in some 36 hours.</p> <p>Congratulations, you're now syncing with Polkadot. Keep in mind that the process is identical when using any other Substrate chain.</p>"},{"location":"maintain/maintain-sync/#running-an-archive-node","title":"Running an Archive Node","text":"<p>When running as a simple sync node (above), only the state of the past 256 blocks will be kept. It defaults to archive mode when validating. To support the full state, use the <code>--pruning</code> flag:</p> <p>Polkadot:</p> <pre><code>./target/release/polkadot --name \"My node's name\" --pruning archive\n</code></pre> <p>It is possible to almost quadruple synchronization speed by using an additional flag: <code>--wasm-execution Compiled</code>. Note that this uses much more CPU and RAM, so it should be turned off after the node syncs.</p>"},{"location":"maintain/maintain-sync/#using-docker","title":"Using Docker","text":"<p>Finally, you can use Docker to run your node in a container. Doing this is more advanced, so it's best left up to those already familiar with docker or who have completed the other set-up instructions in this guide. Be aware that when you run polkadot in docker, the process only listens on localhost by default. If you would like to connect to your node's services (rpc, and prometheus) you need to ensure that you run you node with the <code>--rpc-external</code>, and <code>--prometheus-external</code> commands.</p> <pre><code>docker run -p 9944:9944 -p 9615:9615 parity/polkadot:v0.9.13 --name \"calling_home_from_a_docker_container\" --rpc-external --prometheus-external\n</code></pre>"},{"location":"maintain/maintain-wss/","title":"Secure the WebSocket","text":""},{"location":"maintain/maintain-wss/#secure-a-ws-port","title":"Secure a WS Port","text":"<p>A non-secure ws port can be converted to a secure wss port by placing it behind an SSL-enabled proxy. This can be used to secure a bootnode or secure a RPC server. The SSL-enabled apache2/nginx/other proxy server redirects requests to the internal ws and converts it to a secure (wss) connection. For this, you will need an SSL certificate for which you can use a service like letsencrypt or self-signing.</p>"},{"location":"maintain/maintain-wss/#obtaining-an-ssl-certificate","title":"Obtaining an SSL Certificate","text":"<p>One easy way to get a free SSL certificate can be achieved by following the LetsEncrypt instructions (nginx/apache). This will auto-generate an SSL certificate and include it in your configuration.</p> <p>Alternatively, you can generate a self-signed certificate and rely on the raw IP address of your node when connecting to it. This is not preferable since you will have to whitelist the certificate to access it from a browser.</p> <pre><code>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/selfsigned.key -out /etc/ssl/certs/selfsigned.crt\nsudo openssl dhparam -out /etc/ssl/certs/dhparam.pem 2048\n</code></pre>"},{"location":"maintain/maintain-wss/#installing-a-proxy-server","title":"Installing a Proxy Server","text":"<p>There are a lot of different implementations of a WebSocket proxy, some of the more widely used are nginx and apache2, for which configuration examples provided below.</p>"},{"location":"maintain/maintain-wss/#nginx","title":"Nginx","text":"<pre><code>apt install nginx\n</code></pre> <p>In an SSL-enabled virtual host add:</p> <pre><code>server {\n  (...)\n  location / {\n    proxy_buffers 16 4k;\n    proxy_buffer_size 2k;\n    proxy_pass http://localhost:9944;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"Upgrade\";\n    proxy_set_header Host $host;\n   }\n}\n</code></pre> <p>Optionally some form of rate limiting can be introduced:</p> <pre><code>http {\n  limit_req_zone  \"$http_x_forwarded_for\" zone=zone:10m rate=2r/s;\n  (...)\n}\n\nlocation / {\n  limit_req zone=zone burst=5;\n  (...)\n}\n</code></pre>"},{"location":"maintain/maintain-wss/#apache2","title":"Apache2","text":"<p>You can run it in different modes such as prefork, worker, or event. In this example, we use event which works well on higher load environments but other modes are also useful given the requirements.</p> <pre><code>apt install apache2\na2dismod mpm_prefork\na2enmod mpm_event proxy proxy_html proxy_http proxy_wstunnel rewrite ssl\n</code></pre> <p>The mod_proxy_wstunnel provides support for the tunneling of web socket connections to a backend websockets server. The connection is automatically upgraded to a WebSocket connection. In an SSL-enabled virtualhost add:</p> <pre><code>(...)\nSSLProxyEngine on\nProxyRequests off\n\nProxyPass / ws://localhost:9944\nProxyPassReverse / ws://localhost:9944\n</code></pre> <p>Older versions of mod_proxy_wstunnel do not upgrade the connection automatically and will need the following config added:</p> <pre><code>RewriteEngine on\nRewriteCond %{HTTP:Upgrade} websocket [NC]\nRewriteRule /(.*) ws://localhost:9944/$1 [P,L]\nRewriteRule /(.*) http://localhost:9944/$1 [P,L]\n</code></pre> <p>Optionally some form of rate limiting can be introduced:</p> <pre><code>apt install libapache2-mod-qos\na2enmod qos\n</code></pre> <p>And edit <code>/etc/apache2/mods-available/qos.conf</code></p> <pre><code># allows max 50 connections from a single ip address:\nQS_SrvMaxConnPerIP                                 50\n</code></pre>"},{"location":"maintain/maintain-wss/#connecting-to-the-node","title":"Connecting to the Node","text":"<p>Open Polkadot-JS UI and click the logo in the top left to switch the node. Activate the \"Development\" toggle and input your node's address - either the domain or the IP address. Remember to prefix with <code>wss://</code> and if you're using the 443 port, append <code>:443</code>, like so: <code>wss://example.com:443</code>.</p> <p></p> <p>Now you have a secure remote connect setup for your Substrate node.</p>"},{"location":"maintain/archive/","title":"Archive","text":"<ul> <li>Democracy Guide - Guide on Democracy.</li> <li>How to Join Council - Guide on How to Join Council.</li> <li>How to Vote Councillor - Guide on How to Vote for a Councillor.</li> </ul>"},{"location":"maintain/archive/maintain-guides-democracy/","title":"Participate in Democracy","text":"<p>     The content on this page is archived. For up-to-date information about governance, see the            Polkadot OpenGov page.      </p> \u2716 <p>The public referenda chamber is one of the three bodies of on-chain governance as it's instantiated in Polkadot and Kusama. The other two bodies are the council and the technical committee.</p> <p>Public referenda can be proposed and voted on by any token holder in the system as long as they provide a bond. After a proposal is made, others can agree with it by endorsing it and putting up tokens equal to the original bond. During every launch period, the most endorsed proposal will be moved to the public referenda table where it can be voted upon. Voters who are willing to lock up their tokens for a greater duration of time can do so and get their votes amplified. For more details on the governance system please see here.</p> <p>This guide will instruct token holders how to propose and vote on public referenda using the Democracy module. Below are a few links to stay informed and directly engage with the community.</p> <ul> <li>Polkadot Direction - a place to discuss   governance and the future of Polkadot.</li> <li>Kusama Direction - a place to discuss   governance and the future of Kusama.</li> <li>Polkadot and Kusama   Polkassembly - for current referenda, latest proposals, motions, treasury proposals, tips,   bounties, and more.</li> <li>Polkadot Daily Digest - News about what is   happening in the Polkadot ecosystem, published every weekday except holidays.</li> </ul>"},{"location":"maintain/archive/maintain-guides-democracy/#important-parameters","title":"Important Parameters","text":"<p>The important parameters to be aware of when voting using the Democracy module are as follows:</p> <p>Launch Period - How often new public referenda are launched.</p> <p>Voting Period - How often votes for referenda are tallied.</p> <p>Emergency Voting Period - The minimum voting period for a fast-tracked emergency referendum.</p> <p>Minimum Deposit - The minimum amount to be used as a deposit for a public referendum proposal.</p> <p>Enactment Period - The minimum period for locking funds and the period between a proposal being approved and enacted.</p> <p>Cooloff Period - The period in blocks where a proposal may not be re-submitted after being vetoed.</p>"},{"location":"maintain/archive/maintain-guides-democracy/#proposing-an-action","title":"Proposing an Action","text":"<p>Proposing an action to be taken requires you to bond some tokens. In order to ensure you have enough tokens to make the minimum deposit, you can check the parameter in the chain state. Navigate to Developer &gt; Chain State &gt; Constants &gt; selected constant query: democracy &gt; minimumDeposit: u128 and then click on the plus button. The bonded tokens will only be released once the proposal is tabled (that is, brought to a vote); there is no way for the user to \"revoke\" their proposal and get the bond back before it has become a referendum. Since it is essentially impossible to predict definitely when a proposal may become a referendum (if ever), this means that any tokens bonded will be locked for an indeterminate amount of time.</p> <p>Proposals cannot be revoked by the proposer, even if they never turn into a referendum</p> <p>It is important to realize that there is no guarantee that DOT you use for proposing or endorsing a proposal will be returned to that account in any given timeframe.</p> <p>On Polkadot Apps, you can navigate to the Governance -&gt; Democracy tab to make a new proposal. In order to submit a proposal, you will need to submit what's called the preimage hash. The preimage hash is simply the hash of the proposal to be enacted. The easiest way to get the preimage hash is by clicking on the \"Submit preimage\" button and configuring the action that you are proposing.</p> <p>The example below demonstrates the creation of a proposal on Kusama (the same procedure applies to Polkadot). If you wanted to propose that a remark \"Expect Chaos!\" is added, the preimage hash would be <code>0x8ac3f722caf7677254e25ca4ad77d533ca893c7d2ad4009e258d749f2004ef94</code>. You can copy this preimage hash and save it for the next step. There is no need to click Submit Preimage at this point, though you could. We'll go over that in the next section.</p> <p></p> <p>Now you will click on the \"Submit proposal\" button and enter the preimage hash in the input titled \"preimage hash\" and at least the minimum deposit into the \"locked balance\" field. Click on the \"Submit proposal\" button and confirm the transaction. You should now see your proposal appear in the \"proposals\" column on the page.</p> <p></p> <p>Now your proposal is visible to anyone who accesses the chain and others can endorse it or submit a preimage. However, it's hard to tell what exactly this proposal does since it shows the hash of the action. Other holders will not be able to make a judgement on whether they endorse it or not until someone submits the actual preimage for this proposal. In the next step, you will submit the preimage.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#submitting-a-preimage","title":"Submitting a Preimage","text":"<p>The act of making a proposal is split from submitting the preimage for the proposal since the storage cost of submitting a large preimage could be pretty expensive. Allowing for the preimage submission to come as a separate transaction means that another account could submit the preimage for you if you don't have the funds to do so. It also means that you don't have to pay so many funds right away as you can prove the preimage hash out-of-band.</p> <p>However, at some point before the proposal passes you will need to submit the preimage or else the proposal cannot be enacted. The guide will now show you how to do this.</p> <p>Click on the blue \"Submit preimage\" button and configure it to be the same as what you did before to acquire the preimage hash. This time, instead of copying the hash to another tab, you will follow through and click \"Submit preimage\" and confirm the transaction.</p> <p></p> <p>Once the transaction is included you should see the UI update with the information for your already submitted proposal.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#endorsing-a-proposal","title":"Endorsing a Proposal","text":"<p>Endorsing a proposal means that you are agreeing with the proposal and backing it with an equal amount of deposit as was originally locked. The bonded tokens will be released once the proposal is tabled (that is, brought to a vote), just like the original proposer's bond. By endorsing a proposal you will move it higher up the rank of proposals. The most endorsed proposal \u2014 in value, not the number of supporters \u2014 will be brought to a referendum every launch period.</p> <p>It is important to note that there is no way to stop or cancel endorsing a proposal once it has been done. Therefore, the DOT that was endorsed will be reserved until the proposal is tabled as a referendum. This is an indeterminate amount of time, since there is no guarantee that a proposal will become a referendum for a given period, as other proposals may be proposed and tabled before it.</p> <p>Note that it is possible for a single account to endorse a proposal multiple times. This is by design; it is the value, not the number of endorsements per se, that counts in terms of weighting. If there were a limit of one endorsement per account, it would be trivial for a user with, for example, 1000 DOT to create ten accounts with 100 DOT instead of a single account with 1000 DOT. Thus, no restrictions are made on the number of times a single account can endorse a proposal.</p> <p>To endorse a proposal, navigate to the proposal you want to endorse and click on the \"Endorse\" button.</p> <p></p> <p>You will be prompted with the full details of the proposal (if the preimage has been submitted!) and can then broadcast the transaction by clicking the blue \"Endorse\" button.</p> <p></p> <p>Once successful, you will see your endorsement appear in the dropdown in the proposal details.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#voting-on-a-proposal","title":"Voting on a Proposal","text":"<p>At the end of each launch period, the most endorsed proposal will move to a referendum. During this time you can cast a vote for or against the proposal. You may also lock up your tokens for a greater length of time to weigh your vote more strongly. During the time your tokens are locked, you are unable to transfer them, however they can still be used for further votes. Locks are layered on top of each other, so an eight-week lock does not become a 15-week lock if you vote again a week later, rather another eight-week lock is placed to extend the lock just one extra week.</p> <p>To vote on a referendum, navigate to the \"Democracy\" tab of Polkadot Apps. Any active referendum will show in the \"referenda\" column. Click the blue button \"Vote\" to cast a vote for the referendum.</p> <p>If you would like to cast your vote for the proposal select the \"Aye, I approve\" option. If you would like to cast your vote against the proposal in the referendum you will select \"Nay, I do not approve\" option.</p> <p>The endorsement option is to select your conviction for this vote. The longer you are willing to lock your tokens, the stronger your vote will be weighted. The timeline for the conviction starts after the voting period ends; tokens used for voting will always be locked until the end of the voting period, no matter what conviction you vote with. Unwillingness to lock your tokens means that your vote only counts for 10% of the tokens that you hold, while the maximum lock-up of 896 days means you can make your vote count for 600% of the tokens that you hold. It is possible to vote with tokens already locked by staking.</p> <p>When you are comfortable with the decision you have made, click the blue \"Vote\" button to submit your transaction and wait for it to be included in a block.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#unlocking-locked-tokens","title":"Unlocking Locked Tokens","text":"<p>The tokens that are locked in democracy are unlocked lazily. This means that you, the user, must explicitly call an unlock extrinsic to make your funds available again after the lock expires. Unbonding is another term you hear a lot in Polkadot, it means withdrawing your DOT that was used in staking. To know more about it, please see here.</p> <p>You can do this from the \"Accounts\" page in Polkadot-JS Apps, unless you use Ledger (see below). First, check that your account has a \"democracy\" lock by opening the details on your balance. In the example below the account has 150 KSM locked in democracy.</p> <p></p> <p>Now you can click the menu button (the three dots) and find the option that says \"Clear expired democracy locks\". After selecting this option you may confirm the transaction and your locks will be cleared when successful.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#with-a-ledger-hardware-wallet-or-unlocking-very-old-locks","title":"With a Ledger hardware wallet or Unlocking Very Old Locks","text":"<p>If you do not see an option to clear expired democracy votes, it may be that the lock is very old. Or, if you are using the Ledger hardware wallet, you will not be able to issue the batch Unlock action from the UI.</p> <p>Instead, you must clear the lock by directly issuing the correct extrinsics.</p> <p>Navigate to the Extrinsics page and submit the following extrinsic: <code>democracy.removeVote(index)</code> using the account that you voted with. For the index number (ReferendumIndex), enter the number of the referendum for which you voted (\"12\" in the image below).</p> <p>The number of the referendum for which you voted is visible in an explorer such as Subscan.</p> <p>You need to press the \"Submit Transaction\" button to submit the extrinsic.</p> <p></p> <p>Now submit the following extrinsic: `democracy.unlock(target), where the target is your account address.</p> <p></p> <p>If you return to the Accounts page, you should see that the democracy lock has been released.</p> <p>Note that this applies only to locked DOT that were used for voting on referenda. In order to unlock DOT locked by voting for members of the Polkadot Council, you need to go to the Council page, click \"Vote\", and then click on \"Unvote All\".</p>"},{"location":"maintain/archive/maintain-guides-democracy/#delegate-a-vote","title":"Delegate a Vote","text":"<p>If you are too busy to keep up and vote on upcoming referenda, there is an option to delegate your vote to another account whose opinion you trust. When you delegate to another account, that account gets the added voting power of your tokens along with the conviction that you set. The conviction for delegation works just like the conviction for regular voting, except your tokens may be locked longer than they would normally since locking resets when you undelegate your vote.</p> <p>The account that is being delegated to does not make any special action once the delegation is in place. They can continue to vote on referenda how they see fit. The difference is now when the Democracy system tallies votes, the delegated tokens now are added to whatever vote the delegatee has made.</p> <p>You can delegate your vote to another account and even attach a \"Conviction\" to the delegation. Navigate to the \"Accounts\" tab on Polkadot-JS UI and click on the three vertical dots and select \"Delegate democracy votes\" option for the account of your choice. Then you would be presented with a pop-up window which lets you enter the account details of the delegated account, delegated amount and conviction. You can enter the relevant details and click on the delegate button and then sign and submit the transaction.</p> <p></p> <p>Your delegation will count toward whatever account you delegated for votes on until you explicitly undelegate your vote.</p> <p>Query the chain state for an account's delegation preferences</p> <p>It is possible to query the delegation preferences of any actively delegating account on the network through <code>democracy.votingOf</code> extrinsic.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#undelegate-a-vote","title":"Undelegate a Vote","text":"<p>Caution</p> <p>If there is an existing lock due to a previous delegation change or undelegation, any new change or undelegation will restart the lock period for the larger DOT amount and the longest conviction period between the existing and the new lock.</p> <p>This will only matter to accounts with conviction, as the accounts with no conviction don't have any lock period.</p> <p>Examples:</p> <ol> <li> <p>Delegate 500 DOT with 1x conviction, then change delegation to 1000 DOT with 1x conviction, the   lock period will reset for 1000 DOT with 1x conviction.</p> </li> <li> <p>Delegate 500 DOT with 3x conviction, then change the delegation to 1000 DOT with 1x conviction,   the lock period will reset for 1000 DOT with 3x conviction.</p> </li> <li> <p>Delegate 500 DOT with 1x conviction, then change the delegation to 200 DOT with 1x conviction,   the lock period will reset for 500 DOT with 1x conviction.</p> </li> </ol> <p>To understand this in further detail checkout this stackexchange post.</p> <p>You may decide at some point in the future to remove your delegation to a target account. In this case, your tokens will be locked for the maximum amount of time in accordance with the conviction you set at the beginning of the delegation. For example, if you chose \"2x\" delegation for four weeks of lock-up time, your tokens will be locked for 4 weeks after sending the <code>undelegate</code> transaction. Once your vote has been undelegated, you are in control of making votes with it once again. You can start to vote directly, or choose a different account to act as your delegate.</p> <p>The <code>undelegate</code> transaction must be sent from the account that you wish to clear of its delegation. For example, if Alice has delegated her tokens to Bob, Alice would need to be the one to call the <code>undelegate</code> transaction to clear her delegation.</p> <p>The easiest way to do this is from the \"Accounts\" tab on Polkadot-JS UI where you can manage the delegation of your account.</p> <p></p> <p>When you click on \"manage delegation\", you would be presented with a pre-populated pop-up window with that account's delegation preferences. Here, you have an option to undelegate or save the modifications made to the account's delegation preferences.</p> <p></p>"},{"location":"maintain/archive/maintain-guides-democracy/#voting-with-a-governance-proxy","title":"Voting with a Governance Proxy","text":"<p>Making a vote on behalf of a stash requires a \"proxy\" transaction from the Proxy pallet. When you choose this transaction from the \"Extrinsics\" tab, it will let you select \"vote\" from the Democracy pallet, and you will specify the index of the referendum that is being voted, the judgement (i.e. \"Aye\" for approval or \"Nay\" for rejection), and the conviction, just like a normal vote.</p> <p>For more material on adding and removing Governance proxies, as well as other types, please see the Proxy page.</p>"},{"location":"maintain/archive/maintain-guides-how-to-join-council/","title":"Join the Council","text":"<p>     The content on this page is archived. For up-to-date information about governance, see the            Polkadot OpenGov page.      </p> \u2716 <p>The council is an elected body of on-chain accounts that are intended to represent the passive stakeholders of Polkadot and/or Kusama. The council has two major tasks in governance: proposing referenda and vetoing dangerous or malicious referenda. For more information on the council, see the governance page. This guide will walk you through entering your candidacy to the council.</p>"},{"location":"maintain/archive/maintain-guides-how-to-join-council/#submit-candidacy","title":"Submit Candidacy","text":"<p>Submitting your candidacy for the council requires a small bond of DOT / KSM. Unless your candidacy wins, the bond will be forfeited. You can receive your bond back if you manually renounce your candidacy before losing. Runners-up are selected after every round and are reserved members in case one of the winners gets forcefully removed.</p> <p>Note</p> <p>Currently the bond for submitting a council candidacy on Polkadot is 100 DOT, and 0.0033 KSM on Kusama.</p> <p>It is a good idea to announce your council intention before submitting your candidacy so that your supporters will know when they can start to vote for you. You can also vote for yourself in case no one else does.</p> <p>Go to Polkadot Apps Dashboard and navigate to the \"Council\" tab. Click the button on the right that says \"Submit Candidacy.\"</p> <p></p> <p>After making the transaction, you will see your account appear underneath the row \"Candidates.\"</p> <p></p> <p>It is a good idea now to lead by example and give yourself a vote.</p>"},{"location":"maintain/archive/maintain-guides-how-to-join-council/#voting-on-candidates","title":"Voting on Candidates","text":"<p>Next to the button to submit candidacy is another button titled \"Vote.\" You will click this button to make a vote for yourself (optional).</p> <p></p> <p>The council uses Phragm\u00e9n approval voting, which is also used in the validator elections. This means that you can choose up to 16 distinct candidates to vote for and your stake will equalize between them. For this guide, choose to approve your own candidacy by clicking on the switch next to your account and changing it to say \"Aye.\"</p> <p></p>"},{"location":"maintain/archive/maintain-guides-how-to-join-council/#winning","title":"Winning","text":"<p>If you are one of the lucky ones to win a council election you will see your account move underneath the row \"Members\".</p> <p></p> <p>Now you are able to participate on the council by making motions or voting proposals. To join in on the active discussions, join the Polkadot Direction channel.</p>"},{"location":"maintain/archive/maintain-guides-how-to-vote-councillor/","title":"Voting for Councillors","text":"<p>     The content on this page is archived. For up-to-date information about governance, see the            Polkadot OpenGov page.      </p> \u2716 <p>The council is an elected body of on-chain accounts that are intended to represent the passive stakeholders of Polkadot and/or Kusama. The council has two major tasks in governance: proposing referenda and vetoing dangerous or malicious referenda. For more information on the council, see the governance page. This guide will walk you through governance page. This guide will walk you through voting for councillors in the elections.</p>"},{"location":"maintain/archive/maintain-guides-how-to-vote-councillor/#voting-for-councillors","title":"Voting for Councillors","text":"<p>Voting for councillors requires you to reserve 20.064 DOT (0.067 KSM on Kusama) as a base amount and an amount of 0.032 DOT (0.0001 KSM on Kusama) per vote. You can then bond whatever amount you wish to put behind your vote. See the democracy guide for more information.</p> <p>Warning</p> <p>If your balance is vesting, you cannot use unvested tokens for this lock. You will have to wait until you have at least that many free tokens to vote.</p> <p>Like the validator elections, you can approve up to 16 different councillors and your vote will be equalized among the chosen group. Unlike validator elections, there is no unbonding period for your reserved tokens. Once you remove your vote, your tokens will be liquid again.</p> <p>Warning</p> <p>It is your responsibility not to put your entire balance into the reserved value when you make a vote for councillors. It's best to keep at least enough DOT/KSM to pay for transaction fees.</p> <p>Go to the Polkadot-JS Apps Dashboard and click on the \"Council\" tab. On the right side of the window there are two blue buttons, click on the one that says \"Vote.\"</p> <p>Since the council uses approval voting, when you vote you signal which of the candidates you approve of and your voted tokens will be equalized among the selected candidates. Select up to 16 council candidates by moving the slider to \"Aye\" for each one that you want to be elected. When you've made the proper configuration submit your transaction.</p> <p>You should see your vote appear in the interface immediately after your transaction is included.</p>"},{"location":"maintain/archive/maintain-guides-how-to-vote-councillor/#removing-your-vote","title":"Removing your Vote","text":"<p>In order to get your reserved tokens back, you will need to remove your vote. Only remove your vote when you're done participating in elections and you no longer want your reserved tokens to count for the councillors that you approve.</p> <p>Go to the \"Governance\" &gt; \"Council\" tab on the Polkadot-JS Apps Dashboard.</p> <p>Under the \"Council overview\" tab, click on \"Vote\".</p> <p></p> <p>Issue the \"Unvote all\" option.</p> <p>When the transaction is included in a block you should have your reserved tokens made liquid again and your vote will no longer be counting for any councillors in the elections starting in the next term.</p>"},{"location":"maintain/collator/","title":"Collator","text":"<ul> <li>Async Backing - Guide on Async Backing.</li> </ul>"},{"location":"maintain/kusama/maintain-guides-how-to-validate-kusama/","title":"Run a Validator (Kusama)","text":""},{"location":"maintain/kusama/maintain-guides-how-to-validate-kusama/#preliminaries","title":"Preliminaries","text":"<p>Running a validator on a live network is a lot of responsibility! You will be accountable for not only your own stake, but also the stake of your current nominators. If you make a mistake and get slashed, your tokens and your reputation will be at risk. However, running a validator can also be very rewarding, knowing that you contribute to the security of a decentralized network while growing your stash.</p> <p>Warning</p> <p>It is highly recommended that you have significant system administration experience before attempting to run your own validator.</p> <p>You must be able to handle technical issues and anomalies with your node which you must be able to tackle yourself. Being a validator involves more than just executing the binary file.</p> <p>Since security is so important to running a successful validator, you should take a look at the secure validator information to make sure you understand the factors to consider when constructing your infrastructure. As you progress in your journey as a validator, you will likely want to use this repository as a starting point for your own modifications and customizations.</p> <p>If you need help, please reach out on the Kusama Validator Lounge on Element. The team and other validators are there to help answer questions and provide tips from experience.</p>"},{"location":"maintain/kusama/maintain-guides-how-to-validate-kusama/#how-many-ksm-do-i-need-to-become-an-active-validator","title":"How many KSM do I need to become an active Validator?","text":"<p>Controller accounts are deprecated</p> <p>Controller accounts are deprecated. For more information, see this discussion.</p> <p>You can have a rough estimate on that by using the methods listed here. To be elected into the set, you need a minimum stake behind your validator. This stake can come from yourself or from nominators. This means that as a minimum, you will need enough KSM to set up Stash and staking proxy accounts with the existential deposit, plus a little extra for transaction fees. The rest can come from nominators. To understand how validators are elected, check the NPoS Election algorithms page.</p> <p>Join the Decentralized Nodes program</p> <p>The Decentralized Nodes program is an initiative by Web3 Foundation and Parity Technologies to use the funds held by both organizations to nominate validators in the community.</p> <p>Warning: Any KSM that you stake for your validator is liable to be slashed, meaning that an insecure or improper setup may result in loss of KSM tokens! If you are not confident in your ability to run a validator node, it is recommended to nominate your KSM to a trusted validator node instead.</p>"},{"location":"maintain/kusama/maintain-guides-how-to-validate-kusama/#validator-rewards","title":"Validator Rewards","text":"<p>On Kusama, one day is approximately four eras whereas on Polkadot, one era is approximately a day. In each era, the validators elected to the active set earn era points which correspond to the actual rewards earned that are distributed proportionally to the nominators after deducting the validator commission. The minimum validator commission can be set through on-chain governance. For more information rewards and payouts, check the validator payout document.</p>"},{"location":"maintain/kusama/maintain-guides-how-to-validate-kusama/#run-a-kusama-validator","title":"Run a Kusama Validator","text":"<p>Running a validator on the Kusama network is identical to running a Polkadot validator. Check out the Polkadot guide on how to setup a validator.</p> <p>Make sure to adjust the Polkadot guide to run a Kusama network validator (the instructions will also be available in the Polkadot Validator guide):</p> <ul> <li>When starting the node pass <code>--chain=kusama</code> CLI flag</li> </ul>"},{"location":"maintain/kusama/maintain-guides-society-kusama/","title":"Kappa Sigma Mu","text":"<p>Kappa Sigma Mu is a membership club using the Substrate Society pallet. It is an economic game to incentivize users to join a society that coordinates around whatever the rules are decided to be. The members of the society are incentivized to participate in the society via the rewards paid by the treasury. Currently, there is only one society on Kusama but it is possible to have multiple societies in the future through a runtime upgrade.</p> <p> </p> <p>Before joining the society, let's take a brief look at the Society UI on Polkadot-JS apps and read through all the rules to become a member.</p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#ui-overview","title":"UI Overview","text":"<ul> <li><code>Members</code>: The number of members in the society. Currently, the maximum number of members is set   to <code>150</code>. It can be changed by using governance to increase the number.</li> <li><code>Rotation</code>: The time period for membership rotations.</li> <li><code>Challenge</code>: The time period to randomly select one of the members to defend his membership in the   society.</li> <li><code>Pot</code>: Resource balance that is used to support members of the society.</li> <li><code>Bids</code>: A list of users who submitted a bid to join the society.</li> </ul>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#user-types","title":"User Types","text":"<p>Below are the various types of users at different stages.</p> <ul> <li><code>Bidder</code> - A token holder who intends to join the society by placing a bid.</li> <li><code>Candidate</code> - The selected bidders that will be voted on by members of the society.</li> <li><code>Suspended Candidate</code> - The candidates that failed to join the society.</li> <li><code>Member</code> - Member of the society.</li> <li><code>Suspender Member</code> - A member of the society who has accumulated too many strikes or failed their   membership challenge.</li> <li><code>Head</code> - One winning candidate will be randomly chosen as head of the members, weighted by the   number of approvals the winning candidates accumulated.</li> <li><code>Defender</code> - In every challenge period, one of the members will be randomly selected to defend   their membership in the society. The rules for defending the membership are documented   in the rules.</li> </ul>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#procedure","title":"Procedure","text":"<p>Remember to take a look at the rules first. And since those rules are not enforced entirely on-chain, it is recommended to join the Kappa Sigma Mu Lounge to ask any questions if anything is unclear.</p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#1-bid-phase","title":"1. Bid Phase","text":"<p>To submit a bid, click the Submit Bid button on the Society page.</p> <p>Anyone can submit a bid to join the society by reserving a deposit or finding an existing member to create a bid on their behalf by vouching for them. At every rotation period, as many bids as the society pot can support will be selected. The selected bids will be moved to the candidate phase, whereas bids that were not selected will stay in the bidder pool until they are selected or a user chooses to unbid.</p> <p>Anyone who wants to join the society is required to deposit 1.6 KSM for reserve on Kusama and declare the bid amount (1 KSM in this case) that they will receive for joining the society.</p> <p></p> <p>Once you have submitted the transaction, your bid will be shown on the Society page under the bids section. You can cancel the bidding if you changed your mind about joining the society by calling <code>unbid</code> on the same page.</p> <p>You can find an existing member to place a bid on your behalf if you do not have KSM and you are willing to give them a tip. An existing member can submit a <code>vouch</code> transaction through the Extrinsics page.</p> <p>vouch(who,value,tip)</p> <ul> <li>who: The user you are vouching for</li> <li>value: The value that the user would like to get when joining the society</li> <li>tip: Fees you get</li> </ul> <p>The final value that the candidate will get = (value - tip)</p> <p></p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#2-candidate-phase","title":"2. Candidate Phase","text":"<p>Bids selected in this phase will be voted on by the existing members to decide whether or not you will be approved to join the society. Members will vote for all the candidates and the final outcome will be randomly selected by one of the votes. Let's take a look the example shown below:</p> <p>Note</p> <p>If the randomly selected member does not vote, it will be treated as a rejection. For each rotation period, the maximum number of members that can be accepted is set as 10.</p> <p>A - Accept, R - Reject, S - Skeptic</p> Member 1 2 3 4 5 Vote A A A R S Selected X <p>In this example, a candidate will be approved to join the society since member 3 was selected as a final voting outcome. A number of members will also be randomly chosen as \"skeptics\" to vote for the candidates during the rotation period.</p> <p>Since member 5 was chosen as a skeptic, they are required to participate in the voting process. If they do not participate in voting, they will be punished with one strike per missing vote. If one accumulates too many strikes, one's membership is suspended which means they may need to re-apply and their unclaimed payouts will be slashed. Moreover, each member who voted opposite to the randomly selected vote will have their unclaimed payouts slashed and strikes increased. In this case, member 4 will be punished.</p> <p>Info</p> <p>The maximum number of strikes you can have is on Kusama is 10</p> <p>The slashed funds (2 KSM currently) will be given to a random member who voted the same as the selected vote as a reward for participating in the vote. The reward is escrowed for some period of time - see below.</p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#lock-up-time","title":"Lock-up Time","text":"<p>It would take the number of members of the society as the variable to determine how many blocks you have to wait in order to get the payout. The longest lockup time is close to 3 years. The formula is defined in the society pallet if you would like to have a look.</p> <p>Example:</p> <pre><code>Let's assume we have 5 members in the society\n\nlock_duration = 100 - 50_000 / (5 + 500)\nlock_duration * MAX_LOCK_DURATION_IN_BLOCKS\n\nResult = 1% * 15_552_000 ~ 11 days\n</code></pre> <p>Based on the above calculation, it is required to wait close to 11 days to get the slashed funds.</p> <p>If the candidate wins the vote, they receive their bid reward as a future payout. If the bid was placed by a voucher, they will get back the reward that was set during vouching with the remainder given to the candidate - both escrowed for some time.</p> <p>If the candidate loses the vote, they are suspended and it is up to the founder of the society (the <code>Suspension Judgement Origin</code>) to determine if the candidate should go through the bidding process again, should be accepted into the membership society, or rejected and their deposit slashed.</p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#3-member-phase","title":"3. Member Phase","text":"<p>Once you become a member of the society, you will get back the deposit that you have reserved during the bidding. A few things you need to be aware of. First, you should vote on candidates who applied for the membership in every rotation period.</p> <p>Second, you will need to claim your payout manually by calling <code>payout</code> after the lockup time. It is the same as the above mentioned lockup formula.</p> <p></p> <p>Third, there will be a membership challenge every seven days on Kusama. So one of the members will be randomly selected as a defender. Then, other members can vote whether this defender should stay in the society or not. A simple majority wins the vote. You can take a look here and search for \"Existing Members (Challenges)\". Besides that, you can earn extra KSM by helping a user apply for the membership and requesting a tip. This is useful when a user does not have enough balance to reserve a deposit. The tip will be given when a user successfully joins the society.</p> <p>Info</p> <p>Each member can only vouch for one user at a time. A member is not required to reserve the deposit when vouching for a user.</p> <p>If a member accumulates too many strikes or fails their membership challenge, they will become suspended. While a member is suspended, they are unable to claim matured payouts. It is up to the suspension judgment origin to determine if the member should re-enter society or be removed from society with all their future payouts slashed.</p>"},{"location":"maintain/kusama/maintain-guides-society-kusama/#useful-links","title":"Useful links","text":"<p>Convention of Approval of Membership - Rules about joining the Kusama society</p> <p>The rules are encoded on-chain in UTF-8 format. This is displayed in most block explorers as a hexadecimal string. In order to see the rules in human-readable format, you can convert it. In the extrinsic's parameters go to Element 1 (\"proposal\") -&gt; \"value\" -&gt; \"params\" -&gt; Element 2 (\"rules\") and copy the value corresponding to the key \"value\". You can use a hex-to-UTF8 converter to then display the text. Note that the text is formatted with Markdown.</p>"},{"location":"maintain/node/","title":"Nodes and Dapps","text":"<ul> <li>Endpoints - Information on endpoints.</li> <li>Sync - Guide on syncing nodes.</li> <li>Bootnode - Setting up a bootnode.</li> <li>RPC - Remote Procedure Call details.</li> <li>WSS - WebSocket Secure information.</li> <li>Networks - Network configurations.</li> <li>Errors - Common errors and solutions.</li> </ul>"},{"location":"maintain/validator/","title":"Validator","text":"<ul> <li>How to Validate Polkadot - Guide on how to validate Polkadot.</li> <li>Validator Payout - Information on validator payouts.</li> <li>How to Systemd - Guide on using systemd.</li> <li>Secure Validator - Tips for securing your validator.</li> <li>How to Upgrade - Instructions on upgrading.</li> <li>How to Monitor Your Node - Guide on monitoring your node.</li> <li>How to Chill - How to chill your validator.</li> <li>How to Stop Validating - Steps to stop validating.</li> <li>Community Validator Guide - Community guide for validators.</li> </ul>"}]}